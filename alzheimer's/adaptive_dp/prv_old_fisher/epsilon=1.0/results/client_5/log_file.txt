Initial Train Dataset Size: 1088 Sample rate: 0.17
Global Epoch (Round): 1, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0967, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0612, Accuracy: 0.5160, AUC: 0.7097
Global Epoch (Round): 2, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0687, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1627, Accuracy: 0.5066, AUC: 0.7280
Global Epoch (Round): 3, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.1196, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1313, Accuracy: 0.5207, AUC: 0.7378
Global Epoch (Round): 4, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0824, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1363, Accuracy: 0.5324, AUC: 0.7445
Global Epoch (Round): 5, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0444, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1077, Accuracy: 0.5340, AUC: 0.7500
Global Epoch (Round): 6, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0643, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1004, Accuracy: 0.5403, AUC: 0.7542
Global Epoch (Round): 7, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0706, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0959, Accuracy: 0.5434, AUC: 0.7582
Global Epoch (Round): 8, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0011, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1248, Accuracy: 0.5356, AUC: 0.7610
Global Epoch (Round): 9, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0721, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1048, Accuracy: 0.5504, AUC: 0.7636
Global Epoch (Round): 10, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0286, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1182, Accuracy: 0.5434, AUC: 0.7661
Global Epoch (Round): 11, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0560, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0493, Accuracy: 0.5598, AUC: 0.7702
Global Epoch (Round): 12, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0130, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1034, Accuracy: 0.5512, AUC: 0.7712
Global Epoch (Round): 13, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0532, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0756, Accuracy: 0.5590, AUC: 0.7733
Global Epoch (Round): 14, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0339, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0729, Accuracy: 0.5622, AUC: 0.7739
Global Epoch (Round): 15, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0062, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0868, Accuracy: 0.5614, AUC: 0.7755
Global Epoch (Round): 16, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0744, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0736, Accuracy: 0.5614, AUC: 0.7770
Global Epoch (Round): 17, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9956, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1040, Accuracy: 0.5582, AUC: 0.7782
Global Epoch (Round): 18, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0487, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0825, Accuracy: 0.5606, AUC: 0.7793
Global Epoch (Round): 19, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0463, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0958, Accuracy: 0.5590, AUC: 0.7793
Global Epoch (Round): 20, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9811, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1431, Accuracy: 0.5536, AUC: 0.7799
Global Epoch (Round): 21, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0569, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0871, Accuracy: 0.5668, AUC: 0.7825
Global Epoch (Round): 22, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9669, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0711, Accuracy: 0.5700, AUC: 0.7830
Global Epoch (Round): 23, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9870, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0961, Accuracy: 0.5645, AUC: 0.7833
Global Epoch (Round): 24, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0318, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0808, Accuracy: 0.5715, AUC: 0.7841
Global Epoch (Round): 25, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9773, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0706, Accuracy: 0.5715, AUC: 0.7857
Global Epoch (Round): 26, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9941, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.1242, Accuracy: 0.5614, AUC: 0.7856
Global Epoch (Round): 27, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0309, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0718, Accuracy: 0.5731, AUC: 0.7887
Global Epoch (Round): 28, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0195, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0639, Accuracy: 0.5794, AUC: 0.7897
Global Epoch (Round): 29, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9798, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0340, Accuracy: 0.5801, AUC: 0.7897
Global Epoch (Round): 30, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9554, Epsilon: 1.00, Dynamic Noise Multiplier: 0.11
Loss: 1.0625, Accuracy: 0.5809, AUC: 0.7912
