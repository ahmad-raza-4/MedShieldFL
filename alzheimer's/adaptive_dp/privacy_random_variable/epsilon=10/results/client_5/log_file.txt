Initial Train Dataset Size: 1088 Sample rate: 0.17
Global Epoch (Round): 1, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0852, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0711, Accuracy: 0.5215, AUC: 0.7230
Global Epoch (Round): 2, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0470, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.1518, Accuracy: 0.5176, AUC: 0.7423
Global Epoch (Round): 3, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.1006, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.1502, Accuracy: 0.5301, AUC: 0.7524
Global Epoch (Round): 4, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0759, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.1004, Accuracy: 0.5379, AUC: 0.7621
Global Epoch (Round): 5, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0254, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0772, Accuracy: 0.5512, AUC: 0.7679
Global Epoch (Round): 6, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0532, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0890, Accuracy: 0.5575, AUC: 0.7722
Global Epoch (Round): 7, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0649, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0923, Accuracy: 0.5551, AUC: 0.7754
Global Epoch (Round): 8, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9861, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0884, Accuracy: 0.5551, AUC: 0.7783
Global Epoch (Round): 9, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0647, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0892, Accuracy: 0.5622, AUC: 0.7800
Global Epoch (Round): 10, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0215, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0884, Accuracy: 0.5543, AUC: 0.7832
Global Epoch (Round): 11, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0511, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0230, Accuracy: 0.5653, AUC: 0.7871
Global Epoch (Round): 12, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0046, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0652, Accuracy: 0.5700, AUC: 0.7887
Global Epoch (Round): 13, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0377, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0500, Accuracy: 0.5715, AUC: 0.7897
Global Epoch (Round): 14, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0165, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0476, Accuracy: 0.5700, AUC: 0.7898
Global Epoch (Round): 15, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9935, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0586, Accuracy: 0.5754, AUC: 0.7910
Global Epoch (Round): 16, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0543, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0523, Accuracy: 0.5801, AUC: 0.7925
Global Epoch (Round): 17, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9980, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0802, Accuracy: 0.5700, AUC: 0.7940
Global Epoch (Round): 18, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0414, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0391, Accuracy: 0.5809, AUC: 0.7956
Global Epoch (Round): 19, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0278, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0553, Accuracy: 0.5794, AUC: 0.7952
Global Epoch (Round): 20, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9548, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.1201, Accuracy: 0.5684, AUC: 0.7958
Global Epoch (Round): 21, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0302, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0540, Accuracy: 0.5794, AUC: 0.7991
Global Epoch (Round): 22, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9540, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0523, Accuracy: 0.5833, AUC: 0.7992
Global Epoch (Round): 23, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9728, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0575, Accuracy: 0.5817, AUC: 0.7998
Global Epoch (Round): 24, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0150, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0564, Accuracy: 0.5872, AUC: 0.8003
Global Epoch (Round): 25, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9635, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0124, Accuracy: 0.5848, AUC: 0.8034
Global Epoch (Round): 26, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9714, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.1022, Accuracy: 0.5747, AUC: 0.8030
Global Epoch (Round): 27, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0212, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0423, Accuracy: 0.5911, AUC: 0.8055
Global Epoch (Round): 28, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0054, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0229, Accuracy: 0.5880, AUC: 0.8064
Global Epoch (Round): 29, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9581, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0137, Accuracy: 0.5919, AUC: 0.8057
Global Epoch (Round): 30, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9376, Epsilon: 10.00, Dynamic Noise Multiplier: 0.03
Loss: 1.0215, Accuracy: 0.5934, AUC: 0.8078
