nohup: ignoring input
02/04/2025 10:09:49:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/04/2025 10:09:49:DEBUG:ChannelConnectivity.IDLE
02/04/2025 10:09:49:DEBUG:ChannelConnectivity.CONNECTING
02/04/2025 10:09:49:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
02/04/2025 10:09:49:INFO:
[92mINFO [0m:      Received: get_parameters message 03a3c83d-487e-48b7-af79-68d3025bcbbe
02/04/2025 10:09:49:INFO:Received: get_parameters message 03a3c83d-487e-48b7-af79-68d3025bcbbe
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738692589.266909 3949431 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      Sent reply
02/04/2025 10:09:53:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:10:02:INFO:
[92mINFO [0m:      Received: train message 5d766c1d-fc2b-4eb0-b91a-0cd26055a688
02/04/2025 10:10:02:INFO:Received: train message 5d766c1d-fc2b-4eb0-b91a-0cd26055a688
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:11:01:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:11:14:INFO:
[92mINFO [0m:      Received: evaluate message 524dde8b-1f08-4ae0-9653-3b4068345105
02/04/2025 10:11:14:INFO:Received: evaluate message 524dde8b-1f08-4ae0-9653-3b4068345105
[92mINFO [0m:      Sent reply
02/04/2025 10:11:16:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:11:23:INFO:
[92mINFO [0m:      Received: train message 72ebd24f-6420-4d3e-9b07-16e79ce17d33
02/04/2025 10:11:23:INFO:Received: train message 72ebd24f-6420-4d3e-9b07-16e79ce17d33
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:12:24:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:12:37:INFO:
[92mINFO [0m:      Received: evaluate message d1506834-aa84-4c23-b639-497b312e1bf2
02/04/2025 10:12:37:INFO:Received: evaluate message d1506834-aa84-4c23-b639-497b312e1bf2
[92mINFO [0m:      Sent reply
02/04/2025 10:12:39:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:12:46:INFO:
[92mINFO [0m:      Received: train message 857f23fc-31e7-40a8-a738-974eba869380
02/04/2025 10:12:46:INFO:Received: train message 857f23fc-31e7-40a8-a738-974eba869380
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:13:48:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:14:00:INFO:
[92mINFO [0m:      Received: evaluate message 6da00958-7b53-4178-a7ca-04782e7ef5e8
02/04/2025 10:14:00:INFO:Received: evaluate message 6da00958-7b53-4178-a7ca-04782e7ef5e8
[92mINFO [0m:      Sent reply
02/04/2025 10:14:02:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:14:08:INFO:
[92mINFO [0m:      Received: train message ad6680b1-ea0e-4102-9ea2-8e001450cf67
02/04/2025 10:14:08:INFO:Received: train message ad6680b1-ea0e-4102-9ea2-8e001450cf67
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:15:07:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:15:20:INFO:
[92mINFO [0m:      Received: evaluate message 8b3531e7-2420-46b5-b130-12b41fc9a76b
02/04/2025 10:15:20:INFO:Received: evaluate message 8b3531e7-2420-46b5-b130-12b41fc9a76b
[92mINFO [0m:      Sent reply
02/04/2025 10:15:22:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:15:29:INFO:
[92mINFO [0m:      Received: train message 978988c0-3bd6-4f8d-8473-94a6998e1469
02/04/2025 10:15:29:INFO:Received: train message 978988c0-3bd6-4f8d-8473-94a6998e1469
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:16:31:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:16:42:INFO:
[92mINFO [0m:      Received: evaluate message 3c81462c-78e8-4cdc-b484-7515cfc1dcf0
02/04/2025 10:16:42:INFO:Received: evaluate message 3c81462c-78e8-4cdc-b484-7515cfc1dcf0
[92mINFO [0m:      Sent reply
02/04/2025 10:16:44:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:16:50:INFO:
[92mINFO [0m:      Received: train message ab158ba7-8877-42ef-b3c9-b08e34afbd4c
02/04/2025 10:16:50:INFO:Received: train message ab158ba7-8877-42ef-b3c9-b08e34afbd4c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:17:50:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:18:02:INFO:
[92mINFO [0m:      Received: evaluate message 8b41258f-05e6-4b5c-833a-05bf521a025e
02/04/2025 10:18:02:INFO:Received: evaluate message 8b41258f-05e6-4b5c-833a-05bf521a025e
[92mINFO [0m:      Sent reply
02/04/2025 10:18:04:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:18:10:INFO:
[92mINFO [0m:      Received: train message a4cdea60-90e9-461b-9d3e-f23dad8fdab3
02/04/2025 10:18:10:INFO:Received: train message a4cdea60-90e9-461b-9d3e-f23dad8fdab3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:19:11:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:19:22:INFO:
[92mINFO [0m:      Received: evaluate message 5228e9c6-d3d4-45cf-92f5-7839c8986788
02/04/2025 10:19:22:INFO:Received: evaluate message 5228e9c6-d3d4-45cf-92f5-7839c8986788
[92mINFO [0m:      Sent reply
02/04/2025 10:19:24:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:19:30:INFO:
[92mINFO [0m:      Received: train message 3d804688-d2d3-484a-9819-966b8b07ab5a
02/04/2025 10:19:30:INFO:Received: train message 3d804688-d2d3-484a-9819-966b8b07ab5a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:20:29:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:20:41:INFO:
[92mINFO [0m:      Received: evaluate message 1a5651c2-1cc3-4ba2-83c2-146609553e2c
02/04/2025 10:20:41:INFO:Received: evaluate message 1a5651c2-1cc3-4ba2-83c2-146609553e2c
[92mINFO [0m:      Sent reply
02/04/2025 10:20:43:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:20:49:INFO:
[92mINFO [0m:      Received: train message 61a58413-42da-4c49-9e31-32caa752a6ae
02/04/2025 10:20:49:INFO:Received: train message 61a58413-42da-4c49-9e31-32caa752a6ae
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:21:49:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:22:01:INFO:
[92mINFO [0m:      Received: evaluate message a0131a83-3d3d-427e-88d1-8ea428762d4b
02/04/2025 10:22:01:INFO:Received: evaluate message a0131a83-3d3d-427e-88d1-8ea428762d4b
[92mINFO [0m:      Sent reply
02/04/2025 10:22:03:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:22:09:INFO:
[92mINFO [0m:      Received: train message ce774ecc-d697-4f90-8444-ea7a26a314bc
02/04/2025 10:22:09:INFO:Received: train message ce774ecc-d697-4f90-8444-ea7a26a314bc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:23:10:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:23:23:INFO:
[92mINFO [0m:      Received: evaluate message 58d0a845-010e-4878-97f0-47a09f558909
02/04/2025 10:23:23:INFO:Received: evaluate message 58d0a845-010e-4878-97f0-47a09f558909
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 1.0, target_epsilon: 1.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0048

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769], 'accuracy': [0.3502736512900704], 'auc': [0.5120144452028692]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0055

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323], 'accuracy': [0.3502736512900704, 0.5144644253322909], 'auc': [0.5120144452028692, 0.7338228881634812]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0055

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0042

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0110

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0090

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0051

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0110

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0122

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0126

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/04/2025 10:23:25:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:23:32:INFO:
[92mINFO [0m:      Received: train message d7c78496-640b-452f-9906-84d19a3eeb8e
02/04/2025 10:23:32:INFO:Received: train message d7c78496-640b-452f-9906-84d19a3eeb8e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:24:32:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:24:43:INFO:
[92mINFO [0m:      Received: evaluate message 19b05dbf-6578-4e96-a2ee-3046c3fe4a37
02/04/2025 10:24:43:INFO:Received: evaluate message 19b05dbf-6578-4e96-a2ee-3046c3fe4a37
[92mINFO [0m:      Sent reply
02/04/2025 10:24:45:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:24:51:INFO:
[92mINFO [0m:      Received: train message 4ad14f75-6d66-47bf-9f35-4276b6099cf0
02/04/2025 10:24:51:INFO:Received: train message 4ad14f75-6d66-47bf-9f35-4276b6099cf0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:25:50:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:26:03:INFO:
[92mINFO [0m:      Received: evaluate message 325fcae7-e5f1-404e-8089-08850f51f2da
02/04/2025 10:26:03:INFO:Received: evaluate message 325fcae7-e5f1-404e-8089-08850f51f2da
[92mINFO [0m:      Sent reply
02/04/2025 10:26:05:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:26:11:INFO:
[92mINFO [0m:      Received: train message 7920efcd-9250-411d-9d1e-af5143dc37d0
02/04/2025 10:26:11:INFO:Received: train message 7920efcd-9250-411d-9d1e-af5143dc37d0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:27:04:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:27:15:INFO:
[92mINFO [0m:      Received: evaluate message 39c53f77-f8e1-42e9-a5e5-39768cd54509
02/04/2025 10:27:15:INFO:Received: evaluate message 39c53f77-f8e1-42e9-a5e5-39768cd54509
[92mINFO [0m:      Sent reply
02/04/2025 10:27:17:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:27:23:INFO:
[92mINFO [0m:      Received: train message 119e8e69-636e-44c4-ae5a-cec3405255b6
02/04/2025 10:27:23:INFO:Received: train message 119e8e69-636e-44c4-ae5a-cec3405255b6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:28:25:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:28:36:INFO:
[92mINFO [0m:      Received: evaluate message 4ce3a976-6ef6-4163-a8bf-62b4a939f55e
02/04/2025 10:28:36:INFO:Received: evaluate message 4ce3a976-6ef6-4163-a8bf-62b4a939f55e
[92mINFO [0m:      Sent reply
02/04/2025 10:28:38:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:28:44:INFO:
[92mINFO [0m:      Received: train message e61a5d8e-0532-43c9-af2a-b671352e5418
02/04/2025 10:28:44:INFO:Received: train message e61a5d8e-0532-43c9-af2a-b671352e5418
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:29:45:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:29:55:INFO:
[92mINFO [0m:      Received: evaluate message 430be7d1-8e98-42d5-949c-860f90e877b0
02/04/2025 10:29:55:INFO:Received: evaluate message 430be7d1-8e98-42d5-949c-860f90e877b0
[92mINFO [0m:      Sent reply
02/04/2025 10:29:57:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:30:03:INFO:
[92mINFO [0m:      Received: train message 0e254508-0b35-4fed-a21a-f25508ee26a5
02/04/2025 10:30:03:INFO:Received: train message 0e254508-0b35-4fed-a21a-f25508ee26a5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:31:02:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:31:14:INFO:
[92mINFO [0m:      Received: evaluate message 1cd0e0e6-6d9f-42a8-937b-9cf47e9614fb
02/04/2025 10:31:14:INFO:Received: evaluate message 1cd0e0e6-6d9f-42a8-937b-9cf47e9614fb

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0170

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 12
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0223

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0210

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0444

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 15
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0330

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0500

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/04/2025 10:31:16:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:31:22:INFO:
[92mINFO [0m:      Received: train message 0248f9bd-716b-4c99-aacd-509009437736
02/04/2025 10:31:22:INFO:Received: train message 0248f9bd-716b-4c99-aacd-509009437736
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:32:25:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:32:35:INFO:
[92mINFO [0m:      Received: evaluate message 790e4e9c-9e53-4052-bc1c-d8ed64d1911c
02/04/2025 10:32:35:INFO:Received: evaluate message 790e4e9c-9e53-4052-bc1c-d8ed64d1911c
[92mINFO [0m:      Sent reply
02/04/2025 10:32:38:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:32:43:INFO:
[92mINFO [0m:      Received: train message 94935d9f-347f-40c2-ad49-35dc38f337e0
02/04/2025 10:32:43:INFO:Received: train message 94935d9f-347f-40c2-ad49-35dc38f337e0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:33:41:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:33:52:INFO:
[92mINFO [0m:      Received: evaluate message cf37c697-3b51-4794-ab7b-7cfa776ebaf7
02/04/2025 10:33:52:INFO:Received: evaluate message cf37c697-3b51-4794-ab7b-7cfa776ebaf7
[92mINFO [0m:      Sent reply
02/04/2025 10:33:54:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:34:00:INFO:
[92mINFO [0m:      Received: train message 3efbb275-371b-4c60-acf3-384caf7e3e79
02/04/2025 10:34:00:INFO:Received: train message 3efbb275-371b-4c60-acf3-384caf7e3e79
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:35:00:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:35:12:INFO:
[92mINFO [0m:      Received: evaluate message 20012b56-668d-4610-98f4-f8e7f383eff3
02/04/2025 10:35:12:INFO:Received: evaluate message 20012b56-668d-4610-98f4-f8e7f383eff3
[92mINFO [0m:      Sent reply
02/04/2025 10:35:14:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:35:20:INFO:
[92mINFO [0m:      Received: train message 3bde8954-699b-44bf-9453-b59e2f2af0b1
02/04/2025 10:35:20:INFO:Received: train message 3bde8954-699b-44bf-9453-b59e2f2af0b1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:36:17:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:36:30:INFO:
[92mINFO [0m:      Received: evaluate message db0eae2e-3afc-4505-9117-2057b8e15f70
02/04/2025 10:36:30:INFO:Received: evaluate message db0eae2e-3afc-4505-9117-2057b8e15f70
[92mINFO [0m:      Sent reply
02/04/2025 10:36:33:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:36:39:INFO:
[92mINFO [0m:      Received: train message f8174ce7-c512-473d-9dbd-621ccf6c2d5a
02/04/2025 10:36:39:INFO:Received: train message f8174ce7-c512-473d-9dbd-621ccf6c2d5a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:37:35:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:37:47:INFO:
[92mINFO [0m:      Received: evaluate message e651c34f-d819-4eb2-9788-d095bf6b70ef
02/04/2025 10:37:47:INFO:Received: evaluate message e651c34f-d819-4eb2-9788-d095bf6b70ef

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0319

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0286

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.1280

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0520

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0663

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/04/2025 10:37:49:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:37:55:INFO:
[92mINFO [0m:      Received: train message f873a586-ca4f-4c02-a1e8-4a5a0fbb59fa
02/04/2025 10:37:55:INFO:Received: train message f873a586-ca4f-4c02-a1e8-4a5a0fbb59fa
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:38:53:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:39:05:INFO:
[92mINFO [0m:      Received: evaluate message 0e3cdce9-2f49-4de2-bdd9-b5d2d7614310
02/04/2025 10:39:05:INFO:Received: evaluate message 0e3cdce9-2f49-4de2-bdd9-b5d2d7614310
[92mINFO [0m:      Sent reply
02/04/2025 10:39:07:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:39:13:INFO:
[92mINFO [0m:      Received: train message e03e166e-79e5-4341-be83-ecd6edaf6487
02/04/2025 10:39:13:INFO:Received: train message e03e166e-79e5-4341-be83-ecd6edaf6487
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:40:10:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:40:22:INFO:
[92mINFO [0m:      Received: evaluate message 680b1768-6cbc-4319-8c1f-5f07b3393d6f
02/04/2025 10:40:22:INFO:Received: evaluate message 680b1768-6cbc-4319-8c1f-5f07b3393d6f
[92mINFO [0m:      Sent reply
02/04/2025 10:40:24:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:40:30:INFO:
[92mINFO [0m:      Received: train message c1ea5bb7-ec20-4784-ab11-4c93a8c6bf74
02/04/2025 10:40:30:INFO:Received: train message c1ea5bb7-ec20-4784-ab11-4c93a8c6bf74
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:41:28:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:41:40:INFO:
[92mINFO [0m:      Received: evaluate message 723beefc-6eb7-4571-b5ba-75847d017ea9
02/04/2025 10:41:40:INFO:Received: evaluate message 723beefc-6eb7-4571-b5ba-75847d017ea9
[92mINFO [0m:      Sent reply
02/04/2025 10:41:42:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:41:48:INFO:
[92mINFO [0m:      Received: train message 24adbbf4-f415-44aa-8e1f-323620ae76ff
02/04/2025 10:41:48:INFO:Received: train message 24adbbf4-f415-44aa-8e1f-323620ae76ff
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:42:45:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:42:57:INFO:
[92mINFO [0m:      Received: evaluate message 9a8b0744-6412-4de9-9778-44bc4e423073
02/04/2025 10:42:57:INFO:Received: evaluate message 9a8b0744-6412-4de9-9778-44bc4e423073

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0531

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994, 1.7470399529976803], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693, 0.7677873338545739], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259, 0.8670194031895609]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0203

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994, 1.7470399529976803, 2.1555100771787115], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693, 0.7677873338545739, 0.7771696637998436], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259, 0.8670194031895609, 0.8627624033955511]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0218

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994, 1.7470399529976803, 2.1555100771787115, 2.248170737855783], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693, 0.7677873338545739, 0.7771696637998436, 0.7763878029710711], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259, 0.8670194031895609, 0.8627624033955511, 0.8721863969453796]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0062

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/04/2025 10:42:59:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:43:05:INFO:
[92mINFO [0m:      Received: train message fc78eb80-eccc-4c32-8bd3-666e4b4650ff
02/04/2025 10:43:05:INFO:Received: train message fc78eb80-eccc-4c32-8bd3-666e4b4650ff
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:44:02:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:44:14:INFO:
[92mINFO [0m:      Received: evaluate message 49a7efd2-6b75-4639-9bbd-8d8edecc5aaf
02/04/2025 10:44:14:INFO:Received: evaluate message 49a7efd2-6b75-4639-9bbd-8d8edecc5aaf
[92mINFO [0m:      Sent reply
02/04/2025 10:44:16:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:44:22:INFO:
[92mINFO [0m:      Received: train message 1bfa1c7f-5d73-48e2-88cd-9d74afdbd470
02/04/2025 10:44:22:INFO:Received: train message 1bfa1c7f-5d73-48e2-88cd-9d74afdbd470
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:45:20:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:45:32:INFO:
[92mINFO [0m:      Received: evaluate message d263d33a-5e18-4cdb-a127-3af12ad35be8
02/04/2025 10:45:32:INFO:Received: evaluate message d263d33a-5e18-4cdb-a127-3af12ad35be8
[92mINFO [0m:      Sent reply
02/04/2025 10:45:34:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:45:40:INFO:
[92mINFO [0m:      Received: train message 9ccf93a0-158e-4d3d-8244-42508c95b099
02/04/2025 10:45:40:INFO:Received: train message 9ccf93a0-158e-4d3d-8244-42508c95b099
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:46:36:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:46:48:INFO:
[92mINFO [0m:      Received: evaluate message 33be9012-7758-42df-a1fb-91395a3eece0
02/04/2025 10:46:48:INFO:Received: evaluate message 33be9012-7758-42df-a1fb-91395a3eece0
[92mINFO [0m:      Sent reply
02/04/2025 10:46:50:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:46:56:INFO:
[92mINFO [0m:      Received: train message e673ec63-533d-4dc1-91ed-9a613449fd3d
02/04/2025 10:46:56:INFO:Received: train message e673ec63-533d-4dc1-91ed-9a613449fd3d

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994, 1.7470399529976803, 2.1555100771787115, 2.248170737855783, 2.0771471118908362], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693, 0.7677873338545739, 0.7771696637998436, 0.7763878029710711, 0.7912431587177482], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259, 0.8670194031895609, 0.8627624033955511, 0.8721863969453796, 0.8890898171152943]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0370

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994, 1.7470399529976803, 2.1555100771787115, 2.248170737855783, 2.0771471118908362, 2.5417886104986676], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693, 0.7677873338545739, 0.7771696637998436, 0.7763878029710711, 0.7912431587177482, 0.7568412822517592], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259, 0.8670194031895609, 0.8627624033955511, 0.8721863969453796, 0.8890898171152943, 0.8726996205821963]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0385

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994, 1.7470399529976803, 2.1555100771787115, 2.248170737855783, 2.0771471118908362, 2.5417886104986676, 2.121729152767895], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693, 0.7677873338545739, 0.7771696637998436, 0.7763878029710711, 0.7912431587177482, 0.7568412822517592, 0.7834245504300235], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259, 0.8670194031895609, 0.8627624033955511, 0.8721863969453796, 0.8890898171152943, 0.8726996205821963, 0.8802506387783535]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0153

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994, 1.7470399529976803, 2.1555100771787115, 2.248170737855783, 2.0771471118908362, 2.5417886104986676, 2.121729152767895, 2.5540947782941035], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693, 0.7677873338545739, 0.7771696637998436, 0.7763878029710711, 0.7912431587177482, 0.7568412822517592, 0.7834245504300235, 0.7685691946833464], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259, 0.8670194031895609, 0.8627624033955511, 0.8721863969453796, 0.8890898171152943, 0.8726996205821963, 0.8802506387783535, 0.884912067009599]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0621

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:47:52:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:48:04:INFO:
[92mINFO [0m:      Received: evaluate message 940c6a8f-e044-47fe-8c09-0f228e70d605
02/04/2025 10:48:04:INFO:Received: evaluate message 940c6a8f-e044-47fe-8c09-0f228e70d605
[92mINFO [0m:      Sent reply
02/04/2025 10:48:06:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:48:12:INFO:
[92mINFO [0m:      Received: train message 98163abb-7272-4b7d-b36f-e7e2513cef36
02/04/2025 10:48:12:INFO:Received: train message 98163abb-7272-4b7d-b36f-e7e2513cef36
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 10:49:10:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:49:23:INFO:
[92mINFO [0m:      Received: evaluate message 63d3d775-9ef3-4c28-b695-2de8f5242385
02/04/2025 10:49:23:INFO:Received: evaluate message 63d3d775-9ef3-4c28-b695-2de8f5242385
[92mINFO [0m:      Sent reply
02/04/2025 10:49:25:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 10:49:25:INFO:
[92mINFO [0m:      Received: reconnect message 639deb30-28f4-473a-aa7f-11d1688f3ebe
02/04/2025 10:49:25:INFO:Received: reconnect message 639deb30-28f4-473a-aa7f-11d1688f3ebe
02/04/2025 10:49:25:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/04/2025 10:49:25:INFO:Disconnect and shut down
Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994, 1.7470399529976803, 2.1555100771787115, 2.248170737855783, 2.0771471118908362, 2.5417886104986676, 2.121729152767895, 2.5540947782941035, 2.6186210297280557], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693, 0.7677873338545739, 0.7771696637998436, 0.7763878029710711, 0.7912431587177482, 0.7568412822517592, 0.7834245504300235, 0.7685691946833464, 0.7357310398749023], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259, 0.8670194031895609, 0.8627624033955511, 0.8721863969453796, 0.8890898171152943, 0.8726996205821963, 0.8802506387783535, 0.884912067009599, 0.8579031479057416]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.1024

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994, 1.7470399529976803, 2.1555100771787115, 2.248170737855783, 2.0771471118908362, 2.5417886104986676, 2.121729152767895, 2.5540947782941035, 2.6186210297280557, 2.57697589095446], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693, 0.7677873338545739, 0.7771696637998436, 0.7763878029710711, 0.7912431587177482, 0.7568412822517592, 0.7834245504300235, 0.7685691946833464, 0.7357310398749023, 0.7177482408131353], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259, 0.8670194031895609, 0.8627624033955511, 0.8721863969453796, 0.8890898171152943, 0.8726996205821963, 0.8802506387783535, 0.884912067009599, 0.8579031479057416, 0.838503900582227]}



Final client history:
{'loss': [2.017634144272769, 1.9789936943642323, 1.738541361034802, 1.8998282065700982, 1.7505937169733412, 1.906043174176348, 2.0100368295823157, 2.064636842220253, 1.934978564055032, 1.5356983317818094, 2.458607466321983, 1.5596891662587964, 1.6892242042509442, 1.6906696165255777, 1.6174769307413168, 1.9462123966897438, 2.0955675490742274, 2.6585190526994005, 1.663902610097666, 2.119435426683702, 1.9767781569912994, 1.7470399529976803, 2.1555100771787115, 2.248170737855783, 2.0771471118908362, 2.5417886104986676, 2.121729152767895, 2.5540947782941035, 2.6186210297280557, 2.57697589095446], 'accuracy': [0.3502736512900704, 0.5144644253322909, 0.5543393275996873, 0.5676309616888194, 0.5715402658326818, 0.5574667709147771, 0.6059421422986708, 0.6004691164972635, 0.565285379202502, 0.6434714620797498, 0.616106333072713, 0.7185301016419078, 0.7326035965598123, 0.7396403440187647, 0.7763878029710711, 0.7349491790461298, 0.7341673182173573, 0.7169663799843627, 0.7474589523064894, 0.7318217357310399, 0.7537138389366693, 0.7677873338545739, 0.7771696637998436, 0.7763878029710711, 0.7912431587177482, 0.7568412822517592, 0.7834245504300235, 0.7685691946833464, 0.7357310398749023, 0.7177482408131353], 'auc': [0.5120144452028692, 0.7338228881634812, 0.739718533604541, 0.7564126537293436, 0.7744189181916332, 0.7716789827335995, 0.7985783354918146, 0.8169775675641324, 0.7985062159715046, 0.8279534101671299, 0.8389124290350691, 0.8657192827097526, 0.8811692797115218, 0.8809701126438374, 0.893989706303264, 0.8835721745574255, 0.8878273096154514, 0.8684548303480069, 0.8682583030402987, 0.8703006827822022, 0.8594619617662259, 0.8670194031895609, 0.8627624033955511, 0.8721863969453796, 0.8890898171152943, 0.8726996205821963, 0.8802506387783535, 0.884912067009599, 0.8579031479057416, 0.838503900582227]}

