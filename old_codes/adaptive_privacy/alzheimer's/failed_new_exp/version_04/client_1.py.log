nohup: ignoring input
02/04/2025 11:52:14:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/04/2025 11:52:14:DEBUG:ChannelConnectivity.IDLE
02/04/2025 11:52:14:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
02/04/2025 11:52:14:INFO:
[92mINFO [0m:      Received: get_parameters message beb744b0-385b-4b4f-9c5f-87d504f4a8ef
02/04/2025 11:52:14:INFO:Received: get_parameters message beb744b0-385b-4b4f-9c5f-87d504f4a8ef
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738698734.698610 4040784 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      Sent reply
02/04/2025 11:52:20:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:52:27:INFO:
[92mINFO [0m:      Received: train message da0684b8-47f2-4126-88b9-f3d721607081
02/04/2025 11:52:27:INFO:Received: train message da0684b8-47f2-4126-88b9-f3d721607081
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 11:53:22:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:53:35:INFO:
[92mINFO [0m:      Received: evaluate message 91e011d1-5c22-45e0-ae13-b2d03efce1e6
02/04/2025 11:53:35:INFO:Received: evaluate message 91e011d1-5c22-45e0-ae13-b2d03efce1e6
[92mINFO [0m:      Sent reply
02/04/2025 11:53:37:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:53:44:INFO:
[92mINFO [0m:      Received: train message c1f94e27-351a-45e0-a5a3-6725d467d270
02/04/2025 11:53:44:INFO:Received: train message c1f94e27-351a-45e0-a5a3-6725d467d270
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 11:54:44:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:54:58:INFO:
[92mINFO [0m:      Received: evaluate message 85e3eafd-2ac6-4775-b765-c3e4fa2a0d99
02/04/2025 11:54:58:INFO:Received: evaluate message 85e3eafd-2ac6-4775-b765-c3e4fa2a0d99
[92mINFO [0m:      Sent reply
02/04/2025 11:55:01:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:55:08:INFO:
[92mINFO [0m:      Received: train message 30400b85-b438-4c98-992b-08b24e78f5c2
02/04/2025 11:55:08:INFO:Received: train message 30400b85-b438-4c98-992b-08b24e78f5c2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 11:56:13:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:56:24:INFO:
[92mINFO [0m:      Received: evaluate message 57be4df1-b987-4a02-bd95-78d7847a7d39
02/04/2025 11:56:24:INFO:Received: evaluate message 57be4df1-b987-4a02-bd95-78d7847a7d39
[92mINFO [0m:      Sent reply
02/04/2025 11:56:27:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:56:33:INFO:
[92mINFO [0m:      Received: train message b76e76b0-2422-41d7-b19b-b10756ac7d75
02/04/2025 11:56:33:INFO:Received: train message b76e76b0-2422-41d7-b19b-b10756ac7d75
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 11:57:29:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:57:41:INFO:
[92mINFO [0m:      Received: evaluate message 0ce6e508-9527-4e28-9609-e6eada433bb3
02/04/2025 11:57:41:INFO:Received: evaluate message 0ce6e508-9527-4e28-9609-e6eada433bb3
[92mINFO [0m:      Sent reply
02/04/2025 11:57:44:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:57:50:INFO:
[92mINFO [0m:      Received: train message 0149c82b-2c02-404c-8bc4-5eec328caab6
02/04/2025 11:57:50:INFO:Received: train message 0149c82b-2c02-404c-8bc4-5eec328caab6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 11:58:51:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:59:04:INFO:
[92mINFO [0m:      Received: evaluate message 8794e1da-a9d4-4c79-be77-0934db86cac3
02/04/2025 11:59:04:INFO:Received: evaluate message 8794e1da-a9d4-4c79-be77-0934db86cac3
[92mINFO [0m:      Sent reply
02/04/2025 11:59:06:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 11:59:13:INFO:
[92mINFO [0m:      Received: train message f9eadaf6-d673-49c2-885e-1fcc5fc3b9f5
02/04/2025 11:59:13:INFO:Received: train message f9eadaf6-d673-49c2-885e-1fcc5fc3b9f5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:00:14:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:00:26:INFO:
[92mINFO [0m:      Received: evaluate message 62beab36-6fde-413b-8a36-a24658dd06b8
02/04/2025 12:00:26:INFO:Received: evaluate message 62beab36-6fde-413b-8a36-a24658dd06b8
[92mINFO [0m:      Sent reply
02/04/2025 12:00:29:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:00:35:INFO:
[92mINFO [0m:      Received: train message 5a8e2fd2-5270-44c0-8416-bfbfc6c87cf7
02/04/2025 12:00:35:INFO:Received: train message 5a8e2fd2-5270-44c0-8416-bfbfc6c87cf7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:01:38:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:01:50:INFO:
[92mINFO [0m:      Received: evaluate message 1598aa0a-334f-4989-ad41-61d6352e87c8
02/04/2025 12:01:50:INFO:Received: evaluate message 1598aa0a-334f-4989-ad41-61d6352e87c8
[92mINFO [0m:      Sent reply
02/04/2025 12:01:52:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:01:59:INFO:
[92mINFO [0m:      Received: train message 4bfe55df-7fb5-44d4-b79e-5457127550f0
02/04/2025 12:01:59:INFO:Received: train message 4bfe55df-7fb5-44d4-b79e-5457127550f0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:02:55:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:03:07:INFO:
[92mINFO [0m:      Received: evaluate message fb6de2e2-2cb1-4ccd-b362-56945f8bbbce
02/04/2025 12:03:07:INFO:Received: evaluate message fb6de2e2-2cb1-4ccd-b362-56945f8bbbce
[92mINFO [0m:      Sent reply
02/04/2025 12:03:09:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:03:15:INFO:
[92mINFO [0m:      Received: train message f27b32af-9c5c-4426-9896-4c8cd74e217b
02/04/2025 12:03:15:INFO:Received: train message f27b32af-9c5c-4426-9896-4c8cd74e217b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:04:13:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:04:24:INFO:
[92mINFO [0m:      Received: evaluate message f2d2a732-3580-4568-9df8-5a8feba7d6d4
02/04/2025 12:04:24:INFO:Received: evaluate message f2d2a732-3580-4568-9df8-5a8feba7d6d4
[92mINFO [0m:      Sent reply
02/04/2025 12:04:27:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:04:33:INFO:
[92mINFO [0m:      Received: train message a9cbf701-d2d1-402d-b4a5-dfea866320e2
02/04/2025 12:04:33:INFO:Received: train message a9cbf701-d2d1-402d-b4a5-dfea866320e2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:05:34:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:05:47:INFO:
[92mINFO [0m:      Received: evaluate message 4ba7f1c0-e2a0-48c0-a768-ba78aa7d068e
02/04/2025 12:05:47:INFO:Received: evaluate message 4ba7f1c0-e2a0-48c0-a768-ba78aa7d068e
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 1.0, target_epsilon: 1.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0479

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026], 'accuracy': [0.3502736512900704], 'auc': [0.5651657693948702]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0615

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747], 'accuracy': [0.3502736512900704, 0.490226739640344], 'auc': [0.5651657693948702, 0.7541221089705862]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0697

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.0992

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.1928

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.2809

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.2143

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.3690

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.3823

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.2700

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/04/2025 12:05:49:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:05:55:INFO:
[92mINFO [0m:      Received: train message 742b1149-dc2d-4fb4-8f73-7c72349c44d6
02/04/2025 12:05:55:INFO:Received: train message 742b1149-dc2d-4fb4-8f73-7c72349c44d6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:06:55:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:07:06:INFO:
[92mINFO [0m:      Received: evaluate message 4037d77a-bf91-483d-9b06-93ea7b934322
02/04/2025 12:07:06:INFO:Received: evaluate message 4037d77a-bf91-483d-9b06-93ea7b934322
[92mINFO [0m:      Sent reply
02/04/2025 12:07:09:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:07:15:INFO:
[92mINFO [0m:      Received: train message 1c5d735d-442d-43e2-9c17-bf8168c87ffa
02/04/2025 12:07:15:INFO:Received: train message 1c5d735d-442d-43e2-9c17-bf8168c87ffa
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:08:13:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:08:25:INFO:
[92mINFO [0m:      Received: evaluate message f94f7dbe-758d-45be-9d1d-37aba1af8d2d
02/04/2025 12:08:25:INFO:Received: evaluate message f94f7dbe-758d-45be-9d1d-37aba1af8d2d
[92mINFO [0m:      Sent reply
02/04/2025 12:08:29:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:08:35:INFO:
[92mINFO [0m:      Received: train message 088242d4-e648-4b7d-8874-aacc0803309c
02/04/2025 12:08:35:INFO:Received: train message 088242d4-e648-4b7d-8874-aacc0803309c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:09:33:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:09:44:INFO:
[92mINFO [0m:      Received: evaluate message ff515084-e6e3-4b28-bf40-4d2546dda5b6
02/04/2025 12:09:44:INFO:Received: evaluate message ff515084-e6e3-4b28-bf40-4d2546dda5b6
[92mINFO [0m:      Sent reply
02/04/2025 12:09:47:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:09:53:INFO:
[92mINFO [0m:      Received: train message 82befdff-2e55-4b2b-a192-368c286a9703
02/04/2025 12:09:53:INFO:Received: train message 82befdff-2e55-4b2b-a192-368c286a9703
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:10:54:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:11:06:INFO:
[92mINFO [0m:      Received: evaluate message d0ab4746-b3d8-46b3-ab5b-8da833e6f81b
02/04/2025 12:11:06:INFO:Received: evaluate message d0ab4746-b3d8-46b3-ab5b-8da833e6f81b
[92mINFO [0m:      Sent reply
02/04/2025 12:11:09:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:11:15:INFO:
[92mINFO [0m:      Received: train message 09ddc92d-b87a-431b-8666-28a3fb46f2e4
02/04/2025 12:11:15:INFO:Received: train message 09ddc92d-b87a-431b-8666-28a3fb46f2e4
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:12:16:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:12:28:INFO:
[92mINFO [0m:      Received: evaluate message 9e1adc12-6e96-4519-a9bc-bbfbe365f7c9
02/04/2025 12:12:28:INFO:Received: evaluate message 9e1adc12-6e96-4519-a9bc-bbfbe365f7c9
[92mINFO [0m:      Sent reply
02/04/2025 12:12:32:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:12:38:INFO:
[92mINFO [0m:      Received: train message f4863f7c-ee1c-467e-8a84-936f852356f8
02/04/2025 12:12:38:INFO:Received: train message f4863f7c-ee1c-467e-8a84-936f852356f8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:13:36:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:13:48:INFO:
[92mINFO [0m:      Received: evaluate message f3345a6a-fc36-433b-afd9-fc2dee778bb1
02/04/2025 12:13:48:INFO:Received: evaluate message f3345a6a-fc36-433b-afd9-fc2dee778bb1

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.4220

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 12
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5143

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.4916

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5328

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 15
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.4079

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.6387

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/04/2025 12:13:50:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:13:57:INFO:
[92mINFO [0m:      Received: train message 42758f34-f72b-45c5-8966-cad62da1f95c
02/04/2025 12:13:57:INFO:Received: train message 42758f34-f72b-45c5-8966-cad62da1f95c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:14:56:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:15:09:INFO:
[92mINFO [0m:      Received: evaluate message 8ddda63c-7314-4b66-9338-f6fc9ff7fc30
02/04/2025 12:15:09:INFO:Received: evaluate message 8ddda63c-7314-4b66-9338-f6fc9ff7fc30
[92mINFO [0m:      Sent reply
02/04/2025 12:15:11:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:15:17:INFO:
[92mINFO [0m:      Received: train message f191245f-687f-4e39-9151-85d4a09ac624
02/04/2025 12:15:17:INFO:Received: train message f191245f-687f-4e39-9151-85d4a09ac624
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:16:15:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:16:29:INFO:
[92mINFO [0m:      Received: evaluate message c32ac027-7112-41eb-a783-b43f9dd4458b
02/04/2025 12:16:29:INFO:Received: evaluate message c32ac027-7112-41eb-a783-b43f9dd4458b
[92mINFO [0m:      Sent reply
02/04/2025 12:16:31:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:16:38:INFO:
[92mINFO [0m:      Received: train message ec8b352e-3dff-44cc-a121-334d5ae11021
02/04/2025 12:16:38:INFO:Received: train message ec8b352e-3dff-44cc-a121-334d5ae11021
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:17:34:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:17:48:INFO:
[92mINFO [0m:      Received: evaluate message 0fd0b52c-570d-43da-8195-b11a8a1a4146
02/04/2025 12:17:48:INFO:Received: evaluate message 0fd0b52c-570d-43da-8195-b11a8a1a4146
[92mINFO [0m:      Sent reply
02/04/2025 12:17:50:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:17:57:INFO:
[92mINFO [0m:      Received: train message 3be0734c-8e32-47a2-ae3c-83272033359c
02/04/2025 12:17:57:INFO:Received: train message 3be0734c-8e32-47a2-ae3c-83272033359c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:18:53:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:19:08:INFO:
[92mINFO [0m:      Received: evaluate message a324f33c-93e3-48e0-ae66-33376402ef25
02/04/2025 12:19:08:INFO:Received: evaluate message a324f33c-93e3-48e0-ae66-33376402ef25
[92mINFO [0m:      Sent reply
02/04/2025 12:19:10:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:19:17:INFO:
[92mINFO [0m:      Received: train message ae37a68f-84c7-47e9-b415-3fe0c05a1739
02/04/2025 12:19:17:INFO:Received: train message ae37a68f-84c7-47e9-b415-3fe0c05a1739
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:20:13:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:20:26:INFO:
[92mINFO [0m:      Received: evaluate message b2dc2fb1-e58b-41b3-8445-098a665bd149
02/04/2025 12:20:26:INFO:Received: evaluate message b2dc2fb1-e58b-41b3-8445-098a665bd149

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5109

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5551

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.6546

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5575

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.7321

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/04/2025 12:20:28:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:20:34:INFO:
[92mINFO [0m:      Received: train message d3ee372c-ccca-4a84-bb5b-d96f89c57b41
02/04/2025 12:20:34:INFO:Received: train message d3ee372c-ccca-4a84-bb5b-d96f89c57b41
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:21:30:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:21:43:INFO:
[92mINFO [0m:      Received: evaluate message 577be724-1d22-47dd-a6db-f08100e7789d
02/04/2025 12:21:43:INFO:Received: evaluate message 577be724-1d22-47dd-a6db-f08100e7789d
[92mINFO [0m:      Sent reply
02/04/2025 12:21:45:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:21:51:INFO:
[92mINFO [0m:      Received: train message cb401744-e68d-4666-9525-b8858cdc0669
02/04/2025 12:21:51:INFO:Received: train message cb401744-e68d-4666-9525-b8858cdc0669
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:22:47:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:23:00:INFO:
[92mINFO [0m:      Received: evaluate message b38433b2-45b2-4513-93f4-64f165f45a16
02/04/2025 12:23:00:INFO:Received: evaluate message b38433b2-45b2-4513-93f4-64f165f45a16
[92mINFO [0m:      Sent reply
02/04/2025 12:23:03:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:23:09:INFO:
[92mINFO [0m:      Received: train message b4c57765-eb61-4788-bcc7-124cf42fccff
02/04/2025 12:23:09:INFO:Received: train message b4c57765-eb61-4788-bcc7-124cf42fccff
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:24:05:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:24:19:INFO:
[92mINFO [0m:      Received: evaluate message 9b03c0e9-d506-4501-920f-a7cffde24b4c
02/04/2025 12:24:19:INFO:Received: evaluate message 9b03c0e9-d506-4501-920f-a7cffde24b4c
[92mINFO [0m:      Sent reply
02/04/2025 12:24:21:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:24:27:INFO:
[92mINFO [0m:      Received: train message 17b4edb0-9b6c-467e-878e-487f7fe1a9e2
02/04/2025 12:24:27:INFO:Received: train message 17b4edb0-9b6c-467e-878e-487f7fe1a9e2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:25:25:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:25:38:INFO:
[92mINFO [0m:      Received: evaluate message e549c0af-109a-4931-aca6-386600232e75
02/04/2025 12:25:38:INFO:Received: evaluate message e549c0af-109a-4931-aca6-386600232e75

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.6612

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397, 2.6750506346111793], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845, 0.527756059421423], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035, 0.6837844429489691]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5899

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397, 2.6750506346111793, 2.330356518070245], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845, 0.527756059421423, 0.5910867865519938], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035, 0.6837844429489691, 0.6941258260309062]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5540

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397, 2.6750506346111793, 2.330356518070245, 2.161488398268784], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845, 0.527756059421423, 0.5910867865519938, 0.5879593432369038], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035, 0.6837844429489691, 0.6941258260309062, 0.7079355506365178]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5640

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/04/2025 12:25:40:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:25:46:INFO:
[92mINFO [0m:      Received: train message e8aa4c2e-7ea7-4107-b722-91f17e39f785
02/04/2025 12:25:46:INFO:Received: train message e8aa4c2e-7ea7-4107-b722-91f17e39f785
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:26:42:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:26:54:INFO:
[92mINFO [0m:      Received: evaluate message c5aef12a-fcfd-4c16-94d6-39ac0db3e178
02/04/2025 12:26:54:INFO:Received: evaluate message c5aef12a-fcfd-4c16-94d6-39ac0db3e178
[92mINFO [0m:      Sent reply
02/04/2025 12:26:56:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:27:02:INFO:
[92mINFO [0m:      Received: train message 26eb2c6c-5c4c-415b-bb09-a7f9d30d85e2
02/04/2025 12:27:02:INFO:Received: train message 26eb2c6c-5c4c-415b-bb09-a7f9d30d85e2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:27:57:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:28:10:INFO:
[92mINFO [0m:      Received: evaluate message 1bfd1f57-a545-490d-a1f5-2a26ee4ea159
02/04/2025 12:28:10:INFO:Received: evaluate message 1bfd1f57-a545-490d-a1f5-2a26ee4ea159
[92mINFO [0m:      Sent reply
02/04/2025 12:28:12:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:28:17:INFO:
[92mINFO [0m:      Received: train message 077fae04-fa9d-4e59-885b-040a14b5b7f1
02/04/2025 12:28:17:INFO:Received: train message 077fae04-fa9d-4e59-885b-040a14b5b7f1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:29:13:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:29:25:INFO:
[92mINFO [0m:      Received: evaluate message 7581668b-edb6-4720-871c-381cb24beda8
02/04/2025 12:29:25:INFO:Received: evaluate message 7581668b-edb6-4720-871c-381cb24beda8
[92mINFO [0m:      Sent reply
02/04/2025 12:29:27:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:29:33:INFO:
[92mINFO [0m:      Received: train message 61f854a9-1154-46d7-bca9-0bbdd1fe9e86
02/04/2025 12:29:33:INFO:Received: train message 61f854a9-1154-46d7-bca9-0bbdd1fe9e86
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:30:28:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:30:41:INFO:
[92mINFO [0m:      Received: evaluate message b5e083e7-13ae-4325-bc96-7cf7304679ef
02/04/2025 12:30:41:INFO:Received: evaluate message b5e083e7-13ae-4325-bc96-7cf7304679ef

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397, 2.6750506346111793, 2.330356518070245, 2.161488398268784, 3.0910131330259634], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845, 0.527756059421423, 0.5910867865519938, 0.5879593432369038, 0.46051602814698983], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035, 0.6837844429489691, 0.6941258260309062, 0.7079355506365178, 0.7363247627978078]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.8683

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397, 2.6750506346111793, 2.330356518070245, 2.161488398268784, 3.0910131330259634, 2.805644504556999], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845, 0.527756059421423, 0.5910867865519938, 0.5879593432369038, 0.46051602814698983, 0.5285379202501954], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035, 0.6837844429489691, 0.6941258260309062, 0.7079355506365178, 0.7363247627978078, 0.6588356038258099]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5676

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397, 2.6750506346111793, 2.330356518070245, 2.161488398268784, 3.0910131330259634, 2.805644504556999, 2.349876100367825], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845, 0.527756059421423, 0.5910867865519938, 0.5879593432369038, 0.46051602814698983, 0.5285379202501954, 0.5543393275996873], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035, 0.6837844429489691, 0.6941258260309062, 0.7079355506365178, 0.7363247627978078, 0.6588356038258099, 0.7196748547402398]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5613

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397, 2.6750506346111793, 2.330356518070245, 2.161488398268784, 3.0910131330259634, 2.805644504556999, 2.349876100367825, 2.22136693580063], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845, 0.527756059421423, 0.5910867865519938, 0.5879593432369038, 0.46051602814698983, 0.5285379202501954, 0.5543393275996873, 0.5723221266614542], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035, 0.6837844429489691, 0.6941258260309062, 0.7079355506365178, 0.7363247627978078, 0.6588356038258099, 0.7196748547402398, 0.7030370839545812]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5877

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
[92mINFO [0m:      Sent reply
02/04/2025 12:30:43:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:30:49:INFO:
[92mINFO [0m:      Received: train message 88198036-e0ae-4318-9c36-c23aa1563eba
02/04/2025 12:30:49:INFO:Received: train message 88198036-e0ae-4318-9c36-c23aa1563eba
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/04/2025 12:31:44:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:31:57:INFO:
[92mINFO [0m:      Received: evaluate message c096db68-2cd9-4296-906f-bc61d8c669ff
02/04/2025 12:31:57:INFO:Received: evaluate message c096db68-2cd9-4296-906f-bc61d8c669ff
[92mINFO [0m:      Sent reply
02/04/2025 12:32:00:INFO:Sent reply
[92mINFO [0m:      
02/04/2025 12:32:00:INFO:
[92mINFO [0m:      Received: reconnect message d21be573-8a72-400b-84fc-29b76f4e086c
02/04/2025 12:32:00:INFO:Received: reconnect message d21be573-8a72-400b-84fc-29b76f4e086c
02/04/2025 12:32:00:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/04/2025 12:32:00:INFO:Disconnect and shut down
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397, 2.6750506346111793, 2.330356518070245, 2.161488398268784, 3.0910131330259634, 2.805644504556999, 2.349876100367825, 2.22136693580063, 2.424788690317041], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845, 0.527756059421423, 0.5910867865519938, 0.5879593432369038, 0.46051602814698983, 0.5285379202501954, 0.5543393275996873, 0.5723221266614542, 0.5613760750586395], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035, 0.6837844429489691, 0.6941258260309062, 0.7079355506365178, 0.7363247627978078, 0.6588356038258099, 0.7196748547402398, 0.7030370839545812, 0.6526171146984793]}

Step 1.5: Recomputing Fisher Information dynamically for Global Epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically

Base NM: 3.7891, Dynamic NM: 0.5913

Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397, 2.6750506346111793, 2.330356518070245, 2.161488398268784, 3.0910131330259634, 2.805644504556999, 2.349876100367825, 2.22136693580063, 2.424788690317041, 2.129972377869186], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845, 0.527756059421423, 0.5910867865519938, 0.5879593432369038, 0.46051602814698983, 0.5285379202501954, 0.5543393275996873, 0.5723221266614542, 0.5613760750586395, 0.5809225957779516], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035, 0.6837844429489691, 0.6941258260309062, 0.7079355506365178, 0.7363247627978078, 0.6588356038258099, 0.7196748547402398, 0.7030370839545812, 0.6526171146984793, 0.6893051133421214]}



Final client history:
{'loss': [2.4623043266350026, 1.9199356534361747, 2.276541871470898, 2.0011680756489496, 1.9116586419732613, 2.12145130582113, 2.305809678697698, 2.394084287468021, 1.88118795287432, 2.2509778279452886, 2.7923649421269023, 2.3651584780383987, 2.298818945511884, 1.9572381320365058, 2.4984005489696086, 1.9554056346742692, 2.2576973275620085, 1.9158624321618427, 2.2540034310043184, 2.0268664132626006, 2.5177589892129397, 2.6750506346111793, 2.330356518070245, 2.161488398268784, 3.0910131330259634, 2.805644504556999, 2.349876100367825, 2.22136693580063, 2.424788690317041, 2.129972377869186], 'accuracy': [0.3502736512900704, 0.490226739640344, 0.5613760750586395, 0.5777951524628616, 0.5746677091477717, 0.5535574667709148, 0.5754495699765442, 0.5566849100860047, 0.5418295543393276, 0.5738858483189992, 0.5175918686473807, 0.5676309616888194, 0.5793588741204065, 0.5832681782642689, 0.5723221266614542, 0.5746677091477717, 0.5519937451133698, 0.5824863174354965, 0.5660672400312744, 0.5824863174354965, 0.5629397967161845, 0.527756059421423, 0.5910867865519938, 0.5879593432369038, 0.46051602814698983, 0.5285379202501954, 0.5543393275996873, 0.5723221266614542, 0.5613760750586395, 0.5809225957779516], 'auc': [0.5651657693948702, 0.7541221089705862, 0.7397553636208634, 0.7486773885806774, 0.754811767913074, 0.6938593167934037, 0.7038534352356007, 0.6572635210707303, 0.7220767383789553, 0.7181181170228013, 0.673877292585241, 0.7028454299192519, 0.6832325248180444, 0.7245115213959828, 0.725548702759594, 0.7563112381767196, 0.694777666884821, 0.7208957570768932, 0.7183179374936688, 0.7165194921766544, 0.6408336786064035, 0.6837844429489691, 0.6941258260309062, 0.7079355506365178, 0.7363247627978078, 0.6588356038258099, 0.7196748547402398, 0.7030370839545812, 0.6526171146984793, 0.6893051133421214]}

