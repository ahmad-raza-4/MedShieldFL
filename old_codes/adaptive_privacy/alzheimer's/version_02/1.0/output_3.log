nohup: ignoring input
01/31/2025 05:19:17:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 05:19:17:DEBUG:ChannelConnectivity.IDLE
01/31/2025 05:19:17:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 05:19:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:19:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 425a5439-d933-4eaf-91d8-cabfad2f6395
01/31/2025 05:19:56:INFO:Received: train message 425a5439-d933-4eaf-91d8-cabfad2f6395
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:20:13:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:20:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:20:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b822f603-ed9f-4ded-b830-6e5e347588d8
01/31/2025 05:20:45:INFO:Received: evaluate message b822f603-ed9f-4ded-b830-6e5e347588d8
[92mINFO [0m:      Sent reply
01/31/2025 05:20:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:21:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:21:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4e17ef2e-6ab9-4038-b569-499930e37d6b
01/31/2025 05:21:28:INFO:Received: train message 4e17ef2e-6ab9-4038-b569-499930e37d6b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:21:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:22:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:22:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message af3e795d-3ccd-4661-9b93-daf9448407e8
01/31/2025 05:22:31:INFO:Received: evaluate message af3e795d-3ccd-4661-9b93-daf9448407e8
[92mINFO [0m:      Sent reply
01/31/2025 05:22:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:23:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:23:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c7da933d-c723-42a7-a0f0-53c9ed9f3a72
01/31/2025 05:23:12:INFO:Received: train message c7da933d-c723-42a7-a0f0-53c9ed9f3a72
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:23:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:24:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:24:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2f4fadff-d526-4b46-995f-37967a1b563a
01/31/2025 05:24:13:INFO:Received: evaluate message 2f4fadff-d526-4b46-995f-37967a1b563a
[92mINFO [0m:      Sent reply
01/31/2025 05:24:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:24:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:24:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 827113e9-6440-47ad-af2f-d868d0f0c236
01/31/2025 05:24:53:INFO:Received: train message 827113e9-6440-47ad-af2f-d868d0f0c236
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:25:05:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:25:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:25:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9ce2dcae-af6f-454d-9120-f2351cfb1a06
01/31/2025 05:25:35:INFO:Received: evaluate message 9ce2dcae-af6f-454d-9120-f2351cfb1a06
[92mINFO [0m:      Sent reply
01/31/2025 05:25:37:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:26:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:26:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b9bf0725-5489-446d-9f7e-33357677c017
01/31/2025 05:26:13:INFO:Received: train message b9bf0725-5489-446d-9f7e-33357677c017
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:26:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:27:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:27:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b514389c-57e8-4f48-8d98-94c11f5908e2
01/31/2025 05:27:12:INFO:Received: evaluate message b514389c-57e8-4f48-8d98-94c11f5908e2
[92mINFO [0m:      Sent reply
01/31/2025 05:27:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:27:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:27:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 123aae6d-2c48-40be-a8e0-f25100e5907d
01/31/2025 05:27:59:INFO:Received: train message 123aae6d-2c48-40be-a8e0-f25100e5907d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:28:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:29:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:29:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 64d4fb59-fa6c-4e44-8f64-f3de1de6e131
01/31/2025 05:29:05:INFO:Received: evaluate message 64d4fb59-fa6c-4e44-8f64-f3de1de6e131
[92mINFO [0m:      Sent reply
01/31/2025 05:29:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:29:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:29:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f35641bf-be6d-4d67-b410-99f09d1a4073
01/31/2025 05:29:39:INFO:Received: train message f35641bf-be6d-4d67-b410-99f09d1a4073
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:29:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:30:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:30:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b0de1f8d-fd76-406a-b00a-19adc681a8ea
01/31/2025 05:30:45:INFO:Received: evaluate message b0de1f8d-fd76-406a-b00a-19adc681a8ea
[92mINFO [0m:      Sent reply
01/31/2025 05:30:47:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:31:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:31:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c66aaf8b-21c7-45b9-bd70-9858a8fa4129
01/31/2025 05:31:30:INFO:Received: train message c66aaf8b-21c7-45b9-bd70-9858a8fa4129
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:31:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:32:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:32:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 50cd6631-a3b2-455c-b126-5db644ffee9a
01/31/2025 05:32:27:INFO:Received: evaluate message 50cd6631-a3b2-455c-b126-5db644ffee9a
[92mINFO [0m:      Sent reply
01/31/2025 05:32:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:32:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:32:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 83e8bb42-f15d-48ba-9d38-2ee92d23845d
01/31/2025 05:32:44:INFO:Received: train message 83e8bb42-f15d-48ba-9d38-2ee92d23845d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:32:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:34:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:34:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fe29aba6-7180-47dc-96fd-7f2c42073f32
01/31/2025 05:34:04:INFO:Received: evaluate message fe29aba6-7180-47dc-96fd-7f2c42073f32
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 1.0, target_epsilon: 1.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118], 'accuracy': [0.5175918686473807], 'auc': [0.737810384411014]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651], 'accuracy': [0.5175918686473807, 0.5215011727912432], 'auc': [0.737810384411014, 0.754622171691574]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:34:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:34:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:34:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message eb524066-bdd8-4a1f-82c7-9ffdb55fee38
01/31/2025 05:34:44:INFO:Received: train message eb524066-bdd8-4a1f-82c7-9ffdb55fee38
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:35:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:35:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:35:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0e16d93e-3091-451a-8de9-73f572436f2c
01/31/2025 05:35:46:INFO:Received: evaluate message 0e16d93e-3091-451a-8de9-73f572436f2c
[92mINFO [0m:      Sent reply
01/31/2025 05:35:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:36:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:36:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 88cf3c56-e6f9-4923-a3fc-a9fc1327f7f9
01/31/2025 05:36:40:INFO:Received: train message 88cf3c56-e6f9-4923-a3fc-a9fc1327f7f9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:36:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:37:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:37:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 84920043-4a26-4d28-9e95-c7d1253fde12
01/31/2025 05:37:52:INFO:Received: evaluate message 84920043-4a26-4d28-9e95-c7d1253fde12
[92mINFO [0m:      Sent reply
01/31/2025 05:37:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:38:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:38:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 44a64402-e343-4786-b66a-512122e4ec38
01/31/2025 05:38:37:INFO:Received: train message 44a64402-e343-4786-b66a-512122e4ec38
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:38:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:39:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:39:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2f6ef8ab-9cfe-4487-b780-9f042e0df600
01/31/2025 05:39:50:INFO:Received: evaluate message 2f6ef8ab-9cfe-4487-b780-9f042e0df600
[92mINFO [0m:      Sent reply
01/31/2025 05:39:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:40:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:40:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a68f72cb-9604-4108-be5e-6e2d4e780aca
01/31/2025 05:40:29:INFO:Received: train message a68f72cb-9604-4108-be5e-6e2d4e780aca
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:40:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:41:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:41:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 12f5eaaf-4105-45a1-bf75-7185245964b6
01/31/2025 05:41:40:INFO:Received: evaluate message 12f5eaaf-4105-45a1-bf75-7185245964b6
[92mINFO [0m:      Sent reply
01/31/2025 05:41:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:42:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:42:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2ac2212d-7322-4091-8ca0-55065f427aa8
01/31/2025 05:42:16:INFO:Received: train message 2ac2212d-7322-4091-8ca0-55065f427aa8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:42:27:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:43:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:43:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e7b78c0e-9329-4ac0-a16e-83e9e5d3f627
01/31/2025 05:43:12:INFO:Received: evaluate message e7b78c0e-9329-4ac0-a16e-83e9e5d3f627
[92mINFO [0m:      Sent reply
01/31/2025 05:43:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:43:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:43:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 824deab2-e133-4e1b-8c73-322c83387145
01/31/2025 05:43:36:INFO:Received: train message 824deab2-e133-4e1b-8c73-322c83387145
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:43:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:44:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:44:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 72174855-0a33-4aa8-90cf-0bd09011b690
01/31/2025 05:44:43:INFO:Received: evaluate message 72174855-0a33-4aa8-90cf-0bd09011b690

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:44:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:45:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:45:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1744b306-a0de-4905-9527-e4f5ddacfd12
01/31/2025 05:45:04:INFO:Received: train message 1744b306-a0de-4905-9527-e4f5ddacfd12
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:45:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:45:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:45:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f4dcfdbd-f54e-4ccf-9245-22adb170501d
01/31/2025 05:45:56:INFO:Received: evaluate message f4dcfdbd-f54e-4ccf-9245-22adb170501d
[92mINFO [0m:      Sent reply
01/31/2025 05:45:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:46:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:46:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cc78693c-50d1-43eb-9b67-c56ef104b879
01/31/2025 05:46:39:INFO:Received: train message cc78693c-50d1-43eb-9b67-c56ef104b879
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:46:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:47:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:47:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 88a4be8b-8a72-4bad-81ec-fe2f497ff0cd
01/31/2025 05:47:35:INFO:Received: evaluate message 88a4be8b-8a72-4bad-81ec-fe2f497ff0cd
[92mINFO [0m:      Sent reply
01/31/2025 05:47:38:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:48:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:48:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 67d10bfe-bc97-4809-af3f-fb15d8a9df03
01/31/2025 05:48:09:INFO:Received: train message 67d10bfe-bc97-4809-af3f-fb15d8a9df03
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:48:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:48:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:48:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d6298e6c-ea3a-40b2-9d73-f0e5658814db
01/31/2025 05:48:54:INFO:Received: evaluate message d6298e6c-ea3a-40b2-9d73-f0e5658814db
[92mINFO [0m:      Sent reply
01/31/2025 05:48:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:49:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:49:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6ec59e15-00a8-4aae-8708-97e8942f7000
01/31/2025 05:49:29:INFO:Received: train message 6ec59e15-00a8-4aae-8708-97e8942f7000
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:49:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:50:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:50:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6b3b3624-19a4-4d42-87d2-8c083ce7a5be
01/31/2025 05:50:23:INFO:Received: evaluate message 6b3b3624-19a4-4d42-87d2-8c083ce7a5be
[92mINFO [0m:      Sent reply
01/31/2025 05:50:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:51:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:51:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8227d114-a768-4465-8003-26e4de2ea9d0
01/31/2025 05:51:06:INFO:Received: train message 8227d114-a768-4465-8003-26e4de2ea9d0
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:51:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:51:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:51:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 29e237a0-2134-4f5f-8d20-7f2311ba2641
01/31/2025 05:51:55:INFO:Received: evaluate message 29e237a0-2134-4f5f-8d20-7f2311ba2641

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:51:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:52:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:52:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 063efa97-64f0-48ba-b4d4-de6257b77068
01/31/2025 05:52:32:INFO:Received: train message 063efa97-64f0-48ba-b4d4-de6257b77068
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:52:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:53:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:53:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6a8884c6-a989-4a02-a56d-a92993f8dd9b
01/31/2025 05:53:22:INFO:Received: evaluate message 6a8884c6-a989-4a02-a56d-a92993f8dd9b
[92mINFO [0m:      Sent reply
01/31/2025 05:53:24:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:54:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:54:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ef1bce79-848b-4493-9f87-805181199111
01/31/2025 05:54:02:INFO:Received: train message ef1bce79-848b-4493-9f87-805181199111
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:54:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:54:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:54:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6c835397-6222-4ca1-8fc0-19c4f2bcf7e5
01/31/2025 05:54:59:INFO:Received: evaluate message 6c835397-6222-4ca1-8fc0-19c4f2bcf7e5
[92mINFO [0m:      Sent reply
01/31/2025 05:55:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:55:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:55:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6e9f561d-2fe5-43f4-a252-137140d95345
01/31/2025 05:55:30:INFO:Received: train message 6e9f561d-2fe5-43f4-a252-137140d95345
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:55:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:56:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:56:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1a54c9a7-65db-4792-908a-34e490cab537
01/31/2025 05:56:36:INFO:Received: evaluate message 1a54c9a7-65db-4792-908a-34e490cab537
[92mINFO [0m:      Sent reply
01/31/2025 05:56:38:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:56:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:56:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 23ed1b29-5501-49bd-ab4f-a6895291fe95
01/31/2025 05:56:53:INFO:Received: train message 23ed1b29-5501-49bd-ab4f-a6895291fe95
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:57:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:58:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:58:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fcf7ea2b-6922-46ef-9ac2-e72dc5b38ca5
01/31/2025 05:58:09:INFO:Received: evaluate message fcf7ea2b-6922-46ef-9ac2-e72dc5b38ca5

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:58:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:58:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:58:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 18732727-f96a-487d-9839-dc7ecf39934c
01/31/2025 05:58:43:INFO:Received: train message 18732727-f96a-487d-9839-dc7ecf39934c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:58:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:59:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:59:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message bac7ff47-cbba-4c92-ab44-58f2f1055144
01/31/2025 05:59:43:INFO:Received: evaluate message bac7ff47-cbba-4c92-ab44-58f2f1055144
[92mINFO [0m:      Sent reply
01/31/2025 05:59:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:00:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:00:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6ded3fca-3ca8-45de-ae5b-6afc41f18385
01/31/2025 06:00:26:INFO:Received: train message 6ded3fca-3ca8-45de-ae5b-6afc41f18385
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:00:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:01:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:01:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message acf30abd-d856-457a-84cf-f46636e4ec6c
01/31/2025 06:01:10:INFO:Received: evaluate message acf30abd-d856-457a-84cf-f46636e4ec6c
[92mINFO [0m:      Sent reply
01/31/2025 06:01:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:01:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:01:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 85cfd979-2bbc-4b9b-b56e-5073d9abe2e0
01/31/2025 06:01:45:INFO:Received: train message 85cfd979-2bbc-4b9b-b56e-5073d9abe2e0
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:01:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:02:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:02:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 558079d2-0755-4dd5-a951-ad4368ec36d8
01/31/2025 06:02:32:INFO:Received: evaluate message 558079d2-0755-4dd5-a951-ad4368ec36d8
[92mINFO [0m:      Sent reply
01/31/2025 06:02:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:03:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:03:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a4b59142-4228-4f96-8864-2c8c330cc6e9
01/31/2025 06:03:30:INFO:Received: train message a4b59142-4228-4f96-8864-2c8c330cc6e9

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:03:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:04:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:04:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message cb6497c7-93d5-4f28-ad5e-324197b8bb84
01/31/2025 06:04:31:INFO:Received: evaluate message cb6497c7-93d5-4f28-ad5e-324197b8bb84
[92mINFO [0m:      Sent reply
01/31/2025 06:04:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:05:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:05:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d7b6999f-4087-4dbf-9845-a1f7bcccb28b
01/31/2025 06:05:13:INFO:Received: train message d7b6999f-4087-4dbf-9845-a1f7bcccb28b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:05:27:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:06:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:06:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 852f866e-2507-4fb2-a1e6-c4938b293bf6
01/31/2025 06:06:06:INFO:Received: evaluate message 852f866e-2507-4fb2-a1e6-c4938b293bf6
[92mINFO [0m:      Sent reply
01/31/2025 06:06:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:06:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:06:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 097879e2-0e7d-4ef0-808f-17154b01d01d
01/31/2025 06:06:53:INFO:Received: train message 097879e2-0e7d-4ef0-808f-17154b01d01d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:07:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:08:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:08:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c2e21f6b-b406-409c-8efc-cfdee44a0783
01/31/2025 06:08:20:INFO:Received: evaluate message c2e21f6b-b406-409c-8efc-cfdee44a0783
[92mINFO [0m:      Sent reply
01/31/2025 06:08:23:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:08:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:08:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message 72803885-6abb-4e3e-b3ce-326c377bd947
01/31/2025 06:08:23:INFO:Received: reconnect message 72803885-6abb-4e3e-b3ce-326c377bd947
01/31/2025 06:08:23:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 06:08:23:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678, 1.014726576626161], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409, 0.8129799795083197]}



Final client history:
{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678, 1.014726576626161], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409, 0.8129799795083197]}

