nohup: ignoring input
01/31/2025 05:19:21:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 05:19:21:DEBUG:ChannelConnectivity.IDLE
01/31/2025 05:19:21:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 05:19:21:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 05:19:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:19:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 04b49ed9-e47f-4c38-a1b0-02d85863b3a2
01/31/2025 05:19:56:INFO:Received: train message 04b49ed9-e47f-4c38-a1b0-02d85863b3a2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:20:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:20:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:20:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5fa42a04-62a9-4e60-a49c-bf23efae8bb8
01/31/2025 05:20:55:INFO:Received: evaluate message 5fa42a04-62a9-4e60-a49c-bf23efae8bb8
[92mINFO [0m:      Sent reply
01/31/2025 05:20:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:21:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:21:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 683238a7-5be8-490a-a76b-ae173e44e556
01/31/2025 05:21:31:INFO:Received: train message 683238a7-5be8-490a-a76b-ae173e44e556
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:21:51:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:22:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:22:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 14d26224-3f9e-4a18-b92e-1fe4892edbf3
01/31/2025 05:22:17:INFO:Received: evaluate message 14d26224-3f9e-4a18-b92e-1fe4892edbf3
[92mINFO [0m:      Sent reply
01/31/2025 05:22:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:22:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:22:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 99600350-6e50-4ce0-bf55-a264a3977cca
01/31/2025 05:22:58:INFO:Received: train message 99600350-6e50-4ce0-bf55-a264a3977cca
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:23:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:24:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:24:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4f784772-9349-4bfc-82e9-e256754b3f01
01/31/2025 05:24:13:INFO:Received: evaluate message 4f784772-9349-4bfc-82e9-e256754b3f01
[92mINFO [0m:      Sent reply
01/31/2025 05:24:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:24:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:24:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message dc6c72e0-66ee-4ab8-9142-02b1bdda7350
01/31/2025 05:24:33:INFO:Received: train message dc6c72e0-66ee-4ab8-9142-02b1bdda7350
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:24:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:25:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:25:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ea5b8371-34a9-471e-b292-03e0e2f0faec
01/31/2025 05:25:51:INFO:Received: evaluate message ea5b8371-34a9-471e-b292-03e0e2f0faec
[92mINFO [0m:      Sent reply
01/31/2025 05:25:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:26:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:26:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 69423553-ffb0-465b-abe0-29281a8d38aa
01/31/2025 05:26:20:INFO:Received: train message 69423553-ffb0-465b-abe0-29281a8d38aa
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:26:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:27:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:27:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b0986c67-8047-4796-89a1-6868d691e628
01/31/2025 05:27:27:INFO:Received: evaluate message b0986c67-8047-4796-89a1-6868d691e628
[92mINFO [0m:      Sent reply
01/31/2025 05:27:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:28:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:28:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cc96c062-2638-4324-a2c4-74a74125d617
01/31/2025 05:28:06:INFO:Received: train message cc96c062-2638-4324-a2c4-74a74125d617
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:28:23:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:28:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:28:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b26ad501-60f7-4cbb-a74c-e77977a3e9b7
01/31/2025 05:28:59:INFO:Received: evaluate message b26ad501-60f7-4cbb-a74c-e77977a3e9b7
[92mINFO [0m:      Sent reply
01/31/2025 05:29:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:29:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:29:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 02a9fb92-e2da-400e-a022-48837f867f56
01/31/2025 05:29:27:INFO:Received: train message 02a9fb92-e2da-400e-a022-48837f867f56
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:29:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:30:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:30:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3d17b54d-a755-4f03-81b1-a37c6f979707
01/31/2025 05:30:54:INFO:Received: evaluate message 3d17b54d-a755-4f03-81b1-a37c6f979707
[92mINFO [0m:      Sent reply
01/31/2025 05:30:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:31:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:31:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c5d44852-6bc0-4cbf-ab8e-b64c4b1c72f5
01/31/2025 05:31:33:INFO:Received: train message c5d44852-6bc0-4cbf-ab8e-b64c4b1c72f5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:31:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:32:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:32:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d124d8d5-33f6-4d9d-b8b4-851342e9d261
01/31/2025 05:32:23:INFO:Received: evaluate message d124d8d5-33f6-4d9d-b8b4-851342e9d261
[92mINFO [0m:      Sent reply
01/31/2025 05:32:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:33:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:33:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b7b78594-302f-4f5f-855e-77b4e214ef06
01/31/2025 05:33:09:INFO:Received: train message b7b78594-302f-4f5f-855e-77b4e214ef06
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:33:24:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:34:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:34:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 81d2656e-b3c3-4900-bae8-a1457d54e8f6
01/31/2025 05:34:04:INFO:Received: evaluate message 81d2656e-b3c3-4900-bae8-a1457d54e8f6
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 1.0, target_epsilon: 1.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118], 'accuracy': [0.5175918686473807], 'auc': [0.737810384411014]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651], 'accuracy': [0.5175918686473807, 0.5215011727912432], 'auc': [0.737810384411014, 0.754622171691574]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:34:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:34:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:34:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 77296ca4-f270-4857-9ff5-e2dbb64701c2
01/31/2025 05:34:35:INFO:Received: train message 77296ca4-f270-4857-9ff5-e2dbb64701c2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:35:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:36:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:36:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 90cc955d-a171-4287-a6ef-8f7e51a6ce33
01/31/2025 05:36:01:INFO:Received: evaluate message 90cc955d-a171-4287-a6ef-8f7e51a6ce33
[92mINFO [0m:      Sent reply
01/31/2025 05:36:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:36:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:36:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 72deace2-ce68-4e8a-8406-82122ba27725
01/31/2025 05:36:38:INFO:Received: train message 72deace2-ce68-4e8a-8406-82122ba27725
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:37:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:37:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:37:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d36ade2c-841b-4d28-847b-35ae8da6abd5
01/31/2025 05:37:54:INFO:Received: evaluate message d36ade2c-841b-4d28-847b-35ae8da6abd5
[92mINFO [0m:      Sent reply
01/31/2025 05:37:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:38:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:38:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 92f53569-454b-45b6-a163-9d08d8d993e7
01/31/2025 05:38:30:INFO:Received: train message 92f53569-454b-45b6-a163-9d08d8d993e7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:38:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:39:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:39:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 72ba388c-2aa8-4ee4-aaed-fd2932251ba4
01/31/2025 05:39:52:INFO:Received: evaluate message 72ba388c-2aa8-4ee4-aaed-fd2932251ba4
[92mINFO [0m:      Sent reply
01/31/2025 05:39:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:40:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:40:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6c549f18-cccd-456d-8ebe-11f53f0118fb
01/31/2025 05:40:35:INFO:Received: train message 6c549f18-cccd-456d-8ebe-11f53f0118fb
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:40:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:41:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:41:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 62e7d7b0-c16c-48eb-9635-d7593c680a46
01/31/2025 05:41:45:INFO:Received: evaluate message 62e7d7b0-c16c-48eb-9635-d7593c680a46
[92mINFO [0m:      Sent reply
01/31/2025 05:41:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:42:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:42:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 270d8d11-1157-4495-a83e-f71b451dd2af
01/31/2025 05:42:01:INFO:Received: train message 270d8d11-1157-4495-a83e-f71b451dd2af
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:42:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:42:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:42:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 59c3b64d-907a-4348-94fa-14813e80732e
01/31/2025 05:42:58:INFO:Received: evaluate message 59c3b64d-907a-4348-94fa-14813e80732e
[92mINFO [0m:      Sent reply
01/31/2025 05:43:01:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:43:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:43:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 35b90610-686a-4488-8731-ec34c805fe1f
01/31/2025 05:43:32:INFO:Received: train message 35b90610-686a-4488-8731-ec34c805fe1f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:43:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:44:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:44:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f644736e-5b2b-41ca-9775-1a8fa480ed17
01/31/2025 05:44:34:INFO:Received: evaluate message f644736e-5b2b-41ca-9775-1a8fa480ed17

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:44:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:45:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:45:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 84f8f8af-ca99-4910-9b19-26029089341a
01/31/2025 05:45:11:INFO:Received: train message 84f8f8af-ca99-4910-9b19-26029089341a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:45:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:46:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:46:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fc019bb1-7969-46f0-b898-ef276fa8ba50
01/31/2025 05:46:00:INFO:Received: evaluate message fc019bb1-7969-46f0-b898-ef276fa8ba50
[92mINFO [0m:      Sent reply
01/31/2025 05:46:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:46:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:46:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a0c08a67-049c-49ca-a531-21ace9e405a9
01/31/2025 05:46:40:INFO:Received: train message a0c08a67-049c-49ca-a531-21ace9e405a9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:47:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:47:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:47:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 031d6e73-623e-405a-a1ae-abdc33f00e84
01/31/2025 05:47:37:INFO:Received: evaluate message 031d6e73-623e-405a-a1ae-abdc33f00e84
[92mINFO [0m:      Sent reply
01/31/2025 05:47:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:47:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:47:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 937783ab-a407-4fb5-8e57-37c542fc9b6f
01/31/2025 05:47:55:INFO:Received: train message 937783ab-a407-4fb5-8e57-37c542fc9b6f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:48:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:48:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:48:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6653a2e1-e18c-404f-a994-b206073aea09
01/31/2025 05:48:48:INFO:Received: evaluate message 6653a2e1-e18c-404f-a994-b206073aea09
[92mINFO [0m:      Sent reply
01/31/2025 05:48:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:49:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:49:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0d7f9fc0-3871-4e1a-97a0-27487a5cf6c6
01/31/2025 05:49:34:INFO:Received: train message 0d7f9fc0-3871-4e1a-97a0-27487a5cf6c6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:49:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:50:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:50:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b540c88f-f180-4ece-97ee-d51b87910d45
01/31/2025 05:50:31:INFO:Received: evaluate message b540c88f-f180-4ece-97ee-d51b87910d45
[92mINFO [0m:      Sent reply
01/31/2025 05:50:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:51:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:51:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c5e85e95-605b-43dd-a4bb-1d80f1272237
01/31/2025 05:51:02:INFO:Received: train message c5e85e95-605b-43dd-a4bb-1d80f1272237
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:51:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:51:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:51:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 50c07f7b-2d89-42d8-a75e-d2a1f09b757a
01/31/2025 05:51:57:INFO:Received: evaluate message 50c07f7b-2d89-42d8-a75e-d2a1f09b757a

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:52:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:52:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:52:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4a3e844f-9126-41a2-8e28-72085b571ca3
01/31/2025 05:52:22:INFO:Received: train message 4a3e844f-9126-41a2-8e28-72085b571ca3
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:52:41:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:53:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:53:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 832cd9fe-96ff-4819-8509-b1fed25d13df
01/31/2025 05:53:24:INFO:Received: evaluate message 832cd9fe-96ff-4819-8509-b1fed25d13df
[92mINFO [0m:      Sent reply
01/31/2025 05:53:27:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:53:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:53:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 121f57e7-1800-4dca-827f-352c5d484190
01/31/2025 05:53:47:INFO:Received: train message 121f57e7-1800-4dca-827f-352c5d484190
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:54:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:54:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:54:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3966e2a3-8992-4440-9d60-2e1846815ae0
01/31/2025 05:54:56:INFO:Received: evaluate message 3966e2a3-8992-4440-9d60-2e1846815ae0
[92mINFO [0m:      Sent reply
01/31/2025 05:54:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:55:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:55:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c03a7823-5731-4cdd-927e-145770599bf0
01/31/2025 05:55:45:INFO:Received: train message c03a7823-5731-4cdd-927e-145770599bf0
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:55:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:56:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:56:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b80ba0b4-650f-4375-9b3b-7f4fee678837
01/31/2025 05:56:18:INFO:Received: evaluate message b80ba0b4-650f-4375-9b3b-7f4fee678837
[92mINFO [0m:      Sent reply
01/31/2025 05:56:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:57:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:57:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5a6fe3a2-ee27-47ce-9dd1-fc026aec9422
01/31/2025 05:57:09:INFO:Received: train message 5a6fe3a2-ee27-47ce-9dd1-fc026aec9422
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:57:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:58:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:58:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5e3bade0-f79c-4016-943a-965357f6aa4b
01/31/2025 05:58:07:INFO:Received: evaluate message 5e3bade0-f79c-4016-943a-965357f6aa4b

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:58:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:58:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:58:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 774bbe50-3002-451d-a848-0f5e2fa1905b
01/31/2025 05:58:38:INFO:Received: train message 774bbe50-3002-451d-a848-0f5e2fa1905b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:58:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:59:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:59:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c8aeff31-87f6-4c1a-9c74-73f6e68153bd
01/31/2025 05:59:34:INFO:Received: evaluate message c8aeff31-87f6-4c1a-9c74-73f6e68153bd
[92mINFO [0m:      Sent reply
01/31/2025 05:59:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:00:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:00:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 70f7807a-34bc-4372-9cab-3212d6008d36
01/31/2025 06:00:22:INFO:Received: train message 70f7807a-34bc-4372-9cab-3212d6008d36
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:00:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:01:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:01:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 93196a22-66f3-4bad-b325-37bba7d6b417
01/31/2025 06:01:08:INFO:Received: evaluate message 93196a22-66f3-4bad-b325-37bba7d6b417
[92mINFO [0m:      Sent reply
01/31/2025 06:01:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:01:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:01:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cf9dbf07-83f9-48a0-b7d1-9d003359dee1
01/31/2025 06:01:53:INFO:Received: train message cf9dbf07-83f9-48a0-b7d1-9d003359dee1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:02:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:02:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:02:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 720a4224-54c2-4922-b4a9-76797aac95f0
01/31/2025 06:02:51:INFO:Received: evaluate message 720a4224-54c2-4922-b4a9-76797aac95f0
[92mINFO [0m:      Sent reply
01/31/2025 06:02:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:03:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:03:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e40e7bc4-2d01-48cd-9e43-52223ffd5a2d
01/31/2025 06:03:27:INFO:Received: train message e40e7bc4-2d01-48cd-9e43-52223ffd5a2d

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:03:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:04:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:04:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 04a07f68-e783-4aac-891f-246d7fd1c465
01/31/2025 06:04:22:INFO:Received: evaluate message 04a07f68-e783-4aac-891f-246d7fd1c465
[92mINFO [0m:      Sent reply
01/31/2025 06:04:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:05:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:05:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message bf358527-cda6-4970-a43b-52c253657573
01/31/2025 06:05:22:INFO:Received: train message bf358527-cda6-4970-a43b-52c253657573
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:05:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:06:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:06:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 45d79794-0158-48ea-940b-e64d5b86c531
01/31/2025 06:06:10:INFO:Received: evaluate message 45d79794-0158-48ea-940b-e64d5b86c531
[92mINFO [0m:      Sent reply
01/31/2025 06:06:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:07:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:07:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 848dc283-242b-4b61-96b8-6dd99ebb49ad
01/31/2025 06:07:13:INFO:Received: train message 848dc283-242b-4b61-96b8-6dd99ebb49ad
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:07:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:08:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:08:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 276ff879-9eef-4bec-b3ad-111364e43aeb
01/31/2025 06:08:17:INFO:Received: evaluate message 276ff879-9eef-4bec-b3ad-111364e43aeb
[92mINFO [0m:      Sent reply
01/31/2025 06:08:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:08:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:08:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message 2d1917a5-0bfb-48f7-997d-563c71f30a1c
01/31/2025 06:08:23:INFO:Received: reconnect message 2d1917a5-0bfb-48f7-997d-563c71f30a1c
01/31/2025 06:08:23:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 06:08:23:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678, 1.014726576626161], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409, 0.8129799795083197]}



Final client history:
{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678, 1.014726576626161], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409, 0.8129799795083197]}

