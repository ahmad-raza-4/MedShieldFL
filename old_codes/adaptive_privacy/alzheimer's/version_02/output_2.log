nohup: ignoring input
01/31/2025 07:59:38:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 07:59:38:DEBUG:ChannelConnectivity.IDLE
01/31/2025 07:59:38:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 07:59:38:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 08:00:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:00:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c9338cf2-1cad-48ed-9df3-344f8c0586c4
01/31/2025 08:00:10:INFO:Received: train message c9338cf2-1cad-48ed-9df3-344f8c0586c4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:00:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:01:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:01:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 67e958ba-374b-4739-bf9c-15c481b350eb
01/31/2025 08:01:27:INFO:Received: evaluate message 67e958ba-374b-4739-bf9c-15c481b350eb
[92mINFO [0m:      Sent reply
01/31/2025 08:01:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:02:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:02:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 540b4104-a367-4a1c-a806-f1dbb9714561
01/31/2025 08:02:05:INFO:Received: train message 540b4104-a367-4a1c-a806-f1dbb9714561
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:02:32:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:03:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:03:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e8ddad50-1d13-49db-beb6-7d143fcda751
01/31/2025 08:03:07:INFO:Received: evaluate message e8ddad50-1d13-49db-beb6-7d143fcda751
[92mINFO [0m:      Sent reply
01/31/2025 08:03:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:03:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:03:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ba3c5a1d-40ea-409c-8027-e35c41f08c8f
01/31/2025 08:03:48:INFO:Received: train message ba3c5a1d-40ea-409c-8027-e35c41f08c8f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:04:13:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:04:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:04:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message be6a894a-1f58-4ffa-b910-60d3bf28e5ba
01/31/2025 08:04:39:INFO:Received: evaluate message be6a894a-1f58-4ffa-b910-60d3bf28e5ba
[92mINFO [0m:      Sent reply
01/31/2025 08:04:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:05:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:05:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 739afedc-2e91-401f-b34c-e2ae138832cf
01/31/2025 08:05:32:INFO:Received: train message 739afedc-2e91-401f-b34c-e2ae138832cf
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:05:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:06:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:06:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 53de5bbb-6e19-4f12-8013-f8dbde0a6664
01/31/2025 08:06:31:INFO:Received: evaluate message 53de5bbb-6e19-4f12-8013-f8dbde0a6664
[92mINFO [0m:      Sent reply
01/31/2025 08:06:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:07:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:07:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4c48b1fe-89ee-45f2-a5ac-3027818647ac
01/31/2025 08:07:05:INFO:Received: train message 4c48b1fe-89ee-45f2-a5ac-3027818647ac
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:07:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:08:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:08:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c5ac3269-0dd2-4069-92a1-3ab3d56d4668
01/31/2025 08:08:11:INFO:Received: evaluate message c5ac3269-0dd2-4069-92a1-3ab3d56d4668
[92mINFO [0m:      Sent reply
01/31/2025 08:08:13:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:08:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:08:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 00b03856-00c3-4a12-a30d-e37006977059
01/31/2025 08:08:31:INFO:Received: train message 00b03856-00c3-4a12-a30d-e37006977059
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:08:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:09:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:09:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5a47de58-9bb1-4941-8e28-d4374426141f
01/31/2025 08:09:50:INFO:Received: evaluate message 5a47de58-9bb1-4941-8e28-d4374426141f
[92mINFO [0m:      Sent reply
01/31/2025 08:09:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:10:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:10:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2d4fb878-9fee-453a-bd5a-ede6598c7248
01/31/2025 08:10:39:INFO:Received: train message 2d4fb878-9fee-453a-bd5a-ede6598c7248
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:11:01:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:11:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:11:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 10b30812-cd6a-46bb-a52c-115863dda126
01/31/2025 08:11:48:INFO:Received: evaluate message 10b30812-cd6a-46bb-a52c-115863dda126
[92mINFO [0m:      Sent reply
01/31/2025 08:11:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:12:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:12:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 694b3e93-3fda-4503-a923-384ef2460425
01/31/2025 08:12:09:INFO:Received: train message 694b3e93-3fda-4503-a923-384ef2460425
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:12:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:13:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:13:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b61b2a53-0bed-457a-a0fe-6e7c9a523e23
01/31/2025 08:13:28:INFO:Received: evaluate message b61b2a53-0bed-457a-a0fe-6e7c9a523e23
[92mINFO [0m:      Sent reply
01/31/2025 08:13:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:14:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:14:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 921e7808-201e-49e1-b8c9-e036258a00bd
01/31/2025 08:14:08:INFO:Received: train message 921e7808-201e-49e1-b8c9-e036258a00bd
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:14:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:15:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:15:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4e9e3446-9824-4e2a-a914-893bcba10e42
01/31/2025 08:15:04:INFO:Received: evaluate message 4e9e3446-9824-4e2a-a914-893bcba10e42
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 20.0, target_epsilon: 20.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969], 'accuracy': [0.5183737294761532], 'auc': [0.7379489183581498]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479], 'accuracy': [0.5183737294761532, 0.5222830336200156], 'auc': [0.7379489183581498, 0.7546630873005361]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:15:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:15:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:15:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3a351c0e-f4df-4d94-abea-8c55de9c4417
01/31/2025 08:15:47:INFO:Received: train message 3a351c0e-f4df-4d94-abea-8c55de9c4417
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:16:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:17:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:17:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c28fe7bd-8e2e-4f4d-8cb9-097998230f56
01/31/2025 08:17:00:INFO:Received: evaluate message c28fe7bd-8e2e-4f4d-8cb9-097998230f56
[92mINFO [0m:      Sent reply
01/31/2025 08:17:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:17:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:17:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 030b4e71-aedd-4f68-8a9d-8a7d531c01be
01/31/2025 08:17:35:INFO:Received: train message 030b4e71-aedd-4f68-8a9d-8a7d531c01be
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:18:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:18:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:18:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message faaf65c7-ff85-4a53-a79b-d6c9d91a862e
01/31/2025 08:18:59:INFO:Received: evaluate message faaf65c7-ff85-4a53-a79b-d6c9d91a862e
[92mINFO [0m:      Sent reply
01/31/2025 08:19:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:19:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:19:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c188c9da-869d-4928-96c2-e31c4e3d5d2d
01/31/2025 08:19:57:INFO:Received: train message c188c9da-869d-4928-96c2-e31c4e3d5d2d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:20:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:21:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:21:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4c3d5342-da6a-4aeb-8f2d-29450f949725
01/31/2025 08:21:13:INFO:Received: evaluate message 4c3d5342-da6a-4aeb-8f2d-29450f949725
[92mINFO [0m:      Sent reply
01/31/2025 08:21:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:21:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:21:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 94c68842-980b-43b7-866a-8423fdf2629a
01/31/2025 08:21:49:INFO:Received: train message 94c68842-980b-43b7-866a-8423fdf2629a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:22:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:22:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:22:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 774ef1c7-9d05-4f2c-8230-cfc7f0c8d01a
01/31/2025 08:22:47:INFO:Received: evaluate message 774ef1c7-9d05-4f2c-8230-cfc7f0c8d01a
[92mINFO [0m:      Sent reply
01/31/2025 08:22:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:23:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:23:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message af5e51cd-6a88-4a90-b827-413f7c6e9c2e
01/31/2025 08:23:30:INFO:Received: train message af5e51cd-6a88-4a90-b827-413f7c6e9c2e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:23:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:24:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:24:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5b941c9b-cb06-4933-9933-a7e949c3485c
01/31/2025 08:24:25:INFO:Received: evaluate message 5b941c9b-cb06-4933-9933-a7e949c3485c
[92mINFO [0m:      Sent reply
01/31/2025 08:24:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:24:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:24:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message bdc2f7dc-788c-4c28-b59b-a1caea97d73e
01/31/2025 08:24:55:INFO:Received: train message bdc2f7dc-788c-4c28-b59b-a1caea97d73e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:25:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:25:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:25:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7965ec55-72bb-4768-a0dd-5c87ceb6d9c6
01/31/2025 08:25:56:INFO:Received: evaluate message 7965ec55-72bb-4768-a0dd-5c87ceb6d9c6

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:25:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:26:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:26:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2063c10c-0b1c-4b8b-abae-e630a583718a
01/31/2025 08:26:45:INFO:Received: train message 2063c10c-0b1c-4b8b-abae-e630a583718a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:27:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:27:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:27:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e1bfc884-6d7d-4f48-93c5-1b6fff8e6ff2
01/31/2025 08:27:43:INFO:Received: evaluate message e1bfc884-6d7d-4f48-93c5-1b6fff8e6ff2
[92mINFO [0m:      Sent reply
01/31/2025 08:27:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:28:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:28:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3d3d2ce2-2e96-4c35-a73f-46bf0689291e
01/31/2025 08:28:09:INFO:Received: train message 3d3d2ce2-2e96-4c35-a73f-46bf0689291e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:28:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:29:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:29:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5d569330-207c-4afb-9e50-c95a58370583
01/31/2025 08:29:01:INFO:Received: evaluate message 5d569330-207c-4afb-9e50-c95a58370583
[92mINFO [0m:      Sent reply
01/31/2025 08:29:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:29:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:29:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 59fc19a0-0f7e-4aab-991d-064d29a0ef2c
01/31/2025 08:29:40:INFO:Received: train message 59fc19a0-0f7e-4aab-991d-064d29a0ef2c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:29:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:31:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:31:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f7a9f531-5e70-4f2c-8b4b-1d2b65b06b35
01/31/2025 08:31:03:INFO:Received: evaluate message f7a9f531-5e70-4f2c-8b4b-1d2b65b06b35
[92mINFO [0m:      Sent reply
01/31/2025 08:31:05:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:31:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:31:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 16a9fcc0-b2c9-4513-bb6a-d76e18b64036
01/31/2025 08:31:18:INFO:Received: train message 16a9fcc0-b2c9-4513-bb6a-d76e18b64036
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:31:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:32:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:32:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3a2b8d61-f838-43a3-af36-772a06e7d3be
01/31/2025 08:32:17:INFO:Received: evaluate message 3a2b8d61-f838-43a3-af36-772a06e7d3be
[92mINFO [0m:      Sent reply
01/31/2025 08:32:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:32:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:32:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e42824e5-010c-40e2-a393-70aead0daff4
01/31/2025 08:32:55:INFO:Received: train message e42824e5-010c-40e2-a393-70aead0daff4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:33:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:34:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:34:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b0c2c4e7-307c-4f55-89b7-6d8beb985e9b
01/31/2025 08:34:44:INFO:Received: evaluate message b0c2c4e7-307c-4f55-89b7-6d8beb985e9b

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:34:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:35:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:35:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f8da6d8d-a5b4-458d-9a5e-e6465b765672
01/31/2025 08:35:34:INFO:Received: train message f8da6d8d-a5b4-458d-9a5e-e6465b765672
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:36:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:36:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:36:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0bdd8c31-0293-4b7d-8a42-0c306f07f7ad
01/31/2025 08:36:58:INFO:Received: evaluate message 0bdd8c31-0293-4b7d-8a42-0c306f07f7ad
[92mINFO [0m:      Sent reply
01/31/2025 08:37:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:37:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:37:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5b0dba70-5549-4ca6-838b-f700433762d2
01/31/2025 08:37:23:INFO:Received: train message 5b0dba70-5549-4ca6-838b-f700433762d2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:37:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:38:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:38:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d2d0f015-6f9b-4192-8fdf-074880bb852e
01/31/2025 08:38:43:INFO:Received: evaluate message d2d0f015-6f9b-4192-8fdf-074880bb852e
[92mINFO [0m:      Sent reply
01/31/2025 08:38:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:39:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:39:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ced08a58-99b6-48dc-912f-87f96bc4f4f5
01/31/2025 08:39:13:INFO:Received: train message ced08a58-99b6-48dc-912f-87f96bc4f4f5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:39:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:40:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:40:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 720794a7-0bfc-42b8-9446-8b57f6977651
01/31/2025 08:40:18:INFO:Received: evaluate message 720794a7-0bfc-42b8-9446-8b57f6977651
[92mINFO [0m:      Sent reply
01/31/2025 08:40:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:40:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:40:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e95508b0-27d5-4dfa-b5ed-a98f8f1f8c20
01/31/2025 08:40:40:INFO:Received: train message e95508b0-27d5-4dfa-b5ed-a98f8f1f8c20
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:40:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:41:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:41:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 295c52dc-5733-4b50-837b-56f30dacfc0f
01/31/2025 08:41:54:INFO:Received: evaluate message 295c52dc-5733-4b50-837b-56f30dacfc0f

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:41:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:42:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:42:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ccaa0d63-a9bf-4f02-bdaa-26b58d846d67
01/31/2025 08:42:13:INFO:Received: train message ccaa0d63-a9bf-4f02-bdaa-26b58d846d67
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:42:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:43:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:43:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c17980ca-c949-4fc2-a300-980f5c09af2e
01/31/2025 08:43:30:INFO:Received: evaluate message c17980ca-c949-4fc2-a300-980f5c09af2e
[92mINFO [0m:      Sent reply
01/31/2025 08:43:32:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:44:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:44:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8adc9632-a607-4db4-8ab5-206492896a3b
01/31/2025 08:44:05:INFO:Received: train message 8adc9632-a607-4db4-8ab5-206492896a3b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:44:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:44:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:44:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 489e1bef-debd-4de2-8004-47dab513a2cb
01/31/2025 08:44:56:INFO:Received: evaluate message 489e1bef-debd-4de2-8004-47dab513a2cb
[92mINFO [0m:      Sent reply
01/31/2025 08:44:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:45:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:45:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 22687d84-7750-4d0b-a74f-9f77eb3067ef
01/31/2025 08:45:34:INFO:Received: train message 22687d84-7750-4d0b-a74f-9f77eb3067ef
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:45:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:46:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:46:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c6ee7e62-c7d9-4461-839a-9526aec40c24
01/31/2025 08:46:43:INFO:Received: evaluate message c6ee7e62-c7d9-4461-839a-9526aec40c24
[92mINFO [0m:      Sent reply
01/31/2025 08:46:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:47:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:47:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fbb7f5ee-2005-49ed-b101-16b9f1cdb27c
01/31/2025 08:47:29:INFO:Received: train message fbb7f5ee-2005-49ed-b101-16b9f1cdb27c

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:47:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:49:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:49:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6f9b0fcb-5678-4ac8-ac2a-a37e446ad71c
01/31/2025 08:49:04:INFO:Received: evaluate message 6f9b0fcb-5678-4ac8-ac2a-a37e446ad71c
[92mINFO [0m:      Sent reply
01/31/2025 08:49:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:49:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:49:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 71ae53b6-7fc1-48a2-ac75-d945464c5b7f
01/31/2025 08:49:32:INFO:Received: train message 71ae53b6-7fc1-48a2-ac75-d945464c5b7f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:50:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:51:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:51:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0d987e6d-e41c-452d-955c-db3a19623855
01/31/2025 08:51:12:INFO:Received: evaluate message 0d987e6d-e41c-452d-955c-db3a19623855
[92mINFO [0m:      Sent reply
01/31/2025 08:51:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:52:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:52:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0138d755-be2d-4dca-95ae-75e04c2e26cc
01/31/2025 08:52:02:INFO:Received: train message 0138d755-be2d-4dca-95ae-75e04c2e26cc
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:52:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:53:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:53:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5ae89f2d-dc5a-4fe8-83cf-5ee0ebde6107
01/31/2025 08:53:01:INFO:Received: evaluate message 5ae89f2d-dc5a-4fe8-83cf-5ee0ebde6107
[92mINFO [0m:      Sent reply
01/31/2025 08:53:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:53:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:53:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message dfe525f4-2da8-42ec-8c31-dbc65b5ce4e5
01/31/2025 08:53:07:INFO:Received: reconnect message dfe525f4-2da8-42ec-8c31-dbc65b5ce4e5
01/31/2025 08:53:07:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 08:53:07:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399, 1.0146706239891947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817, 0.8129905939058173]}



Final client history:
{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399, 1.0146706239891947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817, 0.8129905939058173]}

