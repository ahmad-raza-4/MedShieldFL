nohup: ignoring input
01/31/2025 07:00:12:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 07:00:12:DEBUG:ChannelConnectivity.IDLE
01/31/2025 07:00:12:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 07:00:13:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 07:00:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:00:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8b6811a0-4bf9-46cf-9608-468185d0b276
01/31/2025 07:00:49:INFO:Received: train message 8b6811a0-4bf9-46cf-9608-468185d0b276
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:01:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:01:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:01:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message dcb9f324-ac1b-45a9-8874-89383db0184a
01/31/2025 07:01:44:INFO:Received: evaluate message dcb9f324-ac1b-45a9-8874-89383db0184a
[92mINFO [0m:      Sent reply
01/31/2025 07:01:47:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:02:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:02:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6df90a14-7ae1-4922-a01c-926664f25e35
01/31/2025 07:02:41:INFO:Received: train message 6df90a14-7ae1-4922-a01c-926664f25e35
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:03:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:03:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:03:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a8fc620f-1175-4363-9d8b-9828a6ef212c
01/31/2025 07:03:44:INFO:Received: evaluate message a8fc620f-1175-4363-9d8b-9828a6ef212c
[92mINFO [0m:      Sent reply
01/31/2025 07:03:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:04:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:04:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ede172ff-1d61-4328-822d-4d808591f112
01/31/2025 07:04:19:INFO:Received: train message ede172ff-1d61-4328-822d-4d808591f112
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:04:39:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:05:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:05:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e4337d99-6691-4d89-b582-4294b0859349
01/31/2025 07:05:37:INFO:Received: evaluate message e4337d99-6691-4d89-b582-4294b0859349
[92mINFO [0m:      Sent reply
01/31/2025 07:05:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:06:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:06:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9bfeee73-7c7e-4579-93f0-c94ef239fe54
01/31/2025 07:06:01:INFO:Received: train message 9bfeee73-7c7e-4579-93f0-c94ef239fe54
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:06:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:07:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:07:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d43b2757-8517-40fd-8683-3152cf73e06c
01/31/2025 07:07:20:INFO:Received: evaluate message d43b2757-8517-40fd-8683-3152cf73e06c
[92mINFO [0m:      Sent reply
01/31/2025 07:07:23:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:07:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:07:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0a12783c-dbd7-4c36-8888-de3a7f298b26
01/31/2025 07:07:49:INFO:Received: train message 0a12783c-dbd7-4c36-8888-de3a7f298b26
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:08:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:09:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:09:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9f369e4d-0814-402a-bd2f-1273458d2dfc
01/31/2025 07:09:07:INFO:Received: evaluate message 9f369e4d-0814-402a-bd2f-1273458d2dfc
[92mINFO [0m:      Sent reply
01/31/2025 07:09:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:09:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:09:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 276c5a8c-afa3-41d6-b18e-a93902fcb641
01/31/2025 07:09:53:INFO:Received: train message 276c5a8c-afa3-41d6-b18e-a93902fcb641
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:10:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:11:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:11:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8441d0ed-2997-439f-b4ee-a43219c9dc3a
01/31/2025 07:11:18:INFO:Received: evaluate message 8441d0ed-2997-439f-b4ee-a43219c9dc3a
[92mINFO [0m:      Sent reply
01/31/2025 07:11:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:11:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:11:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message efafa701-eed7-4898-9d7e-46594f99bbf9
01/31/2025 07:11:49:INFO:Received: train message efafa701-eed7-4898-9d7e-46594f99bbf9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:12:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:13:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:13:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2e380c6a-083f-4618-a657-1b65b4138329
01/31/2025 07:13:27:INFO:Received: evaluate message 2e380c6a-083f-4618-a657-1b65b4138329
[92mINFO [0m:      Sent reply
01/31/2025 07:13:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:13:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:13:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b2d45aec-0660-41c5-9411-30683dc0227f
01/31/2025 07:13:59:INFO:Received: train message b2d45aec-0660-41c5-9411-30683dc0227f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:14:26:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:15:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:15:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 144d8cdd-a002-40c1-810c-35198133554e
01/31/2025 07:15:05:INFO:Received: evaluate message 144d8cdd-a002-40c1-810c-35198133554e
[92mINFO [0m:      Sent reply
01/31/2025 07:15:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:15:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:15:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cfd35320-49f0-4663-a025-a76747e5a5b6
01/31/2025 07:15:55:INFO:Received: train message cfd35320-49f0-4663-a025-a76747e5a5b6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:16:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:17:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:17:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message dc16b103-a319-440a-b65d-81a24bd2576c
01/31/2025 07:17:15:INFO:Received: evaluate message dc16b103-a319-440a-b65d-81a24bd2576c
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 10.0, target_epsilon: 10.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148], 'accuracy': [0.5207193119624707], 'auc': [0.7293562379614749]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048], 'accuracy': [0.5207193119624707, 0.5254104769351056], 'auc': [0.7293562379614749, 0.7490635742179705]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:17:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:17:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:17:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7813963a-83ac-40f2-937a-9268e11e342e
01/31/2025 07:17:48:INFO:Received: train message 7813963a-83ac-40f2-937a-9268e11e342e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:18:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:18:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:18:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f0c40121-e5b0-48cf-995c-e6325794f0f9
01/31/2025 07:18:57:INFO:Received: evaluate message f0c40121-e5b0-48cf-995c-e6325794f0f9
[92mINFO [0m:      Sent reply
01/31/2025 07:19:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:19:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:19:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9e7d9172-9548-4199-b7cc-fcea44b2c1ec
01/31/2025 07:19:36:INFO:Received: train message 9e7d9172-9548-4199-b7cc-fcea44b2c1ec
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:20:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:20:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:20:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0260963b-7412-4882-9d0d-980cca47c74e
01/31/2025 07:20:26:INFO:Received: evaluate message 0260963b-7412-4882-9d0d-980cca47c74e
[92mINFO [0m:      Sent reply
01/31/2025 07:20:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:20:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:20:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3d238689-ff12-44f5-a53b-a82dbc78a231
01/31/2025 07:20:54:INFO:Received: train message 3d238689-ff12-44f5-a53b-a82dbc78a231
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:21:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:22:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:22:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6c3f1af2-bd9e-4169-8526-7938f8290afa
01/31/2025 07:22:05:INFO:Received: evaluate message 6c3f1af2-bd9e-4169-8526-7938f8290afa
[92mINFO [0m:      Sent reply
01/31/2025 07:22:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:22:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:22:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7cda5688-6e87-4a88-8b12-579c35fed8ef
01/31/2025 07:22:58:INFO:Received: train message 7cda5688-6e87-4a88-8b12-579c35fed8ef
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:23:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:24:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:24:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d7ad2897-af4c-44ef-a6c2-4d06f67b2183
01/31/2025 07:24:04:INFO:Received: evaluate message d7ad2897-af4c-44ef-a6c2-4d06f67b2183
[92mINFO [0m:      Sent reply
01/31/2025 07:24:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:24:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:24:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 08155a99-b6a4-4567-b081-2a9e007c8c9d
01/31/2025 07:24:55:INFO:Received: train message 08155a99-b6a4-4567-b081-2a9e007c8c9d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:25:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:26:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:26:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5223475b-f4ce-4831-be1b-c7e25278e4ac
01/31/2025 07:26:02:INFO:Received: evaluate message 5223475b-f4ce-4831-be1b-c7e25278e4ac
[92mINFO [0m:      Sent reply
01/31/2025 07:26:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:26:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:26:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d0da2bb0-6e31-4e88-b77f-8edd2dfa240a
01/31/2025 07:26:53:INFO:Received: train message d0da2bb0-6e31-4e88-b77f-8edd2dfa240a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:27:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:28:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:28:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 928414cd-417e-44c6-8d63-d3acbc99b1ce
01/31/2025 07:28:04:INFO:Received: evaluate message 928414cd-417e-44c6-8d63-d3acbc99b1ce

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:28:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:28:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:28:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9dcafc98-027e-44de-ab1d-f87a0146362f
01/31/2025 07:28:49:INFO:Received: train message 9dcafc98-027e-44de-ab1d-f87a0146362f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:29:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:30:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:30:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message baf88309-26f6-42e9-9175-3fda1cc80895
01/31/2025 07:30:06:INFO:Received: evaluate message baf88309-26f6-42e9-9175-3fda1cc80895
[92mINFO [0m:      Sent reply
01/31/2025 07:30:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:30:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:30:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ed7c8640-dbf5-4f9e-ae02-e9dbd148f57a
01/31/2025 07:30:52:INFO:Received: train message ed7c8640-dbf5-4f9e-ae02-e9dbd148f57a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:31:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:32:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:32:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8ca9c5bf-85e2-40df-a030-20dde3a6f875
01/31/2025 07:32:01:INFO:Received: evaluate message 8ca9c5bf-85e2-40df-a030-20dde3a6f875
[92mINFO [0m:      Sent reply
01/31/2025 07:32:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:32:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:32:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 705adc45-1471-470e-aef2-bd6d6a0d3325
01/31/2025 07:32:34:INFO:Received: train message 705adc45-1471-470e-aef2-bd6d6a0d3325
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:32:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:33:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:33:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5b349419-18bd-4531-a612-cc01d5ed7c92
01/31/2025 07:33:38:INFO:Received: evaluate message 5b349419-18bd-4531-a612-cc01d5ed7c92
[92mINFO [0m:      Sent reply
01/31/2025 07:33:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:34:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:34:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3eac7bd0-8051-435e-b407-91fbb78fd868
01/31/2025 07:34:10:INFO:Received: train message 3eac7bd0-8051-435e-b407-91fbb78fd868
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:34:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:35:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:35:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f3923f4d-0470-49ff-aaab-2e0a48cd5e69
01/31/2025 07:35:16:INFO:Received: evaluate message f3923f4d-0470-49ff-aaab-2e0a48cd5e69
[92mINFO [0m:      Sent reply
01/31/2025 07:35:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:35:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:35:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d5337edb-380c-44dd-ad8e-028edfc18513
01/31/2025 07:35:40:INFO:Received: train message d5337edb-380c-44dd-ad8e-028edfc18513
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:36:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:36:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:36:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e8119420-4657-476f-a3a2-147e0cf5d4f1
01/31/2025 07:36:36:INFO:Received: evaluate message e8119420-4657-476f-a3a2-147e0cf5d4f1

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:36:38:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:37:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:37:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8a2e1e46-eeb7-4331-b10d-089bd0c8760b
01/31/2025 07:37:13:INFO:Received: train message 8a2e1e46-eeb7-4331-b10d-089bd0c8760b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:37:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:38:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:38:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message cc2b84dc-2a7f-4c08-9dc7-d84aa739427e
01/31/2025 07:38:33:INFO:Received: evaluate message cc2b84dc-2a7f-4c08-9dc7-d84aa739427e
[92mINFO [0m:      Sent reply
01/31/2025 07:38:37:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:39:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:39:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e5c77811-20de-4049-bfdf-77d36e837ae4
01/31/2025 07:39:18:INFO:Received: train message e5c77811-20de-4049-bfdf-77d36e837ae4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:39:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:40:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:40:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 72933cad-577d-4688-a6c3-60050c4067f3
01/31/2025 07:40:17:INFO:Received: evaluate message 72933cad-577d-4688-a6c3-60050c4067f3
[92mINFO [0m:      Sent reply
01/31/2025 07:40:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:40:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:40:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4ccec090-9ad0-4d5e-b3ae-f18b6abcdb55
01/31/2025 07:40:58:INFO:Received: train message 4ccec090-9ad0-4d5e-b3ae-f18b6abcdb55
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:41:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:41:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:41:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0aff16f5-42df-4886-aae2-5628b70b9fc1
01/31/2025 07:41:48:INFO:Received: evaluate message 0aff16f5-42df-4886-aae2-5628b70b9fc1
[92mINFO [0m:      Sent reply
01/31/2025 07:41:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:42:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:42:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message afa13442-0669-451c-917c-693824d4e745
01/31/2025 07:42:31:INFO:Received: train message afa13442-0669-451c-917c-693824d4e745
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:42:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:43:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:43:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 70a787ba-8cb9-463c-b5ca-83943937db79
01/31/2025 07:43:31:INFO:Received: evaluate message 70a787ba-8cb9-463c-b5ca-83943937db79

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:43:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:44:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:44:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c7655bd5-be69-4c02-85ec-e7bd73ae1975
01/31/2025 07:44:37:INFO:Received: train message c7655bd5-be69-4c02-85ec-e7bd73ae1975
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:45:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:46:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:46:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a993d628-8c7f-4a97-8760-f69cdf00d2a9
01/31/2025 07:46:06:INFO:Received: evaluate message a993d628-8c7f-4a97-8760-f69cdf00d2a9
[92mINFO [0m:      Sent reply
01/31/2025 07:46:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:46:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:46:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1eca760f-af38-4669-81a5-5014a5de0bb9
01/31/2025 07:46:34:INFO:Received: train message 1eca760f-af38-4669-81a5-5014a5de0bb9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:47:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:47:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:47:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 430be248-dca1-4883-a172-3a280ada10a5
01/31/2025 07:47:58:INFO:Received: evaluate message 430be248-dca1-4883-a172-3a280ada10a5
[92mINFO [0m:      Sent reply
01/31/2025 07:48:01:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:48:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:48:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 667cb192-70cb-4fd9-b640-0988798f4ad1
01/31/2025 07:48:46:INFO:Received: train message 667cb192-70cb-4fd9-b640-0988798f4ad1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:49:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:50:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:50:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 52e59f90-6ea1-4777-8260-c49a42204b2d
01/31/2025 07:50:17:INFO:Received: evaluate message 52e59f90-6ea1-4777-8260-c49a42204b2d
[92mINFO [0m:      Sent reply
01/31/2025 07:50:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:50:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:50:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 682c8c82-6422-4083-a0d4-2ac33be98a8c
01/31/2025 07:50:48:INFO:Received: train message 682c8c82-6422-4083-a0d4-2ac33be98a8c

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:51:23:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:52:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:52:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 62bb9030-a713-438c-982d-af56f990debb
01/31/2025 07:52:06:INFO:Received: evaluate message 62bb9030-a713-438c-982d-af56f990debb
[92mINFO [0m:      Sent reply
01/31/2025 07:52:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:52:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:52:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 48017582-8261-4796-8e06-da357939e49b
01/31/2025 07:52:50:INFO:Received: train message 48017582-8261-4796-8e06-da357939e49b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:53:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:53:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:53:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message db3f73bd-2546-451a-a4d2-669ce8999910
01/31/2025 07:53:40:INFO:Received: evaluate message db3f73bd-2546-451a-a4d2-669ce8999910
[92mINFO [0m:      Sent reply
01/31/2025 07:53:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:54:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:54:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d50e710b-9a38-46c6-86a1-58ccc57f81f6
01/31/2025 07:54:14:INFO:Received: train message d50e710b-9a38-46c6-86a1-58ccc57f81f6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:54:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:55:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:55:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5c877f80-67a1-4231-8458-d653c432d89d
01/31/2025 07:55:39:INFO:Received: evaluate message 5c877f80-67a1-4231-8458-d653c432d89d
[92mINFO [0m:      Sent reply
01/31/2025 07:55:41:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:55:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:55:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message 7ef76edb-b965-48ee-9dbf-0ecaeb72965d
01/31/2025 07:55:41:INFO:Received: reconnect message 7ef76edb-b965-48ee-9dbf-0ecaeb72965d
01/31/2025 07:55:41:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 07:55:41:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348, 1.0159809038543999], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286, 0.5989053948397185], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871, 0.8120961426383593]}



Final client history:
{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348, 1.0159809038543999], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286, 0.5989053948397185], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871, 0.8120961426383593]}

