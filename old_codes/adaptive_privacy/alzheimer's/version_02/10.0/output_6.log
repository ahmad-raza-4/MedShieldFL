nohup: ignoring input
01/31/2025 07:00:12:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 07:00:12:DEBUG:ChannelConnectivity.IDLE
01/31/2025 07:00:12:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 07:00:12:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 07:00:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:00:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 21627428-7ed2-4f8f-8af7-babfe3cf5ed3
01/31/2025 07:00:47:INFO:Received: train message 21627428-7ed2-4f8f-8af7-babfe3cf5ed3
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:01:13:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:02:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:02:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9f8b4bcc-ae62-4b64-8274-cdc697e976cd
01/31/2025 07:02:02:INFO:Received: evaluate message 9f8b4bcc-ae62-4b64-8274-cdc697e976cd
[92mINFO [0m:      Sent reply
01/31/2025 07:02:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:02:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:02:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5a09eb91-8b4e-4bb8-bc87-18317d7c261e
01/31/2025 07:02:49:INFO:Received: train message 5a09eb91-8b4e-4bb8-bc87-18317d7c261e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:03:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:03:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:03:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ae5f3ac7-54d6-4143-b122-c2a61a744e31
01/31/2025 07:03:58:INFO:Received: evaluate message ae5f3ac7-54d6-4143-b122-c2a61a744e31
[92mINFO [0m:      Sent reply
01/31/2025 07:04:01:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:04:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:04:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 295e522b-3a69-43d3-8f5b-89f2b1375be2
01/31/2025 07:04:34:INFO:Received: train message 295e522b-3a69-43d3-8f5b-89f2b1375be2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:04:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:05:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:05:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 473e9d23-0311-4c33-97f5-8f849d1223d9
01/31/2025 07:05:40:INFO:Received: evaluate message 473e9d23-0311-4c33-97f5-8f849d1223d9
[92mINFO [0m:      Sent reply
01/31/2025 07:05:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:06:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:06:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 63161f03-6a10-460d-8655-95726fb220a4
01/31/2025 07:06:18:INFO:Received: train message 63161f03-6a10-460d-8655-95726fb220a4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:06:38:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:07:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:07:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c0a8ceb3-7856-499d-bca3-f8461be5745d
01/31/2025 07:07:27:INFO:Received: evaluate message c0a8ceb3-7856-499d-bca3-f8461be5745d
[92mINFO [0m:      Sent reply
01/31/2025 07:07:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:08:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:08:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b3088c9c-2b78-42bd-9212-0fdc1e2b4d0b
01/31/2025 07:08:03:INFO:Received: train message b3088c9c-2b78-42bd-9212-0fdc1e2b4d0b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:08:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:09:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:09:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9a3091ac-26bd-4e25-b1d9-6f470708034d
01/31/2025 07:09:04:INFO:Received: evaluate message 9a3091ac-26bd-4e25-b1d9-6f470708034d
[92mINFO [0m:      Sent reply
01/31/2025 07:09:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:09:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:09:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 941999ce-54d7-4e30-8dce-f5bf0b695574
01/31/2025 07:09:46:INFO:Received: train message 941999ce-54d7-4e30-8dce-f5bf0b695574
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:10:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:11:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:11:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ea38d75f-1ef9-4521-9c63-bdd4e98ca80c
01/31/2025 07:11:03:INFO:Received: evaluate message ea38d75f-1ef9-4521-9c63-bdd4e98ca80c
[92mINFO [0m:      Sent reply
01/31/2025 07:11:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:11:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:11:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ca9f9eab-fb43-46af-b639-8e090d95429a
01/31/2025 07:11:53:INFO:Received: train message ca9f9eab-fb43-46af-b639-8e090d95429a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:12:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:13:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:13:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fe209922-5ff4-4a74-a4c4-67cac3643b4a
01/31/2025 07:13:34:INFO:Received: evaluate message fe209922-5ff4-4a74-a4c4-67cac3643b4a
[92mINFO [0m:      Sent reply
01/31/2025 07:13:37:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:14:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:14:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 24dfdbb7-acaf-4302-a89d-1afec097840a
01/31/2025 07:14:19:INFO:Received: train message 24dfdbb7-acaf-4302-a89d-1afec097840a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:14:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:15:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:15:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4477ec96-3860-40d8-a32e-e948e1f54615
01/31/2025 07:15:28:INFO:Received: evaluate message 4477ec96-3860-40d8-a32e-e948e1f54615
[92mINFO [0m:      Sent reply
01/31/2025 07:15:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:15:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:15:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 071b9037-ad43-4962-97aa-bfed0d246000
01/31/2025 07:15:49:INFO:Received: train message 071b9037-ad43-4962-97aa-bfed0d246000
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:16:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:17:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:17:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f3912f12-6810-4260-a28a-4dc560e3257a
01/31/2025 07:17:18:INFO:Received: evaluate message f3912f12-6810-4260-a28a-4dc560e3257a
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 10.0, target_epsilon: 10.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148], 'accuracy': [0.5207193119624707], 'auc': [0.7293562379614749]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048], 'accuracy': [0.5207193119624707, 0.5254104769351056], 'auc': [0.7293562379614749, 0.7490635742179705]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:17:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:17:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:17:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2a6b99e3-3d21-461f-b1cd-a5d3f7bb66bd
01/31/2025 07:17:48:INFO:Received: train message 2a6b99e3-3d21-461f-b1cd-a5d3f7bb66bd
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:18:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:18:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:18:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message df099b45-20e0-4bd2-b842-8d58235521c4
01/31/2025 07:18:58:INFO:Received: evaluate message df099b45-20e0-4bd2-b842-8d58235521c4
[92mINFO [0m:      Sent reply
01/31/2025 07:19:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:19:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:19:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ffe802ed-6edf-4aa5-808a-d7f785b70fd6
01/31/2025 07:19:36:INFO:Received: train message ffe802ed-6edf-4aa5-808a-d7f785b70fd6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:20:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:20:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:20:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0dbd5c71-0b4d-48e5-93f3-079b87da3044
01/31/2025 07:20:31:INFO:Received: evaluate message 0dbd5c71-0b4d-48e5-93f3-079b87da3044
[92mINFO [0m:      Sent reply
01/31/2025 07:20:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:21:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:21:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 96776155-f8ea-4baf-a673-347840866ca4
01/31/2025 07:21:01:INFO:Received: train message 96776155-f8ea-4baf-a673-347840866ca4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:21:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:22:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:22:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 276d6eca-67a9-48e8-ba6e-3b1e1a59f16b
01/31/2025 07:22:20:INFO:Received: evaluate message 276d6eca-67a9-48e8-ba6e-3b1e1a59f16b
[92mINFO [0m:      Sent reply
01/31/2025 07:22:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:22:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:22:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 99013126-5581-4fe6-8062-41773e457e8c
01/31/2025 07:22:48:INFO:Received: train message 99013126-5581-4fe6-8062-41773e457e8c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:23:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:24:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:24:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 25a787bd-1278-49d4-8ad2-7e493f540dc7
01/31/2025 07:24:12:INFO:Received: evaluate message 25a787bd-1278-49d4-8ad2-7e493f540dc7
[92mINFO [0m:      Sent reply
01/31/2025 07:24:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:24:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:24:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 70699693-1a20-42bd-88dd-65804ace69b1
01/31/2025 07:24:36:INFO:Received: train message 70699693-1a20-42bd-88dd-65804ace69b1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:25:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:26:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:26:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3e8b723c-858c-4346-90b1-582ee1daa3de
01/31/2025 07:26:11:INFO:Received: evaluate message 3e8b723c-858c-4346-90b1-582ee1daa3de
[92mINFO [0m:      Sent reply
01/31/2025 07:26:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:26:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:26:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ffa337fe-f0b8-40cc-ab84-a3646e8f350b
01/31/2025 07:26:42:INFO:Received: train message ffa337fe-f0b8-40cc-ab84-a3646e8f350b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:27:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:28:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:28:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d5ab1262-be67-4e68-9364-182222e38dfc
01/31/2025 07:28:10:INFO:Received: evaluate message d5ab1262-be67-4e68-9364-182222e38dfc

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:28:13:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:28:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:28:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f256c16f-5b5c-4cf7-b4e0-d5320ef33b14
01/31/2025 07:28:53:INFO:Received: train message f256c16f-5b5c-4cf7-b4e0-d5320ef33b14
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:29:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:29:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:29:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 71d4557c-b2f7-4854-a160-6e6bb0c0d088
01/31/2025 07:29:57:INFO:Received: evaluate message 71d4557c-b2f7-4854-a160-6e6bb0c0d088
[92mINFO [0m:      Sent reply
01/31/2025 07:29:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:30:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:30:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 67d78ce3-e675-44d6-b0ef-560e0c99fa23
01/31/2025 07:30:50:INFO:Received: train message 67d78ce3-e675-44d6-b0ef-560e0c99fa23
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:31:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:31:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:31:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 74004500-2d79-4b73-a655-ed6a35894d8b
01/31/2025 07:31:55:INFO:Received: evaluate message 74004500-2d79-4b73-a655-ed6a35894d8b
[92mINFO [0m:      Sent reply
01/31/2025 07:31:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:32:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:32:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f30fdba2-6af2-42dd-b30d-33fa5dc5b972
01/31/2025 07:32:25:INFO:Received: train message f30fdba2-6af2-42dd-b30d-33fa5dc5b972
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:32:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:33:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:33:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1a7040d1-7ce5-404c-bc54-cc73a70b851b
01/31/2025 07:33:38:INFO:Received: evaluate message 1a7040d1-7ce5-404c-bc54-cc73a70b851b
[92mINFO [0m:      Sent reply
01/31/2025 07:33:41:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:34:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:34:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 62923a08-a7ab-4a17-aab4-d0712be44127
01/31/2025 07:34:07:INFO:Received: train message 62923a08-a7ab-4a17-aab4-d0712be44127
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:34:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:35:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:35:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a88b31e0-988b-4fb6-b393-714ea62d8ef0
01/31/2025 07:35:18:INFO:Received: evaluate message a88b31e0-988b-4fb6-b393-714ea62d8ef0
[92mINFO [0m:      Sent reply
01/31/2025 07:35:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:35:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:35:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fdc9a066-c0cd-41c5-9bcd-e1f22667282a
01/31/2025 07:35:49:INFO:Received: train message fdc9a066-c0cd-41c5-9bcd-e1f22667282a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:36:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:36:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:36:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6ddcaf86-bf96-4d6c-9616-65bcc0f672f1
01/31/2025 07:36:55:INFO:Received: evaluate message 6ddcaf86-bf96-4d6c-9616-65bcc0f672f1

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:36:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:37:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:37:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 81ab32ec-1df3-4fca-bd2c-db0e252f6cb1
01/31/2025 07:37:13:INFO:Received: train message 81ab32ec-1df3-4fca-bd2c-db0e252f6cb1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:37:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:38:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:38:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 68bfdefe-03cf-4147-bea2-56efa14c5638
01/31/2025 07:38:34:INFO:Received: evaluate message 68bfdefe-03cf-4147-bea2-56efa14c5638
[92mINFO [0m:      Sent reply
01/31/2025 07:38:38:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:39:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:39:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 45d57857-3aa3-4bbc-baa3-a3f1e9e7d57a
01/31/2025 07:39:20:INFO:Received: train message 45d57857-3aa3-4bbc-baa3-a3f1e9e7d57a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:39:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:40:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:40:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8d870ce9-38e4-4626-b848-1d3672675212
01/31/2025 07:40:23:INFO:Received: evaluate message 8d870ce9-38e4-4626-b848-1d3672675212
[92mINFO [0m:      Sent reply
01/31/2025 07:40:26:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:40:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:40:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ba81d961-22d8-4ca7-8c84-14df2458cc99
01/31/2025 07:40:40:INFO:Received: train message ba81d961-22d8-4ca7-8c84-14df2458cc99
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:41:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:42:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:42:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 08c3f4ef-149d-4965-8d44-a35af2fdc166
01/31/2025 07:42:04:INFO:Received: evaluate message 08c3f4ef-149d-4965-8d44-a35af2fdc166
[92mINFO [0m:      Sent reply
01/31/2025 07:42:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:42:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:42:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f9ee6dd4-0a5c-4e4a-afb2-a4df0b20c08d
01/31/2025 07:42:36:INFO:Received: train message f9ee6dd4-0a5c-4e4a-afb2-a4df0b20c08d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:42:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:43:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:43:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a7722255-2a0c-4942-b89a-76443ff0519f
01/31/2025 07:43:51:INFO:Received: evaluate message a7722255-2a0c-4942-b89a-76443ff0519f

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:43:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:44:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:44:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fc04a25b-3ae7-4a87-9fea-b11046f825c0
01/31/2025 07:44:45:INFO:Received: train message fc04a25b-3ae7-4a87-9fea-b11046f825c0
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:45:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:45:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:45:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ab7a39ed-6661-4100-b5d9-9df2dd51a7dc
01/31/2025 07:45:40:INFO:Received: evaluate message ab7a39ed-6661-4100-b5d9-9df2dd51a7dc
[92mINFO [0m:      Sent reply
01/31/2025 07:45:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:46:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:46:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5578fcb2-a9ae-4a3d-84b7-247f836f2ce3
01/31/2025 07:46:49:INFO:Received: train message 5578fcb2-a9ae-4a3d-84b7-247f836f2ce3
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:47:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:48:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:48:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e30a4f6f-f1b8-4f3f-873a-3bd40f72ee89
01/31/2025 07:48:13:INFO:Received: evaluate message e30a4f6f-f1b8-4f3f-873a-3bd40f72ee89
[92mINFO [0m:      Sent reply
01/31/2025 07:48:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:49:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:49:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ba259391-720f-42c7-8bbf-15ece52511b3
01/31/2025 07:49:01:INFO:Received: train message ba259391-720f-42c7-8bbf-15ece52511b3
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:49:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:50:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:50:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8ee9ac5d-2360-4d47-86a6-89984facc6e9
01/31/2025 07:50:16:INFO:Received: evaluate message 8ee9ac5d-2360-4d47-86a6-89984facc6e9
[92mINFO [0m:      Sent reply
01/31/2025 07:50:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:51:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:51:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d49fa8a7-e840-47a2-bf83-84b26846ec07
01/31/2025 07:51:06:INFO:Received: train message d49fa8a7-e840-47a2-bf83-84b26846ec07

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:51:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:52:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:52:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message add61937-8b68-416d-96d2-82f6e2fbb124
01/31/2025 07:52:12:INFO:Received: evaluate message add61937-8b68-416d-96d2-82f6e2fbb124
[92mINFO [0m:      Sent reply
01/31/2025 07:52:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:52:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:52:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b9966f5b-d154-4c74-a471-42b1616874aa
01/31/2025 07:52:44:INFO:Received: train message b9966f5b-d154-4c74-a471-42b1616874aa
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:53:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:53:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:53:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 64674157-bfd2-419d-afcc-13b0ae2946ae
01/31/2025 07:53:56:INFO:Received: evaluate message 64674157-bfd2-419d-afcc-13b0ae2946ae
[92mINFO [0m:      Sent reply
01/31/2025 07:53:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:54:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:54:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message bf49682c-1afb-43b9-87e8-3e29cc752a7b
01/31/2025 07:54:18:INFO:Received: train message bf49682c-1afb-43b9-87e8-3e29cc752a7b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:54:39:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:55:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:55:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 99934c9d-958b-4afd-8c01-bb0d472b8d3b
01/31/2025 07:55:25:INFO:Received: evaluate message 99934c9d-958b-4afd-8c01-bb0d472b8d3b
[92mINFO [0m:      Sent reply
01/31/2025 07:55:26:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:55:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:55:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message b19e8f04-162d-4897-9490-19a2b6034a8f
01/31/2025 07:55:41:INFO:Received: reconnect message b19e8f04-162d-4897-9490-19a2b6034a8f
01/31/2025 07:55:41:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 07:55:41:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 591, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348, 1.0159809038543999], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286, 0.5989053948397185], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871, 0.8120961426383593]}



Final client history:
{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348, 1.0159809038543999], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286, 0.5989053948397185], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871, 0.8120961426383593]}

