nohup: ignoring input
01/31/2025 07:00:15:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 07:00:15:DEBUG:ChannelConnectivity.IDLE
01/31/2025 07:00:15:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 07:00:15:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 07:00:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:00:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 205bd163-74c4-41d7-9ed2-6e3e2c700943
01/31/2025 07:00:47:INFO:Received: train message 205bd163-74c4-41d7-9ed2-6e3e2c700943
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:01:18:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:01:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:01:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d2f25f34-f314-406e-a345-1ef674068991
01/31/2025 07:01:51:INFO:Received: evaluate message d2f25f34-f314-406e-a345-1ef674068991
[92mINFO [0m:      Sent reply
01/31/2025 07:01:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:02:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:02:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7d642c4c-7f2d-44a9-811f-ac74936796aa
01/31/2025 07:02:41:INFO:Received: train message 7d642c4c-7f2d-44a9-811f-ac74936796aa
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:03:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:04:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:04:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2968db47-249f-40b0-bd99-7f3df0124c0d
01/31/2025 07:04:00:INFO:Received: evaluate message 2968db47-249f-40b0-bd99-7f3df0124c0d
[92mINFO [0m:      Sent reply
01/31/2025 07:04:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:04:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:04:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 97e89cc4-9565-4801-b9ad-22d94fe741c7
01/31/2025 07:04:35:INFO:Received: train message 97e89cc4-9565-4801-b9ad-22d94fe741c7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:05:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:05:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:05:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e51d275a-62f9-4e71-b705-95189c06f9a5
01/31/2025 07:05:47:INFO:Received: evaluate message e51d275a-62f9-4e71-b705-95189c06f9a5
[92mINFO [0m:      Sent reply
01/31/2025 07:05:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:06:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:06:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 258175a2-9bfb-435d-b34e-b96f052ec413
01/31/2025 07:06:23:INFO:Received: train message 258175a2-9bfb-435d-b34e-b96f052ec413
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:06:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:07:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:07:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a37c8529-1e23-438d-9b11-20dabd98fc57
01/31/2025 07:07:24:INFO:Received: evaluate message a37c8529-1e23-438d-9b11-20dabd98fc57
[92mINFO [0m:      Sent reply
01/31/2025 07:07:26:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:07:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:07:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9615f359-0baa-42ff-a933-984d886399d7
01/31/2025 07:07:59:INFO:Received: train message 9615f359-0baa-42ff-a933-984d886399d7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:08:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:08:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:08:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 79782681-268d-4729-83cf-9c2aa0aacf2a
01/31/2025 07:08:51:INFO:Received: evaluate message 79782681-268d-4729-83cf-9c2aa0aacf2a
[92mINFO [0m:      Sent reply
01/31/2025 07:08:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:09:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:09:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e2554eb1-3a99-49e8-a01e-ab9bec8b5eb8
01/31/2025 07:09:43:INFO:Received: train message e2554eb1-3a99-49e8-a01e-ab9bec8b5eb8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:10:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:11:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:11:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message bcd703a6-6987-4b16-9b33-b50c41b233f6
01/31/2025 07:11:09:INFO:Received: evaluate message bcd703a6-6987-4b16-9b33-b50c41b233f6
[92mINFO [0m:      Sent reply
01/31/2025 07:11:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:11:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:11:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 88cc6ff6-ea5c-4131-90df-7171dba7fb89
01/31/2025 07:11:53:INFO:Received: train message 88cc6ff6-ea5c-4131-90df-7171dba7fb89
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:12:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:13:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:13:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 023a897d-a0ec-4354-89f9-753c91e21be4
01/31/2025 07:13:32:INFO:Received: evaluate message 023a897d-a0ec-4354-89f9-753c91e21be4
[92mINFO [0m:      Sent reply
01/31/2025 07:13:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:14:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:14:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fd7821df-6c86-40a9-89ba-d8d582f3b942
01/31/2025 07:14:11:INFO:Received: train message fd7821df-6c86-40a9-89ba-d8d582f3b942
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:14:39:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:15:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:15:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5c6dbc64-22fb-4791-86a9-1906331ff454
01/31/2025 07:15:27:INFO:Received: evaluate message 5c6dbc64-22fb-4791-86a9-1906331ff454
[92mINFO [0m:      Sent reply
01/31/2025 07:15:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:16:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:16:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6982bba7-cab0-4fd3-9b57-6cf4db8fcf0b
01/31/2025 07:16:03:INFO:Received: train message 6982bba7-cab0-4fd3-9b57-6cf4db8fcf0b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:16:24:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:17:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:17:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7ba8d53d-2d3f-4d53-ac29-f8b2ffec04ad
01/31/2025 07:17:02:INFO:Received: evaluate message 7ba8d53d-2d3f-4d53-ac29-f8b2ffec04ad
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 10.0, target_epsilon: 10.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148], 'accuracy': [0.5207193119624707], 'auc': [0.7293562379614749]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048], 'accuracy': [0.5207193119624707, 0.5254104769351056], 'auc': [0.7293562379614749, 0.7490635742179705]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:17:05:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:17:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:17:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 93de493c-366f-4959-b9a9-d75013c00ccb
01/31/2025 07:17:56:INFO:Received: train message 93de493c-366f-4959-b9a9-d75013c00ccb
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:18:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:18:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:18:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 29a584fb-5c70-4314-a9e2-7dbef003437f
01/31/2025 07:18:58:INFO:Received: evaluate message 29a584fb-5c70-4314-a9e2-7dbef003437f
[92mINFO [0m:      Sent reply
01/31/2025 07:19:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:19:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:19:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 15630260-932f-4cfa-ad1d-14e245459791
01/31/2025 07:19:23:INFO:Received: train message 15630260-932f-4cfa-ad1d-14e245459791
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:19:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:20:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:20:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 53bb0fad-8406-4f7f-bc33-fc723ad8d38c
01/31/2025 07:20:38:INFO:Received: evaluate message 53bb0fad-8406-4f7f-bc33-fc723ad8d38c
[92mINFO [0m:      Sent reply
01/31/2025 07:20:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:21:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:21:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5bd8b112-c7a2-49a5-9e5d-983706fd07eb
01/31/2025 07:21:11:INFO:Received: train message 5bd8b112-c7a2-49a5-9e5d-983706fd07eb
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:21:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:22:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:22:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message cf5e98eb-8eea-410a-87d1-c20d587f2034
01/31/2025 07:22:11:INFO:Received: evaluate message cf5e98eb-8eea-410a-87d1-c20d587f2034
[92mINFO [0m:      Sent reply
01/31/2025 07:22:13:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:22:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:22:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2f89b22b-6a68-450d-ac9e-20bad466715e
01/31/2025 07:22:54:INFO:Received: train message 2f89b22b-6a68-450d-ac9e-20bad466715e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:23:18:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:24:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:24:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3e19b721-5dbb-462a-8f53-875ea4e8df0f
01/31/2025 07:24:04:INFO:Received: evaluate message 3e19b721-5dbb-462a-8f53-875ea4e8df0f
[92mINFO [0m:      Sent reply
01/31/2025 07:24:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:24:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:24:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9270cbb8-a90d-4f33-8cde-048c82d61aad
01/31/2025 07:24:47:INFO:Received: train message 9270cbb8-a90d-4f33-8cde-048c82d61aad
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:25:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:26:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:26:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fa3730db-0e11-4828-838b-23bbeb4e458d
01/31/2025 07:26:06:INFO:Received: evaluate message fa3730db-0e11-4828-838b-23bbeb4e458d
[92mINFO [0m:      Sent reply
01/31/2025 07:26:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:26:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:26:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a28e61d4-ce0e-418a-b9f9-1eee7944c76d
01/31/2025 07:26:52:INFO:Received: train message a28e61d4-ce0e-418a-b9f9-1eee7944c76d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:27:24:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:28:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:28:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d0d88cf5-503c-49ca-bc98-b6bf86612b04
01/31/2025 07:28:11:INFO:Received: evaluate message d0d88cf5-503c-49ca-bc98-b6bf86612b04

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:28:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:28:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:28:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 233c0c3a-0fc1-4a4c-ac8c-f113a2295b60
01/31/2025 07:28:43:INFO:Received: train message 233c0c3a-0fc1-4a4c-ac8c-f113a2295b60
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:29:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:30:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:30:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c3920ea0-e744-4a0c-970b-92d8ca985188
01/31/2025 07:30:13:INFO:Received: evaluate message c3920ea0-e744-4a0c-970b-92d8ca985188
[92mINFO [0m:      Sent reply
01/31/2025 07:30:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:30:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:30:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7fe39547-d0be-4a6e-a1d9-8232dfbc388a
01/31/2025 07:30:52:INFO:Received: train message 7fe39547-d0be-4a6e-a1d9-8232dfbc388a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:31:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:31:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:31:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d758f567-c93c-4d9a-9ed2-e220f3f631e4
01/31/2025 07:31:46:INFO:Received: evaluate message d758f567-c93c-4d9a-9ed2-e220f3f631e4
[92mINFO [0m:      Sent reply
01/31/2025 07:31:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:32:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:32:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2685cd3f-05b7-438b-bd0e-03b36876dea8
01/31/2025 07:32:35:INFO:Received: train message 2685cd3f-05b7-438b-bd0e-03b36876dea8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:33:01:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:33:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:33:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3b91dfcb-b8a3-4997-a695-4ffd2a6567ec
01/31/2025 07:33:43:INFO:Received: evaluate message 3b91dfcb-b8a3-4997-a695-4ffd2a6567ec
[92mINFO [0m:      Sent reply
01/31/2025 07:33:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:34:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:34:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f1eb47c9-ab39-4e58-b7b2-de7fee566bdf
01/31/2025 07:34:16:INFO:Received: train message f1eb47c9-ab39-4e58-b7b2-de7fee566bdf
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:34:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:35:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:35:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c4664d54-3552-45ea-b831-f13f55c2f973
01/31/2025 07:35:08:INFO:Received: evaluate message c4664d54-3552-45ea-b831-f13f55c2f973
[92mINFO [0m:      Sent reply
01/31/2025 07:35:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:35:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:35:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9dc145c8-5476-43b2-a52c-c03728e321ad
01/31/2025 07:35:51:INFO:Received: train message 9dc145c8-5476-43b2-a52c-c03728e321ad
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:36:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:36:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:36:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9d6764dd-b6a5-4992-bc44-05c345a226bd
01/31/2025 07:36:55:INFO:Received: evaluate message 9d6764dd-b6a5-4992-bc44-05c345a226bd

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:36:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:37:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:37:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fe910fc7-d08b-4d61-afee-59ffafd98390
01/31/2025 07:37:27:INFO:Received: train message fe910fc7-d08b-4d61-afee-59ffafd98390
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:37:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:38:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:38:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 14a2c102-f859-42a4-8e46-ae2577f313d9
01/31/2025 07:38:30:INFO:Received: evaluate message 14a2c102-f859-42a4-8e46-ae2577f313d9
[92mINFO [0m:      Sent reply
01/31/2025 07:38:32:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:39:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:39:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 348abfd2-d041-467c-a904-e569b4f65b9b
01/31/2025 07:39:01:INFO:Received: train message 348abfd2-d041-467c-a904-e569b4f65b9b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:39:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:40:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:40:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a818157b-20c3-42f0-8436-fbd2046042cd
01/31/2025 07:40:20:INFO:Received: evaluate message a818157b-20c3-42f0-8436-fbd2046042cd
[92mINFO [0m:      Sent reply
01/31/2025 07:40:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:41:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:41:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 219754f5-1b79-4d02-8878-4adfd0cf7236
01/31/2025 07:41:00:INFO:Received: train message 219754f5-1b79-4d02-8878-4adfd0cf7236
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:41:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:41:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:41:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fa43ae24-e913-4831-8ecc-7b919edede46
01/31/2025 07:41:50:INFO:Received: evaluate message fa43ae24-e913-4831-8ecc-7b919edede46
[92mINFO [0m:      Sent reply
01/31/2025 07:41:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:42:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:42:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 83cdf2ac-c49b-4bb4-b64c-014104c3f7aa
01/31/2025 07:42:30:INFO:Received: train message 83cdf2ac-c49b-4bb4-b64c-014104c3f7aa
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:42:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:44:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:44:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fb5548bd-0083-4f3c-be63-fd5905f872e2
01/31/2025 07:44:00:INFO:Received: evaluate message fb5548bd-0083-4f3c-be63-fd5905f872e2

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:44:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:44:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:44:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fd0e6bef-9ab7-47c3-8e0f-06b2151db87d
01/31/2025 07:44:48:INFO:Received: train message fd0e6bef-9ab7-47c3-8e0f-06b2151db87d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:45:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:46:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:46:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7b260c43-b13b-4196-93d3-a0e96651d7e0
01/31/2025 07:46:05:INFO:Received: evaluate message 7b260c43-b13b-4196-93d3-a0e96651d7e0
[92mINFO [0m:      Sent reply
01/31/2025 07:46:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:46:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:46:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0ae1510d-16b3-49a1-aa5b-9e897903a92b
01/31/2025 07:46:26:INFO:Received: train message 0ae1510d-16b3-49a1-aa5b-9e897903a92b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:46:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:48:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:48:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8c5d1b79-527a-4a8c-b8b0-da1cc515d246
01/31/2025 07:48:06:INFO:Received: evaluate message 8c5d1b79-527a-4a8c-b8b0-da1cc515d246
[92mINFO [0m:      Sent reply
01/31/2025 07:48:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:48:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:48:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9f5c1683-8b87-4b6c-84a0-715655864041
01/31/2025 07:48:33:INFO:Received: train message 9f5c1683-8b87-4b6c-84a0-715655864041
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:49:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:50:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:50:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4a6806c1-026f-4a2d-876c-e77118e8a214
01/31/2025 07:50:22:INFO:Received: evaluate message 4a6806c1-026f-4a2d-876c-e77118e8a214
[92mINFO [0m:      Sent reply
01/31/2025 07:50:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:51:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:51:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 24b8d430-d453-48a6-a9fb-c059dc5ec433
01/31/2025 07:51:10:INFO:Received: train message 24b8d430-d453-48a6-a9fb-c059dc5ec433

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:51:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:52:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:52:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b6805b7c-96f5-496c-b864-5fe186583fa9
01/31/2025 07:52:13:INFO:Received: evaluate message b6805b7c-96f5-496c-b864-5fe186583fa9
[92mINFO [0m:      Sent reply
01/31/2025 07:52:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:52:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:52:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 81ab9e89-7f84-498f-b66e-4570d4821341
01/31/2025 07:52:47:INFO:Received: train message 81ab9e89-7f84-498f-b66e-4570d4821341
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:53:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:53:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:53:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5500caa4-ec74-4d6f-975d-7779b3c2e72b
01/31/2025 07:53:55:INFO:Received: evaluate message 5500caa4-ec74-4d6f-975d-7779b3c2e72b
[92mINFO [0m:      Sent reply
01/31/2025 07:53:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:54:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:54:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 50f58bf0-93de-4282-97eb-fb7de11a1228
01/31/2025 07:54:33:INFO:Received: train message 50f58bf0-93de-4282-97eb-fb7de11a1228
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:54:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:55:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:55:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3046ff3b-dc32-4274-8ea3-41001e8cbb59
01/31/2025 07:55:35:INFO:Received: evaluate message 3046ff3b-dc32-4274-8ea3-41001e8cbb59
[92mINFO [0m:      Sent reply
01/31/2025 07:55:39:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:55:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:55:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message c3c4251d-40d5-40ae-840d-d937d5ea51ab
01/31/2025 07:55:41:INFO:Received: reconnect message c3c4251d-40d5-40ae-840d-d937d5ea51ab
01/31/2025 07:55:41:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 07:55:41:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348, 1.0159809038543999], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286, 0.5989053948397185], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871, 0.8120961426383593]}



Final client history:
{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348, 1.0159809038543999], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286, 0.5989053948397185], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871, 0.8120961426383593]}

