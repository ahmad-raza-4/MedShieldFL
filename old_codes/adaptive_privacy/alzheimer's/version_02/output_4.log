nohup: ignoring input
01/31/2025 07:59:41:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 07:59:41:DEBUG:ChannelConnectivity.IDLE
01/31/2025 07:59:41:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 07:59:41:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 08:00:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:00:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ad0c5fb5-9b4a-41f2-ba24-8f28cfc2ba30
01/31/2025 08:00:16:INFO:Received: train message ad0c5fb5-9b4a-41f2-ba24-8f28cfc2ba30
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:00:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:01:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:01:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 00b48090-9af5-4f41-b21f-209e80195008
01/31/2025 08:01:23:INFO:Received: evaluate message 00b48090-9af5-4f41-b21f-209e80195008
[92mINFO [0m:      Sent reply
01/31/2025 08:01:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:01:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:01:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b3527172-ca88-401b-88b9-41114d50da8a
01/31/2025 08:01:56:INFO:Received: train message b3527172-ca88-401b-88b9-41114d50da8a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:02:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:03:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:03:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 55cab9ba-08fd-473e-bd5c-961042e2e261
01/31/2025 08:03:12:INFO:Received: evaluate message 55cab9ba-08fd-473e-bd5c-961042e2e261
[92mINFO [0m:      Sent reply
01/31/2025 08:03:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:03:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:03:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2ce3c797-c8ca-43ee-bf55-565a144d1cc8
01/31/2025 08:03:46:INFO:Received: train message 2ce3c797-c8ca-43ee-bf55-565a144d1cc8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:04:18:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:04:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:04:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 24aa46b3-0375-456f-8286-a7ebf51ce77e
01/31/2025 08:04:50:INFO:Received: evaluate message 24aa46b3-0375-456f-8286-a7ebf51ce77e
[92mINFO [0m:      Sent reply
01/31/2025 08:04:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:05:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:05:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0067ea70-66aa-415d-bb11-b89e852afdde
01/31/2025 08:05:16:INFO:Received: train message 0067ea70-66aa-415d-bb11-b89e852afdde
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:05:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:06:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:06:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ae099865-5782-4a1a-8bbd-8c7446001f12
01/31/2025 08:06:25:INFO:Received: evaluate message ae099865-5782-4a1a-8bbd-8c7446001f12
[92mINFO [0m:      Sent reply
01/31/2025 08:06:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:07:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:07:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0f0bf476-59ad-47b7-a649-0cd47869ba51
01/31/2025 08:07:13:INFO:Received: train message 0f0bf476-59ad-47b7-a649-0cd47869ba51
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:07:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:08:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:08:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b0e50711-1671-4ab9-83d2-75a69f7a9b38
01/31/2025 08:08:16:INFO:Received: evaluate message b0e50711-1671-4ab9-83d2-75a69f7a9b38
[92mINFO [0m:      Sent reply
01/31/2025 08:08:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:08:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:08:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 03f370e9-c2a1-42de-a634-b03215e946a2
01/31/2025 08:08:48:INFO:Received: train message 03f370e9-c2a1-42de-a634-b03215e946a2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:09:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:10:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:10:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 36c8d5bf-543b-45ec-9920-55005b183c8a
01/31/2025 08:10:03:INFO:Received: evaluate message 36c8d5bf-543b-45ec-9920-55005b183c8a
[92mINFO [0m:      Sent reply
01/31/2025 08:10:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:10:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:10:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0ca58bb4-2629-48bb-bd59-64aada55cd28
01/31/2025 08:10:45:INFO:Received: train message 0ca58bb4-2629-48bb-bd59-64aada55cd28
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:11:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:11:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:11:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c1068f33-6820-4de2-b7e7-bf2308e2e758
01/31/2025 08:11:44:INFO:Received: evaluate message c1068f33-6820-4de2-b7e7-bf2308e2e758
[92mINFO [0m:      Sent reply
01/31/2025 08:11:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:12:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:12:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 44f194c7-e2ac-40c0-b932-0ca5394d825c
01/31/2025 08:12:23:INFO:Received: train message 44f194c7-e2ac-40c0-b932-0ca5394d825c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:12:51:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:13:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:13:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 07121e8b-5ace-48dd-ad0a-41985f74c517
01/31/2025 08:13:31:INFO:Received: evaluate message 07121e8b-5ace-48dd-ad0a-41985f74c517
[92mINFO [0m:      Sent reply
01/31/2025 08:13:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:14:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:14:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b174b8b1-ae1d-481a-854c-a8c8c50cf7be
01/31/2025 08:14:01:INFO:Received: train message b174b8b1-ae1d-481a-854c-a8c8c50cf7be
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:14:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:15:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:15:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 99ff3032-5793-4231-8e56-c57745b5cffa
01/31/2025 08:15:16:INFO:Received: evaluate message 99ff3032-5793-4231-8e56-c57745b5cffa
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 20.0, target_epsilon: 20.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969], 'accuracy': [0.5183737294761532], 'auc': [0.7379489183581498]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479], 'accuracy': [0.5183737294761532, 0.5222830336200156], 'auc': [0.7379489183581498, 0.7546630873005361]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:15:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:15:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:15:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b6a325d4-7577-4eff-9693-6e0c8bdfbcd4
01/31/2025 08:15:51:INFO:Received: train message b6a325d4-7577-4eff-9693-6e0c8bdfbcd4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:16:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:16:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:16:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6dd4170e-41fc-4874-b418-4eb9c38cda1e
01/31/2025 08:16:51:INFO:Received: evaluate message 6dd4170e-41fc-4874-b418-4eb9c38cda1e
[92mINFO [0m:      Sent reply
01/31/2025 08:16:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:17:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:17:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c1383ff2-bd65-40bf-b9db-e997abc78e17
01/31/2025 08:17:32:INFO:Received: train message c1383ff2-bd65-40bf-b9db-e997abc78e17
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:18:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:18:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:18:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c944d00a-9ffe-4f0f-848f-1100c2896292
01/31/2025 08:18:59:INFO:Received: evaluate message c944d00a-9ffe-4f0f-848f-1100c2896292
[92mINFO [0m:      Sent reply
01/31/2025 08:19:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:19:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:19:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3148890b-1169-4be6-a06b-6ddd49ff3573
01/31/2025 08:19:36:INFO:Received: train message 3148890b-1169-4be6-a06b-6ddd49ff3573
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:20:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:21:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:21:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a270bf7b-63e2-4b95-b507-05090760820b
01/31/2025 08:21:21:INFO:Received: evaluate message a270bf7b-63e2-4b95-b507-05090760820b
[92mINFO [0m:      Sent reply
01/31/2025 08:21:24:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:21:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:21:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 828b9b40-7006-493f-823a-0c3433451419
01/31/2025 08:21:57:INFO:Received: train message 828b9b40-7006-493f-823a-0c3433451419
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:22:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:22:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:22:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 09e7a7cc-94c7-45cc-b671-312df02356bb
01/31/2025 08:22:47:INFO:Received: evaluate message 09e7a7cc-94c7-45cc-b671-312df02356bb
[92mINFO [0m:      Sent reply
01/31/2025 08:22:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:23:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:23:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fb347e8c-b1a7-45de-a21a-f7156346c641
01/31/2025 08:23:17:INFO:Received: train message fb347e8c-b1a7-45de-a21a-f7156346c641
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:23:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:24:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:24:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fd350d55-4c92-4924-a5bb-5f3a29855b2d
01/31/2025 08:24:29:INFO:Received: evaluate message fd350d55-4c92-4924-a5bb-5f3a29855b2d
[92mINFO [0m:      Sent reply
01/31/2025 08:24:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:25:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:25:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7e038b5c-3100-4c7f-a347-8d4e4502d126
01/31/2025 08:25:03:INFO:Received: train message 7e038b5c-3100-4c7f-a347-8d4e4502d126
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:25:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:25:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:25:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 12343bb2-2119-4c5e-b04f-918a3baf6b4d
01/31/2025 08:25:51:INFO:Received: evaluate message 12343bb2-2119-4c5e-b04f-918a3baf6b4d

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:25:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:26:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:26:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 16c6fc50-af1b-4f10-a718-49ad9ad5d7b9
01/31/2025 08:26:27:INFO:Received: train message 16c6fc50-af1b-4f10-a718-49ad9ad5d7b9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:27:05:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:27:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:27:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a93f33b7-8e66-4667-a634-f97cb6e87ddc
01/31/2025 08:27:30:INFO:Received: evaluate message a93f33b7-8e66-4667-a634-f97cb6e87ddc
[92mINFO [0m:      Sent reply
01/31/2025 08:27:32:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:28:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:28:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message dc501bf1-c7a4-4b2c-a1b0-02cb3f1aeebb
01/31/2025 08:28:07:INFO:Received: train message dc501bf1-c7a4-4b2c-a1b0-02cb3f1aeebb
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:28:37:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:29:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:29:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b691b307-1d6a-43a6-bb2a-2251004184de
01/31/2025 08:29:09:INFO:Received: evaluate message b691b307-1d6a-43a6-bb2a-2251004184de
[92mINFO [0m:      Sent reply
01/31/2025 08:29:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:30:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:30:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f6e5ed5e-e2c1-4277-8f69-a389e1c2c389
01/31/2025 08:30:01:INFO:Received: train message f6e5ed5e-e2c1-4277-8f69-a389e1c2c389
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:30:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:30:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:30:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 73723396-14cb-41d4-ada5-83870930d940
01/31/2025 08:30:58:INFO:Received: evaluate message 73723396-14cb-41d4-ada5-83870930d940
[92mINFO [0m:      Sent reply
01/31/2025 08:31:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:31:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:31:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e754788c-e806-4eb9-87ce-426f426e6c62
01/31/2025 08:31:28:INFO:Received: train message e754788c-e806-4eb9-87ce-426f426e6c62
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:31:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:32:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:32:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6c3a8843-dc25-4fca-8a7b-bd28b218adff
01/31/2025 08:32:36:INFO:Received: evaluate message 6c3a8843-dc25-4fca-8a7b-bd28b218adff
[92mINFO [0m:      Sent reply
01/31/2025 08:32:39:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:32:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:32:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9025c2f7-e8ee-4866-8912-9fc199a5c7cf
01/31/2025 08:32:50:INFO:Received: train message 9025c2f7-e8ee-4866-8912-9fc199a5c7cf
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:33:23:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:34:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:34:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8ba86d54-08b2-4d05-b7f7-62c9ff888738
01/31/2025 08:34:46:INFO:Received: evaluate message 8ba86d54-08b2-4d05-b7f7-62c9ff888738

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:34:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:35:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:35:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5576df4b-7d3a-4d3e-9779-ebd35561f7b7
01/31/2025 08:35:09:INFO:Received: train message 5576df4b-7d3a-4d3e-9779-ebd35561f7b7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:35:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:36:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:36:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9feb0a0f-3d23-4d22-aa8f-645a4dc5309b
01/31/2025 08:36:55:INFO:Received: evaluate message 9feb0a0f-3d23-4d22-aa8f-645a4dc5309b
[92mINFO [0m:      Sent reply
01/31/2025 08:36:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:37:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:37:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ec48aaa7-8936-467b-858b-7721eb3e67e9
01/31/2025 08:37:39:INFO:Received: train message ec48aaa7-8936-467b-858b-7721eb3e67e9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:38:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:38:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:38:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message de0cdd0a-7f62-4222-8eae-133bb1429a8b
01/31/2025 08:38:25:INFO:Received: evaluate message de0cdd0a-7f62-4222-8eae-133bb1429a8b
[92mINFO [0m:      Sent reply
01/31/2025 08:38:27:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:39:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:39:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 64979ee2-7b50-4dd4-95d2-19960616cd50
01/31/2025 08:39:13:INFO:Received: train message 64979ee2-7b50-4dd4-95d2-19960616cd50
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:39:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:40:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:40:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 66588729-3b6d-42e0-b977-6822b5b1d13a
01/31/2025 08:40:09:INFO:Received: evaluate message 66588729-3b6d-42e0-b977-6822b5b1d13a
[92mINFO [0m:      Sent reply
01/31/2025 08:40:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:40:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:40:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4c098a91-fd80-4565-98b2-332432117f3c
01/31/2025 08:40:45:INFO:Received: train message 4c098a91-fd80-4565-98b2-332432117f3c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:41:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:41:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:41:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3270fdde-516a-42f1-a199-d303567b092a
01/31/2025 08:41:42:INFO:Received: evaluate message 3270fdde-516a-42f1-a199-d303567b092a

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:41:44:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:42:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:42:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2b04c982-a864-41e2-88fe-7d909291373f
01/31/2025 08:42:11:INFO:Received: train message 2b04c982-a864-41e2-88fe-7d909291373f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:42:38:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:43:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:43:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ee8bcba9-cc4b-4089-a8b6-f45035b4e8e5
01/31/2025 08:43:33:INFO:Received: evaluate message ee8bcba9-cc4b-4089-a8b6-f45035b4e8e5
[92mINFO [0m:      Sent reply
01/31/2025 08:43:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:44:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:44:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1784b458-2ff5-4ebd-b9e9-ac6ba26f60ea
01/31/2025 08:44:09:INFO:Received: train message 1784b458-2ff5-4ebd-b9e9-ac6ba26f60ea
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:44:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:45:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:45:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8b7a2d12-3c65-4fad-b1e7-d74a6794870d
01/31/2025 08:45:10:INFO:Received: evaluate message 8b7a2d12-3c65-4fad-b1e7-d74a6794870d
[92mINFO [0m:      Sent reply
01/31/2025 08:45:13:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:45:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:45:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 06f9ed05-a77c-498a-a4ee-a74714267966
01/31/2025 08:45:44:INFO:Received: train message 06f9ed05-a77c-498a-a4ee-a74714267966
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:46:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:46:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:46:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 99df0aa8-0a18-4abf-a20c-c2a451edc12f
01/31/2025 08:46:37:INFO:Received: evaluate message 99df0aa8-0a18-4abf-a20c-c2a451edc12f
[92mINFO [0m:      Sent reply
01/31/2025 08:46:38:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:47:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:47:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8c1fc8be-33c7-4854-90cb-c9560ab637d7
01/31/2025 08:47:00:INFO:Received: train message 8c1fc8be-33c7-4854-90cb-c9560ab637d7

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:47:37:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:49:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:49:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 42de2919-f9d4-4b70-ac9a-af7bace90e35
01/31/2025 08:49:03:INFO:Received: evaluate message 42de2919-f9d4-4b70-ac9a-af7bace90e35
[92mINFO [0m:      Sent reply
01/31/2025 08:49:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:49:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:49:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4bf6d5ef-9808-4a60-88c5-431ddbd689ea
01/31/2025 08:49:37:INFO:Received: train message 4bf6d5ef-9808-4a60-88c5-431ddbd689ea
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:50:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:51:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:51:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f11efd82-1b07-443b-9380-a038f3b75b10
01/31/2025 08:51:14:INFO:Received: evaluate message f11efd82-1b07-443b-9380-a038f3b75b10
[92mINFO [0m:      Sent reply
01/31/2025 08:51:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:52:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:52:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 653b85b7-8f65-4eea-936a-1fc8a0848313
01/31/2025 08:52:03:INFO:Received: train message 653b85b7-8f65-4eea-936a-1fc8a0848313
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:52:26:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:52:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:52:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 00004480-5316-4fdc-84b0-4379d1046198
01/31/2025 08:52:56:INFO:Received: evaluate message 00004480-5316-4fdc-84b0-4379d1046198
[92mINFO [0m:      Sent reply
01/31/2025 08:52:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:53:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:53:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message e33a9046-36f6-4815-9555-de2492528196
01/31/2025 08:53:07:INFO:Received: reconnect message e33a9046-36f6-4815-9555-de2492528196
01/31/2025 08:53:08:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 08:53:08:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1547, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399, 1.0146706239891947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817, 0.8129905939058173]}



Final client history:
{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399, 1.0146706239891947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817, 0.8129905939058173]}

