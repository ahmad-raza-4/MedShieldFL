nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(mpl.__version__) >= "3.0":
/home/dgxuser16/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/cm.py:1582: MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.
  mpl_cm.register_cmap(_name, _cmap)
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/adaptive_privacy/isic/version_02/dyn_noise_1/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
01/23/2025 11:26:04:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/23/2025 11:26:04:DEBUG:ChannelConnectivity.IDLE
01/23/2025 11:26:04:DEBUG:ChannelConnectivity.CONNECTING
01/23/2025 11:26:04:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/23/2025 11:31:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 11:31:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 83a6e078-0adf-4b16-a71f-1ebb15712159
01/23/2025 11:31:14:INFO:Received: train message 83a6e078-0adf-4b16-a71f-1ebb15712159
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 11:35:23:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 11:50:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 11:50:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1ee72395-547f-42bd-b505-58aa72d2bc8a
01/23/2025 11:50:29:INFO:Received: evaluate message 1ee72395-547f-42bd-b505-58aa72d2bc8a
[92mINFO [0m:      Sent reply
01/23/2025 11:54:22:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 11:55:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 11:55:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fdd68366-5171-416a-af2c-c0ea6b5ef24a
01/23/2025 11:55:16:INFO:Received: train message fdd68366-5171-416a-af2c-c0ea6b5ef24a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 11:59:13:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 12:14:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 12:14:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 99eed746-4725-4b9e-b7e4-34a962471bcc
01/23/2025 12:14:23:INFO:Received: evaluate message 99eed746-4725-4b9e-b7e4-34a962471bcc
[92mINFO [0m:      Sent reply
01/23/2025 12:18:33:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 12:18:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 12:18:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 90f18e0e-92d2-45a7-aee6-c2b474e7eea7
01/23/2025 12:18:58:INFO:Received: train message 90f18e0e-92d2-45a7-aee6-c2b474e7eea7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 12:23:03:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 12:38:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 12:38:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 69fd933a-3279-4d13-952b-5b85eec70a1e
01/23/2025 12:38:01:INFO:Received: evaluate message 69fd933a-3279-4d13-952b-5b85eec70a1e
[92mINFO [0m:      Sent reply
01/23/2025 12:42:01:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 12:42:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 12:42:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3f465f74-14c3-43f7-82ad-d4113b266bf2
01/23/2025 12:42:24:INFO:Received: train message 3f465f74-14c3-43f7-82ad-d4113b266bf2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 12:46:25:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 13:01:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 13:01:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0595e5dd-cf1c-480c-860d-5c2bde3d715e
01/23/2025 13:01:36:INFO:Received: evaluate message 0595e5dd-cf1c-480c-860d-5c2bde3d715e
[92mINFO [0m:      Sent reply
01/23/2025 13:05:38:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 13:06:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 13:06:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7f7f80cf-717a-4833-a31c-92b0f5407ef2
01/23/2025 13:06:08:INFO:Received: train message 7f7f80cf-717a-4833-a31c-92b0f5407ef2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 13:10:15:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 13:25:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 13:25:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b2283119-0faf-41ab-bc66-ce57757b2547
01/23/2025 13:25:20:INFO:Received: evaluate message b2283119-0faf-41ab-bc66-ce57757b2547
[92mINFO [0m:      Sent reply
01/23/2025 13:29:24:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 13:29:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 13:29:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3627f321-f042-44ec-a54f-c10f51df8e7a
01/23/2025 13:29:55:INFO:Received: train message 3627f321-f042-44ec-a54f-c10f51df8e7a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 13:33:55:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 13:49:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 13:49:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6b7c54ef-fc7d-416d-a3b8-2a4d4689ffac
01/23/2025 13:49:04:INFO:Received: evaluate message 6b7c54ef-fc7d-416d-a3b8-2a4d4689ffac
[92mINFO [0m:      Sent reply
01/23/2025 13:53:09:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 13:53:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 13:53:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a312049c-ed8f-484a-91da-09ef8cc96ecd
01/23/2025 13:53:32:INFO:Received: train message a312049c-ed8f-484a-91da-09ef8cc96ecd
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 13:56:33:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 14:12:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 14:12:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2a7391b0-6cb4-41bf-859e-3e86724329f8
01/23/2025 14:12:46:INFO:Received: evaluate message 2a7391b0-6cb4-41bf-859e-3e86724329f8
[92mINFO [0m:      Sent reply
01/23/2025 14:16:52:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 14:17:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 14:17:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message aa8b851a-056e-41dc-acc0-97c9eb6ff38b
01/23/2025 14:17:26:INFO:Received: train message aa8b851a-056e-41dc-acc0-97c9eb6ff38b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 14:21:26:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 14:36:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 14:36:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 62cff5a0-b578-440b-8d48-fab3be548567
01/23/2025 14:36:42:INFO:Received: evaluate message 62cff5a0-b578-440b-8d48-fab3be548567
[92mINFO [0m:      Sent reply
01/23/2025 14:40:38:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 14:41:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 14:41:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 34f7530e-e15d-4cb0-b80e-214282d6bfa1
01/23/2025 14:41:04:INFO:Received: train message 34f7530e-e15d-4cb0-b80e-214282d6bfa1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 14:44:58:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 15:00:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 15:00:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e5fa0223-7c01-4395-acdf-5b7e1a20d608
01/23/2025 15:00:19:INFO:Received: evaluate message e5fa0223-7c01-4395-acdf-5b7e1a20d608
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/adaptive_privacy/isic/version_02/dyn_noise_1', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/.local/lib/python3.8/site-packages', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/adaptive_privacy/isic/version_02/dyn_noise_1']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 25331, num_classes: 8

Privacy Params:
 epsilon: 1, target_epsilon: 1, target_delta: 1e-05

Device: cuda:0

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 2.14

{'loss': [137.2596139907837], 'accuracy': [0.3383004430124849], 'auc': [0.5868727978587345]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 1.89

{'loss': [137.2596139907837, 133.6919516324997], 'accuracy': [0.3383004430124849, 0.3407168747482884], 'auc': [0.5868727978587345, 0.6194824557606924]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 1.48

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 1.44

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 2.15

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 1.64

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 1.27

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 1.84

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 2.95
[92mINFO [0m:      Sent reply
01/23/2025 15:04:22:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 15:04:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 15:04:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ac7d6088-a3fc-411f-8e2d-66623b5eadeb
01/23/2025 15:04:37:INFO:Received: train message ac7d6088-a3fc-411f-8e2d-66623b5eadeb
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 15:08:26:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 15:24:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 15:24:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b4cb4f7b-2771-41ba-adfd-2547473a1695
01/23/2025 15:24:01:INFO:Received: evaluate message b4cb4f7b-2771-41ba-adfd-2547473a1695
[92mINFO [0m:      Sent reply
01/23/2025 15:28:04:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 15:28:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 15:28:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c40eb587-13f0-4824-be0c-e24090613ecb
01/23/2025 15:28:37:INFO:Received: train message c40eb587-13f0-4824-be0c-e24090613ecb
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 15:32:31:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 15:47:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 15:47:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 41bc9d50-74a2-4a2a-9658-db93e372b8e3
01/23/2025 15:47:56:INFO:Received: evaluate message 41bc9d50-74a2-4a2a-9658-db93e372b8e3
[92mINFO [0m:      Sent reply
01/23/2025 15:51:56:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 15:52:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 15:52:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6d14e7cb-1ae9-4667-b09c-e618fa3b0f84
01/23/2025 15:52:31:INFO:Received: train message 6d14e7cb-1ae9-4667-b09c-e618fa3b0f84
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 15:56:31:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:11:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:11:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ad34945c-646e-45b1-9a41-2e5ca90e711b
01/23/2025 16:11:32:INFO:Received: evaluate message ad34945c-646e-45b1-9a41-2e5ca90e711b
[92mINFO [0m:      Sent reply
01/23/2025 16:15:28:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:15:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:15:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1ff8ba40-ded0-4cee-9241-210a42866672
01/23/2025 16:15:48:INFO:Received: train message 1ff8ba40-ded0-4cee-9241-210a42866672
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 16:19:32:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:34:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:34:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 28fd53ca-daf3-460f-b088-b9267c1e927a
01/23/2025 16:34:58:INFO:Received: evaluate message 28fd53ca-daf3-460f-b088-b9267c1e927a
[92mINFO [0m:      Sent reply
01/23/2025 16:39:00:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:39:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:39:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message acf57d5c-def4-42eb-8382-32c3ff7d0be3
01/23/2025 16:39:24:INFO:Received: train message acf57d5c-def4-42eb-8382-32c3ff7d0be3
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 16:43:28:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:58:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:58:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 30e6d487-f614-4548-8ba7-47052a063109
01/23/2025 16:58:41:INFO:Received: evaluate message 30e6d487-f614-4548-8ba7-47052a063109
[92mINFO [0m:      Sent reply
01/23/2025 17:02:49:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 17:03:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 17:03:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6daaec46-65bf-4327-bef4-cc7fe5488844
01/23/2025 17:03:09:INFO:Received: train message 6daaec46-65bf-4327-bef4-cc7fe5488844
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 17:07:04:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 17:22:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 17:22:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 13fa3cb1-0198-4060-bbb1-1d2e00e9929b
01/23/2025 17:22:21:INFO:Received: evaluate message 13fa3cb1-0198-4060-bbb1-1d2e00e9929b

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 1.81

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 1.22

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 2.00

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 2.15

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 2.16

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.72720991820097
Epsilon = 1.00 and Loss = 2.04
[92mINFO [0m:      Sent reply
01/23/2025 17:26:21:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 17:27:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 17:27:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6fad366b-4b9a-40cc-bc38-5792c42c17d4
01/23/2025 17:27:04:INFO:Received: train message 6fad366b-4b9a-40cc-bc38-5792c42c17d4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 17:31:09:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 17:46:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 17:46:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3737d9d8-34a1-4b63-88ea-39ea4234c470
01/23/2025 17:46:09:INFO:Received: evaluate message 3737d9d8-34a1-4b63-88ea-39ea4234c470
[92mINFO [0m:      Sent reply
01/23/2025 17:50:12:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 17:50:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 17:50:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7d1e2c1a-19f6-4a10-b59a-3df63e251348
01/23/2025 17:50:34:INFO:Received: train message 7d1e2c1a-19f6-4a10-b59a-3df63e251348
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 17:54:11:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:09:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:09:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message dec8fe24-ec94-42d0-8ade-a61c639fd667
01/23/2025 18:09:48:INFO:Received: evaluate message dec8fe24-ec94-42d0-8ade-a61c639fd667
[92mINFO [0m:      Sent reply
01/23/2025 18:13:24:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:14:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:14:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b2d2a0fd-d316-4404-b930-cafd907d2a20
01/23/2025 18:14:32:INFO:Received: train message b2d2a0fd-d316-4404-b930-cafd907d2a20
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 18:18:24:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:33:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:33:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6ae565f2-8bd5-47f6-8901-2c84b3f1ae9e
01/23/2025 18:33:35:INFO:Received: evaluate message 6ae565f2-8bd5-47f6-8901-2c84b3f1ae9e
[92mINFO [0m:      Sent reply
01/23/2025 18:37:36:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:38:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:38:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d7aec3d2-3853-4640-99d7-07b29e1d1dce
01/23/2025 18:38:03:INFO:Received: train message d7aec3d2-3853-4640-99d7-07b29e1d1dce
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 18:41:50:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:57:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:57:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0e7d3d49-f542-4943-b1b0-9dc41f7b5126
01/23/2025 18:57:19:INFO:Received: evaluate message 0e7d3d49-f542-4943-b1b0-9dc41f7b5126
[92mINFO [0m:      Sent reply
01/23/2025 19:01:20:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 19:01:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 19:01:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4a2aaf7b-9b8c-44c6-a8a7-2d281a48cc82
01/23/2025 19:01:37:INFO:Received: train message 4a2aaf7b-9b8c-44c6-a8a7-2d281a48cc82
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 19:05:26:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 19:21:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 19:21:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message db50c063-a221-4a5c-9045-e93024a50451
01/23/2025 19:21:02:INFO:Received: evaluate message db50c063-a221-4a5c-9045-e93024a50451

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 6.278729256987572
Epsilon = 1.00 and Loss = 2.22

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 5.830248595774174
Epsilon = 1.00 and Loss = 1.47

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 5.381767934560776
Epsilon = 1.00 and Loss = 1.76

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 4.9332872733473785
Epsilon = 1.00 and Loss = 2.21

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 4.484806612133981
Epsilon = 1.00 and Loss = 2.30
[92mINFO [0m:      Sent reply
01/23/2025 19:25:13:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 19:25:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 19:25:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message aaf9f029-ff7f-41a4-a799-0597800c3a94
01/23/2025 19:25:30:INFO:Received: train message aaf9f029-ff7f-41a4-a799-0597800c3a94
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 19:29:20:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 19:44:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 19:44:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5736c2af-3093-4f20-8970-d790c8f91526
01/23/2025 19:44:35:INFO:Received: evaluate message 5736c2af-3093-4f20-8970-d790c8f91526
[92mINFO [0m:      Sent reply
01/23/2025 19:48:18:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 19:49:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 19:49:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9d43e10b-680a-4f1c-a33e-13d12d9a4283
01/23/2025 19:49:09:INFO:Received: train message 9d43e10b-680a-4f1c-a33e-13d12d9a4283
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 19:53:04:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 20:08:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 20:08:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 59fe333c-5d7b-4694-b148-5d5ea14a4042
01/23/2025 20:08:19:INFO:Received: evaluate message 59fe333c-5d7b-4694-b148-5d5ea14a4042
[92mINFO [0m:      Sent reply
01/23/2025 20:12:09:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 20:12:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 20:12:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0037dc6d-6a5a-41c8-b871-5a317382db53
01/23/2025 20:12:58:INFO:Received: train message 0037dc6d-6a5a-41c8-b871-5a317382db53
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 20:17:01:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 20:32:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 20:32:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 40a83cd4-ab4f-46a4-9e3e-fad44e86c946
01/23/2025 20:32:12:INFO:Received: evaluate message 40a83cd4-ab4f-46a4-9e3e-fad44e86c946
[92mINFO [0m:      Sent reply
01/23/2025 20:36:24:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 20:36:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 20:36:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c9dc17fd-ea3f-43ee-889e-6e1f9bac8d4b
01/23/2025 20:36:45:INFO:Received: train message c9dc17fd-ea3f-43ee-889e-6e1f9bac8d4b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 20:40:44:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 20:56:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 20:56:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 49840736-704d-4d3f-b16a-827ed6762f3b
01/23/2025 20:56:09:INFO:Received: evaluate message 49840736-704d-4d3f-b16a-827ed6762f3b

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 4.036325950920582
Epsilon = 1.00 and Loss = 2.38

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 3.5878452897071837
Epsilon = 1.00 and Loss = 1.95

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191, 119.36390566825867], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665, 0.5159081755940395], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389, 0.7144465959612978]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 3.139364628493786
Epsilon = 1.00 and Loss = 1.76

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191, 119.36390566825867, 118.71580564975739], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665, 0.5159081755940395, 0.5175191300845751], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389, 0.7144465959612978, 0.7169617778359723]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 2.690883967280388
Epsilon = 1.00 and Loss = 1.64
[92mINFO [0m:      Sent reply
01/23/2025 21:00:16:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 21:00:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 21:00:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8dfc0e4c-860e-4b09-b310-c83c0635e949
01/23/2025 21:00:51:INFO:Received: train message 8dfc0e4c-860e-4b09-b310-c83c0635e949
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 21:04:52:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 21:20:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 21:20:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8339b9a6-851b-496c-bbed-9a3333784136
01/23/2025 21:20:16:INFO:Received: evaluate message 8339b9a6-851b-496c-bbed-9a3333784136
[92mINFO [0m:      Sent reply
01/23/2025 21:24:17:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 21:24:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 21:24:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8cafa474-7a78-4903-ac31-590ec3ff7207
01/23/2025 21:24:45:INFO:Received: train message 8cafa474-7a78-4903-ac31-590ec3ff7207
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 21:28:49:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 21:44:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 21:44:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 12065776-fd5a-484a-8624-bf10fa03dc26
01/23/2025 21:44:17:INFO:Received: evaluate message 12065776-fd5a-484a-8624-bf10fa03dc26
[92mINFO [0m:      Sent reply
01/23/2025 21:48:17:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 21:49:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 21:49:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message caec1bea-bd6d-475b-a2b2-afb51b5df2d2
01/23/2025 21:49:08:INFO:Received: train message caec1bea-bd6d-475b-a2b2-afb51b5df2d2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 21:53:14:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 22:08:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 22:08:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message db7579a9-6319-45a4-9f82-17907fb789d0
01/23/2025 22:08:36:INFO:Received: evaluate message db7579a9-6319-45a4-9f82-17907fb789d0
[92mINFO [0m:      Sent reply
01/23/2025 22:12:41:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 22:13:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 22:13:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4af213e5-c525-451c-91b0-8964d5e779c1
01/23/2025 22:13:18:INFO:Received: train message 4af213e5-c525-451c-91b0-8964d5e779c1

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191, 119.36390566825867, 118.71580564975739, 118.17940270900726], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665, 0.5159081755940395, 0.5175191300845751, 0.5203383004430124], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389, 0.7144465959612978, 0.7169617778359723, 0.7195841148130424]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 2.2424033060669903
Epsilon = 1.00 and Loss = 2.21

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191, 119.36390566825867, 118.71580564975739, 118.17940270900726, 117.86651146411896], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665, 0.5159081755940395, 0.5175191300845751, 0.5203383004430124, 0.5247684252919855], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389, 0.7144465959612978, 0.7169617778359723, 0.7195841148130424, 0.7220698200809929]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 1.7939226448535923
Epsilon = 1.00 and Loss = 2.03

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191, 119.36390566825867, 118.71580564975739, 118.17940270900726, 117.86651146411896, 117.7983648777008], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665, 0.5159081755940395, 0.5175191300845751, 0.5203383004430124, 0.5247684252919855, 0.5255739025372533], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389, 0.7144465959612978, 0.7169617778359723, 0.7195841148130424, 0.7220698200809929, 0.7238531010048092]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 1.3454419836401936
Epsilon = 1.00 and Loss = 1.27

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191, 119.36390566825867, 118.71580564975739, 118.17940270900726, 117.86651146411896, 117.7983648777008, 117.46852028369904], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665, 0.5159081755940395, 0.5175191300845751, 0.5203383004430124, 0.5247684252919855, 0.5255739025372533, 0.5300040273862263], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389, 0.7144465959612978, 0.7169617778359723, 0.7195841148130424, 0.7220698200809929, 0.7238531010048092, 0.7259609180441174]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 22:17:02:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 22:32:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 22:32:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 21f84b42-654f-4868-8095-a6fa03c1b527
01/23/2025 22:32:34:INFO:Received: evaluate message 21f84b42-654f-4868-8095-a6fa03c1b527
[92mINFO [0m:      Sent reply
01/23/2025 22:36:35:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 22:37:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 22:37:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c18d3eff-f31c-4226-ac6c-3ec3239bef16
01/23/2025 22:37:07:INFO:Received: train message c18d3eff-f31c-4226-ac6c-3ec3239bef16
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 22:41:04:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 22:56:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 22:56:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4001d6ac-226a-472e-86c4-7becf4b9aede
01/23/2025 22:56:24:INFO:Received: evaluate message 4001d6ac-226a-472e-86c4-7becf4b9aede
[92mINFO [0m:      Sent reply
01/23/2025 23:00:22:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 23:01:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 23:01:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9b867bf8-5d8e-4feb-be0f-33be46a23900
01/23/2025 23:01:11:INFO:Received: train message 9b867bf8-5d8e-4feb-be0f-33be46a23900
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 23:05:18:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 23:20:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 23:20:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0be14848-4aa0-4741-b801-4a8d287061ec
01/23/2025 23:20:33:INFO:Received: evaluate message 0be14848-4aa0-4741-b801-4a8d287061ec
[92mINFO [0m:      Sent reply
01/23/2025 23:24:33:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 23:25:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 23:25:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message aa4bb57e-9222-405b-a37b-51cce650725f
01/23/2025 23:25:00:INFO:Received: reconnect message aa4bb57e-9222-405b-a37b-51cce650725f
01/23/2025 23:25:00:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/23/2025 23:25:00:INFO:Disconnect and shut down
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 0.8969613224267957
Epsilon = 1.00 and Loss = 2.40

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191, 119.36390566825867, 118.71580564975739, 118.17940270900726, 117.86651146411896, 117.7983648777008, 117.46852028369904, 116.91642844676971], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665, 0.5159081755940395, 0.5175191300845751, 0.5203383004430124, 0.5247684252919855, 0.5255739025372533, 0.5300040273862263, 0.5324204591220298], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389, 0.7144465959612978, 0.7169617778359723, 0.7195841148130424, 0.7220698200809929, 0.7238531010048092, 0.7259609180441174, 0.7282000937855511]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 0.44848066121339786
Epsilon = 1.00 and Loss = 1.60

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191, 119.36390566825867, 118.71580564975739, 118.17940270900726, 117.86651146411896, 117.7983648777008, 117.46852028369904, 116.91642844676971, 116.7303866147995], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665, 0.5159081755940395, 0.5175191300845751, 0.5203383004430124, 0.5247684252919855, 0.5255739025372533, 0.5300040273862263, 0.5324204591220298, 0.5336286749899315], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389, 0.7144465959612978, 0.7169617778359723, 0.7195841148130424, 0.7220698200809929, 0.7238531010048092, 0.7259609180441174, 0.7282000937855511, 0.7298981633751142]}

Base Noise Multiplier Received:  1.396484375
Data Scaling Factor: 38.67328244274809 where Client Data Size: 655
Noise Multiplier after Fisher Scaling:  [11.47662353515625, 26.475725173950195, 0.8334968686103821, 2.4141290187835693, 9.48544979095459, 1.4703137874603271, 0.7471461892127991, 0.9147949814796448]
Noise Multiplier after list and tensor:  6.72720991820097
Noise Multiplier after Epsilon Scaling:  6.72720991820097
Noise Multiplier after Convergence: 0.0
Epsilon = 1.00 and Loss = 2.04

{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191, 119.36390566825867, 118.71580564975739, 118.17940270900726, 117.86651146411896, 117.7983648777008, 117.46852028369904, 116.91642844676971, 116.7303866147995, 116.7615122795105], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665, 0.5159081755940395, 0.5175191300845751, 0.5203383004430124, 0.5247684252919855, 0.5255739025372533, 0.5300040273862263, 0.5324204591220298, 0.5336286749899315, 0.5368505839710028], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389, 0.7144465959612978, 0.7169617778359723, 0.7195841148130424, 0.7220698200809929, 0.7238531010048092, 0.7259609180441174, 0.7282000937855511, 0.7298981633751142, 0.7311505973177221]}



Final client history:
{'loss': [137.2596139907837, 133.6919516324997, 136.09523212909698, 138.6259878873825, 139.713250041008, 139.4705867767334, 137.49091362953186, 135.83193266391754, 132.71509325504303, 130.50868046283722, 128.72331547737122, 127.73188984394073, 126.37969863414764, 125.48011147975922, 124.28206539154053, 123.43013620376587, 122.3192925453186, 121.99394845962524, 121.36356103420258, 120.53682029247284, 120.03408372402191, 119.36390566825867, 118.71580564975739, 118.17940270900726, 117.86651146411896, 117.7983648777008, 117.46852028369904, 116.91642844676971, 116.7303866147995, 116.7615122795105], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3499798630688683, 0.3568264196536448, 0.37575513491743856, 0.39468385018123237, 0.41723721304873135, 0.4333467579540878, 0.4482480869915425, 0.4571083366894885, 0.4679822795006041, 0.47643979057591623, 0.48409182440596055, 0.4881192106322996, 0.49174385823600486, 0.49536850583971004, 0.5014095851792187, 0.5058397100281917, 0.5114780507450665, 0.5159081755940395, 0.5175191300845751, 0.5203383004430124, 0.5247684252919855, 0.5255739025372533, 0.5300040273862263, 0.5324204591220298, 0.5336286749899315, 0.5368505839710028], 'auc': [0.5868727978587345, 0.6194824557606924, 0.6332747268286469, 0.6409784505427432, 0.6475128342621772, 0.6521635288666228, 0.6577039549239638, 0.6629549860977864, 0.6687035869251049, 0.6726062551192823, 0.6778951726604219, 0.6821951189999591, 0.6862314148221464, 0.6903174656640896, 0.6935635788905234, 0.697246263995306, 0.7006663096721644, 0.7032523867222171, 0.7059213245135924, 0.7094335125819758, 0.7118719042376389, 0.7144465959612978, 0.7169617778359723, 0.7195841148130424, 0.7220698200809929, 0.7238531010048092, 0.7259609180441174, 0.7282000937855511, 0.7298981633751142, 0.7311505973177221]}

