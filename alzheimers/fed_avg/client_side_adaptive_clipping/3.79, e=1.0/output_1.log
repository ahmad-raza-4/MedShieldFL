nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
02/06/2025 20:35:09:WARNING:Ignoring drop_last as it is not compatible with DPDataLoader.
02/06/2025 20:35:09:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/06/2025 20:35:09:DEBUG:ChannelConnectivity.IDLE
02/06/2025 20:35:09:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
02/06/2025 20:35:09:INFO:
[92mINFO [0m:      Received: get_parameters message 004f7d61-14d6-42da-af37-24b88af67bc8
02/06/2025 20:35:09:INFO:Received: get_parameters message 004f7d61-14d6-42da-af37-24b88af67bc8
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738902909.235696  943143 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      Sent reply
02/06/2025 20:35:15:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:35:57:INFO:
[92mINFO [0m:      Received: train message d77da1b6-2dd3-4db3-b182-d25c0c71ba71
02/06/2025 20:35:57:INFO:Received: train message d77da1b6-2dd3-4db3-b182-d25c0c71ba71
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:36:25:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:37:24:INFO:
[92mINFO [0m:      Received: evaluate message 1a563372-2cdb-424f-bf0f-926474fece67
02/06/2025 20:37:24:INFO:Received: evaluate message 1a563372-2cdb-424f-bf0f-926474fece67
[92mINFO [0m:      Sent reply
02/06/2025 20:37:32:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:38:10:INFO:
[92mINFO [0m:      Received: train message 7fc5c8d4-23a0-483a-a6d2-24d3ae09c1dc
02/06/2025 20:38:10:INFO:Received: train message 7fc5c8d4-23a0-483a-a6d2-24d3ae09c1dc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:38:36:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:40:22:INFO:
[92mINFO [0m:      Received: evaluate message 00bbe375-b74d-4a9b-97a6-7cbe28acd8dc
02/06/2025 20:40:22:INFO:Received: evaluate message 00bbe375-b74d-4a9b-97a6-7cbe28acd8dc
[92mINFO [0m:      Sent reply
02/06/2025 20:40:34:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:41:10:INFO:
[92mINFO [0m:      Received: train message 82a7536f-9e1e-4b23-943b-6bf0a628e14d
02/06/2025 20:41:10:INFO:Received: train message 82a7536f-9e1e-4b23-943b-6bf0a628e14d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:41:31:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:42:36:INFO:
[92mINFO [0m:      Received: evaluate message c5937c13-82e6-4ff1-aec2-c3a7a3f8bdca
02/06/2025 20:42:36:INFO:Received: evaluate message c5937c13-82e6-4ff1-aec2-c3a7a3f8bdca
[92mINFO [0m:      Sent reply
02/06/2025 20:42:46:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:43:17:INFO:
[92mINFO [0m:      Received: train message 0239ba8b-ab5a-45f2-a813-19472df6693c
02/06/2025 20:43:17:INFO:Received: train message 0239ba8b-ab5a-45f2-a813-19472df6693c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:43:40:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:44:25:INFO:
[92mINFO [0m:      Received: evaluate message 7027aade-6c04-4667-8e91-132a8708d054
02/06/2025 20:44:25:INFO:Received: evaluate message 7027aade-6c04-4667-8e91-132a8708d054
[92mINFO [0m:      Sent reply
02/06/2025 20:44:29:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:45:16:INFO:
[92mINFO [0m:      Received: train message b73af150-6458-4c60-b4e4-55cf65aa332e
02/06/2025 20:45:16:INFO:Received: train message b73af150-6458-4c60-b4e4-55cf65aa332e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:45:41:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:46:43:INFO:
[92mINFO [0m:      Received: evaluate message 8fc9a69c-78bc-4076-9c55-96638cc2e326
02/06/2025 20:46:43:INFO:Received: evaluate message 8fc9a69c-78bc-4076-9c55-96638cc2e326
[92mINFO [0m:      Sent reply
02/06/2025 20:46:47:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:47:55:INFO:
[92mINFO [0m:      Received: train message a047831d-50fb-4de2-9d2a-7b4cefd1148a
02/06/2025 20:47:55:INFO:Received: train message a047831d-50fb-4de2-9d2a-7b4cefd1148a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:48:26:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:49:19:INFO:
[92mINFO [0m:      Received: evaluate message e4a50e5e-72d2-417a-a515-9d6aecf06a33
02/06/2025 20:49:19:INFO:Received: evaluate message e4a50e5e-72d2-417a-a515-9d6aecf06a33
[92mINFO [0m:      Sent reply
02/06/2025 20:49:24:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:50:20:INFO:
[92mINFO [0m:      Received: train message 5f3d7141-d48c-44a6-a654-1babaabe7870
02/06/2025 20:50:20:INFO:Received: train message 5f3d7141-d48c-44a6-a654-1babaabe7870
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:50:44:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:51:40:INFO:
[92mINFO [0m:      Received: evaluate message 192d3987-b961-45aa-aba9-3b20d8da6163
02/06/2025 20:51:40:INFO:Received: evaluate message 192d3987-b961-45aa-aba9-3b20d8da6163
[92mINFO [0m:      Sent reply
02/06/2025 20:51:44:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:52:38:INFO:
[92mINFO [0m:      Received: train message a29a5ed2-6eb7-43d2-b665-65bd06bb5088
02/06/2025 20:52:38:INFO:Received: train message a29a5ed2-6eb7-43d2-b665-65bd06bb5088
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:53:10:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:53:51:INFO:
[92mINFO [0m:      Received: evaluate message 423fca34-00ca-466d-b3d2-8650417d7fc3
02/06/2025 20:53:51:INFO:Received: evaluate message 423fca34-00ca-466d-b3d2-8650417d7fc3
[92mINFO [0m:      Sent reply
02/06/2025 20:53:55:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:55:34:INFO:
[92mINFO [0m:      Received: train message 414040f3-2d22-4561-8529-6cf80c250ed6
02/06/2025 20:55:34:INFO:Received: train message 414040f3-2d22-4561-8529-6cf80c250ed6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:56:00:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:56:32:INFO:
[92mINFO [0m:      Received: evaluate message 21320cc9-99d2-4601-836d-008db0d3c4da
02/06/2025 20:56:32:INFO:Received: evaluate message 21320cc9-99d2-4601-836d-008db0d3c4da
[92mINFO [0m:      Sent reply
02/06/2025 20:56:36:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:57:21:INFO:
[92mINFO [0m:      Received: train message a9d72113-39fc-4029-a8ac-e6e30237c97e
02/06/2025 20:57:21:INFO:Received: train message a9d72113-39fc-4029-a8ac-e6e30237c97e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:57:49:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:58:47:INFO:
[92mINFO [0m:      Received: evaluate message 5454a109-e5b6-4fa2-af14-a7ced7058380
02/06/2025 20:58:47:INFO:Received: evaluate message 5454a109-e5b6-4fa2-af14-a7ced7058380
[92mINFO [0m:      Sent reply
02/06/2025 20:58:51:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:59:35:INFO:
[92mINFO [0m:      Received: train message 79a1a234-d486-412c-88e1-c3cad6e35c78
02/06/2025 20:59:35:INFO:Received: train message 79a1a234-d486-412c-88e1-c3cad6e35c78
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:00:08:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:00:46:INFO:
[92mINFO [0m:      Received: evaluate message 0e87489c-a05b-446e-828b-0dd83dc0a658
02/06/2025 21:00:46:INFO:Received: evaluate message 0e87489c-a05b-446e-828b-0dd83dc0a658
[92mINFO [0m:      Sent reply
02/06/2025 21:00:50:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:01:36:INFO:
[92mINFO [0m:      Received: train message ddfb1719-5b48-4b73-b833-73549fc4c38f
02/06/2025 21:01:36:INFO:Received: train message ddfb1719-5b48-4b73-b833-73549fc4c38f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:02:00:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:03:05:INFO:
[92mINFO [0m:      Received: evaluate message e4acda26-1554-4ee1-ab4c-fb7bcba1c47f
02/06/2025 21:03:05:INFO:Received: evaluate message e4acda26-1554-4ee1-ab4c-fb7bcba1c47f
[92mINFO [0m:      Sent reply
02/06/2025 21:03:08:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:04:00:INFO:
[92mINFO [0m:      Received: train message 912e1427-4705-4e26-8ebc-9a96420d6056
02/06/2025 21:04:00:INFO:Received: train message 912e1427-4705-4e26-8ebc-9a96420d6056
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:04:27:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:05:41:INFO:
[92mINFO [0m:      Received: evaluate message c2ca5f65-d413-4fb3-b576-540a4b5b917a
02/06/2025 21:05:41:INFO:Received: evaluate message c2ca5f65-d413-4fb3-b576-540a4b5b917a
[92mINFO [0m:      Sent reply
02/06/2025 21:05:45:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:06:21:INFO:
[92mINFO [0m:      Received: train message 42909c10-ad48-4e9e-bcf7-06651ddb90a7
02/06/2025 21:06:21:INFO:Received: train message 42909c10-ad48-4e9e-bcf7-06651ddb90a7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:06:47:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:07:49:INFO:
[92mINFO [0m:      Received: evaluate message 5ce8392a-8065-45c0-bd90-79e3d4043913
02/06/2025 21:07:49:INFO:Received: evaluate message 5ce8392a-8065-45c0-bd90-79e3d4043913
[92mINFO [0m:      Sent reply
02/06/2025 21:07:54:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:09:03:INFO:
[92mINFO [0m:      Received: train message f27d2b59-c1ad-46c7-993a-9883f91bb672
02/06/2025 21:09:03:INFO:Received: train message f27d2b59-c1ad-46c7-993a-9883f91bb672
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:09:24:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:10:42:INFO:
[92mINFO [0m:      Received: evaluate message 9c0562e9-3a46-4e71-92f2-1bff0e012447
02/06/2025 21:10:42:INFO:Received: evaluate message 9c0562e9-3a46-4e71-92f2-1bff0e012447
[92mINFO [0m:      Sent reply
02/06/2025 21:10:46:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:11:23:INFO:
[92mINFO [0m:      Received: train message 585b74c3-9c28-4909-9cae-0a07daf41dc3
02/06/2025 21:11:23:INFO:Received: train message 585b74c3-9c28-4909-9cae-0a07daf41dc3
Device: cuda:0
Params: {'batch_size': 32, 'local_epochs': 3, 'full_dataset_size': 6400, 'number_of_classes': 4}
Privacy Params: {'target_delta': 1e-05, 'noise_multiplier': 3.79, 'max_grad_norm': 1.0}
Epsilon = 0.2204

{'loss': [4.302713655139246], 'accuracy': [0.2400312744331509], 'auc': [0.47827474369261547]}

Epsilon = 0.3138

{'loss': [4.302713655139246, 27.84521985970368], 'accuracy': [0.2400312744331509, 0.3502736512900704], 'auc': [0.47827474369261547, 0.47614211926726857]}

Epsilon = 0.3872

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693]}

Epsilon = 0.4499

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073]}

Epsilon = 0.5059

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092]}

Epsilon = 0.5569

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525]}

Epsilon = 0.6042

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793]}

Epsilon = 0.6486

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444]}

Epsilon = 0.6905

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716]}

Epsilon = 0.7304

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254]}

Epsilon = 0.7685

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565]}

Epsilon = 0.8051

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707]}

Epsilon = 0.8404

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118]}

Epsilon = 0.8744

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909]}

Epsilon = 0.9074

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879]}

/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:11:49:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:12:21:INFO:
[92mINFO [0m:      Received: evaluate message e09f9b86-ff00-41c0-a1f0-034f9aebecb9
02/06/2025 21:12:21:INFO:Received: evaluate message e09f9b86-ff00-41c0-a1f0-034f9aebecb9
[92mINFO [0m:      Sent reply
02/06/2025 21:12:28:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:13:59:INFO:
[92mINFO [0m:      Received: train message 4de44826-1b44-468b-adef-bff5b4f160c9
02/06/2025 21:13:59:INFO:Received: train message 4de44826-1b44-468b-adef-bff5b4f160c9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:14:20:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:14:59:INFO:
[92mINFO [0m:      Received: evaluate message f99662f9-40a7-4860-b613-0a9938a1730e
02/06/2025 21:14:59:INFO:Received: evaluate message f99662f9-40a7-4860-b613-0a9938a1730e
[92mINFO [0m:      Sent reply
02/06/2025 21:15:03:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:15:40:INFO:
[92mINFO [0m:      Received: train message e05395cf-590c-40e7-9125-d525eb9c4d53
02/06/2025 21:15:40:INFO:Received: train message e05395cf-590c-40e7-9125-d525eb9c4d53
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:16:12:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:17:11:INFO:
[92mINFO [0m:      Received: evaluate message 3736bb3f-c9a5-45b1-b5f5-85e665c88d60
02/06/2025 21:17:11:INFO:Received: evaluate message 3736bb3f-c9a5-45b1-b5f5-85e665c88d60
[92mINFO [0m:      Sent reply
02/06/2025 21:17:16:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:18:00:INFO:
[92mINFO [0m:      Received: train message 6944b8b1-a91d-42c0-a424-791d82d2d854
02/06/2025 21:18:00:INFO:Received: train message 6944b8b1-a91d-42c0-a424-791d82d2d854
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:18:24:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:19:13:INFO:
[92mINFO [0m:      Received: evaluate message a14fcdc5-cdfb-44ce-acde-cef1bd68937e
02/06/2025 21:19:13:INFO:Received: evaluate message a14fcdc5-cdfb-44ce-acde-cef1bd68937e
[92mINFO [0m:      Sent reply
02/06/2025 21:19:15:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:19:27:INFO:
[92mINFO [0m:      Received: train message a2a67353-d731-4a1d-853d-071202348392
02/06/2025 21:19:27:INFO:Received: train message a2a67353-d731-4a1d-853d-071202348392
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:19:54:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:21:12:INFO:
[92mINFO [0m:      Received: evaluate message e2127211-99df-4514-9a33-88a1981874c5
02/06/2025 21:21:12:INFO:Received: evaluate message e2127211-99df-4514-9a33-88a1981874c5
[92mINFO [0m:      Sent reply
02/06/2025 21:21:18:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:22:01:INFO:
[92mINFO [0m:      Received: train message dc2acc70-1a00-443f-8b5e-c2b789ce1a99
02/06/2025 21:22:01:INFO:Received: train message dc2acc70-1a00-443f-8b5e-c2b789ce1a99
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:22:28:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:23:21:INFO:
[92mINFO [0m:      Received: evaluate message c0e6d04f-a44e-4cc0-acb0-e2dae327e8fa
02/06/2025 21:23:21:INFO:Received: evaluate message c0e6d04f-a44e-4cc0-acb0-e2dae327e8fa
[92mINFO [0m:      Sent reply
02/06/2025 21:23:24:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:23:42:INFO:
[92mINFO [0m:      Received: train message f4be017e-d696-4583-8291-886927161085
02/06/2025 21:23:42:INFO:Received: train message f4be017e-d696-4583-8291-886927161085
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:24:06:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:25:29:INFO:
[92mINFO [0m:      Received: evaluate message 30e25953-f24f-49d5-a1db-a85c164994cf
02/06/2025 21:25:29:INFO:Received: evaluate message 30e25953-f24f-49d5-a1db-a85c164994cf
Epsilon = 0.9395

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285]}

Epsilon = 0.9706

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458, 68.29736875723451], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721, 0.34636434714620795], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285, 0.48409113633022693]}

Epsilon = 1.0010

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458, 68.29736875723451, 131.3007213124267], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721, 0.34636434714620795, 0.5003909304143862], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285, 0.48409113633022693, 0.5009446419502286]}

Epsilon = 1.0306

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458, 68.29736875723451, 131.3007213124267, 113.53652393531031], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721, 0.34636434714620795, 0.5003909304143862, 0.34401876465989056], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285, 0.48409113633022693, 0.5009446419502286, 0.4855675811475806]}

Epsilon = 1.0595

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458, 68.29736875723451, 131.3007213124267, 113.53652393531031, 99.00178407597485], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721, 0.34636434714620795, 0.5003909304143862, 0.34401876465989056, 0.2720875684128225], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285, 0.48409113633022693, 0.5009446419502286, 0.4855675811475806, 0.4923742563741979]}

Epsilon = 1.0878

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458, 68.29736875723451, 131.3007213124267, 113.53652393531031, 99.00178407597485, 87.74225192931222], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721, 0.34636434714620795, 0.5003909304143862, 0.34401876465989056, 0.2720875684128225, 0.16888193901485535], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285, 0.48409113633022693, 0.5009446419502286, 0.4855675811475806, 0.4923742563741979, 0.4869044776323245]}

Epsilon = 1.1155
[92mINFO [0m:      Sent reply
02/06/2025 21:25:34:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:26:14:INFO:
[92mINFO [0m:      Received: train message 2d6593b9-e9aa-4b2d-845e-5c78d581af3c
02/06/2025 21:26:14:INFO:Received: train message 2d6593b9-e9aa-4b2d-845e-5c78d581af3c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:26:46:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:27:22:INFO:
[92mINFO [0m:      Received: evaluate message ce65d1bb-a74a-4765-b7e1-a34e73ad8728
02/06/2025 21:27:22:INFO:Received: evaluate message ce65d1bb-a74a-4765-b7e1-a34e73ad8728
[92mINFO [0m:      Sent reply
02/06/2025 21:27:27:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:28:07:INFO:
[92mINFO [0m:      Received: train message c972b633-5b22-4aa6-9336-1634162630fd
02/06/2025 21:28:07:INFO:Received: train message c972b633-5b22-4aa6-9336-1634162630fd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:28:28:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:29:45:INFO:
[92mINFO [0m:      Received: evaluate message 9b0a0e67-542a-494d-821d-36b460ad0b7b
02/06/2025 21:29:45:INFO:Received: evaluate message 9b0a0e67-542a-494d-821d-36b460ad0b7b
[92mINFO [0m:      Sent reply
02/06/2025 21:29:48:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:30:20:INFO:
[92mINFO [0m:      Received: train message a3fd838f-4112-4345-961a-7b94d2b12015
02/06/2025 21:30:20:INFO:Received: train message a3fd838f-4112-4345-961a-7b94d2b12015
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:30:40:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:31:54:INFO:
[92mINFO [0m:      Received: evaluate message 5de4c99c-ed97-43c2-8c52-13adae074339
02/06/2025 21:31:54:INFO:Received: evaluate message 5de4c99c-ed97-43c2-8c52-13adae074339
[92mINFO [0m:      Sent reply
02/06/2025 21:31:59:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:32:50:INFO:
[92mINFO [0m:      Received: train message 5112a54e-250b-45a4-a3bf-ced178573352
02/06/2025 21:32:51:INFO:Received: train message 5112a54e-250b-45a4-a3bf-ced178573352
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:33:19:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:36:51:INFO:
[92mINFO [0m:      Received: evaluate message 27a40de3-e573-4655-b98e-a6ef3db72aeb
02/06/2025 21:36:51:INFO:Received: evaluate message 27a40de3-e573-4655-b98e-a6ef3db72aeb
[92mINFO [0m:      Sent reply
02/06/2025 21:36:55:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:37:20:INFO:
[92mINFO [0m:      Received: train message bfe4f4d2-e134-4ccc-98fa-4a7f3580ddb7
02/06/2025 21:37:20:INFO:Received: train message bfe4f4d2-e134-4ccc-98fa-4a7f3580ddb7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:37:46:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:38:31:INFO:
[92mINFO [0m:      Received: evaluate message fe14c5bd-6da7-42af-8dff-5bb95ab9b630
02/06/2025 21:38:31:INFO:Received: evaluate message fe14c5bd-6da7-42af-8dff-5bb95ab9b630

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458, 68.29736875723451, 131.3007213124267, 113.53652393531031, 99.00178407597485, 87.74225192931222, 60.11921580434952], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721, 0.34636434714620795, 0.5003909304143862, 0.34401876465989056, 0.2720875684128225, 0.16888193901485535, 0.4980453479280688], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285, 0.48409113633022693, 0.5009446419502286, 0.4855675811475806, 0.4923742563741979, 0.4869044776323245, 0.4889168729897405]}

Epsilon = 1.1427

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458, 68.29736875723451, 131.3007213124267, 113.53652393531031, 99.00178407597485, 87.74225192931222, 60.11921580434952, 122.91617952873224], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721, 0.34636434714620795, 0.5003909304143862, 0.34401876465989056, 0.2720875684128225, 0.16888193901485535, 0.4980453479280688, 0.31352619233776385], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285, 0.48409113633022693, 0.5009446419502286, 0.4855675811475806, 0.4923742563741979, 0.4869044776323245, 0.4889168729897405, 0.4859810260384417]}

Epsilon = 1.1694

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458, 68.29736875723451, 131.3007213124267, 113.53652393531031, 99.00178407597485, 87.74225192931222, 60.11921580434952, 122.91617952873224, 100.19474501457476], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721, 0.34636434714620795, 0.5003909304143862, 0.34401876465989056, 0.2720875684128225, 0.16888193901485535, 0.4980453479280688, 0.31352619233776385, 0.3518373729476153], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285, 0.48409113633022693, 0.5009446419502286, 0.4855675811475806, 0.4923742563741979, 0.4869044776323245, 0.4889168729897405, 0.4859810260384417, 0.48370460459750425]}

Epsilon = 1.1955

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458, 68.29736875723451, 131.3007213124267, 113.53652393531031, 99.00178407597485, 87.74225192931222, 60.11921580434952, 122.91617952873224, 100.19474501457476, 121.31444915931051], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721, 0.34636434714620795, 0.5003909304143862, 0.34401876465989056, 0.2720875684128225, 0.16888193901485535, 0.4980453479280688, 0.31352619233776385, 0.3518373729476153, 0.30258014073494915], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285, 0.48409113633022693, 0.5009446419502286, 0.4855675811475806, 0.4923742563741979, 0.4869044776323245, 0.4889168729897405, 0.4859810260384417, 0.48370460459750425, 0.5072145946930078]}

Epsilon = 1.2212

{'loss': [4.302713655139246, 27.84521985970368, 63.69507396659225, 63.943002755983066, 26.92415244596684, 24.596068852762397, 55.975927321588365, 19.211376316858683, 32.965100957603546, 99.59893965851617, 108.52776598538898, 134.5001859210076, 45.35990655388911, 153.78809197420622, 154.13307041279387, 124.87446291806458, 68.29736875723451, 131.3007213124267, 113.53652393531031, 99.00178407597485, 87.74225192931222, 60.11921580434952, 122.91617952873224, 100.19474501457476, 121.31444915931051, 339.4090980239164], 'accuracy': [0.2400312744331509, 0.3502736512900704, 0.009382329945269743, 0.5003909304143862, 0.4949179046129789, 0.3299452697419859, 0.0328381548084441, 0.4878811571540266, 0.43080531665363564, 0.5003909304143862, 0.3502736512900704, 0.3502736512900704, 0.49257232212666147, 0.5003909304143862, 0.44253322908522286, 0.2877247849882721, 0.34636434714620795, 0.5003909304143862, 0.34401876465989056, 0.2720875684128225, 0.16888193901485535, 0.4980453479280688, 0.31352619233776385, 0.3518373729476153, 0.30258014073494915, 0.3502736512900704], 'auc': [0.47827474369261547, 0.47614211926726857, 0.4709913259050693, 0.4878160424334073, 0.518922525359092, 0.5957321441744525, 0.5411312872716793, 0.535240254577444, 0.5174875776734716, 0.5002585364019254, 0.49703241148278565, 0.5001947011932707, 0.499541646476118, 0.4996590909090909, 0.4677117650335879, 0.46780556261554285, 0.48409113633022693, 0.5009446419502286, 0.4855675811475806, 0.4923742563741979, 0.4869044776323245, 0.4889168729897405, 0.4859810260384417, 0.48370460459750425, 0.5072145946930078, 0.4926696869921653]}

Epsilon = 1.2465
[92mINFO [0m:      Sent reply
02/06/2025 21:38:34:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:39:32:INFO:
[92mINFO [0m:      Received: train message ae2bb234-55d3-4ba5-bd51-515942a9ea4b
02/06/2025 21:39:32:INFO:Received: train message ae2bb234-55d3-4ba5-bd51-515942a9ea4b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:40:05:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:41:00:INFO:
[92mINFO [0m:      Received: evaluate message 42798083-7435-4bb0-ae83-7816117ae31d
02/06/2025 21:41:00:INFO:Received: evaluate message 42798083-7435-4bb0-ae83-7816117ae31d
[92mINFO [0m:      Sent reply
02/06/2025 21:41:06:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:41:33:INFO:
[92mINFO [0m:      Received: train message 25c207d7-124d-4105-a4fc-f8046fb4be57
02/06/2025 21:41:33:INFO:Received: train message 25c207d7-124d-4105-a4fc-f8046fb4be57
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:41:59:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:43:09:INFO:
[92mINFO [0m:      Received: evaluate message 7835a875-5006-4360-a4ae-c5f8791293ae
02/06/2025 21:43:09:INFO:Received: evaluate message 7835a875-5006-4360-a4ae-c5f8791293ae
[92mINFO [0m:      Sent reply
02/06/2025 21:43:14:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:44:06:INFO:
[92mINFO [0m:      Received: train message 538b84e2-34e5-4475-b793-471ee714e410
02/06/2025 21:44:06:INFO:Received: train message 538b84e2-34e5-4475-b793-471ee714e410
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:44:27:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:45:19:INFO:
[92mINFO [0m:      Received: evaluate message ed0d2c16-07d7-41f4-bde9-f182091421ba
02/06/2025 21:45:19:INFO:Received: evaluate message ed0d2c16-07d7-41f4-bde9-f182091421ba
[92mINFO [0m:      Sent reply
02/06/2025 21:45:23:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:45:56:INFO:
[92mINFO [0m:      Received: reconnect message 4eb2bf78-5c97-4995-8957-112e1c6bfeb9
02/06/2025 21:45:56:INFO:Received: reconnect message 4eb2bf78-5c97-4995-8957-112e1c6bfeb9
02/06/2025 21:45:56:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/06/2025 21:45:56:INFO:Disconnect and shut down
