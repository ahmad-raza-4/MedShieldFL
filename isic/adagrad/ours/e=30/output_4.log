nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.4 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
02/12/2025 06:43:22:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/12/2025 06:43:22:DEBUG:ChannelConnectivity.IDLE
02/12/2025 06:43:22:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1739371402.612663 2069984 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/12/2025 06:49:09:INFO:
[92mINFO [0m:      Received: train message 6d4e569c-c2db-4603-a669-920ceb0e56a8
02/12/2025 06:49:09:INFO:Received: train message 6d4e569c-c2db-4603-a669-920ceb0e56a8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 07:00:34:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:22:00:INFO:
[92mINFO [0m:      Received: evaluate message b5b2fca7-0812-4f0d-99c1-57b2fa1ef034
02/12/2025 07:22:00:INFO:Received: evaluate message b5b2fca7-0812-4f0d-99c1-57b2fa1ef034
[92mINFO [0m:      Sent reply
02/12/2025 07:25:56:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:26:33:INFO:
[92mINFO [0m:      Received: train message 9f2d06a9-720a-4e68-8fc7-c3dacadc75a5
02/12/2025 07:26:33:INFO:Received: train message 9f2d06a9-720a-4e68-8fc7-c3dacadc75a5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 07:38:21:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:59:47:INFO:
[92mINFO [0m:      Received: evaluate message edc4e3f8-02c9-4e9f-aee3-d714e28657b2
02/12/2025 07:59:47:INFO:Received: evaluate message edc4e3f8-02c9-4e9f-aee3-d714e28657b2
[92mINFO [0m:      Sent reply
02/12/2025 08:03:41:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:04:29:INFO:
[92mINFO [0m:      Received: train message 7be9bac9-6d4f-4c06-bed1-43aa02908857
02/12/2025 08:04:29:INFO:Received: train message 7be9bac9-6d4f-4c06-bed1-43aa02908857
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 08:16:17:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:38:24:INFO:
[92mINFO [0m:      Received: evaluate message bbd1cf4d-742c-4ebf-9d60-6742882e40b0
02/12/2025 08:38:24:INFO:Received: evaluate message bbd1cf4d-742c-4ebf-9d60-6742882e40b0
[92mINFO [0m:      Sent reply
02/12/2025 08:42:21:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:42:54:INFO:
[92mINFO [0m:      Received: train message 794df783-075a-4a58-a515-e6622b14bc47
02/12/2025 08:42:54:INFO:Received: train message 794df783-075a-4a58-a515-e6622b14bc47
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 08:54:31:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:16:48:INFO:
[92mINFO [0m:      Received: evaluate message cd653c7b-006a-42d8-8a97-ea6419ebb082
02/12/2025 09:16:48:INFO:Received: evaluate message cd653c7b-006a-42d8-8a97-ea6419ebb082
[92mINFO [0m:      Sent reply
02/12/2025 09:20:51:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:21:22:INFO:
[92mINFO [0m:      Received: train message 980e21d7-44b8-4536-8fbe-18f0a54a2ef8
02/12/2025 09:21:22:INFO:Received: train message 980e21d7-44b8-4536-8fbe-18f0a54a2ef8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 09:33:30:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:54:35:INFO:
[92mINFO [0m:      Received: evaluate message 4dcee2ff-5be3-4a5d-8c91-aa41b6702355
02/12/2025 09:54:35:INFO:Received: evaluate message 4dcee2ff-5be3-4a5d-8c91-aa41b6702355
[92mINFO [0m:      Sent reply
02/12/2025 09:58:08:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:59:04:INFO:
[92mINFO [0m:      Received: train message 7d1c95db-445a-4f6f-864e-89ba23732576
02/12/2025 09:59:04:INFO:Received: train message 7d1c95db-445a-4f6f-864e-89ba23732576
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 10:10:49:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 10:32:54:INFO:
[92mINFO [0m:      Received: evaluate message c5856027-601b-4eb1-b3fa-c08a53046f43
02/12/2025 10:32:54:INFO:Received: evaluate message c5856027-601b-4eb1-b3fa-c08a53046f43
[92mINFO [0m:      Sent reply
02/12/2025 10:36:59:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 10:37:28:INFO:
[92mINFO [0m:      Received: train message 2d79ca2f-4b50-4a20-8c29-a3ac0bbf095e
02/12/2025 10:37:28:INFO:Received: train message 2d79ca2f-4b50-4a20-8c29-a3ac0bbf095e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 10:49:28:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:11:07:INFO:
[92mINFO [0m:      Received: evaluate message 16f81676-6cb3-469a-a728-ad090bce5e99
02/12/2025 11:11:07:INFO:Received: evaluate message 16f81676-6cb3-469a-a728-ad090bce5e99
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 18597, num_classes: 8

Privacy Params:
 epsilon: 30.0, target_epsilon: 30.0, target_delta: 1e-05

Device: cuda:0

Step 1a: Client Initialized
Step 1b: Recomputing FIM for epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904], 'accuracy': [0.21143777688280307], 'auc': [0.5402203774856965], 'precision': [0.27998875874705753], 'recall': [0.21143777688280307], 'f1': [0.20810330062677435]}

Step 1b: Recomputing FIM for epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124], 'accuracy': [0.21143777688280307, 0.270237615787354], 'auc': [0.5402203774856965, 0.5733188230827513], 'precision': [0.27998875874705753, 0.3166973493865562], 'recall': [0.21143777688280307, 0.270237615787354], 'f1': [0.20810330062677435, 0.2665872516861315]}

Step 1b: Recomputing FIM for epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709]}

Step 1b: Recomputing FIM for epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124]}

Step 1b: Recomputing FIM for epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753]}

Step 1b: Recomputing FIM for epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195]}

Step 1b: Recomputing FIM for epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 11:15:07:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:15:41:INFO:
[92mINFO [0m:      Received: train message 479010e4-0687-4fd7-9234-3828b1ab784e
02/12/2025 11:15:41:INFO:Received: train message 479010e4-0687-4fd7-9234-3828b1ab784e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 11:27:37:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:48:53:INFO:
[92mINFO [0m:      Received: evaluate message 379e90fb-c0d7-4092-923d-e3e779e18462
02/12/2025 11:48:53:INFO:Received: evaluate message 379e90fb-c0d7-4092-923d-e3e779e18462
[92mINFO [0m:      Sent reply
02/12/2025 11:52:54:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:53:49:INFO:
[92mINFO [0m:      Received: train message 56960202-2857-435b-9f83-560e303be109
02/12/2025 11:53:49:INFO:Received: train message 56960202-2857-435b-9f83-560e303be109
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 12:05:27:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 12:26:28:INFO:
[92mINFO [0m:      Received: evaluate message d006ede2-3cc7-4636-a395-6558fa857758
02/12/2025 12:26:28:INFO:Received: evaluate message d006ede2-3cc7-4636-a395-6558fa857758
[92mINFO [0m:      Sent reply
02/12/2025 12:30:37:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 12:31:23:INFO:
[92mINFO [0m:      Received: train message 46407703-826f-419a-bfe5-3d5d1879ae99
02/12/2025 12:31:23:INFO:Received: train message 46407703-826f-419a-bfe5-3d5d1879ae99
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 12:43:30:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:04:25:INFO:
[92mINFO [0m:      Received: evaluate message f7f1f6bf-f973-4950-b82d-32544eed1dc7
02/12/2025 13:04:25:INFO:Received: evaluate message f7f1f6bf-f973-4950-b82d-32544eed1dc7
[92mINFO [0m:      Sent reply
02/12/2025 13:08:41:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:09:12:INFO:
[92mINFO [0m:      Received: train message ee8f1da1-8918-45e5-970e-2ac2217a7341
02/12/2025 13:09:12:INFO:Received: train message ee8f1da1-8918-45e5-970e-2ac2217a7341
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 13:21:26:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:42:26:INFO:
[92mINFO [0m:      Received: evaluate message 8b8fb8b3-a94a-4f66-9dac-60c4a06053d3
02/12/2025 13:42:26:INFO:Received: evaluate message 8b8fb8b3-a94a-4f66-9dac-60c4a06053d3

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905]}

Step 1b: Recomputing FIM for epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977]}

Step 1b: Recomputing FIM for epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446]}

Step 1b: Recomputing FIM for epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335]}

Step 1b: Recomputing FIM for epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 13:46:40:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:46:57:INFO:
[92mINFO [0m:      Received: train message bb92415b-0f95-4bc6-8285-059ff20c5e84
02/12/2025 13:46:57:INFO:Received: train message bb92415b-0f95-4bc6-8285-059ff20c5e84
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 13:59:15:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:20:13:INFO:
[92mINFO [0m:      Received: evaluate message 22c280e0-0905-4068-82c8-732af7b15923
02/12/2025 14:20:13:INFO:Received: evaluate message 22c280e0-0905-4068-82c8-732af7b15923
[92mINFO [0m:      Sent reply
02/12/2025 14:24:17:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:24:48:INFO:
[92mINFO [0m:      Received: train message 9765f560-1c78-45a3-8a48-ddf43cddd133
02/12/2025 14:24:48:INFO:Received: train message 9765f560-1c78-45a3-8a48-ddf43cddd133
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 14:37:11:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:57:15:INFO:
[92mINFO [0m:      Received: evaluate message 2792f5b8-2aef-43cb-87d2-b3ba24f6316c
02/12/2025 14:57:15:INFO:Received: evaluate message 2792f5b8-2aef-43cb-87d2-b3ba24f6316c
[92mINFO [0m:      Sent reply
02/12/2025 15:01:35:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:02:23:INFO:
[92mINFO [0m:      Received: train message 297dcd24-071d-4750-bdfd-810ac775b9a7
02/12/2025 15:02:23:INFO:Received: train message 297dcd24-071d-4750-bdfd-810ac775b9a7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 15:14:39:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:35:04:INFO:
[92mINFO [0m:      Received: evaluate message b2a370a2-3f8d-40a0-b40e-6f0d08edc8ac
02/12/2025 15:35:04:INFO:Received: evaluate message b2a370a2-3f8d-40a0-b40e-6f0d08edc8ac
[92mINFO [0m:      Sent reply
02/12/2025 15:39:26:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:39:50:INFO:
[92mINFO [0m:      Received: train message 02afe8db-0e5f-4231-be7f-66ecdb73166e
02/12/2025 15:39:50:INFO:Received: train message 02afe8db-0e5f-4231-be7f-66ecdb73166e

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202]}

Step 1b: Recomputing FIM for epoch 12
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254]}

Step 1b: Recomputing FIM for epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472]}

Step 1b: Recomputing FIM for epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679]}

Step 1b: Recomputing FIM for epoch 15
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 15:51:48:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:12:23:INFO:
[92mINFO [0m:      Received: evaluate message 934229d8-7d29-4c9f-a94d-32d8b23812c4
02/12/2025 16:12:23:INFO:Received: evaluate message 934229d8-7d29-4c9f-a94d-32d8b23812c4
[92mINFO [0m:      Sent reply
02/12/2025 16:16:40:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:17:15:INFO:
[92mINFO [0m:      Received: train message d13f589e-b6f8-4e1c-9f89-eb1de2df1920
02/12/2025 16:17:15:INFO:Received: train message d13f589e-b6f8-4e1c-9f89-eb1de2df1920
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 16:29:41:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:49:39:INFO:
[92mINFO [0m:      Received: evaluate message e01c1423-dba3-4332-b515-60bc581a6147
02/12/2025 16:49:39:INFO:Received: evaluate message e01c1423-dba3-4332-b515-60bc581a6147
[92mINFO [0m:      Sent reply
02/12/2025 16:54:10:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:54:31:INFO:
[92mINFO [0m:      Received: train message c5345d1c-72e0-4973-98e1-3167287d8d9f
02/12/2025 16:54:31:INFO:Received: train message c5345d1c-72e0-4973-98e1-3167287d8d9f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 17:06:50:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 17:26:33:INFO:
[92mINFO [0m:      Received: evaluate message 6f6233db-2550-427e-ac86-121fecc2b8dd
02/12/2025 17:26:33:INFO:Received: evaluate message 6f6233db-2550-427e-ac86-121fecc2b8dd
[92mINFO [0m:      Sent reply
02/12/2025 17:30:44:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 17:31:09:INFO:
[92mINFO [0m:      Received: train message 5b17230a-fa6e-4d5d-99bc-5bb5192c4504
02/12/2025 17:31:09:INFO:Received: train message 5b17230a-fa6e-4d5d-99bc-5bb5192c4504
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161]}

Step 1b: Recomputing FIM for epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574]}

Step 1b: Recomputing FIM for epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617]}

Step 1b: Recomputing FIM for epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 17:43:48:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:03:28:INFO:
[92mINFO [0m:      Received: evaluate message cba061ef-02fd-4638-8bf1-4cc6a5f670eb
02/12/2025 18:03:28:INFO:Received: evaluate message cba061ef-02fd-4638-8bf1-4cc6a5f670eb
[92mINFO [0m:      Sent reply
02/12/2025 18:07:34:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:08:29:INFO:
[92mINFO [0m:      Received: train message 16a6d24b-e0e8-47fb-b19c-4ace088db2cb
02/12/2025 18:08:29:INFO:Received: train message 16a6d24b-e0e8-47fb-b19c-4ace088db2cb
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 18:20:54:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:41:02:INFO:
[92mINFO [0m:      Received: evaluate message cda2c501-7413-4b6e-97d0-14e168c60e8e
02/12/2025 18:41:02:INFO:Received: evaluate message cda2c501-7413-4b6e-97d0-14e168c60e8e
[92mINFO [0m:      Sent reply
02/12/2025 18:45:02:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:45:23:INFO:
[92mINFO [0m:      Received: train message 02ec4b90-6aae-4b45-9dfc-f6ecd4f64a8e
02/12/2025 18:45:23:INFO:Received: train message 02ec4b90-6aae-4b45-9dfc-f6ecd4f64a8e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 18:57:54:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:18:05:INFO:
[92mINFO [0m:      Received: evaluate message 40b38d5c-cb91-4d5e-97b2-7401771d49a9
02/12/2025 19:18:05:INFO:Received: evaluate message 40b38d5c-cb91-4d5e-97b2-7401771d49a9
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015]}

Step 1b: Recomputing FIM for epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708]}

Step 1b: Recomputing FIM for epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 19:22:03:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:22:51:INFO:
[92mINFO [0m:      Received: train message b57c0d65-7171-48e8-a66c-44f2092f1f6e
02/12/2025 19:22:51:INFO:Received: train message b57c0d65-7171-48e8-a66c-44f2092f1f6e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 19:35:24:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:55:14:INFO:
[92mINFO [0m:      Received: evaluate message 4a4d1762-55a8-43cd-9b49-fdcef88f0fd3
02/12/2025 19:55:14:INFO:Received: evaluate message 4a4d1762-55a8-43cd-9b49-fdcef88f0fd3
[92mINFO [0m:      Sent reply
02/12/2025 19:59:26:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:59:57:INFO:
[92mINFO [0m:      Received: train message 5c7f1566-89fd-4272-9304-ee10efea9154
02/12/2025 19:59:57:INFO:Received: train message 5c7f1566-89fd-4272-9304-ee10efea9154
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 20:12:43:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 20:32:53:INFO:
[92mINFO [0m:      Received: evaluate message b601b70c-7349-4d65-848e-ffc93513f750
02/12/2025 20:32:53:INFO:Received: evaluate message b601b70c-7349-4d65-848e-ffc93513f750

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091]}

Step 1b: Recomputing FIM for epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084]}

Step 1b: Recomputing FIM for epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 20:36:58:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 20:37:16:INFO:
[92mINFO [0m:      Received: train message eb6722fb-616a-4940-b797-adb8c2fb1e64
02/12/2025 20:37:16:INFO:Received: train message eb6722fb-616a-4940-b797-adb8c2fb1e64
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 20:49:19:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:10:13:INFO:
[92mINFO [0m:      Received: evaluate message 302935e7-c4a4-4050-aa28-c1fc14afe2b0
02/12/2025 21:10:13:INFO:Received: evaluate message 302935e7-c4a4-4050-aa28-c1fc14afe2b0
[92mINFO [0m:      Sent reply
02/12/2025 21:14:13:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:14:47:INFO:
[92mINFO [0m:      Received: train message 511e415f-b0da-4ec1-8351-79a57a30c365
02/12/2025 21:14:47:INFO:Received: train message 511e415f-b0da-4ec1-8351-79a57a30c365
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 21:27:06:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:48:00:INFO:
[92mINFO [0m:      Received: evaluate message a85c639f-accd-4827-8f1c-30a03ab3efb3
02/12/2025 21:48:00:INFO:Received: evaluate message a85c639f-accd-4827-8f1c-30a03ab3efb3

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246]}

Step 1b: Recomputing FIM for epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406]}

Step 1b: Recomputing FIM for epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 21:52:24:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:52:46:INFO:
[92mINFO [0m:      Received: train message 4dd8136b-6bb3-4ec6-9218-f0f4ecb796a7
02/12/2025 21:52:46:INFO:Received: train message 4dd8136b-6bb3-4ec6-9218-f0f4ecb796a7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 22:05:20:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 22:29:50:INFO:
[92mINFO [0m:      Received: evaluate message b3055246-ede5-4423-a70e-b94dc1a61e4c
02/12/2025 22:29:50:INFO:Received: evaluate message b3055246-ede5-4423-a70e-b94dc1a61e4c
[92mINFO [0m:      Sent reply
02/12/2025 22:33:45:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 22:34:59:INFO:
[92mINFO [0m:      Received: train message eb27e62c-a898-4647-94db-ab2569b5882d
02/12/2025 22:34:59:INFO:Received: train message eb27e62c-a898-4647-94db-ab2569b5882d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 22:47:43:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:09:08:INFO:
[92mINFO [0m:      Received: evaluate message 13e5ce58-48f4-41b7-9e2c-20d904dff4fb
02/12/2025 23:09:08:INFO:Received: evaluate message 13e5ce58-48f4-41b7-9e2c-20d904dff4fb

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254]}

Step 1b: Recomputing FIM for epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472]}

Step 1b: Recomputing FIM for epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 23:13:01:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:13:42:INFO:
[92mINFO [0m:      Received: train message 187815e9-a99e-46a9-9dbe-815a1238c8ea
02/12/2025 23:13:42:INFO:Received: train message 187815e9-a99e-46a9-9dbe-815a1238c8ea
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 23:25:29:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:47:03:INFO:
[92mINFO [0m:      Received: evaluate message dbfeec0a-29fa-4c9e-b3e5-d35f6741ebe2
02/12/2025 23:47:03:INFO:Received: evaluate message dbfeec0a-29fa-4c9e-b3e5-d35f6741ebe2
[92mINFO [0m:      Sent reply
02/12/2025 23:51:01:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:51:28:INFO:
[92mINFO [0m:      Received: train message a531dfe6-d6e2-4755-b4f2-5d2106412bfd
02/12/2025 23:51:28:INFO:Received: train message a531dfe6-d6e2-4755-b4f2-5d2106412bfd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 00:03:08:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 00:24:45:INFO:
[92mINFO [0m:      Received: evaluate message a6c5145d-3022-43d3-9ba3-898a24f1e13e
02/13/2025 00:24:45:INFO:Received: evaluate message a6c5145d-3022-43d3-9ba3-898a24f1e13e

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674]}

Step 1b: Recomputing FIM for epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489]}

Step 1b: Recomputing FIM for epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/13/2025 00:28:38:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 00:28:59:INFO:
[92mINFO [0m:      Received: train message 77059427-1df3-497f-aa3d-29ee47cb9623
02/13/2025 00:28:59:INFO:Received: train message 77059427-1df3-497f-aa3d-29ee47cb9623
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 00:40:33:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:03:50:INFO:
[92mINFO [0m:      Received: evaluate message 4e25a003-8e4b-4aec-bcbc-756a9b64fa5f
02/13/2025 01:03:50:INFO:Received: evaluate message 4e25a003-8e4b-4aec-bcbc-756a9b64fa5f
[92mINFO [0m:      Sent reply
02/13/2025 01:07:56:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:08:29:INFO:
[92mINFO [0m:      Received: train message 14abe736-d542-47eb-9be0-70d5f67bf9e7
02/13/2025 01:08:29:INFO:Received: train message 14abe736-d542-47eb-9be0-70d5f67bf9e7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 01:20:21:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:41:25:INFO:
[92mINFO [0m:      Received: evaluate message b93d3922-a2ab-4dcc-b946-6d2720531db6
02/13/2025 01:41:25:INFO:Received: evaluate message b93d3922-a2ab-4dcc-b946-6d2720531db6

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508]}

Step 1b: Recomputing FIM for epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325]}

Step 1b: Recomputing FIM for epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
[92mINFO [0m:      Sent reply
02/13/2025 01:45:37:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:46:09:INFO:
[92mINFO [0m:      Received: reconnect message edcd7bcc-dbf8-430c-9179-4ba3098bb730
02/13/2025 01:46:09:INFO:Received: reconnect message edcd7bcc-dbf8-430c-9179-4ba3098bb730
02/13/2025 01:46:09:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/13/2025 01:46:09:INFO:Disconnect and shut down
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892, 1.4863234110719679], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786, 0.8018291515091863], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276, 0.49597451052139874], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325, 0.49389366507549604]}



Final client history:
{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892, 1.4863234110719679], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786, 0.8018291515091863], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276, 0.49597451052139874], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325, 0.49389366507549604]}

