nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.4 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
02/12/2025 06:45:10:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/12/2025 06:45:10:DEBUG:ChannelConnectivity.IDLE
02/12/2025 06:45:10:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1739371510.646564 2071244 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/12/2025 06:49:09:INFO:
[92mINFO [0m:      Received: train message cb95780a-6a36-4a5d-9fc3-3aca52c10c0b
02/12/2025 06:49:09:INFO:Received: train message cb95780a-6a36-4a5d-9fc3-3aca52c10c0b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 07:06:51:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:22:04:INFO:
[92mINFO [0m:      Received: evaluate message e4f752f0-4e04-44da-a36f-56ad5c44d84b
02/12/2025 07:22:04:INFO:Received: evaluate message e4f752f0-4e04-44da-a36f-56ad5c44d84b
[92mINFO [0m:      Sent reply
02/12/2025 07:26:05:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:26:39:INFO:
[92mINFO [0m:      Received: train message bcb97cd2-e16e-421d-8697-1a1dbf6c0af7
02/12/2025 07:26:39:INFO:Received: train message bcb97cd2-e16e-421d-8697-1a1dbf6c0af7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 07:44:25:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:59:56:INFO:
[92mINFO [0m:      Received: evaluate message f153c7d8-1982-4c80-b58a-7681fb90f065
02/12/2025 07:59:56:INFO:Received: evaluate message f153c7d8-1982-4c80-b58a-7681fb90f065
[92mINFO [0m:      Sent reply
02/12/2025 08:03:56:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:04:29:INFO:
[92mINFO [0m:      Received: train message eb06cf70-a496-49af-bc00-89c985c620cc
02/12/2025 08:04:29:INFO:Received: train message eb06cf70-a496-49af-bc00-89c985c620cc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 08:22:15:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:38:09:INFO:
[92mINFO [0m:      Received: evaluate message 734d3a11-fc30-4fb6-85c2-1c3b9efa7398
02/12/2025 08:38:09:INFO:Received: evaluate message 734d3a11-fc30-4fb6-85c2-1c3b9efa7398
[92mINFO [0m:      Sent reply
02/12/2025 08:42:07:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:42:42:INFO:
[92mINFO [0m:      Received: train message a67d9ffc-3a58-4930-92bf-f7aa7eedcb88
02/12/2025 08:42:42:INFO:Received: train message a67d9ffc-3a58-4930-92bf-f7aa7eedcb88
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 09:00:31:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:16:41:INFO:
[92mINFO [0m:      Received: evaluate message bea10873-6bff-4478-9845-23aaca3da601
02/12/2025 09:16:41:INFO:Received: evaluate message bea10873-6bff-4478-9845-23aaca3da601
[92mINFO [0m:      Sent reply
02/12/2025 09:20:36:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:21:11:INFO:
[92mINFO [0m:      Received: train message 681113df-514b-4c2a-937c-34a3fa849715
02/12/2025 09:21:11:INFO:Received: train message 681113df-514b-4c2a-937c-34a3fa849715
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 09:39:20:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:54:52:INFO:
[92mINFO [0m:      Received: evaluate message c02382c1-2a9c-468e-b58f-1acdc0b78fd6
02/12/2025 09:54:52:INFO:Received: evaluate message c02382c1-2a9c-468e-b58f-1acdc0b78fd6
[92mINFO [0m:      Sent reply
02/12/2025 09:58:50:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:59:23:INFO:
[92mINFO [0m:      Received: train message 12fb8e9c-6959-4cc9-8daa-11b57b5a75d6
02/12/2025 09:59:23:INFO:Received: train message 12fb8e9c-6959-4cc9-8daa-11b57b5a75d6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 10:17:11:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 10:32:45:INFO:
[92mINFO [0m:      Received: evaluate message 86c8399e-9a5e-44ae-9cba-a26d518f1414
02/12/2025 10:32:45:INFO:Received: evaluate message 86c8399e-9a5e-44ae-9cba-a26d518f1414
[92mINFO [0m:      Sent reply
02/12/2025 10:36:51:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 10:37:33:INFO:
[92mINFO [0m:      Received: train message 2af09108-2129-4712-ae55-0a1f72d95506
02/12/2025 10:37:33:INFO:Received: train message 2af09108-2129-4712-ae55-0a1f72d95506
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 10:54:44:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:11:13:INFO:
[92mINFO [0m:      Received: evaluate message e7b75f7f-cffb-4eb8-ab14-dc9ab3552639
02/12/2025 11:11:13:INFO:Received: evaluate message e7b75f7f-cffb-4eb8-ab14-dc9ab3552639
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 18597, num_classes: 8

Privacy Params:
 epsilon: 30.0, target_epsilon: 30.0, target_delta: 1e-05

Device: cuda:0

Step 1a: Client Initialized
Step 1b: Recomputing FIM for epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904], 'accuracy': [0.21143777688280307], 'auc': [0.5402203774856965], 'precision': [0.27998875874705753], 'recall': [0.21143777688280307], 'f1': [0.20810330062677435]}

Step 1b: Recomputing FIM for epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124], 'accuracy': [0.21143777688280307, 0.270237615787354], 'auc': [0.5402203774856965, 0.5733188230827513], 'precision': [0.27998875874705753, 0.3166973493865562], 'recall': [0.21143777688280307, 0.270237615787354], 'f1': [0.20810330062677435, 0.2665872516861315]}

Step 1b: Recomputing FIM for epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709]}

Step 1b: Recomputing FIM for epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124]}

Step 1b: Recomputing FIM for epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753]}

Step 1b: Recomputing FIM for epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195]}

Step 1b: Recomputing FIM for epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 11:15:12:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:15:49:INFO:
[92mINFO [0m:      Received: train message c6954213-6b9d-4393-aebf-7e55111d8bb3
02/12/2025 11:15:49:INFO:Received: train message c6954213-6b9d-4393-aebf-7e55111d8bb3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 11:33:04:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:49:11:INFO:
[92mINFO [0m:      Received: evaluate message 316913fd-234e-408d-9a19-b5ae215c13ad
02/12/2025 11:49:11:INFO:Received: evaluate message 316913fd-234e-408d-9a19-b5ae215c13ad
[92mINFO [0m:      Sent reply
02/12/2025 11:53:21:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:53:54:INFO:
[92mINFO [0m:      Received: train message ca38b51e-c5c6-4e9b-b9ae-008196fa1caa
02/12/2025 11:53:54:INFO:Received: train message ca38b51e-c5c6-4e9b-b9ae-008196fa1caa
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 12:11:02:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 12:26:27:INFO:
[92mINFO [0m:      Received: evaluate message ef887b99-6307-46ac-9fc9-3c3a571c3215
02/12/2025 12:26:27:INFO:Received: evaluate message ef887b99-6307-46ac-9fc9-3c3a571c3215
[92mINFO [0m:      Sent reply
02/12/2025 12:30:38:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 12:31:18:INFO:
[92mINFO [0m:      Received: train message 053a2fe3-33ca-4f62-8481-2b644555bc5d
02/12/2025 12:31:18:INFO:Received: train message 053a2fe3-33ca-4f62-8481-2b644555bc5d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 12:48:38:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:04:27:INFO:
[92mINFO [0m:      Received: evaluate message 0bf82328-4689-460b-bb50-4e415a769302
02/12/2025 13:04:27:INFO:Received: evaluate message 0bf82328-4689-460b-bb50-4e415a769302
[92mINFO [0m:      Sent reply
02/12/2025 13:08:40:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:08:55:INFO:
[92mINFO [0m:      Received: train message 1c69efc3-c034-4981-aed9-d9ffd4ee266d
02/12/2025 13:08:55:INFO:Received: train message 1c69efc3-c034-4981-aed9-d9ffd4ee266d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 13:26:19:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:42:26:INFO:
[92mINFO [0m:      Received: evaluate message a1a45f8a-29c8-4cd7-b550-59e7068c2eca
02/12/2025 13:42:26:INFO:Received: evaluate message a1a45f8a-29c8-4cd7-b550-59e7068c2eca

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905]}

Step 1b: Recomputing FIM for epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977]}

Step 1b: Recomputing FIM for epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446]}

Step 1b: Recomputing FIM for epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335]}

Step 1b: Recomputing FIM for epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 13:46:38:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:46:58:INFO:
[92mINFO [0m:      Received: train message 5e8656c1-b607-4fe3-a93e-810cda1b5310
02/12/2025 13:46:58:INFO:Received: train message 5e8656c1-b607-4fe3-a93e-810cda1b5310
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 14:04:35:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:19:54:INFO:
[92mINFO [0m:      Received: evaluate message 8ac7f005-b9f1-450b-92b4-647a10f41f0b
02/12/2025 14:19:54:INFO:Received: evaluate message 8ac7f005-b9f1-450b-92b4-647a10f41f0b
[92mINFO [0m:      Sent reply
02/12/2025 14:23:22:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:24:55:INFO:
[92mINFO [0m:      Received: train message f9dc5b1d-4907-4f8a-bf8e-f2da7f98e393
02/12/2025 14:24:55:INFO:Received: train message f9dc5b1d-4907-4f8a-bf8e-f2da7f98e393
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 14:42:16:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:57:21:INFO:
[92mINFO [0m:      Received: evaluate message 977ca431-de56-4a83-a1aa-8b387121db00
02/12/2025 14:57:21:INFO:Received: evaluate message 977ca431-de56-4a83-a1aa-8b387121db00
[92mINFO [0m:      Sent reply
02/12/2025 15:01:39:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:02:23:INFO:
[92mINFO [0m:      Received: train message b0086b13-cf80-4c58-9510-0d4217b7957e
02/12/2025 15:02:23:INFO:Received: train message b0086b13-cf80-4c58-9510-0d4217b7957e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 15:20:01:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:35:11:INFO:
[92mINFO [0m:      Received: evaluate message 3a8929d6-497f-4675-ba38-4ef112ecfcd3
02/12/2025 15:35:11:INFO:Received: evaluate message 3a8929d6-497f-4675-ba38-4ef112ecfcd3
[92mINFO [0m:      Sent reply
02/12/2025 15:39:31:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:40:02:INFO:
[92mINFO [0m:      Received: train message f8d4c66c-206c-431f-a274-1fa681fcbcf4
02/12/2025 15:40:02:INFO:Received: train message f8d4c66c-206c-431f-a274-1fa681fcbcf4

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202]}

Step 1b: Recomputing FIM for epoch 12
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254]}

Step 1b: Recomputing FIM for epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472]}

Step 1b: Recomputing FIM for epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679]}

Step 1b: Recomputing FIM for epoch 15
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 15:57:42:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:12:19:INFO:
[92mINFO [0m:      Received: evaluate message 4e4410e2-3f4a-484e-9340-8909ca447e7a
02/12/2025 16:12:19:INFO:Received: evaluate message 4e4410e2-3f4a-484e-9340-8909ca447e7a
[92mINFO [0m:      Sent reply
02/12/2025 16:16:40:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:17:13:INFO:
[92mINFO [0m:      Received: train message 50fc158b-6417-4886-98fb-baef7a7129d5
02/12/2025 16:17:13:INFO:Received: train message 50fc158b-6417-4886-98fb-baef7a7129d5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 16:35:13:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:49:41:INFO:
[92mINFO [0m:      Received: evaluate message 3c9ffefd-1835-42f2-a53c-7174dfebd918
02/12/2025 16:49:41:INFO:Received: evaluate message 3c9ffefd-1835-42f2-a53c-7174dfebd918
[92mINFO [0m:      Sent reply
02/12/2025 16:53:58:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:54:29:INFO:
[92mINFO [0m:      Received: train message d630ad34-6e0c-4fbf-8922-ed7f86912d1c
02/12/2025 16:54:29:INFO:Received: train message d630ad34-6e0c-4fbf-8922-ed7f86912d1c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 17:12:21:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 17:26:33:INFO:
[92mINFO [0m:      Received: evaluate message 19e11d23-599a-42b8-aed9-25633b4465f8
02/12/2025 17:26:33:INFO:Received: evaluate message 19e11d23-599a-42b8-aed9-25633b4465f8
[92mINFO [0m:      Sent reply
02/12/2025 17:30:45:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 17:31:16:INFO:
[92mINFO [0m:      Received: train message e6d12778-7db3-4db5-ae8b-a2b49a15cca1
02/12/2025 17:31:16:INFO:Received: train message e6d12778-7db3-4db5-ae8b-a2b49a15cca1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161]}

Step 1b: Recomputing FIM for epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574]}

Step 1b: Recomputing FIM for epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617]}

Step 1b: Recomputing FIM for epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 17:49:45:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:03:46:INFO:
[92mINFO [0m:      Received: evaluate message 80a36b40-7745-4a4c-b84f-516fc2a6eeb7
02/12/2025 18:03:46:INFO:Received: evaluate message 80a36b40-7745-4a4c-b84f-516fc2a6eeb7
[92mINFO [0m:      Sent reply
02/12/2025 18:08:01:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:08:35:INFO:
[92mINFO [0m:      Received: train message 4807f2fa-8b05-467f-8890-64789782fc28
02/12/2025 18:08:35:INFO:Received: train message 4807f2fa-8b05-467f-8890-64789782fc28
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 18:26:38:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:41:07:INFO:
[92mINFO [0m:      Received: evaluate message 72c3df4a-a26f-46f1-850b-a5dd2b1fe49c
02/12/2025 18:41:07:INFO:Received: evaluate message 72c3df4a-a26f-46f1-850b-a5dd2b1fe49c
[92mINFO [0m:      Sent reply
02/12/2025 18:45:04:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:45:38:INFO:
[92mINFO [0m:      Received: train message 2043f561-1054-4e8b-bcaa-033c76881634
02/12/2025 18:45:38:INFO:Received: train message 2043f561-1054-4e8b-bcaa-033c76881634
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 19:03:44:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:17:56:INFO:
[92mINFO [0m:      Received: evaluate message 0eacbdf9-1ab6-4c0e-b3ec-5d5b5fb65dcb
02/12/2025 19:17:56:INFO:Received: evaluate message 0eacbdf9-1ab6-4c0e-b3ec-5d5b5fb65dcb
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015]}

Step 1b: Recomputing FIM for epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708]}

Step 1b: Recomputing FIM for epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 19:21:17:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:22:51:INFO:
[92mINFO [0m:      Received: train message 8ff9fb27-d127-4e5f-901c-40c1f3fe8b06
02/12/2025 19:22:51:INFO:Received: train message 8ff9fb27-d127-4e5f-901c-40c1f3fe8b06
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 19:40:52:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:55:04:INFO:
[92mINFO [0m:      Received: evaluate message c5cf2130-7462-42c1-b37d-ad63a36d8a32
02/12/2025 19:55:04:INFO:Received: evaluate message c5cf2130-7462-42c1-b37d-ad63a36d8a32
[92mINFO [0m:      Sent reply
02/12/2025 19:58:42:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:59:49:INFO:
[92mINFO [0m:      Received: train message f3595ba5-4a23-476d-bcd7-31a3b9c4c69e
02/12/2025 19:59:49:INFO:Received: train message f3595ba5-4a23-476d-bcd7-31a3b9c4c69e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 20:18:10:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 20:32:40:INFO:
[92mINFO [0m:      Received: evaluate message 5f9c8d41-7e47-465b-862f-a92ad90ff3d8
02/12/2025 20:32:40:INFO:Received: evaluate message 5f9c8d41-7e47-465b-862f-a92ad90ff3d8

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091]}

Step 1b: Recomputing FIM for epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084]}

Step 1b: Recomputing FIM for epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 20:36:36:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 20:37:28:INFO:
[92mINFO [0m:      Received: train message 9ef5594b-7fb8-44ea-9773-fe99caf78960
02/12/2025 20:37:28:INFO:Received: train message 9ef5594b-7fb8-44ea-9773-fe99caf78960
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 20:55:21:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:10:02:INFO:
[92mINFO [0m:      Received: evaluate message 6b74b70f-fc0a-4f50-99f5-1fd4ef3b11d5
02/12/2025 21:10:02:INFO:Received: evaluate message 6b74b70f-fc0a-4f50-99f5-1fd4ef3b11d5
[92mINFO [0m:      Sent reply
02/12/2025 21:14:09:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:14:44:INFO:
[92mINFO [0m:      Received: train message 1715e35b-bdce-48b0-89df-db6e01d420e7
02/12/2025 21:14:44:INFO:Received: train message 1715e35b-bdce-48b0-89df-db6e01d420e7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 21:32:30:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:47:51:INFO:
[92mINFO [0m:      Received: evaluate message c218b764-15ee-452b-b707-2745d7b7730c
02/12/2025 21:47:51:INFO:Received: evaluate message c218b764-15ee-452b-b707-2745d7b7730c

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246]}

Step 1b: Recomputing FIM for epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406]}

Step 1b: Recomputing FIM for epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 21:52:00:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:52:57:INFO:
[92mINFO [0m:      Received: train message 9c265f49-f856-4c8b-ae50-6b92b7f88977
02/12/2025 21:52:57:INFO:Received: train message 9c265f49-f856-4c8b-ae50-6b92b7f88977
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 22:11:41:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 22:30:03:INFO:
[92mINFO [0m:      Received: evaluate message 3322930d-9711-461b-8f30-c9bce13534f6
02/12/2025 22:30:03:INFO:Received: evaluate message 3322930d-9711-461b-8f30-c9bce13534f6
[92mINFO [0m:      Sent reply
02/12/2025 22:34:16:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 22:34:48:INFO:
[92mINFO [0m:      Received: train message a01241d3-35b6-4205-b137-4a5f85b06ccc
02/12/2025 22:34:48:INFO:Received: train message a01241d3-35b6-4205-b137-4a5f85b06ccc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 22:53:31:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:09:20:INFO:
[92mINFO [0m:      Received: evaluate message e6e0b0ee-4fab-4303-a1b7-45f05e78a7e4
02/12/2025 23:09:20:INFO:Received: evaluate message e6e0b0ee-4fab-4303-a1b7-45f05e78a7e4

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254]}

Step 1b: Recomputing FIM for epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472]}

Step 1b: Recomputing FIM for epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 23:13:24:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:13:58:INFO:
[92mINFO [0m:      Received: train message 87beef7e-610b-45f9-a504-4f196f1c761c
02/12/2025 23:13:58:INFO:Received: train message 87beef7e-610b-45f9-a504-4f196f1c761c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 23:31:18:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:46:54:INFO:
[92mINFO [0m:      Received: evaluate message c44382dd-f884-4408-840a-23486afceede
02/12/2025 23:46:54:INFO:Received: evaluate message c44382dd-f884-4408-840a-23486afceede
[92mINFO [0m:      Sent reply
02/12/2025 23:50:48:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:51:32:INFO:
[92mINFO [0m:      Received: train message 577f7c07-94ed-4193-80ad-e4ad601e0732
02/12/2025 23:51:32:INFO:Received: train message 577f7c07-94ed-4193-80ad-e4ad601e0732
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 00:08:49:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 00:24:24:INFO:
[92mINFO [0m:      Received: evaluate message e61c5ad7-8bef-4c4e-bff3-89b925b82e0d
02/13/2025 00:24:24:INFO:Received: evaluate message e61c5ad7-8bef-4c4e-bff3-89b925b82e0d

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674]}

Step 1b: Recomputing FIM for epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489]}

Step 1b: Recomputing FIM for epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/13/2025 00:28:20:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 00:29:06:INFO:
[92mINFO [0m:      Received: train message 8a56e147-1259-40fa-9a66-3796f74b2b4d
02/13/2025 00:29:06:INFO:Received: train message 8a56e147-1259-40fa-9a66-3796f74b2b4d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 00:46:18:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:03:36:INFO:
[92mINFO [0m:      Received: evaluate message 95f513de-ef7d-405c-b006-f21bb4eeb5fb
02/13/2025 01:03:36:INFO:Received: evaluate message 95f513de-ef7d-405c-b006-f21bb4eeb5fb
[92mINFO [0m:      Sent reply
02/13/2025 01:08:09:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:08:38:INFO:
[92mINFO [0m:      Received: train message f39dc531-1e37-41df-a99d-611809ef72fb
02/13/2025 01:08:38:INFO:Received: train message f39dc531-1e37-41df-a99d-611809ef72fb
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 01:25:33:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:41:47:INFO:
[92mINFO [0m:      Received: evaluate message 65d04ac5-8733-47e3-b9ff-94679d75a996
02/13/2025 01:41:47:INFO:Received: evaluate message 65d04ac5-8733-47e3-b9ff-94679d75a996

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508]}

Step 1b: Recomputing FIM for epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325]}

Step 1b: Recomputing FIM for epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 3163, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
[92mINFO [0m:      Sent reply
02/13/2025 01:45:40:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:46:10:INFO:
[92mINFO [0m:      Received: reconnect message c97992a4-60e5-48a1-9595-e47313722f6b
02/13/2025 01:46:10:INFO:Received: reconnect message c97992a4-60e5-48a1-9595-e47313722f6b
02/13/2025 01:46:10:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/13/2025 01:46:10:INFO:Disconnect and shut down
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892, 1.4863234110719679], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786, 0.8018291515091863], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276, 0.49597451052139874], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325, 0.49389366507549604]}



Final client history:
{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892, 1.4863234110719679], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786, 0.8018291515091863], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276, 0.49597451052139874], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325, 0.49389366507549604]}

