nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.4 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
02/12/2025 06:41:10:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/12/2025 06:41:10:DEBUG:ChannelConnectivity.IDLE
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1739371270.651086 2068840 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
02/12/2025 06:41:10:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
02/12/2025 06:48:55:INFO:
[92mINFO [0m:      Received: train message 37ef05b5-1a8f-4efc-af9f-eb12a5ef76c4
02/12/2025 06:48:55:INFO:Received: train message 37ef05b5-1a8f-4efc-af9f-eb12a5ef76c4
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 06:51:57:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:21:53:INFO:
[92mINFO [0m:      Received: evaluate message 29367abc-a75e-4c62-86fe-86b33027888b
02/12/2025 07:21:53:INFO:Received: evaluate message 29367abc-a75e-4c62-86fe-86b33027888b
[92mINFO [0m:      Sent reply
02/12/2025 07:25:53:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:26:30:INFO:
[92mINFO [0m:      Received: train message e2ceb012-76e5-4ba7-9a02-83ee2b8777a3
02/12/2025 07:26:30:INFO:Received: train message e2ceb012-76e5-4ba7-9a02-83ee2b8777a3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 07:29:39:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:59:37:INFO:
[92mINFO [0m:      Received: evaluate message 712440b4-bac9-4e06-8f7e-6af1afcb87c2
02/12/2025 07:59:37:INFO:Received: evaluate message 712440b4-bac9-4e06-8f7e-6af1afcb87c2
[92mINFO [0m:      Sent reply
02/12/2025 08:03:25:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:04:26:INFO:
[92mINFO [0m:      Received: train message 8c7a3f28-00c9-4074-8246-6d28c750b93e
02/12/2025 08:04:26:INFO:Received: train message 8c7a3f28-00c9-4074-8246-6d28c750b93e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 08:07:44:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:38:17:INFO:
[92mINFO [0m:      Received: evaluate message 6005c6a2-9a3f-46b7-b950-ca0161bd124c
02/12/2025 08:38:17:INFO:Received: evaluate message 6005c6a2-9a3f-46b7-b950-ca0161bd124c
[92mINFO [0m:      Sent reply
02/12/2025 08:42:19:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:42:55:INFO:
[92mINFO [0m:      Received: train message c9647c11-5b60-4ca6-ae9d-5d6ef036733c
02/12/2025 08:42:55:INFO:Received: train message c9647c11-5b60-4ca6-ae9d-5d6ef036733c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 08:46:15:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:16:41:INFO:
[92mINFO [0m:      Received: evaluate message e55442cb-170e-4002-a36f-ff902f564b2b
02/12/2025 09:16:41:INFO:Received: evaluate message e55442cb-170e-4002-a36f-ff902f564b2b
[92mINFO [0m:      Sent reply
02/12/2025 09:20:49:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:21:24:INFO:
[92mINFO [0m:      Received: train message e1692260-4a45-41ff-afb0-99ad9693d21a
02/12/2025 09:21:24:INFO:Received: train message e1692260-4a45-41ff-afb0-99ad9693d21a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 09:24:51:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:54:52:INFO:
[92mINFO [0m:      Received: evaluate message d0026bea-21cd-4a27-b8f3-87917c143322
02/12/2025 09:54:52:INFO:Received: evaluate message d0026bea-21cd-4a27-b8f3-87917c143322
[92mINFO [0m:      Sent reply
02/12/2025 09:58:49:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:59:13:INFO:
[92mINFO [0m:      Received: train message 8f5e8650-35bd-4ce9-8d6f-8db56a294b7f
02/12/2025 09:59:13:INFO:Received: train message 8f5e8650-35bd-4ce9-8d6f-8db56a294b7f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 10:02:11:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 10:32:55:INFO:
[92mINFO [0m:      Received: evaluate message 9ceae686-5ef0-4803-99be-153d2fb29b45
02/12/2025 10:32:55:INFO:Received: evaluate message 9ceae686-5ef0-4803-99be-153d2fb29b45
[92mINFO [0m:      Sent reply
02/12/2025 10:37:00:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 10:37:28:INFO:
[92mINFO [0m:      Received: train message 99ef6fe5-8ed6-4ab6-a221-7f96fc45023b
02/12/2025 10:37:28:INFO:Received: train message 99ef6fe5-8ed6-4ab6-a221-7f96fc45023b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 10:40:37:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:11:16:INFO:
[92mINFO [0m:      Received: evaluate message 065eaacc-e5bc-4229-b418-a1d47edb575a
02/12/2025 11:11:16:INFO:Received: evaluate message 065eaacc-e5bc-4229-b418-a1d47edb575a
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 18597, num_classes: 8

Privacy Params:
 epsilon: 30.0, target_epsilon: 30.0, target_delta: 1e-05

Device: cuda:0

Step 1a: Client Initialized
Step 1b: Recomputing FIM for epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904], 'accuracy': [0.21143777688280307], 'auc': [0.5402203774856965], 'precision': [0.27998875874705753], 'recall': [0.21143777688280307], 'f1': [0.20810330062677435]}

Step 1b: Recomputing FIM for epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124], 'accuracy': [0.21143777688280307, 0.270237615787354], 'auc': [0.5402203774856965, 0.5733188230827513], 'precision': [0.27998875874705753, 0.3166973493865562], 'recall': [0.21143777688280307, 0.270237615787354], 'f1': [0.20810330062677435, 0.2665872516861315]}

Step 1b: Recomputing FIM for epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709]}

Step 1b: Recomputing FIM for epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124]}

Step 1b: Recomputing FIM for epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753]}

Step 1b: Recomputing FIM for epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195]}

Step 1b: Recomputing FIM for epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 11:15:13:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:15:45:INFO:
[92mINFO [0m:      Received: train message f5c9e7f2-c1b3-4b85-815d-d784c5e99fd7
02/12/2025 11:15:45:INFO:Received: train message f5c9e7f2-c1b3-4b85-815d-d784c5e99fd7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 11:19:04:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:49:12:INFO:
[92mINFO [0m:      Received: evaluate message 33282425-ab51-4d31-92bf-620f0e51527c
02/12/2025 11:49:12:INFO:Received: evaluate message 33282425-ab51-4d31-92bf-620f0e51527c
[92mINFO [0m:      Sent reply
02/12/2025 11:53:21:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:53:36:INFO:
[92mINFO [0m:      Received: train message ec5a8729-c36b-430d-b71f-d713a1dd4f99
02/12/2025 11:53:36:INFO:Received: train message ec5a8729-c36b-430d-b71f-d713a1dd4f99
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 11:56:23:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 12:26:39:INFO:
[92mINFO [0m:      Received: evaluate message 8292824d-2571-480c-9def-f27662f3989b
02/12/2025 12:26:39:INFO:Received: evaluate message 8292824d-2571-480c-9def-f27662f3989b
[92mINFO [0m:      Sent reply
02/12/2025 12:30:50:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 12:31:09:INFO:
[92mINFO [0m:      Received: train message 019dda44-53a5-4fd7-b7cf-6b18dfd2c20c
02/12/2025 12:31:09:INFO:Received: train message 019dda44-53a5-4fd7-b7cf-6b18dfd2c20c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 12:34:00:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:04:29:INFO:
[92mINFO [0m:      Received: evaluate message 92073ba6-8986-4195-8b34-6af9b17541cb
02/12/2025 13:04:29:INFO:Received: evaluate message 92073ba6-8986-4195-8b34-6af9b17541cb
[92mINFO [0m:      Sent reply
02/12/2025 13:08:43:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:09:08:INFO:
[92mINFO [0m:      Received: train message 51bcc067-5cd3-4098-91c0-6d7e8bba961c
02/12/2025 13:09:08:INFO:Received: train message 51bcc067-5cd3-4098-91c0-6d7e8bba961c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 13:12:31:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:42:28:INFO:
[92mINFO [0m:      Received: evaluate message 6b61c51b-bab7-4b84-9e31-6867cb3ad436
02/12/2025 13:42:28:INFO:Received: evaluate message 6b61c51b-bab7-4b84-9e31-6867cb3ad436

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905]}

Step 1b: Recomputing FIM for epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977]}

Step 1b: Recomputing FIM for epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446]}

Step 1b: Recomputing FIM for epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335]}

Step 1b: Recomputing FIM for epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 13:46:40:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:47:14:INFO:
[92mINFO [0m:      Received: train message 380db44b-a856-4141-9df1-ad5c4dc54a7f
02/12/2025 13:47:14:INFO:Received: train message 380db44b-a856-4141-9df1-ad5c4dc54a7f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 13:51:06:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:20:08:INFO:
[92mINFO [0m:      Received: evaluate message 570b1128-74e6-4c8d-892d-c9479f15afdf
02/12/2025 14:20:08:INFO:Received: evaluate message 570b1128-74e6-4c8d-892d-c9479f15afdf
[92mINFO [0m:      Sent reply
02/12/2025 14:24:15:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:24:32:INFO:
[92mINFO [0m:      Received: train message c015bb03-5da4-4aba-98ac-9cc3655cef56
02/12/2025 14:24:32:INFO:Received: train message c015bb03-5da4-4aba-98ac-9cc3655cef56
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 14:27:25:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:57:17:INFO:
[92mINFO [0m:      Received: evaluate message e128a71b-ed66-4061-acaa-3faf63713db7
02/12/2025 14:57:17:INFO:Received: evaluate message e128a71b-ed66-4061-acaa-3faf63713db7
[92mINFO [0m:      Sent reply
02/12/2025 15:01:41:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:02:24:INFO:
[92mINFO [0m:      Received: train message 845d441f-6a25-4099-9537-7d87c72881e8
02/12/2025 15:02:24:INFO:Received: train message 845d441f-6a25-4099-9537-7d87c72881e8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 15:05:56:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:35:10:INFO:
[92mINFO [0m:      Received: evaluate message 1df9cc38-0a0d-446a-98c5-1427eeba5896
02/12/2025 15:35:10:INFO:Received: evaluate message 1df9cc38-0a0d-446a-98c5-1427eeba5896
[92mINFO [0m:      Sent reply
02/12/2025 15:39:31:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:39:43:INFO:
[92mINFO [0m:      Received: train message ad4d4237-c650-4569-9bba-51321863af64
02/12/2025 15:39:43:INFO:Received: train message ad4d4237-c650-4569-9bba-51321863af64

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202]}

Step 1b: Recomputing FIM for epoch 12
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254]}

Step 1b: Recomputing FIM for epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472]}

Step 1b: Recomputing FIM for epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679]}

Step 1b: Recomputing FIM for epoch 15
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 15:42:44:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:12:17:INFO:
[92mINFO [0m:      Received: evaluate message 2e2a0701-2a8f-4ade-b06b-5496d776e0e4
02/12/2025 16:12:17:INFO:Received: evaluate message 2e2a0701-2a8f-4ade-b06b-5496d776e0e4
[92mINFO [0m:      Sent reply
02/12/2025 16:16:35:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:17:11:INFO:
[92mINFO [0m:      Received: train message ef865de6-ce0a-418c-9d51-e2705967ccb9
02/12/2025 16:17:11:INFO:Received: train message ef865de6-ce0a-418c-9d51-e2705967ccb9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 16:20:35:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:49:47:INFO:
[92mINFO [0m:      Received: evaluate message bef731e7-65d5-48ec-b3ad-992cbd7112c3
02/12/2025 16:49:47:INFO:Received: evaluate message bef731e7-65d5-48ec-b3ad-992cbd7112c3
[92mINFO [0m:      Sent reply
02/12/2025 16:54:11:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:54:44:INFO:
[92mINFO [0m:      Received: train message 4418a17e-ebe5-4617-bccd-31aa60492549
02/12/2025 16:54:44:INFO:Received: train message 4418a17e-ebe5-4617-bccd-31aa60492549
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 16:58:10:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 17:26:39:INFO:
[92mINFO [0m:      Received: evaluate message c9427c33-e816-4427-98e8-057a6080a3af
02/12/2025 17:26:39:INFO:Received: evaluate message c9427c33-e816-4427-98e8-057a6080a3af
[92mINFO [0m:      Sent reply
02/12/2025 17:30:51:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 17:31:26:INFO:
[92mINFO [0m:      Received: train message 88720683-68a4-4de1-a452-df9f413494b0
02/12/2025 17:31:26:INFO:Received: train message 88720683-68a4-4de1-a452-df9f413494b0
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161]}

Step 1b: Recomputing FIM for epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574]}

Step 1b: Recomputing FIM for epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617]}

Step 1b: Recomputing FIM for epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 17:35:01:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:03:44:INFO:
[92mINFO [0m:      Received: evaluate message 91a2d177-8019-4898-a34a-31580ebba723
02/12/2025 18:03:44:INFO:Received: evaluate message 91a2d177-8019-4898-a34a-31580ebba723
[92mINFO [0m:      Sent reply
02/12/2025 18:08:04:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:08:38:INFO:
[92mINFO [0m:      Received: train message 300d635c-05eb-404e-b5c4-6958b2d63cd7
02/12/2025 18:08:38:INFO:Received: train message 300d635c-05eb-404e-b5c4-6958b2d63cd7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 18:12:01:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:40:57:INFO:
[92mINFO [0m:      Received: evaluate message 261b7a1c-1823-40e1-9b33-0af247f5a345
02/12/2025 18:40:57:INFO:Received: evaluate message 261b7a1c-1823-40e1-9b33-0af247f5a345
[92mINFO [0m:      Sent reply
02/12/2025 18:44:55:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:45:38:INFO:
[92mINFO [0m:      Received: train message 3496e28a-ac22-4183-ab8c-11edd12481af
02/12/2025 18:45:38:INFO:Received: train message 3496e28a-ac22-4183-ab8c-11edd12481af
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 18:49:20:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:18:14:INFO:
[92mINFO [0m:      Received: evaluate message 1d85525a-9493-4447-ab8a-747397ed64a3
02/12/2025 19:18:14:INFO:Received: evaluate message 1d85525a-9493-4447-ab8a-747397ed64a3
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015]}

Step 1b: Recomputing FIM for epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708]}

Step 1b: Recomputing FIM for epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 19:22:18:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:22:38:INFO:
[92mINFO [0m:      Received: train message cbb687c4-483f-4f01-8333-6e8fa284312a
02/12/2025 19:22:38:INFO:Received: train message cbb687c4-483f-4f01-8333-6e8fa284312a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 19:25:58:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:55:11:INFO:
[92mINFO [0m:      Received: evaluate message 860c3ab2-608c-464d-a1c7-98634654c824
02/12/2025 19:55:11:INFO:Received: evaluate message 860c3ab2-608c-464d-a1c7-98634654c824
[92mINFO [0m:      Sent reply
02/12/2025 19:59:24:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:59:59:INFO:
[92mINFO [0m:      Received: train message 62ccd91d-5020-4832-a790-60a03d418a12
02/12/2025 19:59:59:INFO:Received: train message 62ccd91d-5020-4832-a790-60a03d418a12
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 20:03:39:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 20:32:48:INFO:
[92mINFO [0m:      Received: evaluate message fe9f3ba9-bab1-4d34-a2e6-c5a151b574dd
02/12/2025 20:32:48:INFO:Received: evaluate message fe9f3ba9-bab1-4d34-a2e6-c5a151b574dd

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091]}

Step 1b: Recomputing FIM for epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084]}

Step 1b: Recomputing FIM for epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 20:36:51:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 20:37:30:INFO:
[92mINFO [0m:      Received: train message a5ce00c5-cb83-4895-92fa-0a3b1e6a27ec
02/12/2025 20:37:30:INFO:Received: train message a5ce00c5-cb83-4895-92fa-0a3b1e6a27ec
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 20:40:47:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:10:08:INFO:
[92mINFO [0m:      Received: evaluate message 14461ee7-4e8b-4c6b-b3de-996ccf0b98d1
02/12/2025 21:10:08:INFO:Received: evaluate message 14461ee7-4e8b-4c6b-b3de-996ccf0b98d1
[92mINFO [0m:      Sent reply
02/12/2025 21:14:13:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:14:37:INFO:
[92mINFO [0m:      Received: train message 5f258f65-a29f-4694-807a-9c2a6c5a2d9b
02/12/2025 21:14:37:INFO:Received: train message 5f258f65-a29f-4694-807a-9c2a6c5a2d9b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 21:17:45:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:47:59:INFO:
[92mINFO [0m:      Received: evaluate message ccd39b96-84d0-4df0-9b90-4a38f4de3297
02/12/2025 21:47:59:INFO:Received: evaluate message ccd39b96-84d0-4df0-9b90-4a38f4de3297

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246]}

Step 1b: Recomputing FIM for epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406]}

Step 1b: Recomputing FIM for epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 21:52:23:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:52:55:INFO:
[92mINFO [0m:      Received: train message 78333bd9-b31f-4286-bf1b-9c18e7955dd0
02/12/2025 21:52:55:INFO:Received: train message 78333bd9-b31f-4286-bf1b-9c18e7955dd0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 21:56:23:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 22:30:04:INFO:
[92mINFO [0m:      Received: evaluate message c281c322-3b99-4593-858f-24baeb7c75cb
02/12/2025 22:30:04:INFO:Received: evaluate message c281c322-3b99-4593-858f-24baeb7c75cb
[92mINFO [0m:      Sent reply
02/12/2025 22:34:28:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 22:35:05:INFO:
[92mINFO [0m:      Received: train message de0d1166-e954-4d24-9296-fe31683cc772
02/12/2025 22:35:05:INFO:Received: train message de0d1166-e954-4d24-9296-fe31683cc772
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 22:38:24:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:09:29:INFO:
[92mINFO [0m:      Received: evaluate message 64894c51-dcaf-4489-9e9b-b1448d9a67d0
02/12/2025 23:09:29:INFO:Received: evaluate message 64894c51-dcaf-4489-9e9b-b1448d9a67d0

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254]}

Step 1b: Recomputing FIM for epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472]}

Step 1b: Recomputing FIM for epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 23:13:27:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:14:02:INFO:
[92mINFO [0m:      Received: train message 76d5ed74-f939-442e-8ff9-83cece538919
02/12/2025 23:14:02:INFO:Received: train message 76d5ed74-f939-442e-8ff9-83cece538919
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 23:17:22:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:46:47:INFO:
[92mINFO [0m:      Received: evaluate message d42a5258-461a-464a-a803-ac64566b8b36
02/12/2025 23:46:47:INFO:Received: evaluate message d42a5258-461a-464a-a803-ac64566b8b36
[92mINFO [0m:      Sent reply
02/12/2025 23:50:23:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:51:20:INFO:
[92mINFO [0m:      Received: train message a4ae0ba7-e7d6-4915-9828-5f9434c3f39d
02/12/2025 23:51:20:INFO:Received: train message a4ae0ba7-e7d6-4915-9828-5f9434c3f39d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 23:53:58:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 00:24:43:INFO:
[92mINFO [0m:      Received: evaluate message 650c7206-7ec9-4b8d-b710-41e0921ff820
02/13/2025 00:24:43:INFO:Received: evaluate message 650c7206-7ec9-4b8d-b710-41e0921ff820

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674]}

Step 1b: Recomputing FIM for epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489]}

Step 1b: Recomputing FIM for epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/13/2025 00:28:37:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 00:29:11:INFO:
[92mINFO [0m:      Received: train message 839ccd5b-3fba-4a5e-b4f6-9578cd603718
02/13/2025 00:29:11:INFO:Received: train message 839ccd5b-3fba-4a5e-b4f6-9578cd603718
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 00:32:27:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:03:37:INFO:
[92mINFO [0m:      Received: evaluate message 260f042c-9842-4209-b3be-ce98eb7711f0
02/13/2025 01:03:37:INFO:Received: evaluate message 260f042c-9842-4209-b3be-ce98eb7711f0
[92mINFO [0m:      Sent reply
02/13/2025 01:07:40:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:08:39:INFO:
[92mINFO [0m:      Received: train message 9eb1b707-cc18-4738-9cd6-45a5ba691cde
02/13/2025 01:08:39:INFO:Received: train message 9eb1b707-cc18-4738-9cd6-45a5ba691cde
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 01:12:01:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:41:46:INFO:
[92mINFO [0m:      Received: evaluate message 3f69abef-3ee5-49dc-93e6-6dcccb00ff49
02/13/2025 01:41:46:INFO:Received: evaluate message 3f69abef-3ee5-49dc-93e6-6dcccb00ff49

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508]}

Step 1b: Recomputing FIM for epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325]}

Step 1b: Recomputing FIM for epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
[92mINFO [0m:      Sent reply
02/13/2025 01:46:09:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:46:09:INFO:
[92mINFO [0m:      Received: reconnect message b2e79b81-2762-406a-b6a0-3c3086e87d5e
02/13/2025 01:46:09:INFO:Received: reconnect message b2e79b81-2762-406a-b6a0-3c3086e87d5e
02/13/2025 01:46:10:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/13/2025 01:46:10:INFO:Disconnect and shut down
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892, 1.4863234110719679], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786, 0.8018291515091863], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276, 0.49597451052139874], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325, 0.49389366507549604]}



Final client history:
{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892, 1.4863234110719679], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786, 0.8018291515091863], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276, 0.49597451052139874], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325, 0.49389366507549604]}

