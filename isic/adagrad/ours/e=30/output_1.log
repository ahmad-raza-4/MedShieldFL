nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.4 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
02/12/2025 06:48:35:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/12/2025 06:48:35:DEBUG:ChannelConnectivity.IDLE
02/12/2025 06:48:35:DEBUG:ChannelConnectivity.CONNECTING
02/12/2025 06:48:35:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1739371715.516968 2074990 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/12/2025 06:49:07:INFO:
[92mINFO [0m:      Received: train message c4daa3b3-a7a7-4743-9205-64c437d02079
02/12/2025 06:49:07:INFO:Received: train message c4daa3b3-a7a7-4743-9205-64c437d02079
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 07:21:23:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:22:01:INFO:
[92mINFO [0m:      Received: evaluate message a5fb207d-633e-4ebc-9613-604f6ecbbc89
02/12/2025 07:22:01:INFO:Received: evaluate message a5fb207d-633e-4ebc-9613-604f6ecbbc89
[92mINFO [0m:      Sent reply
02/12/2025 07:26:04:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:26:33:INFO:
[92mINFO [0m:      Received: train message 7000facc-eda3-41fa-a31d-1834b3e2ea6e
02/12/2025 07:26:33:INFO:Received: train message 7000facc-eda3-41fa-a31d-1834b3e2ea6e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 07:59:17:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:59:55:INFO:
[92mINFO [0m:      Received: evaluate message 445e2184-5a01-4fe4-a31c-ed525c5d620a
02/12/2025 07:59:55:INFO:Received: evaluate message 445e2184-5a01-4fe4-a31c-ed525c5d620a
[92mINFO [0m:      Sent reply
02/12/2025 08:03:56:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:04:25:INFO:
[92mINFO [0m:      Received: train message 1bc0944f-1fbb-402e-ba14-4bc9e855575e
02/12/2025 08:04:25:INFO:Received: train message 1bc0944f-1fbb-402e-ba14-4bc9e855575e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 08:37:46:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:38:04:INFO:
[92mINFO [0m:      Received: evaluate message 436c1d31-e040-4e44-994d-43d57ccda9f1
02/12/2025 08:38:04:INFO:Received: evaluate message 436c1d31-e040-4e44-994d-43d57ccda9f1
[92mINFO [0m:      Sent reply
02/12/2025 08:41:45:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:42:49:INFO:
[92mINFO [0m:      Received: train message b019f681-507b-47f8-8d26-f1360c7e0034
02/12/2025 08:42:49:INFO:Received: train message b019f681-507b-47f8-8d26-f1360c7e0034
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 09:16:10:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:16:26:INFO:
[92mINFO [0m:      Received: evaluate message 761de1ba-5545-4679-a60f-1a0c80487e52
02/12/2025 09:16:26:INFO:Received: evaluate message 761de1ba-5545-4679-a60f-1a0c80487e52
[92mINFO [0m:      Sent reply
02/12/2025 09:19:48:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:21:09:INFO:
[92mINFO [0m:      Received: train message 8e78f90b-3ac3-40b1-9564-d1db26b79341
02/12/2025 09:21:09:INFO:Received: train message 8e78f90b-3ac3-40b1-9564-d1db26b79341
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 09:54:16:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:54:54:INFO:
[92mINFO [0m:      Received: evaluate message 65b763ab-7fba-494c-959b-b5912a743965
02/12/2025 09:54:54:INFO:Received: evaluate message 65b763ab-7fba-494c-959b-b5912a743965
[92mINFO [0m:      Sent reply
02/12/2025 09:58:52:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:59:25:INFO:
[92mINFO [0m:      Received: train message 0ec8d461-6461-4f1e-9f78-8ba18c17446b
02/12/2025 09:59:25:INFO:Received: train message 0ec8d461-6461-4f1e-9f78-8ba18c17446b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 10:32:17:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 10:32:50:INFO:
[92mINFO [0m:      Received: evaluate message 91a0b6f8-6f92-4a8f-a3b8-0f444e6f24ff
02/12/2025 10:32:50:INFO:Received: evaluate message 91a0b6f8-6f92-4a8f-a3b8-0f444e6f24ff
[92mINFO [0m:      Sent reply
02/12/2025 10:36:58:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 10:37:32:INFO:
[92mINFO [0m:      Received: train message b01312a6-10cd-481e-9b53-25c26347f81e
02/12/2025 10:37:32:INFO:Received: train message b01312a6-10cd-481e-9b53-25c26347f81e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 11:10:40:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:11:05:INFO:
[92mINFO [0m:      Received: evaluate message c8d455a4-68e5-4bd4-ba5c-e2af6b520e2c
02/12/2025 11:11:05:INFO:Received: evaluate message c8d455a4-68e5-4bd4-ba5c-e2af6b520e2c
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 18597, num_classes: 8

Privacy Params:
 epsilon: 30.0, target_epsilon: 30.0, target_delta: 1e-05

Device: cuda:0

Step 1a: Client Initialized
Step 1b: Recomputing FIM for epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904], 'accuracy': [0.21143777688280307], 'auc': [0.5402203774856965], 'precision': [0.27998875874705753], 'recall': [0.21143777688280307], 'f1': [0.20810330062677435]}

Step 1b: Recomputing FIM for epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124], 'accuracy': [0.21143777688280307, 0.270237615787354], 'auc': [0.5402203774856965, 0.5733188230827513], 'precision': [0.27998875874705753, 0.3166973493865562], 'recall': [0.21143777688280307, 0.270237615787354], 'f1': [0.20810330062677435, 0.2665872516861315]}

Step 1b: Recomputing FIM for epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709]}

Step 1b: Recomputing FIM for epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124]}

Step 1b: Recomputing FIM for epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753]}

Step 1b: Recomputing FIM for epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195]}

Step 1b: Recomputing FIM for epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 11:15:06:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:15:41:INFO:
[92mINFO [0m:      Received: train message bae1def1-c97f-48cd-a2b6-bd0409390010
02/12/2025 11:15:41:INFO:Received: train message bae1def1-c97f-48cd-a2b6-bd0409390010
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 11:48:34:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:49:13:INFO:
[92mINFO [0m:      Received: evaluate message 90a94890-09f1-4d18-8916-ffe6924d19a5
02/12/2025 11:49:13:INFO:Received: evaluate message 90a94890-09f1-4d18-8916-ffe6924d19a5
[92mINFO [0m:      Sent reply
02/12/2025 11:53:22:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:53:40:INFO:
[92mINFO [0m:      Received: train message a3b03b7e-3463-4d1b-94a0-20ce9b96652d
02/12/2025 11:53:40:INFO:Received: train message a3b03b7e-3463-4d1b-94a0-20ce9b96652d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 12:25:59:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 12:26:37:INFO:
[92mINFO [0m:      Received: evaluate message 1ab4e6a7-dc24-4416-bdba-4413c1474fbc
02/12/2025 12:26:37:INFO:Received: evaluate message 1ab4e6a7-dc24-4416-bdba-4413c1474fbc
[92mINFO [0m:      Sent reply
02/12/2025 12:30:52:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 12:31:25:INFO:
[92mINFO [0m:      Received: train message 2bf62af3-7331-4197-b9ac-260c8816b575
02/12/2025 12:31:25:INFO:Received: train message 2bf62af3-7331-4197-b9ac-260c8816b575
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 13:03:50:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:04:18:INFO:
[92mINFO [0m:      Received: evaluate message 3dd8bb6b-40d9-4b2d-b0f5-524130e271cd
02/12/2025 13:04:18:INFO:Received: evaluate message 3dd8bb6b-40d9-4b2d-b0f5-524130e271cd
[92mINFO [0m:      Sent reply
02/12/2025 13:08:25:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:09:15:INFO:
[92mINFO [0m:      Received: train message 98d88c83-46ba-4d6c-b67c-033307e390ca
02/12/2025 13:09:15:INFO:Received: train message 98d88c83-46ba-4d6c-b67c-033307e390ca
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 13:41:48:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:42:12:INFO:
[92mINFO [0m:      Received: evaluate message 2f0a6afe-84ba-4118-8946-2f9a96695e02
02/12/2025 13:42:12:INFO:Received: evaluate message 2f0a6afe-84ba-4118-8946-2f9a96695e02

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905]}

Step 1b: Recomputing FIM for epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977]}

Step 1b: Recomputing FIM for epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446]}

Step 1b: Recomputing FIM for epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335]}

Step 1b: Recomputing FIM for epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 13:46:08:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:47:14:INFO:
[92mINFO [0m:      Received: train message c5ce4eda-b62d-4730-b33f-ddf078ba8bb5
02/12/2025 13:47:14:INFO:Received: train message c5ce4eda-b62d-4730-b33f-ddf078ba8bb5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 14:19:34:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:20:14:INFO:
[92mINFO [0m:      Received: evaluate message e5975f46-a166-4e22-988b-ee498d2bd3ee
02/12/2025 14:20:14:INFO:Received: evaluate message e5975f46-a166-4e22-988b-ee498d2bd3ee
[92mINFO [0m:      Sent reply
02/12/2025 14:24:19:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:24:45:INFO:
[92mINFO [0m:      Received: train message 6b21ef3c-5d7b-49be-b5fe-98c7ac5c0128
02/12/2025 14:24:45:INFO:Received: train message 6b21ef3c-5d7b-49be-b5fe-98c7ac5c0128
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 14:56:47:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:57:23:INFO:
[92mINFO [0m:      Received: evaluate message fc3905f8-fb5f-4928-8a2f-1a9513519147
02/12/2025 14:57:23:INFO:Received: evaluate message fc3905f8-fb5f-4928-8a2f-1a9513519147
[92mINFO [0m:      Sent reply
02/12/2025 15:01:48:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:02:18:INFO:
[92mINFO [0m:      Received: train message 15163bea-1808-4240-a57b-295fc285f651
02/12/2025 15:02:18:INFO:Received: train message 15163bea-1808-4240-a57b-295fc285f651
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 15:34:33:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:35:01:INFO:
[92mINFO [0m:      Received: evaluate message 7e2e759c-7167-49b5-96ed-90b8bba43a95
02/12/2025 15:35:01:INFO:Received: evaluate message 7e2e759c-7167-49b5-96ed-90b8bba43a95
[92mINFO [0m:      Sent reply
02/12/2025 15:39:22:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:40:03:INFO:
[92mINFO [0m:      Received: train message 05dbf229-6707-45a4-8957-267daec7a7b7
02/12/2025 15:40:03:INFO:Received: train message 05dbf229-6707-45a4-8957-267daec7a7b7

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202]}

Step 1b: Recomputing FIM for epoch 12
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254]}

Step 1b: Recomputing FIM for epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472]}

Step 1b: Recomputing FIM for epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679]}

Step 1b: Recomputing FIM for epoch 15
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 16:11:45:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:12:15:INFO:
[92mINFO [0m:      Received: evaluate message 72c38a1b-44c1-4876-84e2-055916815939
02/12/2025 16:12:15:INFO:Received: evaluate message 72c38a1b-44c1-4876-84e2-055916815939
[92mINFO [0m:      Sent reply
02/12/2025 16:16:33:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:17:04:INFO:
[92mINFO [0m:      Received: train message c2d24511-1c50-4319-a0f0-00c19fb2bea6
02/12/2025 16:17:04:INFO:Received: train message c2d24511-1c50-4319-a0f0-00c19fb2bea6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 16:49:06:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:49:44:INFO:
[92mINFO [0m:      Received: evaluate message c896ac02-90e1-4ddd-b411-af62f0bae00a
02/12/2025 16:49:44:INFO:Received: evaluate message c896ac02-90e1-4ddd-b411-af62f0bae00a
[92mINFO [0m:      Sent reply
02/12/2025 16:54:13:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:54:41:INFO:
[92mINFO [0m:      Received: train message 63b4e109-781e-449e-9e1c-22f43f4a8a0f
02/12/2025 16:54:41:INFO:Received: train message 63b4e109-781e-449e-9e1c-22f43f4a8a0f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 17:26:00:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 17:26:17:INFO:
[92mINFO [0m:      Received: evaluate message 112b8f3b-12d8-4c1f-8b05-38050b2aca80
02/12/2025 17:26:17:INFO:Received: evaluate message 112b8f3b-12d8-4c1f-8b05-38050b2aca80
[92mINFO [0m:      Sent reply
02/12/2025 17:29:42:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 17:31:07:INFO:
[92mINFO [0m:      Received: train message 7a0f14c5-8614-4558-b000-85c9e3cd4cad
02/12/2025 17:31:07:INFO:Received: train message 7a0f14c5-8614-4558-b000-85c9e3cd4cad
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161]}

Step 1b: Recomputing FIM for epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574]}

Step 1b: Recomputing FIM for epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617]}

Step 1b: Recomputing FIM for epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 18:03:09:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:03:44:INFO:
[92mINFO [0m:      Received: evaluate message a452abf1-c9bb-4036-b9c0-e724790ecbba
02/12/2025 18:03:44:INFO:Received: evaluate message a452abf1-c9bb-4036-b9c0-e724790ecbba
[92mINFO [0m:      Sent reply
02/12/2025 18:08:03:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:08:39:INFO:
[92mINFO [0m:      Received: train message 8e177160-979c-47d3-a9fb-192c15802d02
02/12/2025 18:08:39:INFO:Received: train message 8e177160-979c-47d3-a9fb-192c15802d02
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 18:40:29:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:41:08:INFO:
[92mINFO [0m:      Received: evaluate message 7584bf30-b951-484e-8d76-49a3beb147d2
02/12/2025 18:41:08:INFO:Received: evaluate message 7584bf30-b951-484e-8d76-49a3beb147d2
[92mINFO [0m:      Sent reply
02/12/2025 18:45:05:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:45:34:INFO:
[92mINFO [0m:      Received: train message 7c73e148-e09e-4bfb-82bd-efd75eab34a1
02/12/2025 18:45:34:INFO:Received: train message 7c73e148-e09e-4bfb-82bd-efd75eab34a1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 19:17:36:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:18:10:INFO:
[92mINFO [0m:      Received: evaluate message 17ee70c9-2caf-4ce3-9ca1-d6395cf93be0
02/12/2025 19:18:10:INFO:Received: evaluate message 17ee70c9-2caf-4ce3-9ca1-d6395cf93be0
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015]}

Step 1b: Recomputing FIM for epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708]}

Step 1b: Recomputing FIM for epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 19:22:17:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:22:47:INFO:
[92mINFO [0m:      Received: train message 3de823e1-b428-4bc7-aba5-68079048c881
02/12/2025 19:22:47:INFO:Received: train message 3de823e1-b428-4bc7-aba5-68079048c881
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 19:54:34:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:55:11:INFO:
[92mINFO [0m:      Received: evaluate message 7d6508ea-c44c-44fd-a09e-5b5cb4b2a1c7
02/12/2025 19:55:11:INFO:Received: evaluate message 7d6508ea-c44c-44fd-a09e-5b5cb4b2a1c7
[92mINFO [0m:      Sent reply
02/12/2025 19:59:24:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:59:40:INFO:
[92mINFO [0m:      Received: train message b4cecfa8-a4e8-46ae-ad99-2a75ff57b930
02/12/2025 19:59:40:INFO:Received: train message b4cecfa8-a4e8-46ae-ad99-2a75ff57b930
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 20:32:13:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 20:32:53:INFO:
[92mINFO [0m:      Received: evaluate message ae0fe5c3-3ff8-466d-8ce8-4068d35befe8
02/12/2025 20:32:53:INFO:Received: evaluate message ae0fe5c3-3ff8-466d-8ce8-4068d35befe8

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091]}

Step 1b: Recomputing FIM for epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084]}

Step 1b: Recomputing FIM for epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 20:36:55:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 20:37:26:INFO:
[92mINFO [0m:      Received: train message a81215e5-3db8-4add-8422-e4b9cb9258ec
02/12/2025 20:37:26:INFO:Received: train message a81215e5-3db8-4add-8422-e4b9cb9258ec
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 21:09:34:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:09:54:INFO:
[92mINFO [0m:      Received: evaluate message 7c9757bd-1f12-467e-bd9a-ba49890920b3
02/12/2025 21:09:54:INFO:Received: evaluate message 7c9757bd-1f12-467e-bd9a-ba49890920b3
[92mINFO [0m:      Sent reply
02/12/2025 21:13:20:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:14:33:INFO:
[92mINFO [0m:      Received: train message 468387b9-0606-450f-bdad-c50a3e048ad8
02/12/2025 21:14:33:INFO:Received: train message 468387b9-0606-450f-bdad-c50a3e048ad8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 21:47:20:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:47:53:INFO:
[92mINFO [0m:      Received: evaluate message b411435f-f358-42b4-836d-6c803beeee2a
02/12/2025 21:47:53:INFO:Received: evaluate message b411435f-f358-42b4-836d-6c803beeee2a

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246]}

Step 1b: Recomputing FIM for epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406]}

Step 1b: Recomputing FIM for epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 21:52:22:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:52:46:INFO:
[92mINFO [0m:      Received: train message 62c90dae-ce7b-45aa-8068-cbd2320c8991
02/12/2025 21:52:46:INFO:Received: train message 62c90dae-ce7b-45aa-8068-cbd2320c8991
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 22:29:28:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 22:30:08:INFO:
[92mINFO [0m:      Received: evaluate message f0fa2022-b00d-4abe-b624-e583dbbbc7a0
02/12/2025 22:30:08:INFO:Received: evaluate message f0fa2022-b00d-4abe-b624-e583dbbbc7a0
[92mINFO [0m:      Sent reply
02/12/2025 22:34:30:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 22:34:48:INFO:
[92mINFO [0m:      Received: train message 95ea4cb3-d798-47c5-8c9f-bf6b905dcd3c
02/12/2025 22:34:48:INFO:Received: train message 95ea4cb3-d798-47c5-8c9f-bf6b905dcd3c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 23:08:51:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:09:24:INFO:
[92mINFO [0m:      Received: evaluate message fb150e91-5e03-4ac9-952f-0d3e4e89d54c
02/12/2025 23:09:24:INFO:Received: evaluate message fb150e91-5e03-4ac9-952f-0d3e4e89d54c

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254]}

Step 1b: Recomputing FIM for epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472]}

Step 1b: Recomputing FIM for epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 23:13:29:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:13:42:INFO:
[92mINFO [0m:      Received: train message 41a98499-339b-45eb-b925-1a23fb91c643
02/12/2025 23:13:42:INFO:Received: train message 41a98499-339b-45eb-b925-1a23fb91c643
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 23:46:23:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:47:01:INFO:
[92mINFO [0m:      Received: evaluate message dac6b037-3573-436f-8e01-697d9b2efa9a
02/12/2025 23:47:01:INFO:Received: evaluate message dac6b037-3573-436f-8e01-697d9b2efa9a
[92mINFO [0m:      Sent reply
02/12/2025 23:51:02:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:51:30:INFO:
[92mINFO [0m:      Received: train message ab584fe9-d1f1-440a-b772-59557b8c737e
02/12/2025 23:51:30:INFO:Received: train message ab584fe9-d1f1-440a-b772-59557b8c737e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 00:24:03:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 00:24:37:INFO:
[92mINFO [0m:      Received: evaluate message 12a9c403-8c45-4e88-9e78-bd5bd0d108fd
02/13/2025 00:24:37:INFO:Received: evaluate message 12a9c403-8c45-4e88-9e78-bd5bd0d108fd

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674]}

Step 1b: Recomputing FIM for epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489]}

Step 1b: Recomputing FIM for epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/13/2025 00:28:32:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 00:29:08:INFO:
[92mINFO [0m:      Received: train message 9d4574de-f78a-4f2f-ad41-dc8d282ef713
02/13/2025 00:29:08:INFO:Received: train message 9d4574de-f78a-4f2f-ad41-dc8d282ef713
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 01:03:04:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:03:50:INFO:
[92mINFO [0m:      Received: evaluate message cf207670-1a7c-4f75-a506-9ae4c32ed6a2
02/13/2025 01:03:50:INFO:Received: evaluate message cf207670-1a7c-4f75-a506-9ae4c32ed6a2
[92mINFO [0m:      Sent reply
02/13/2025 01:07:55:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:08:43:INFO:
[92mINFO [0m:      Received: train message 2fdaf79f-ac8e-467c-9252-bbd8319b32e9
02/13/2025 01:08:43:INFO:Received: train message 2fdaf79f-ac8e-467c-9252-bbd8319b32e9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 01:41:08:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:41:47:INFO:
[92mINFO [0m:      Received: evaluate message 3a1c5767-3256-4c98-8bdc-90483f567714
02/13/2025 01:41:47:INFO:Received: evaluate message 3a1c5767-3256-4c98-8bdc-90483f567714

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508]}

Step 1b: Recomputing FIM for epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325]}

Step 1b: Recomputing FIM for epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 9930, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
[92mINFO [0m:      Sent reply
02/13/2025 01:46:08:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:46:10:INFO:
[92mINFO [0m:      Received: reconnect message b16b4f8d-9e96-4a01-8978-72d7050a956d
02/13/2025 01:46:10:INFO:Received: reconnect message b16b4f8d-9e96-4a01-8978-72d7050a956d
02/13/2025 01:46:10:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/13/2025 01:46:10:INFO:Disconnect and shut down
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892, 1.4863234110719679], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786, 0.8018291515091863], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276, 0.49597451052139874], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325, 0.49389366507549604]}



Final client history:
{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892, 1.4863234110719679], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786, 0.8018291515091863], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276, 0.49597451052139874], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325, 0.49389366507549604]}

