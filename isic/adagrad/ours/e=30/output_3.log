nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.4 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
02/12/2025 06:44:29:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/12/2025 06:44:29:DEBUG:ChannelConnectivity.IDLE
02/12/2025 06:44:29:DEBUG:ChannelConnectivity.CONNECTING
02/12/2025 06:44:29:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1739371469.139287 2070659 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/12/2025 06:49:03:INFO:
[92mINFO [0m:      Received: train message 8ce5b713-e700-4255-9c8f-4370e1979a40
02/12/2025 06:49:03:INFO:Received: train message 8ce5b713-e700-4255-9c8f-4370e1979a40
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 07:04:17:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:22:04:INFO:
[92mINFO [0m:      Received: evaluate message c2bb7c2d-8d57-4432-a814-049e8553e816
02/12/2025 07:22:04:INFO:Received: evaluate message c2bb7c2d-8d57-4432-a814-049e8553e816
[92mINFO [0m:      Sent reply
02/12/2025 07:26:00:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:26:38:INFO:
[92mINFO [0m:      Received: train message 73630f2e-a783-4c6f-8f78-b701610dfe9e
02/12/2025 07:26:38:INFO:Received: train message 73630f2e-a783-4c6f-8f78-b701610dfe9e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 07:42:18:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 07:59:37:INFO:
[92mINFO [0m:      Received: evaluate message fb2bee84-4584-4fde-b4ea-ab5ba3dc7c36
02/12/2025 07:59:37:INFO:Received: evaluate message fb2bee84-4584-4fde-b4ea-ab5ba3dc7c36
[92mINFO [0m:      Sent reply
02/12/2025 08:03:21:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:04:20:INFO:
[92mINFO [0m:      Received: train message 9e1e326f-99ee-4be8-a9fd-690c2e8bc929
02/12/2025 08:04:20:INFO:Received: train message 9e1e326f-99ee-4be8-a9fd-690c2e8bc929
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 08:19:48:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:38:24:INFO:
[92mINFO [0m:      Received: evaluate message e9f386ac-54ef-4c1c-9602-cf2d171f2bc0
02/12/2025 08:38:24:INFO:Received: evaluate message e9f386ac-54ef-4c1c-9602-cf2d171f2bc0
[92mINFO [0m:      Sent reply
02/12/2025 08:42:21:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 08:42:55:INFO:
[92mINFO [0m:      Received: train message 4d47c0a0-1e39-4188-b818-fa45e6d783a8
02/12/2025 08:42:55:INFO:Received: train message 4d47c0a0-1e39-4188-b818-fa45e6d783a8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 08:58:51:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:16:46:INFO:
[92mINFO [0m:      Received: evaluate message f0b6f38a-aa10-4669-9287-af6a37772599
02/12/2025 09:16:46:INFO:Received: evaluate message f0b6f38a-aa10-4669-9287-af6a37772599
[92mINFO [0m:      Sent reply
02/12/2025 09:20:51:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:21:22:INFO:
[92mINFO [0m:      Received: train message 3a471d90-b4c4-433a-b673-b48319cbbc07
02/12/2025 09:21:22:INFO:Received: train message 3a471d90-b4c4-433a-b673-b48319cbbc07
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 09:37:39:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:54:47:INFO:
[92mINFO [0m:      Received: evaluate message 99a85904-1e96-45ab-aee1-65074c31b00c
02/12/2025 09:54:47:INFO:Received: evaluate message 99a85904-1e96-45ab-aee1-65074c31b00c
[92mINFO [0m:      Sent reply
02/12/2025 09:58:46:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 09:59:19:INFO:
[92mINFO [0m:      Received: train message 8ce30185-116a-46aa-a044-65822d0e2f0a
02/12/2025 09:59:19:INFO:Received: train message 8ce30185-116a-46aa-a044-65822d0e2f0a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 10:15:28:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 10:32:50:INFO:
[92mINFO [0m:      Received: evaluate message ffcc0195-60c9-491d-8763-33a7ae88ebb0
02/12/2025 10:32:50:INFO:Received: evaluate message ffcc0195-60c9-491d-8763-33a7ae88ebb0
[92mINFO [0m:      Sent reply
02/12/2025 10:36:58:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 10:37:10:INFO:
[92mINFO [0m:      Received: train message 8b1f07d7-ce55-4e73-b793-97c9a72cbbea
02/12/2025 10:37:10:INFO:Received: train message 8b1f07d7-ce55-4e73-b793-97c9a72cbbea
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 10:52:51:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:11:18:INFO:
[92mINFO [0m:      Received: evaluate message 6e7f1db5-919c-4e6d-ac94-940a718fd72f
02/12/2025 11:11:18:INFO:Received: evaluate message 6e7f1db5-919c-4e6d-ac94-940a718fd72f
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/adagrad/e=30']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 18597, num_classes: 8

Privacy Params:
 epsilon: 30.0, target_epsilon: 30.0, target_delta: 1e-05

Device: cuda:0

Step 1a: Client Initialized
Step 1b: Recomputing FIM for epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904], 'accuracy': [0.21143777688280307], 'auc': [0.5402203774856965], 'precision': [0.27998875874705753], 'recall': [0.21143777688280307], 'f1': [0.20810330062677435]}

Step 1b: Recomputing FIM for epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124], 'accuracy': [0.21143777688280307, 0.270237615787354], 'auc': [0.5402203774856965, 0.5733188230827513], 'precision': [0.27998875874705753, 0.3166973493865562], 'recall': [0.21143777688280307, 0.270237615787354], 'f1': [0.20810330062677435, 0.2665872516861315]}

Step 1b: Recomputing FIM for epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709]}

Step 1b: Recomputing FIM for epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124]}

Step 1b: Recomputing FIM for epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753]}

Step 1b: Recomputing FIM for epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195]}

Step 1b: Recomputing FIM for epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 11:15:14:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:15:30:INFO:
[92mINFO [0m:      Received: train message 80ae011a-e585-4b9a-ab84-099029b64a54
02/12/2025 11:15:30:INFO:Received: train message 80ae011a-e585-4b9a-ab84-099029b64a54
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 11:31:16:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:48:56:INFO:
[92mINFO [0m:      Received: evaluate message 97e107e2-bab4-4d54-8c6a-5fdd04e4df44
02/12/2025 11:48:56:INFO:Received: evaluate message 97e107e2-bab4-4d54-8c6a-5fdd04e4df44
[92mINFO [0m:      Sent reply
02/12/2025 11:53:04:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 11:53:56:INFO:
[92mINFO [0m:      Received: train message 1dc5f6bb-ce44-433b-b698-45024da2aa13
02/12/2025 11:53:56:INFO:Received: train message 1dc5f6bb-ce44-433b-b698-45024da2aa13
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 12:09:21:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 12:26:29:INFO:
[92mINFO [0m:      Received: evaluate message 10eb0b32-46c5-4f98-85e6-bcd8b438275e
02/12/2025 12:26:29:INFO:Received: evaluate message 10eb0b32-46c5-4f98-85e6-bcd8b438275e
[92mINFO [0m:      Sent reply
02/12/2025 12:30:45:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 12:31:23:INFO:
[92mINFO [0m:      Received: train message 29d3b6a9-c4ad-4fbc-b7dc-0a06d91770dd
02/12/2025 12:31:23:INFO:Received: train message 29d3b6a9-c4ad-4fbc-b7dc-0a06d91770dd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 12:47:31:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:04:20:INFO:
[92mINFO [0m:      Received: evaluate message c5d15b62-f054-4388-8a84-9c51a1da77a7
02/12/2025 13:04:20:INFO:Received: evaluate message c5d15b62-f054-4388-8a84-9c51a1da77a7
[92mINFO [0m:      Sent reply
02/12/2025 13:08:36:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:09:06:INFO:
[92mINFO [0m:      Received: train message f1d61ee5-a3e6-402c-9c96-3e760612c71e
02/12/2025 13:09:06:INFO:Received: train message f1d61ee5-a3e6-402c-9c96-3e760612c71e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 13:25:24:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:42:17:INFO:
[92mINFO [0m:      Received: evaluate message 8a879003-11f3-481d-bebd-8c4b2732dd7e
02/12/2025 13:42:17:INFO:Received: evaluate message 8a879003-11f3-481d-bebd-8c4b2732dd7e

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905]}

Step 1b: Recomputing FIM for epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977]}

Step 1b: Recomputing FIM for epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446]}

Step 1b: Recomputing FIM for epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335]}

Step 1b: Recomputing FIM for epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 13:46:26:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 13:47:14:INFO:
[92mINFO [0m:      Received: train message 1eee12f4-1b1f-41fd-b09e-f5d3366e6d18
02/12/2025 13:47:14:INFO:Received: train message 1eee12f4-1b1f-41fd-b09e-f5d3366e6d18
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 14:03:45:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:20:13:INFO:
[92mINFO [0m:      Received: evaluate message 511a5c4d-74bb-408a-b41c-88b1827d726d
02/12/2025 14:20:13:INFO:Received: evaluate message 511a5c4d-74bb-408a-b41c-88b1827d726d
[92mINFO [0m:      Sent reply
02/12/2025 14:24:20:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:24:40:INFO:
[92mINFO [0m:      Received: train message 129698f6-47ce-400d-9255-c81d9e6f523f
02/12/2025 14:24:40:INFO:Received: train message 129698f6-47ce-400d-9255-c81d9e6f523f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 14:40:53:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 14:57:27:INFO:
[92mINFO [0m:      Received: evaluate message 5ebc298b-6815-4196-8cb7-2f36667328d4
02/12/2025 14:57:27:INFO:Received: evaluate message 5ebc298b-6815-4196-8cb7-2f36667328d4
[92mINFO [0m:      Sent reply
02/12/2025 15:01:48:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:02:08:INFO:
[92mINFO [0m:      Received: train message b1902253-eca2-47b3-9e09-326d40eab54f
02/12/2025 15:02:08:INFO:Received: train message b1902253-eca2-47b3-9e09-326d40eab54f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 15:18:25:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:34:56:INFO:
[92mINFO [0m:      Received: evaluate message 662e2aae-d13a-433f-a5e5-2a35dd070b02
02/12/2025 15:34:56:INFO:Received: evaluate message 662e2aae-d13a-433f-a5e5-2a35dd070b02
[92mINFO [0m:      Sent reply
02/12/2025 15:39:16:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 15:40:05:INFO:
[92mINFO [0m:      Received: train message 05e34db0-a874-4ec0-84b3-6df6fdfd7057
02/12/2025 15:40:05:INFO:Received: train message 05e34db0-a874-4ec0-84b3-6df6fdfd7057

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202]}

Step 1b: Recomputing FIM for epoch 12
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254]}

Step 1b: Recomputing FIM for epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472]}

Step 1b: Recomputing FIM for epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679]}

Step 1b: Recomputing FIM for epoch 15
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 15:56:12:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:12:15:INFO:
[92mINFO [0m:      Received: evaluate message 70320712-e3c6-4dc5-9c9b-ca62bfdce80d
02/12/2025 16:12:15:INFO:Received: evaluate message 70320712-e3c6-4dc5-9c9b-ca62bfdce80d
[92mINFO [0m:      Sent reply
02/12/2025 16:16:34:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:16:57:INFO:
[92mINFO [0m:      Received: train message f2d6d8fb-1008-4848-9e10-f3b54373523c
02/12/2025 16:16:57:INFO:Received: train message f2d6d8fb-1008-4848-9e10-f3b54373523c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 16:33:27:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:49:39:INFO:
[92mINFO [0m:      Received: evaluate message 8bc17c71-999a-4b48-8aeb-feb43a185c93
02/12/2025 16:49:39:INFO:Received: evaluate message 8bc17c71-999a-4b48-8aeb-feb43a185c93
[92mINFO [0m:      Sent reply
02/12/2025 16:54:05:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 16:54:49:INFO:
[92mINFO [0m:      Received: train message c41aa70a-12da-4d8f-af0f-d2984757aa48
02/12/2025 16:54:49:INFO:Received: train message c41aa70a-12da-4d8f-af0f-d2984757aa48
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 17:11:37:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 17:26:35:INFO:
[92mINFO [0m:      Received: evaluate message e905a572-7ec9-420c-9e41-7f0de9defe93
02/12/2025 17:26:35:INFO:Received: evaluate message e905a572-7ec9-420c-9e41-7f0de9defe93
[92mINFO [0m:      Sent reply
02/12/2025 17:30:49:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 17:31:16:INFO:
[92mINFO [0m:      Received: train message 11a01d04-4c02-48b6-a74b-c65ced007a83
02/12/2025 17:31:16:INFO:Received: train message 11a01d04-4c02-48b6-a74b-c65ced007a83
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161]}

Step 1b: Recomputing FIM for epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574]}

Step 1b: Recomputing FIM for epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617]}

Step 1b: Recomputing FIM for epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 17:48:15:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:03:34:INFO:
[92mINFO [0m:      Received: evaluate message ad735ebe-646a-42de-bd39-07f3528f96d2
02/12/2025 18:03:34:INFO:Received: evaluate message ad735ebe-646a-42de-bd39-07f3528f96d2
[92mINFO [0m:      Sent reply
02/12/2025 18:07:52:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:08:38:INFO:
[92mINFO [0m:      Received: train message 21f214c9-4368-44f2-b498-061985545731
02/12/2025 18:08:38:INFO:Received: train message 21f214c9-4368-44f2-b498-061985545731
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 18:25:21:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:40:47:INFO:
[92mINFO [0m:      Received: evaluate message dab1586f-9f25-4a9c-98e3-4d555c1f6899
02/12/2025 18:40:47:INFO:Received: evaluate message dab1586f-9f25-4a9c-98e3-4d555c1f6899
[92mINFO [0m:      Sent reply
02/12/2025 18:44:10:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 18:45:29:INFO:
[92mINFO [0m:      Received: train message 2f5024b4-a80a-47df-9315-7c4e55e5359f
02/12/2025 18:45:29:INFO:Received: train message 2f5024b4-a80a-47df-9315-7c4e55e5359f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 19:02:05:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:18:14:INFO:
[92mINFO [0m:      Received: evaluate message 98a4f3f0-b5c8-40b4-bd70-0d7885f915c1
02/12/2025 19:18:14:INFO:Received: evaluate message 98a4f3f0-b5c8-40b4-bd70-0d7885f915c1
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015]}

Step 1b: Recomputing FIM for epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708]}

Step 1b: Recomputing FIM for epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 19:22:19:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:22:53:INFO:
[92mINFO [0m:      Received: train message 3aad2790-a059-4bbf-b6fe-c6701044b1dc
02/12/2025 19:22:53:INFO:Received: train message 3aad2790-a059-4bbf-b6fe-c6701044b1dc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 19:39:27:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:55:10:INFO:
[92mINFO [0m:      Received: evaluate message 24f6cc68-84f0-4f95-99d3-cf40d19710e5
02/12/2025 19:55:10:INFO:Received: evaluate message 24f6cc68-84f0-4f95-99d3-cf40d19710e5
[92mINFO [0m:      Sent reply
02/12/2025 19:59:20:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 19:59:50:INFO:
[92mINFO [0m:      Received: train message 0acf364a-9000-4d25-ae7f-6c1c34b8b918
02/12/2025 19:59:50:INFO:Received: train message 0acf364a-9000-4d25-ae7f-6c1c34b8b918
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 20:16:46:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 20:32:40:INFO:
[92mINFO [0m:      Received: evaluate message 5f8167b8-8cc4-40d2-82df-2d801199d41e
02/12/2025 20:32:40:INFO:Received: evaluate message 5f8167b8-8cc4-40d2-82df-2d801199d41e

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091]}

Step 1b: Recomputing FIM for epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084]}

Step 1b: Recomputing FIM for epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 20:36:36:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 20:37:18:INFO:
[92mINFO [0m:      Received: train message f7d97f06-b9b8-4c79-b886-266ef8d4a869
02/12/2025 20:37:18:INFO:Received: train message f7d97f06-b9b8-4c79-b886-266ef8d4a869
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 20:53:30:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:10:11:INFO:
[92mINFO [0m:      Received: evaluate message 5ad407cd-0d19-4d6e-92fc-d1afe0753ee7
02/12/2025 21:10:11:INFO:Received: evaluate message 5ad407cd-0d19-4d6e-92fc-d1afe0753ee7
[92mINFO [0m:      Sent reply
02/12/2025 21:14:09:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:14:25:INFO:
[92mINFO [0m:      Received: train message b9e79837-7a88-4ab4-b1cc-a37620c4bd48
02/12/2025 21:14:25:INFO:Received: train message b9e79837-7a88-4ab4-b1cc-a37620c4bd48
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 21:30:40:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:47:50:INFO:
[92mINFO [0m:      Received: evaluate message aada567b-02d6-4258-a7d3-b71334c7f790
02/12/2025 21:47:50:INFO:Received: evaluate message aada567b-02d6-4258-a7d3-b71334c7f790

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246]}

Step 1b: Recomputing FIM for epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406]}

Step 1b: Recomputing FIM for epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 21:52:17:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 21:52:59:INFO:
[92mINFO [0m:      Received: train message dcf33375-2867-448b-a1f0-6e1714466318
02/12/2025 21:52:59:INFO:Received: train message dcf33375-2867-448b-a1f0-6e1714466318
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 22:10:17:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 22:30:04:INFO:
[92mINFO [0m:      Received: evaluate message e2fadc16-8d04-4c5f-946b-ba221a8df4d5
02/12/2025 22:30:04:INFO:Received: evaluate message e2fadc16-8d04-4c5f-946b-ba221a8df4d5
[92mINFO [0m:      Sent reply
02/12/2025 22:34:30:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 22:35:03:INFO:
[92mINFO [0m:      Received: train message 6590ed2a-003f-4c8d-992f-a9710ba9a582
02/12/2025 22:35:03:INFO:Received: train message 6590ed2a-003f-4c8d-992f-a9710ba9a582
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 22:52:22:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:09:29:INFO:
[92mINFO [0m:      Received: evaluate message 04104e10-16ef-4c87-a757-c58a665992fe
02/12/2025 23:09:29:INFO:Received: evaluate message 04104e10-16ef-4c87-a757-c58a665992fe

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254]}

Step 1b: Recomputing FIM for epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472]}

Step 1b: Recomputing FIM for epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/12/2025 23:13:29:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:13:56:INFO:
[92mINFO [0m:      Received: train message fe2c915b-5d54-45b7-b263-785afd6e58ad
02/12/2025 23:13:56:INFO:Received: train message fe2c915b-5d54-45b7-b263-785afd6e58ad
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/12/2025 23:30:11:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:46:59:INFO:
[92mINFO [0m:      Received: evaluate message 41ee1a69-c301-48ef-8d9c-1e45a6419dc2
02/12/2025 23:46:59:INFO:Received: evaluate message 41ee1a69-c301-48ef-8d9c-1e45a6419dc2
[92mINFO [0m:      Sent reply
02/12/2025 23:51:02:INFO:Sent reply
[92mINFO [0m:      
02/12/2025 23:51:36:INFO:
[92mINFO [0m:      Received: train message 35ad4afd-afb2-477d-bbb3-04ff7d6cdd8f
02/12/2025 23:51:36:INFO:Received: train message 35ad4afd-afb2-477d-bbb3-04ff7d6cdd8f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 00:07:19:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 00:24:31:INFO:
[92mINFO [0m:      Received: evaluate message 04750b53-56bc-40a1-b57d-1b285f337501
02/13/2025 00:24:31:INFO:Received: evaluate message 04750b53-56bc-40a1-b57d-1b285f337501

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674]}

Step 1b: Recomputing FIM for epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489]}

Step 1b: Recomputing FIM for epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/13/2025 00:28:32:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 00:29:11:INFO:
[92mINFO [0m:      Received: train message 987051ac-c995-4c46-87ff-af7ce2154cb5
02/13/2025 00:29:11:INFO:Received: train message 987051ac-c995-4c46-87ff-af7ce2154cb5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 00:44:54:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:03:36:INFO:
[92mINFO [0m:      Received: evaluate message 36ac7a9f-0074-41cf-89b1-a274a7b50e75
02/13/2025 01:03:36:INFO:Received: evaluate message 36ac7a9f-0074-41cf-89b1-a274a7b50e75
[92mINFO [0m:      Sent reply
02/13/2025 01:07:46:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:08:43:INFO:
[92mINFO [0m:      Received: train message e767e5b2-781d-47d8-a007-b1a48e3fa6bd
02/13/2025 01:08:43:INFO:Received: train message e767e5b2-781d-47d8-a007-b1a48e3fa6bd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/13/2025 01:24:46:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:41:40:INFO:
[92mINFO [0m:      Received: evaluate message b0effb0d-8a35-4ad6-ab31-73024b987989
02/13/2025 01:41:40:INFO:Received: evaluate message b0effb0d-8a35-4ad6-ab31-73024b987989

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508]}

Step 1b: Recomputing FIM for epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325]}

Step 1b: Recomputing FIM for epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
[92mINFO [0m:      Sent reply
02/13/2025 01:46:03:INFO:Sent reply
[92mINFO [0m:      
02/13/2025 01:46:09:INFO:
[92mINFO [0m:      Received: reconnect message 71505921-3df4-44b6-9a09-573118aa63ca
02/13/2025 01:46:09:INFO:Received: reconnect message 71505921-3df4-44b6-9a09-573118aa63ca
02/13/2025 01:46:10:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/13/2025 01:46:10:INFO:Disconnect and shut down
Step 3: Evaluate the model locally

{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892, 1.4863234110719679], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786, 0.8018291515091863], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276, 0.49597451052139874], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325, 0.49389366507549604]}



Final client history:
{'loss': [1.9981816795339904, 1.939694734912124, 1.8941532078645809, 1.858360855559212, 1.8263418021050375, 1.7973532689179426, 1.7719436825834067, 1.7490426567932602, 1.7286410026861398, 1.7110018278387733, 1.6936427238627974, 1.6776791348651297, 1.6614353222756726, 1.6462459160443328, 1.6325624440881066, 1.6190346157747653, 1.6069713311477674, 1.5948702461816493, 1.5846422717689364, 1.5728206963871354, 1.563433775102905, 1.5532295644835412, 1.5435163365512714, 1.53506974395225, 1.5267295740901872, 1.517808071317761, 1.5098878055918952, 1.502372471209836, 1.4942666769891892, 1.4863234110719679], 'accuracy': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'auc': [0.5402203774856965, 0.5733188230827513, 0.5998178011062895, 0.6207792184332013, 0.637682472810652, 0.6533058240237417, 0.6672993448661653, 0.6796255028814422, 0.6901994667752491, 0.6996648730491923, 0.7084781287865607, 0.7165500921375028, 0.7242260540437218, 0.7311314322193772, 0.7372180499402121, 0.7429989231524751, 0.7488400595410707, 0.7538341775776967, 0.7582715814968063, 0.7635072821746824, 0.7678749753645965, 0.771997186961914, 0.7760209885999396, 0.7798498204404419, 0.7835432347154733, 0.7875731949456897, 0.7910628224262941, 0.7945438779156255, 0.7981532900466786, 0.8018291515091863], 'precision': [0.27998875874705753, 0.3166973493865562, 0.3447427746850232, 0.36021148950454457, 0.37378744067299857, 0.3901725325089301, 0.4060077010421194, 0.4185325003529702, 0.4244581040278484, 0.4286082108529076, 0.43330720973936443, 0.4428330325819267, 0.44452870486994417, 0.44820071100060765, 0.4542731245656989, 0.453521834876275, 0.45737986782709006, 0.4633411165156323, 0.46719995617090193, 0.46986811684218377, 0.4735244154937081, 0.4742310439347519, 0.4782382946394784, 0.4816056969277048, 0.48580003752936957, 0.489786351489605, 0.4912401369300666, 0.49300960590559806, 0.49243306345118276, 0.49597451052139874], 'recall': [0.21143777688280307, 0.270237615787354, 0.3266210229561015, 0.36488119210632297, 0.39790575916230364, 0.4260974627466774, 0.4486508256141764, 0.4675795408779702, 0.4780507450664519, 0.48449456302859445, 0.490938380990737, 0.5006041079339508, 0.5026178010471204, 0.5050342327829239, 0.5118807893677003, 0.5102698348771647, 0.5130890052356021, 0.518324607329843, 0.522351993556182, 0.5247684252919855, 0.5279903342730567, 0.5296012887635925, 0.5320177204993959, 0.5340314136125655, 0.5364478453483689, 0.5392670157068062, 0.540475231574708, 0.5424889246878776, 0.5416834474426098, 0.5428916633105115], 'f1': [0.20810330062677435, 0.2665872516861315, 0.3199689605891709, 0.3536709652009124, 0.38038908145870753, 0.4041473739953195, 0.4234661427824905, 0.43948620167204977, 0.4470523247194446, 0.45180243644735335, 0.4569534411411202, 0.46558038186836254, 0.4656629061253472, 0.4669835042393679, 0.4722384390776161, 0.46939637161522574, 0.4715542321174617, 0.47593759271831015, 0.4793854431974708, 0.4808388708809091, 0.4831409607055084, 0.48344588537713246, 0.48572317370403406, 0.48694052243831254, 0.48955596546472, 0.49196079325765674, 0.4929930849443489, 0.4943955151942508, 0.4929329931401325, 0.49389366507549604]}

