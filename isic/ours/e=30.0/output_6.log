nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=30.0/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
02/07/2025 20:10:06:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 20:10:06:DEBUG:ChannelConnectivity.IDLE
02/07/2025 20:10:06:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
02/07/2025 20:10:06:INFO:
[92mINFO [0m:      Received: get_parameters message fd6a99cd-8acb-4f43-bd75-c230e1e58fb5
02/07/2025 20:10:06:INFO:Received: get_parameters message fd6a99cd-8acb-4f43-bd75-c230e1e58fb5
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738987806.164153 1676829 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      Sent reply
02/07/2025 20:10:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 20:26:10:INFO:
[92mINFO [0m:      Received: train message 8fb28674-79be-4e2a-a970-b5d1d2e41158
02/07/2025 20:26:10:INFO:Received: train message 8fb28674-79be-4e2a-a970-b5d1d2e41158
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 20:31:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:25:33:INFO:
[92mINFO [0m:      Received: evaluate message 55557eab-26fd-440b-abb0-102c4322b984
02/07/2025 21:25:33:INFO:Received: evaluate message 55557eab-26fd-440b-abb0-102c4322b984
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 21:31:06:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:31:43:INFO:
[92mINFO [0m:      Received: train message 5231f470-17c3-4841-9a62-4de63a50a3e2
02/07/2025 21:31:43:INFO:Received: train message 5231f470-17c3-4841-9a62-4de63a50a3e2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 21:35:49:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:28:33:INFO:
[92mINFO [0m:      Received: evaluate message 0c6d5d2c-c512-4dd3-a0dc-48fd51a1a48b
02/07/2025 22:28:33:INFO:Received: evaluate message 0c6d5d2c-c512-4dd3-a0dc-48fd51a1a48b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 22:35:15:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:53:INFO:
[92mINFO [0m:      Received: train message 39cf08e9-2d8f-43bc-9c33-22344b49781d
02/07/2025 22:35:53:INFO:Received: train message 39cf08e9-2d8f-43bc-9c33-22344b49781d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:40:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 23:37:24:INFO:
[92mINFO [0m:      Received: evaluate message d692ffa8-f642-42a2-98e3-ce558b28578f
02/07/2025 23:37:24:INFO:Received: evaluate message d692ffa8-f642-42a2-98e3-ce558b28578f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 23:43:43:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 23:43:59:INFO:
[92mINFO [0m:      Received: train message c2b3e8cb-8006-4810-a699-39846f1ac9c3
02/07/2025 23:43:59:INFO:Received: train message c2b3e8cb-8006-4810-a699-39846f1ac9c3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 23:47:56:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:40:50:INFO:
[92mINFO [0m:      Received: evaluate message 5f702267-6832-4337-af58-91c241c0da0e
02/08/2025 00:40:50:INFO:Received: evaluate message 5f702267-6832-4337-af58-91c241c0da0e
[92mINFO [0m:      Sent reply
02/08/2025 00:46:44:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:47:21:INFO:
[92mINFO [0m:      Received: train message 56d2e549-0c60-45e2-ba80-80f90ee3913b
02/08/2025 00:47:21:INFO:Received: train message 56d2e549-0c60-45e2-ba80-80f90ee3913b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 00:51:48:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 01:43:13:INFO:
[92mINFO [0m:      Received: evaluate message 7f4e61bd-5683-4b92-97b1-e5081811858d
02/08/2025 01:43:13:INFO:Received: evaluate message 7f4e61bd-5683-4b92-97b1-e5081811858d
[92mINFO [0m:      Sent reply
02/08/2025 01:49:04:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 01:50:08:INFO:
[92mINFO [0m:      Received: train message fa859083-8035-4c06-8c7e-921766d4121f
02/08/2025 01:50:08:INFO:Received: train message fa859083-8035-4c06-8c7e-921766d4121f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 01:54:38:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 02:48:06:INFO:
[92mINFO [0m:      Received: evaluate message d5230195-13e2-43df-b8db-4fb3468faf77
02/08/2025 02:48:06:INFO:Received: evaluate message d5230195-13e2-43df-b8db-4fb3468faf77
[92mINFO [0m:      Sent reply
02/08/2025 02:53:58:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 02:54:34:INFO:
[92mINFO [0m:      Received: train message eaa0dfe7-2d0c-4970-92ed-e171022f07f5
02/08/2025 02:54:34:INFO:Received: train message eaa0dfe7-2d0c-4970-92ed-e171022f07f5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 02:58:26:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:52:09:INFO:
[92mINFO [0m:      Received: evaluate message 860a7881-5651-4924-b202-81a0673eb580
02/08/2025 03:52:09:INFO:Received: evaluate message 860a7881-5651-4924-b202-81a0673eb580
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=30.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=30.0']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 18597, num_classes: 8

Privacy Params:
 epsilon: 30.0, target_epsilon: 30.0, target_delta: 1e-05

Device: cuda:0

Step 1a: Client Initialized
Step 1b: Recomputing FIM for epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415], 'accuracy': [0.5734997986306887], 'auc': [0.8209263333238899], 'precision': [0.5896199585980895], 'recall': [0.5734997986306887], 'f1': [0.5251729041892587]}

Step 1b: Recomputing FIM for epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146], 'accuracy': [0.5734997986306887, 0.6061216270640355], 'auc': [0.8209263333238899, 0.8524348169466368], 'precision': [0.5896199585980895, 0.6033971678272441], 'recall': [0.5734997986306887, 0.6061216270640355], 'f1': [0.5251729041892587, 0.5708840472582581]}

Step 1b: Recomputing FIM for epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035]}

Step 1b: Recomputing FIM for epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997]}

Step 1b: Recomputing FIM for epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345]}

Step 1b: Recomputing FIM for epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566]}

Step 1b: Recomputing FIM for epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 03:58:01:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:58:44:INFO:
[92mINFO [0m:      Received: train message 5dfe3dc7-b009-44b9-901f-3acc7c861e70
02/08/2025 03:58:44:INFO:Received: train message 5dfe3dc7-b009-44b9-901f-3acc7c861e70
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 04:03:26:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 04:57:24:INFO:
[92mINFO [0m:      Received: evaluate message 6f713dab-f3d2-4d0c-af06-abca251e21ed
02/08/2025 04:57:24:INFO:Received: evaluate message 6f713dab-f3d2-4d0c-af06-abca251e21ed
[92mINFO [0m:      Sent reply
02/08/2025 05:02:55:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 05:03:37:INFO:
[92mINFO [0m:      Received: train message 8671e312-106a-4500-9a1f-0ecaf0e9ce5b
02/08/2025 05:03:37:INFO:Received: train message 8671e312-106a-4500-9a1f-0ecaf0e9ce5b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 05:07:50:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:01:26:INFO:
[92mINFO [0m:      Received: evaluate message cf4fde1d-f63e-4266-b4d1-f322d80db0b8
02/08/2025 06:01:26:INFO:Received: evaluate message cf4fde1d-f63e-4266-b4d1-f322d80db0b8
[92mINFO [0m:      Sent reply
02/08/2025 06:07:19:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:07:35:INFO:
[92mINFO [0m:      Received: train message e186f371-5bf8-4aae-a798-385bd5683775
02/08/2025 06:07:35:INFO:Received: train message e186f371-5bf8-4aae-a798-385bd5683775
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 06:11:38:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 07:05:12:INFO:
[92mINFO [0m:      Received: evaluate message 52bcb5e2-0b57-443b-85ae-957d31d0128d
02/08/2025 07:05:12:INFO:Received: evaluate message 52bcb5e2-0b57-443b-85ae-957d31d0128d
[92mINFO [0m:      Sent reply
02/08/2025 07:11:28:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 07:12:12:INFO:
[92mINFO [0m:      Received: train message 75cc558b-f46d-42c3-ae9d-b35a0011e4f8
02/08/2025 07:12:12:INFO:Received: train message 75cc558b-f46d-42c3-ae9d-b35a0011e4f8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 07:16:40:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 08:10:27:INFO:
[92mINFO [0m:      Received: evaluate message 8367946c-d9e9-435d-8e94-f5d2b377b686
02/08/2025 08:10:27:INFO:Received: evaluate message 8367946c-d9e9-435d-8e94-f5d2b377b686
[92mINFO [0m:      Sent reply
02/08/2025 08:15:52:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 08:16:35:INFO:
[92mINFO [0m:      Received: train message 1cbc5f69-3efb-48cf-8b6a-80650b6d625b
02/08/2025 08:16:35:INFO:Received: train message 1cbc5f69-3efb-48cf-8b6a-80650b6d625b

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031]}

Step 1b: Recomputing FIM for epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301]}

Step 1b: Recomputing FIM for epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037]}

Step 1b: Recomputing FIM for epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631]}

Step 1b: Recomputing FIM for epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482]}

Step 1b: Recomputing FIM for epoch 12
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 08:20:38:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:13:37:INFO:
[92mINFO [0m:      Received: evaluate message 4e25d2f0-1774-4c6f-8409-267b200878c6
02/08/2025 09:13:37:INFO:Received: evaluate message 4e25d2f0-1774-4c6f-8409-267b200878c6
[92mINFO [0m:      Sent reply
02/08/2025 09:19:22:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:20:29:INFO:
[92mINFO [0m:      Received: train message 07e71daf-f09d-4314-83c2-262c08bac1ca
02/08/2025 09:20:29:INFO:Received: train message 07e71daf-f09d-4314-83c2-262c08bac1ca
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 09:25:27:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:19:18:INFO:
[92mINFO [0m:      Received: evaluate message 1608ad52-d94d-41b7-bac5-1f2fbdd3db02
02/08/2025 10:19:18:INFO:Received: evaluate message 1608ad52-d94d-41b7-bac5-1f2fbdd3db02
[92mINFO [0m:      Sent reply
02/08/2025 10:24:44:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:25:16:INFO:
[92mINFO [0m:      Received: train message 21ee7dd8-b168-4c91-82f8-0f6f6d1eb8d8
02/08/2025 10:25:16:INFO:Received: train message 21ee7dd8-b168-4c91-82f8-0f6f6d1eb8d8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 10:29:19:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 11:23:56:INFO:
[92mINFO [0m:      Received: evaluate message 198ee464-befb-47ee-95e0-49d4b99ec67b
02/08/2025 11:23:56:INFO:Received: evaluate message 198ee464-befb-47ee-95e0-49d4b99ec67b
[92mINFO [0m:      Sent reply
02/08/2025 11:28:48:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 11:29:33:INFO:
[92mINFO [0m:      Received: train message 3cc60d26-8099-4521-8314-fc3eae5a17e7
02/08/2025 11:29:33:INFO:Received: train message 3cc60d26-8099-4521-8314-fc3eae5a17e7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 11:33:28:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 12:27:54:INFO:
[92mINFO [0m:      Received: evaluate message a71b5348-77e6-4cbc-9672-8206aa625fbe
02/08/2025 12:27:54:INFO:Received: evaluate message a71b5348-77e6-4cbc-9672-8206aa625fbe
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704]}

Step 1b: Recomputing FIM for epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276]}

Step 1b: Recomputing FIM for epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152]}

Step 1b: Recomputing FIM for epoch 15
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 12:33:33:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 12:34:57:INFO:
[92mINFO [0m:      Received: train message e5bf51c8-0e7f-4186-a189-d752e87fd97d
02/08/2025 12:34:57:INFO:Received: train message e5bf51c8-0e7f-4186-a189-d752e87fd97d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 12:39:20:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:30:38:INFO:
[92mINFO [0m:      Received: evaluate message 571b5995-0543-4b38-b481-3a7923635b73
02/08/2025 13:30:38:INFO:Received: evaluate message 571b5995-0543-4b38-b481-3a7923635b73
[92mINFO [0m:      Sent reply
02/08/2025 13:34:31:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:35:17:INFO:
[92mINFO [0m:      Received: train message 718095e5-4205-415b-b270-ead0f8f2ed01
02/08/2025 13:35:17:INFO:Received: train message 718095e5-4205-415b-b270-ead0f8f2ed01
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 13:38:14:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 14:21:02:INFO:
[92mINFO [0m:      Received: evaluate message ba67c973-8882-43e4-9087-b6883e502739
02/08/2025 14:21:02:INFO:Received: evaluate message ba67c973-8882-43e4-9087-b6883e502739
[92mINFO [0m:      Sent reply
02/08/2025 14:24:43:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 14:26:00:INFO:
[92mINFO [0m:      Received: train message f6cef515-01cb-4018-8de6-100c848704e5
02/08/2025 14:26:00:INFO:Received: train message f6cef515-01cb-4018-8de6-100c848704e5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 14:29:03:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 15:11:17:INFO:
[92mINFO [0m:      Received: evaluate message 347d5030-d089-4f6b-b2d4-d31ab7e6f71a
02/08/2025 15:11:17:INFO:Received: evaluate message 347d5030-d089-4f6b-b2d4-d31ab7e6f71a

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898]}

Step 1b: Recomputing FIM for epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916]}

Step 1b: Recomputing FIM for epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964]}

Step 1b: Recomputing FIM for epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 15:15:07:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 15:16:03:INFO:
[92mINFO [0m:      Received: train message 47674a1b-ff4a-4d9e-8602-b12bc6ad919f
02/08/2025 15:16:03:INFO:Received: train message 47674a1b-ff4a-4d9e-8602-b12bc6ad919f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 15:18:56:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 16:00:55:INFO:
[92mINFO [0m:      Received: evaluate message 13c12983-5fbc-46fd-be21-a9c805455a29
02/08/2025 16:00:55:INFO:Received: evaluate message 13c12983-5fbc-46fd-be21-a9c805455a29
[92mINFO [0m:      Sent reply
02/08/2025 16:04:33:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 16:05:36:INFO:
[92mINFO [0m:      Received: train message 14f3595c-60f7-4f81-bfda-c8e111fd6be1
02/08/2025 16:05:36:INFO:Received: train message 14f3595c-60f7-4f81-bfda-c8e111fd6be1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 16:08:41:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 16:50:15:INFO:
[92mINFO [0m:      Received: evaluate message 8ad63cd4-14c9-4c7f-b5a0-09512b8476e5
02/08/2025 16:50:15:INFO:Received: evaluate message 8ad63cd4-14c9-4c7f-b5a0-09512b8476e5

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616]}

Step 1b: Recomputing FIM for epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366]}

Step 1b: Recomputing FIM for epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 16:53:48:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 16:55:31:INFO:
[92mINFO [0m:      Received: train message c5cdb2e0-f7b1-4bf5-a6e4-78fcdd699d50
02/08/2025 16:55:31:INFO:Received: train message c5cdb2e0-f7b1-4bf5-a6e4-78fcdd699d50
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 16:58:38:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:39:24:INFO:
[92mINFO [0m:      Received: evaluate message af04ca75-a7cb-4372-ad54-f4e96ff4542e
02/08/2025 17:39:24:INFO:Received: evaluate message af04ca75-a7cb-4372-ad54-f4e96ff4542e
[92mINFO [0m:      Sent reply
02/08/2025 17:43:07:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:44:41:INFO:
[92mINFO [0m:      Received: train message 47dcfb63-12db-4848-be4f-d72443c79c5b
02/08/2025 17:44:41:INFO:Received: train message 47dcfb63-12db-4848-be4f-d72443c79c5b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 17:47:51:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 18:27:57:INFO:
[92mINFO [0m:      Received: evaluate message 2628adb0-aad9-41ad-95d9-f8e8a5c3864f
02/08/2025 18:27:57:INFO:Received: evaluate message 2628adb0-aad9-41ad-95d9-f8e8a5c3864f

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707]}

Step 1b: Recomputing FIM for epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778]}

Step 1b: Recomputing FIM for epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 18:31:59:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 18:33:19:INFO:
[92mINFO [0m:      Received: train message 0f7dde34-a2c8-417c-87b0-f05b4d3dbe94
02/08/2025 18:33:19:INFO:Received: train message 0f7dde34-a2c8-417c-87b0-f05b4d3dbe94
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 18:36:28:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 19:17:07:INFO:
[92mINFO [0m:      Received: evaluate message 206dcad5-4c3f-4a63-aebe-1ddf5aa95aa3
02/08/2025 19:17:07:INFO:Received: evaluate message 206dcad5-4c3f-4a63-aebe-1ddf5aa95aa3
[92mINFO [0m:      Sent reply
02/08/2025 19:20:54:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 19:22:21:INFO:
[92mINFO [0m:      Received: train message 57d5e169-e836-45b8-a98b-e8832496c840
02/08/2025 19:22:21:INFO:Received: train message 57d5e169-e836-45b8-a98b-e8832496c840
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 19:25:20:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 19:55:08:INFO:
[92mINFO [0m:      Received: evaluate message 2c385717-adb2-4978-85e7-299018d8aca1
02/08/2025 19:55:08:INFO:Received: evaluate message 2c385717-adb2-4978-85e7-299018d8aca1

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614, 1.298693851794728], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986, 0.8996870757485629], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281, 0.6669345697944524], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778, 0.6455838373810933]}

Step 1b: Recomputing FIM for epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614, 1.298693851794728, 1.2951653664312774], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986, 0.8996870757485629, 0.9007796017681694], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281, 0.6669345697944524, 0.6664606460734918], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778, 0.6455838373810933, 0.6490171879912949]}

Step 1b: Recomputing FIM for epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 19:58:41:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 20:00:10:INFO:
[92mINFO [0m:      Received: train message 53f77368-933e-4317-ac81-9407d8888b3a
02/08/2025 20:00:10:INFO:Received: train message 53f77368-933e-4317-ac81-9407d8888b3a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 20:03:21:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 20:32:02:INFO:
[92mINFO [0m:      Received: evaluate message 03845425-e7d3-4291-bd4b-c92d52ef5818
02/08/2025 20:32:02:INFO:Received: evaluate message 03845425-e7d3-4291-bd4b-c92d52ef5818
[92mINFO [0m:      Sent reply
02/08/2025 20:35:55:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 20:36:58:INFO:
[92mINFO [0m:      Received: train message 44fa7b31-33f2-4774-9b02-92179fd15435
02/08/2025 20:36:58:INFO:Received: train message 44fa7b31-33f2-4774-9b02-92179fd15435
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 20:40:07:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 21:08:49:INFO:
[92mINFO [0m:      Received: evaluate message 695112f7-c665-414b-9174-6ce84da79eb3
02/08/2025 21:08:49:INFO:Received: evaluate message 695112f7-c665-414b-9174-6ce84da79eb3

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614, 1.298693851794728, 1.2951653664312774, 1.3044213814405103], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986, 0.8996870757485629, 0.9007796017681694, 0.9011216759205583], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281, 0.6669345697944524, 0.6664606460734918, 0.666695373703402], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778, 0.6455838373810933, 0.6490171879912949, 0.6478382917736635]}

Step 1b: Recomputing FIM for epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614, 1.298693851794728, 1.2951653664312774, 1.3044213814405103, 1.2847175358573708], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986, 0.8996870757485629, 0.9007796017681694, 0.9011216759205583, 0.9029478773060325], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281, 0.6669345697944524, 0.6664606460734918, 0.666695373703402, 0.6730571937320927], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778, 0.6455838373810933, 0.6490171879912949, 0.6478382917736635, 0.6519532596938682]}

Step 1b: Recomputing FIM for epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 21:12:55:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 21:13:44:INFO:
[92mINFO [0m:      Received: train message 38428d75-10d2-47aa-89fb-d2805b90b8d8
02/08/2025 21:13:44:INFO:Received: train message 38428d75-10d2-47aa-89fb-d2805b90b8d8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 21:16:58:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 21:45:45:INFO:
[92mINFO [0m:      Received: evaluate message 43e291e3-573f-4e23-b5a5-603e48fffcf8
02/08/2025 21:45:45:INFO:Received: evaluate message 43e291e3-573f-4e23-b5a5-603e48fffcf8
[92mINFO [0m:      Sent reply
02/08/2025 21:49:48:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 21:50:08:INFO:
[92mINFO [0m:      Received: train message 9b05b81e-aac3-4053-ba5b-617415e7aae5
02/08/2025 21:50:08:INFO:Received: train message 9b05b81e-aac3-4053-ba5b-617415e7aae5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 21:52:47:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 22:23:17:INFO:
[92mINFO [0m:      Received: evaluate message 7a67fa7f-963b-4af2-98c6-edd820e01756
02/08/2025 22:23:17:INFO:Received: evaluate message 7a67fa7f-963b-4af2-98c6-edd820e01756

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614, 1.298693851794728, 1.2951653664312774, 1.3044213814405103, 1.2847175358573708, 1.3185475385097838], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986, 0.8996870757485629, 0.9007796017681694, 0.9011216759205583, 0.9029478773060325, 0.9027586538608232], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281, 0.6669345697944524, 0.6664606460734918, 0.666695373703402, 0.6730571937320927, 0.678026646197293], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778, 0.6455838373810933, 0.6490171879912949, 0.6478382917736635, 0.6519532596938682, 0.6509285601262981]}

Step 1b: Recomputing FIM for epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614, 1.298693851794728, 1.2951653664312774, 1.3044213814405103, 1.2847175358573708, 1.3185475385097838, 1.2741964666823251], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472, 0.657672170761176], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986, 0.8996870757485629, 0.9007796017681694, 0.9011216759205583, 0.9029478773060325, 0.9027586538608232, 0.9043753022262412], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281, 0.6669345697944524, 0.6664606460734918, 0.666695373703402, 0.6730571937320927, 0.678026646197293, 0.6766303262499491], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472, 0.657672170761176], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778, 0.6455838373810933, 0.6490171879912949, 0.6478382917736635, 0.6519532596938682, 0.6509285601262981, 0.6513272226171777]}

Step 1b: Recomputing FIM for epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 22:27:16:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 22:27:51:INFO:
[92mINFO [0m:      Received: train message 8adc7a12-bbc1-482f-b6c4-bb5861b24d89
02/08/2025 22:27:51:INFO:Received: train message 8adc7a12-bbc1-482f-b6c4-bb5861b24d89
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 22:31:14:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 23:00:14:INFO:
[92mINFO [0m:      Received: evaluate message 2248a2d8-bdcc-4f90-bdb1-c6fecb81dbc7
02/08/2025 23:00:14:INFO:Received: evaluate message 2248a2d8-bdcc-4f90-bdb1-c6fecb81dbc7
[92mINFO [0m:      Sent reply
02/08/2025 23:04:27:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 23:05:02:INFO:
[92mINFO [0m:      Received: train message 1460fa11-e729-43be-9119-b2c33c3485a3
02/08/2025 23:05:02:INFO:Received: train message 1460fa11-e729-43be-9119-b2c33c3485a3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 23:08:20:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 23:37:30:INFO:
[92mINFO [0m:      Received: evaluate message 5f6e3e38-a830-46c3-86f1-58ca9f7d5164
02/08/2025 23:37:30:INFO:Received: evaluate message 5f6e3e38-a830-46c3-86f1-58ca9f7d5164

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614, 1.298693851794728, 1.2951653664312774, 1.3044213814405103, 1.2847175358573708, 1.3185475385097838, 1.2741964666823251, 1.2812168351642748], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472, 0.657672170761176, 0.6584776480064438], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986, 0.8996870757485629, 0.9007796017681694, 0.9011216759205583, 0.9029478773060325, 0.9027586538608232, 0.9043753022262412, 0.9049618852789625], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281, 0.6669345697944524, 0.6664606460734918, 0.666695373703402, 0.6730571937320927, 0.678026646197293, 0.6766303262499491, 0.6708704491403805], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472, 0.657672170761176, 0.6584776480064438], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778, 0.6455838373810933, 0.6490171879912949, 0.6478382917736635, 0.6519532596938682, 0.6509285601262981, 0.6513272226171777, 0.6526233140714557]}

Step 1b: Recomputing FIM for epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614, 1.298693851794728, 1.2951653664312774, 1.3044213814405103, 1.2847175358573708, 1.3185475385097838, 1.2741964666823251, 1.2812168351642748, 1.2479766714107208], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472, 0.657672170761176, 0.6584776480064438, 0.6697543294401933], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986, 0.8996870757485629, 0.9007796017681694, 0.9011216759205583, 0.9029478773060325, 0.9027586538608232, 0.9043753022262412, 0.9049618852789625, 0.9066339823013814], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281, 0.6669345697944524, 0.6664606460734918, 0.666695373703402, 0.6730571937320927, 0.678026646197293, 0.6766303262499491, 0.6708704491403805, 0.6722172714652418], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472, 0.657672170761176, 0.6584776480064438, 0.6697543294401933], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778, 0.6455838373810933, 0.6490171879912949, 0.6478382917736635, 0.6519532596938682, 0.6509285601262981, 0.6513272226171777, 0.6526233140714557, 0.6613982788101018]}

Step 1b: Recomputing FIM for epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 23:41:36:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 23:41:37:INFO:
[92mINFO [0m:      Received: reconnect message bf1b00ab-d361-4568-8b4b-33cfe2f8dd3e
02/08/2025 23:41:37:INFO:Received: reconnect message bf1b00ab-d361-4568-8b4b-33cfe2f8dd3e
02/08/2025 23:41:37:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/08/2025 23:41:37:INFO:Disconnect and shut down

{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614, 1.298693851794728, 1.2951653664312774, 1.3044213814405103, 1.2847175358573708, 1.3185475385097838, 1.2741964666823251, 1.2812168351642748, 1.2479766714107208, 1.3531703354608517], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472, 0.657672170761176, 0.6584776480064438, 0.6697543294401933, 0.6508256141763995], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986, 0.8996870757485629, 0.9007796017681694, 0.9011216759205583, 0.9029478773060325, 0.9027586538608232, 0.9043753022262412, 0.9049618852789625, 0.9066339823013814, 0.9051206490422763], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281, 0.6669345697944524, 0.6664606460734918, 0.666695373703402, 0.6730571937320927, 0.678026646197293, 0.6766303262499491, 0.6708704491403805, 0.6722172714652418, 0.6712632027903389], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472, 0.657672170761176, 0.6584776480064438, 0.6697543294401933, 0.6508256141763995], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778, 0.6455838373810933, 0.6490171879912949, 0.6478382917736635, 0.6519532596938682, 0.6509285601262981, 0.6513272226171777, 0.6526233140714557, 0.6613982788101018, 0.6422848655738752]}



Final client history:
{'loss': [1.3763256583826415, 1.3285103418680146, 1.3373394124795004, 1.3422987826447597, 1.3102117085764113, 1.3099978007331186, 1.329323493997464, 1.2717419178121954, 1.2958960361745728, 1.2888935617367394, 1.2881886062965824, 1.2887983894905062, 1.312919552965698, 1.3169054160231406, 1.2907440043292697, 1.321296288416936, 1.2718990556760705, 1.290925056474419, 1.2610760287944702, 1.276824944666495, 1.2620323399262614, 1.298693851794728, 1.2951653664312774, 1.3044213814405103, 1.2847175358573708, 1.3185475385097838, 1.2741964666823251, 1.2812168351642748, 1.2479766714107208, 1.3531703354608517], 'accuracy': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472, 0.657672170761176, 0.6584776480064438, 0.6697543294401933, 0.6508256141763995], 'auc': [0.8209263333238899, 0.8524348169466368, 0.8667376756683434, 0.8745173398074795, 0.8782702551231041, 0.8801935054025718, 0.88263935537671, 0.887688678788253, 0.8889845428036838, 0.8908908422457996, 0.8926486526794739, 0.8938847058924138, 0.8931904755600379, 0.8945284681199597, 0.8958333912742964, 0.8964178056890348, 0.8976175956966725, 0.8973934394207038, 0.8978345893454193, 0.8987692165307118, 0.8997203127063986, 0.8996870757485629, 0.9007796017681694, 0.9011216759205583, 0.9029478773060325, 0.9027586538608232, 0.9043753022262412, 0.9049618852789625, 0.9066339823013814, 0.9051206490422763], 'precision': [0.5896199585980895, 0.6033971678272441, 0.62144158439859, 0.6301441218311281, 0.6218734892459606, 0.6328067685281672, 0.640615794509741, 0.6441346852042644, 0.644807241713974, 0.6415755643940348, 0.6430752057990011, 0.640544675079917, 0.64713648551798, 0.6460003433712027, 0.6491245310723439, 0.6396580476596774, 0.6599851599103794, 0.6533956895846124, 0.6515813903201264, 0.6549487231913611, 0.6657130767185281, 0.6669345697944524, 0.6664606460734918, 0.666695373703402, 0.6730571937320927, 0.678026646197293, 0.6766303262499491, 0.6708704491403805, 0.6722172714652418, 0.6712632027903389], 'recall': [0.5734997986306887, 0.6061216270640355, 0.6190092629883206, 0.6294804671768023, 0.6347160692710431, 0.6383407168747482, 0.6415626258558196, 0.6512283527990335, 0.6480064438179621, 0.6455900120821587, 0.6472009665726943, 0.644381796214257, 0.6492146596858639, 0.6472009665726943, 0.6528393072895691, 0.63954893274265, 0.6560612162706404, 0.6508256141763995, 0.6580749093838099, 0.6608940797422472, 0.6568666935159082, 0.6596858638743456, 0.6633105114780508, 0.662505034232783, 0.6608940797422472, 0.6608940797422472, 0.657672170761176, 0.6584776480064438, 0.6697543294401933, 0.6508256141763995], 'f1': [0.5251729041892587, 0.5708840472582581, 0.5892360851580035, 0.598800274008997, 0.6070932447135345, 0.6151881228635566, 0.6158988570268031, 0.6321393128720301, 0.6275179048620037, 0.6277193351722631, 0.6275907055431482, 0.6262783389599704, 0.6306495462552276, 0.6313109858859152, 0.6359831572121898, 0.6234353526377916, 0.6445620112605964, 0.6382335618121616, 0.6448924165569366, 0.6467796320689707, 0.6493960416087778, 0.6455838373810933, 0.6490171879912949, 0.6478382917736635, 0.6519532596938682, 0.6509285601262981, 0.6513272226171777, 0.6526233140714557, 0.6613982788101018, 0.6422848655738752]}

