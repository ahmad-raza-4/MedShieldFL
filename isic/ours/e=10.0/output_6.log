nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=10.0/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
02/07/2025 20:06:20:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 20:06:20:DEBUG:ChannelConnectivity.IDLE
02/07/2025 20:06:20:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
02/07/2025 20:06:20:INFO:
[92mINFO [0m:      Received: get_parameters message f655e392-a9dd-4f7d-9d8e-a4b803836f12
02/07/2025 20:06:20:INFO:Received: get_parameters message f655e392-a9dd-4f7d-9d8e-a4b803836f12
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738987580.607882 1673117 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      Sent reply
02/07/2025 20:06:26:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 20:16:59:INFO:
[92mINFO [0m:      Received: train message ffadf140-e472-4863-b0ef-792ae48a39fd
02/07/2025 20:16:59:INFO:Received: train message ffadf140-e472-4863-b0ef-792ae48a39fd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 20:20:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 20:57:28:INFO:
[92mINFO [0m:      Received: evaluate message 88c4bc18-bac3-4d1b-8173-6d526bd596de
02/07/2025 20:57:28:INFO:Received: evaluate message 88c4bc18-bac3-4d1b-8173-6d526bd596de
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 21:01:54:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:02:38:INFO:
[92mINFO [0m:      Received: train message fc251f3e-5663-4738-a193-cb0932323f10
02/07/2025 21:02:38:INFO:Received: train message fc251f3e-5663-4738-a193-cb0932323f10
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 21:06:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:42:31:INFO:
[92mINFO [0m:      Received: evaluate message ea4a3726-26b3-4634-b8a8-a5a2ed0aa35e
02/07/2025 21:42:31:INFO:Received: evaluate message ea4a3726-26b3-4634-b8a8-a5a2ed0aa35e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 21:47:20:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:47:52:INFO:
[92mINFO [0m:      Received: train message 4641f759-f770-4f47-810b-b237e2a7251d
02/07/2025 21:47:52:INFO:Received: train message 4641f759-f770-4f47-810b-b237e2a7251d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 21:51:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:26:12:INFO:
[92mINFO [0m:      Received: evaluate message 6d213fa1-a97d-48ce-bb1c-c72dd12cde32
02/07/2025 22:26:12:INFO:Received: evaluate message 6d213fa1-a97d-48ce-bb1c-c72dd12cde32
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 22:30:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:31:40:INFO:
[92mINFO [0m:      Received: train message 1add0e03-8a31-446f-a44c-1d721a772f46
02/07/2025 22:31:40:INFO:Received: train message 1add0e03-8a31-446f-a44c-1d721a772f46
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:39:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 23:14:52:INFO:
[92mINFO [0m:      Received: evaluate message ac761fb6-2364-4e86-910c-6e42d32331cd
02/07/2025 23:14:52:INFO:Received: evaluate message ac761fb6-2364-4e86-910c-6e42d32331cd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 23:19:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 23:19:55:INFO:
[92mINFO [0m:      Received: train message b3bab03a-02a7-4e39-b40f-96f7e939401d
02/07/2025 23:19:55:INFO:Received: train message b3bab03a-02a7-4e39-b40f-96f7e939401d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 23:23:41:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:00:46:INFO:
[92mINFO [0m:      Received: evaluate message 07cc24ba-bb00-498b-94e7-8548372e9874
02/08/2025 00:00:46:INFO:Received: evaluate message 07cc24ba-bb00-498b-94e7-8548372e9874
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/08/2025 00:05:08:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:05:40:INFO:
[92mINFO [0m:      Received: train message a9194295-11d6-40fa-80f0-a315b64c7eb7
02/08/2025 00:05:40:INFO:Received: train message a9194295-11d6-40fa-80f0-a315b64c7eb7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 00:09:31:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:44:48:INFO:
[92mINFO [0m:      Received: evaluate message fe6714f6-f21d-42c7-9d1c-689dd5a78058
02/08/2025 00:44:48:INFO:Received: evaluate message fe6714f6-f21d-42c7-9d1c-689dd5a78058
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/08/2025 00:49:19:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:49:39:INFO:
[92mINFO [0m:      Received: train message 475b646c-6a89-4112-907c-05616ffc6305
02/08/2025 00:49:39:INFO:Received: train message 475b646c-6a89-4112-907c-05616ffc6305
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 00:53:07:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 01:30:29:INFO:
[92mINFO [0m:      Received: evaluate message 5b05608d-d386-4d29-83b4-56c33b812368
02/08/2025 01:30:29:INFO:Received: evaluate message 5b05608d-d386-4d29-83b4-56c33b812368
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=10.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=10.0']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 18597, num_classes: 8

Privacy Params:
 epsilon: 10.0, target_epsilon: 10.0, target_delta: 1e-05

Device: cuda:0

Step 1a: Client Initialized
Step 1b: Recomputing FIM for epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232], 'accuracy': [0.5553765606121627], 'auc': [0.7952128841995612], 'precision': [0.5630504832476843], 'recall': [0.5553765606121627], 'f1': [0.5014109976972659]}

Step 1b: Recomputing FIM for epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068], 'accuracy': [0.5553765606121627, 0.6004832863471606], 'auc': [0.7952128841995612, 0.8346505194429128], 'precision': [0.5630504832476843, 0.588172573519457], 'recall': [0.5553765606121627, 0.6004832863471606], 'f1': [0.5014109976972659, 0.559282479633486]}

Step 1b: Recomputing FIM for epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006]}

Step 1b: Recomputing FIM for epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696]}

Step 1b: Recomputing FIM for epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894]}

Step 1b: Recomputing FIM for epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595]}

Step 1b: Recomputing FIM for epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 01:34:54:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 01:35:25:INFO:
[92mINFO [0m:      Received: train message e3f8c677-2ecd-461c-a909-ede881a39dc9
02/08/2025 01:35:25:INFO:Received: train message e3f8c677-2ecd-461c-a909-ede881a39dc9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 01:38:42:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 02:16:48:INFO:
[92mINFO [0m:      Received: evaluate message e5fc766d-bb41-472c-a8d0-59bdaee8967b
02/08/2025 02:16:48:INFO:Received: evaluate message e5fc766d-bb41-472c-a8d0-59bdaee8967b
[92mINFO [0m:      Sent reply
02/08/2025 02:21:00:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 02:21:20:INFO:
[92mINFO [0m:      Received: train message 5267ba90-37e7-4dae-8219-a8a6acaf4be2
02/08/2025 02:21:20:INFO:Received: train message 5267ba90-37e7-4dae-8219-a8a6acaf4be2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 02:24:38:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:01:39:INFO:
[92mINFO [0m:      Received: evaluate message 7ef11e02-79cd-43a9-a6f3-a419468b65de
02/08/2025 03:01:39:INFO:Received: evaluate message 7ef11e02-79cd-43a9-a6f3-a419468b65de
[92mINFO [0m:      Sent reply
02/08/2025 03:06:07:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:06:36:INFO:
[92mINFO [0m:      Received: train message 4162ba94-98d9-4c62-8648-ae1dcabe3d72
02/08/2025 03:06:36:INFO:Received: train message 4162ba94-98d9-4c62-8648-ae1dcabe3d72
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 03:10:13:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:45:26:INFO:
[92mINFO [0m:      Received: evaluate message 12c458f9-6a04-46e2-b48e-853989d81e9c
02/08/2025 03:45:26:INFO:Received: evaluate message 12c458f9-6a04-46e2-b48e-853989d81e9c
[92mINFO [0m:      Sent reply
02/08/2025 03:49:38:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:50:12:INFO:
[92mINFO [0m:      Received: train message f6e3a7f9-aac0-45fb-b57a-f4ddd6be077e
02/08/2025 03:50:12:INFO:Received: train message f6e3a7f9-aac0-45fb-b57a-f4ddd6be077e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 03:53:42:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 04:32:51:INFO:
[92mINFO [0m:      Received: evaluate message 1ea0650a-f3cb-47fd-95c6-fe0b73bf7d7c
02/08/2025 04:32:51:INFO:Received: evaluate message 1ea0650a-f3cb-47fd-95c6-fe0b73bf7d7c
[92mINFO [0m:      Sent reply
02/08/2025 04:37:10:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 04:37:46:INFO:
[92mINFO [0m:      Received: train message 3f116d34-abc8-4fe4-80ed-21453c7a22e8
02/08/2025 04:37:46:INFO:Received: train message 3f116d34-abc8-4fe4-80ed-21453c7a22e8

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815]}

Step 1b: Recomputing FIM for epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657]}

Step 1b: Recomputing FIM for epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914]}

Step 1b: Recomputing FIM for epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116]}

Step 1b: Recomputing FIM for epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986]}

Step 1b: Recomputing FIM for epoch 12
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 04:41:18:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 05:20:59:INFO:
[92mINFO [0m:      Received: evaluate message cfd3c6a1-4506-4f8d-a0ec-5dc976fd484b
02/08/2025 05:20:59:INFO:Received: evaluate message cfd3c6a1-4506-4f8d-a0ec-5dc976fd484b
[92mINFO [0m:      Sent reply
02/08/2025 05:25:13:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 05:25:43:INFO:
[92mINFO [0m:      Received: train message 0cd7ba1e-bd5b-4004-96c5-568509c39334
02/08/2025 05:25:43:INFO:Received: train message 0cd7ba1e-bd5b-4004-96c5-568509c39334
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 05:28:44:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:05:36:INFO:
[92mINFO [0m:      Received: evaluate message b1e82642-3e92-429e-a1f2-45ebf2f1925c
02/08/2025 06:05:36:INFO:Received: evaluate message b1e82642-3e92-429e-a1f2-45ebf2f1925c
[92mINFO [0m:      Sent reply
02/08/2025 06:10:20:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:10:56:INFO:
[92mINFO [0m:      Received: train message 2737928e-8092-4e43-9f5d-ccca66612fd7
02/08/2025 06:10:56:INFO:Received: train message 2737928e-8092-4e43-9f5d-ccca66612fd7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 06:14:45:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:51:53:INFO:
[92mINFO [0m:      Received: evaluate message d92d04da-1ba7-4914-8387-4e2746839d75
02/08/2025 06:51:53:INFO:Received: evaluate message d92d04da-1ba7-4914-8387-4e2746839d75
[92mINFO [0m:      Sent reply
02/08/2025 06:55:50:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:57:01:INFO:
[92mINFO [0m:      Received: train message d835edb3-9a1d-47f0-a38c-57f2f7d5d432
02/08/2025 06:57:01:INFO:Received: train message d835edb3-9a1d-47f0-a38c-57f2f7d5d432
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 07:00:30:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 07:39:55:INFO:
[92mINFO [0m:      Received: evaluate message c5047a59-20b8-40ac-97c4-dca3bbb6e9bf
02/08/2025 07:39:55:INFO:Received: evaluate message c5047a59-20b8-40ac-97c4-dca3bbb6e9bf
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747]}

Step 1b: Recomputing FIM for epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504]}

Step 1b: Recomputing FIM for epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675]}

Step 1b: Recomputing FIM for epoch 15
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 07:44:03:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 07:44:29:INFO:
[92mINFO [0m:      Received: train message 3da0a21e-03b4-470d-b525-52779aeb78b2
02/08/2025 07:44:29:INFO:Received: train message 3da0a21e-03b4-470d-b525-52779aeb78b2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 07:47:59:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 08:26:02:INFO:
[92mINFO [0m:      Received: evaluate message 5019e8c2-ad2c-4874-8740-c4e015042794
02/08/2025 08:26:02:INFO:Received: evaluate message 5019e8c2-ad2c-4874-8740-c4e015042794
[92mINFO [0m:      Sent reply
02/08/2025 08:30:29:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 08:31:10:INFO:
[92mINFO [0m:      Received: train message d2cc129e-23c9-4042-acc2-3b1f7441fd12
02/08/2025 08:31:10:INFO:Received: train message d2cc129e-23c9-4042-acc2-3b1f7441fd12
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 08:34:33:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:09:47:INFO:
[92mINFO [0m:      Received: evaluate message d727e45c-969c-4a8a-9c34-a72d8a666a87
02/08/2025 09:09:47:INFO:Received: evaluate message d727e45c-969c-4a8a-9c34-a72d8a666a87
[92mINFO [0m:      Sent reply
02/08/2025 09:13:47:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:14:52:INFO:
[92mINFO [0m:      Received: train message bc29e48c-d2b3-4f8c-a377-865720e6b49f
02/08/2025 09:14:52:INFO:Received: train message bc29e48c-d2b3-4f8c-a377-865720e6b49f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 09:18:34:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:56:50:INFO:
[92mINFO [0m:      Received: evaluate message 4fe981b8-a040-4963-9ba0-bcb48026b229
02/08/2025 09:56:50:INFO:Received: evaluate message 4fe981b8-a040-4963-9ba0-bcb48026b229

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132]}

Step 1b: Recomputing FIM for epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951]}

Step 1b: Recomputing FIM for epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673]}

Step 1b: Recomputing FIM for epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 10:01:03:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:01:53:INFO:
[92mINFO [0m:      Received: train message f1280cd5-3274-44cb-bb42-66ecebc475dc
02/08/2025 10:01:53:INFO:Received: train message f1280cd5-3274-44cb-bb42-66ecebc475dc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 10:05:11:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:44:43:INFO:
[92mINFO [0m:      Received: evaluate message 0a8b15a3-9fb8-45b7-ac32-2c87527256c8
02/08/2025 10:44:43:INFO:Received: evaluate message 0a8b15a3-9fb8-45b7-ac32-2c87527256c8
[92mINFO [0m:      Sent reply
02/08/2025 10:48:48:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:49:46:INFO:
[92mINFO [0m:      Received: train message 1c93d9bd-451e-4eb1-81f4-6f81a495245c
02/08/2025 10:49:46:INFO:Received: train message 1c93d9bd-451e-4eb1-81f4-6f81a495245c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 10:53:40:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 11:29:47:INFO:
[92mINFO [0m:      Received: evaluate message e2649ab5-51e8-49f4-b5cf-34b45730b402
02/08/2025 11:29:47:INFO:Received: evaluate message e2649ab5-51e8-49f4-b5cf-34b45730b402

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372]}

Step 1b: Recomputing FIM for epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079]}

Step 1b: Recomputing FIM for epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 11:34:16:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 11:34:57:INFO:
[92mINFO [0m:      Received: train message 5ab12805-45c9-43a0-bece-1f2dc25d02d9
02/08/2025 11:34:57:INFO:Received: train message 5ab12805-45c9-43a0-bece-1f2dc25d02d9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 11:38:57:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 12:15:03:INFO:
[92mINFO [0m:      Received: evaluate message 393934c1-e823-4c68-b95b-740ca9ef6d84
02/08/2025 12:15:03:INFO:Received: evaluate message 393934c1-e823-4c68-b95b-740ca9ef6d84
[92mINFO [0m:      Sent reply
02/08/2025 12:19:23:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 12:19:47:INFO:
[92mINFO [0m:      Received: train message c6598641-2c0c-49b0-b741-82a851568489
02/08/2025 12:19:47:INFO:Received: train message c6598641-2c0c-49b0-b741-82a851568489
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 12:23:26:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:02:53:INFO:
[92mINFO [0m:      Received: evaluate message 2da3cef3-0a8f-4ac6-bfe8-bbe4e8303d57
02/08/2025 13:02:53:INFO:Received: evaluate message 2da3cef3-0a8f-4ac6-bfe8-bbe4e8303d57

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863]}

Step 1b: Recomputing FIM for epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035]}

Step 1b: Recomputing FIM for epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 13:07:31:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:08:16:INFO:
[92mINFO [0m:      Received: train message 752e3cd0-111c-4d6b-891d-c4e39b8ba81c
02/08/2025 13:08:16:INFO:Received: train message 752e3cd0-111c-4d6b-891d-c4e39b8ba81c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 13:12:08:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:51:15:INFO:
[92mINFO [0m:      Received: evaluate message 2e47d4af-0c52-4165-87a7-d9bb4e70216b
02/08/2025 13:51:15:INFO:Received: evaluate message 2e47d4af-0c52-4165-87a7-d9bb4e70216b
[92mINFO [0m:      Sent reply
02/08/2025 13:56:08:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:56:41:INFO:
[92mINFO [0m:      Received: train message d1357270-d236-4183-b740-0d7cfab0a652
02/08/2025 13:56:41:INFO:Received: train message d1357270-d236-4183-b740-0d7cfab0a652
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 13:59:54:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 14:39:33:INFO:
[92mINFO [0m:      Received: evaluate message fa945c8d-cd06-4821-9879-9072c37021b2
02/08/2025 14:39:33:INFO:Received: evaluate message fa945c8d-cd06-4821-9879-9072c37021b2

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596]}

Step 1b: Recomputing FIM for epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102]}

Step 1b: Recomputing FIM for epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 14:44:29:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 14:44:55:INFO:
[92mINFO [0m:      Received: train message 386eec56-ed49-4963-a208-96273fe4caf8
02/08/2025 14:44:55:INFO:Received: train message 386eec56-ed49-4963-a208-96273fe4caf8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 14:48:34:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 15:26:25:INFO:
[92mINFO [0m:      Received: evaluate message 164a4d9d-9853-421d-8a31-c49284c530af
02/08/2025 15:26:25:INFO:Received: evaluate message 164a4d9d-9853-421d-8a31-c49284c530af
[92mINFO [0m:      Sent reply
02/08/2025 15:31:31:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 15:32:23:INFO:
[92mINFO [0m:      Received: train message 80e7f127-7821-479b-b695-fc0098861a38
02/08/2025 15:32:23:INFO:Received: train message 80e7f127-7821-479b-b695-fc0098861a38
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 15:36:22:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 16:15:37:INFO:
[92mINFO [0m:      Received: evaluate message c29c2188-400c-4817-8f87-e9ba8b1b3394
02/08/2025 16:15:37:INFO:Received: evaluate message c29c2188-400c-4817-8f87-e9ba8b1b3394

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934]}

Step 1b: Recomputing FIM for epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051]}

Step 1b: Recomputing FIM for epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 16:20:27:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 16:21:13:INFO:
[92mINFO [0m:      Received: train message 342b2fcb-63da-4487-90b1-97addac68324
02/08/2025 16:21:13:INFO:Received: train message 342b2fcb-63da-4487-90b1-97addac68324
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 16:25:09:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:03:28:INFO:
[92mINFO [0m:      Received: evaluate message 8053079f-ac0e-456f-9156-57e3867cb587
02/08/2025 17:03:28:INFO:Received: evaluate message 8053079f-ac0e-456f-9156-57e3867cb587
[92mINFO [0m:      Sent reply
02/08/2025 17:08:25:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:09:05:INFO:
[92mINFO [0m:      Received: train message 21178659-b906-4347-b67f-33758a0eb3a9
02/08/2025 17:09:05:INFO:Received: train message 21178659-b906-4347-b67f-33758a0eb3a9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 17:12:42:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:53:01:INFO:
[92mINFO [0m:      Received: evaluate message 0d8561e9-436b-4e60-bf1a-f554e1fba53a
02/08/2025 17:53:01:INFO:Received: evaluate message 0d8561e9-436b-4e60-bf1a-f554e1fba53a

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268]}

Step 1b: Recomputing FIM for epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499]}

Step 1b: Recomputing FIM for epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 17:58:01:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:58:44:INFO:
[92mINFO [0m:      Received: train message 6750f7f9-fc0c-4360-9fed-20c39f7e483d
02/08/2025 17:58:44:INFO:Received: train message 6750f7f9-fc0c-4360-9fed-20c39f7e483d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 18:02:52:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 18:42:25:INFO:
[92mINFO [0m:      Received: evaluate message 07cd53aa-04b1-44ad-be03-aab8ea5dbcef
02/08/2025 18:42:25:INFO:Received: evaluate message 07cd53aa-04b1-44ad-be03-aab8ea5dbcef
[92mINFO [0m:      Sent reply
02/08/2025 18:47:18:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 18:48:02:INFO:
[92mINFO [0m:      Received: train message 4348c597-f6e1-4800-9ad0-b809b4f397d7
02/08/2025 18:48:02:INFO:Received: train message 4348c597-f6e1-4800-9ad0-b809b4f397d7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 18:51:52:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 19:27:35:INFO:
[92mINFO [0m:      Received: evaluate message 0783ef53-8412-4619-8e5e-0333b5d02a00
02/08/2025 19:27:35:INFO:Received: evaluate message 0783ef53-8412-4619-8e5e-0333b5d02a00

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697, 1.2701550575211027], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748, 0.8990099129770881], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207, 0.6583154352356761], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499, 0.6458983891160318]}

Step 1b: Recomputing FIM for epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697, 1.2701550575211027, 1.2586158710144433], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748, 0.8990099129770881, 0.9004977288641947], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207, 0.6583154352356761, 0.6579979095347669], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499, 0.6458983891160318, 0.6490721132841767]}

Step 1b: Recomputing FIM for epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 351, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 19:31:58:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 19:31:59:INFO:
[92mINFO [0m:      Received: reconnect message c37ac470-3086-4d2b-a04c-be3f6d6a4ab5
02/08/2025 19:31:59:INFO:Received: reconnect message c37ac470-3086-4d2b-a04c-be3f6d6a4ab5
02/08/2025 19:31:59:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/08/2025 19:31:59:INFO:Disconnect and shut down

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697, 1.2701550575211027, 1.2586158710144433, 1.3398930698309126], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812, 0.6455900120821587], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748, 0.8990099129770881, 0.9004977288641947, 0.9001085710167956], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207, 0.6583154352356761, 0.6579979095347669, 0.6540454901821245], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812, 0.6455900120821587], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499, 0.6458983891160318, 0.6490721132841767, 0.6330882930625233]}



Final client history:
{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697, 1.2701550575211027, 1.2586158710144433, 1.3398930698309126], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812, 0.6455900120821587], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748, 0.8990099129770881, 0.9004977288641947, 0.9001085710167956], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207, 0.6583154352356761, 0.6579979095347669, 0.6540454901821245], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812, 0.6455900120821587], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499, 0.6458983891160318, 0.6490721132841767, 0.6330882930625233]}

