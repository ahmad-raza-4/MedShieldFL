nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=10.0/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
02/07/2025 20:09:26:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 20:09:26:DEBUG:ChannelConnectivity.IDLE
02/07/2025 20:09:26:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738987766.786987 1676477 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/07/2025 20:17:09:INFO:
[92mINFO [0m:      Received: train message 8c37c188-e47e-485a-b01b-dadfe395d8c3
02/07/2025 20:17:09:INFO:Received: train message 8c37c188-e47e-485a-b01b-dadfe395d8c3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 20:31:26:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 20:57:31:INFO:
[92mINFO [0m:      Received: evaluate message d57807d7-b5e9-4bb9-a051-9adc0f6d3547
02/07/2025 20:57:31:INFO:Received: evaluate message d57807d7-b5e9-4bb9-a051-9adc0f6d3547
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 21:02:00:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:02:25:INFO:
[92mINFO [0m:      Received: train message 2a965ceb-6bb5-4782-95e0-965bb43ccbfc
02/07/2025 21:02:25:INFO:Received: train message 2a965ceb-6bb5-4782-95e0-965bb43ccbfc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 21:15:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:42:40:INFO:
[92mINFO [0m:      Received: evaluate message 6994ee1d-5a95-4c87-a9f5-093fada5cfa1
02/07/2025 21:42:40:INFO:Received: evaluate message 6994ee1d-5a95-4c87-a9f5-093fada5cfa1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 21:47:13:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:48:10:INFO:
[92mINFO [0m:      Received: train message e1e002e6-049f-4bea-9cf7-e44e6119bbc8
02/07/2025 21:48:10:INFO:Received: train message e1e002e6-049f-4bea-9cf7-e44e6119bbc8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:01:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:26:21:INFO:
[92mINFO [0m:      Received: evaluate message d76d5bfb-f730-40d9-b052-fc76b427ba14
02/07/2025 22:26:21:INFO:Received: evaluate message d76d5bfb-f730-40d9-b052-fc76b427ba14
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 22:30:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:31:33:INFO:
[92mINFO [0m:      Received: train message 6448f316-b9f8-4785-a836-abfeee2378e8
02/07/2025 22:31:33:INFO:Received: train message 6448f316-b9f8-4785-a836-abfeee2378e8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:07:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 23:14:43:INFO:
[92mINFO [0m:      Received: evaluate message 8e3f080b-f720-4ec5-9929-fe4e0173e260
02/07/2025 23:14:43:INFO:Received: evaluate message 8e3f080b-f720-4ec5-9929-fe4e0173e260
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 23:18:41:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 23:19:55:INFO:
[92mINFO [0m:      Received: train message edfa5641-8d31-4caf-ab0c-248d0f852137
02/07/2025 23:19:55:INFO:Received: train message edfa5641-8d31-4caf-ab0c-248d0f852137
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 23:33:27:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:00:43:INFO:
[92mINFO [0m:      Received: evaluate message cbf57124-ad18-4704-b42f-80fce9d3b0e6
02/08/2025 00:00:43:INFO:Received: evaluate message cbf57124-ad18-4704-b42f-80fce9d3b0e6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/08/2025 00:05:00:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:05:40:INFO:
[92mINFO [0m:      Received: train message 05acd084-caef-43db-a369-ada78ea96efb
02/08/2025 00:05:40:INFO:Received: train message 05acd084-caef-43db-a369-ada78ea96efb
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 00:19:15:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:44:45:INFO:
[92mINFO [0m:      Received: evaluate message cc9c0e98-9aa8-4a7b-82a2-09b013f9024c
02/08/2025 00:44:45:INFO:Received: evaluate message cc9c0e98-9aa8-4a7b-82a2-09b013f9024c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/08/2025 00:49:08:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:49:52:INFO:
[92mINFO [0m:      Received: train message 2b897777-9d78-442b-a4e3-c94f671f123e
02/08/2025 00:49:52:INFO:Received: train message 2b897777-9d78-442b-a4e3-c94f671f123e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 01:04:04:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 01:30:29:INFO:
[92mINFO [0m:      Received: evaluate message c924fceb-d118-4bd2-9977-f6b4835dfe96
02/08/2025 01:30:29:INFO:Received: evaluate message c924fceb-d118-4bd2-9977-f6b4835dfe96
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=10.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=10.0']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 18597, num_classes: 8

Privacy Params:
 epsilon: 10.0, target_epsilon: 10.0, target_delta: 1e-05

Device: cuda:0

Step 1a: Client Initialized
Step 1b: Recomputing FIM for epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232], 'accuracy': [0.5553765606121627], 'auc': [0.7952128841995612], 'precision': [0.5630504832476843], 'recall': [0.5553765606121627], 'f1': [0.5014109976972659]}

Step 1b: Recomputing FIM for epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068], 'accuracy': [0.5553765606121627, 0.6004832863471606], 'auc': [0.7952128841995612, 0.8346505194429128], 'precision': [0.5630504832476843, 0.588172573519457], 'recall': [0.5553765606121627, 0.6004832863471606], 'f1': [0.5014109976972659, 0.559282479633486]}

Step 1b: Recomputing FIM for epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006]}

Step 1b: Recomputing FIM for epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696]}

Step 1b: Recomputing FIM for epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894]}

Step 1b: Recomputing FIM for epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595]}

Step 1b: Recomputing FIM for epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 01:34:52:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 01:35:29:INFO:
[92mINFO [0m:      Received: train message e9f741dd-bfd7-48ff-badd-35da3e92ffc1
02/08/2025 01:35:29:INFO:Received: train message e9f741dd-bfd7-48ff-badd-35da3e92ffc1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 01:49:53:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 02:16:52:INFO:
[92mINFO [0m:      Received: evaluate message 3be3204e-fabb-4d53-8c96-4bb1cd964adc
02/08/2025 02:16:52:INFO:Received: evaluate message 3be3204e-fabb-4d53-8c96-4bb1cd964adc
[92mINFO [0m:      Sent reply
02/08/2025 02:20:57:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 02:21:19:INFO:
[92mINFO [0m:      Received: train message dbbf9bd0-d518-4c67-896a-b828f3ce410b
02/08/2025 02:21:19:INFO:Received: train message dbbf9bd0-d518-4c67-896a-b828f3ce410b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 02:34:22:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:01:48:INFO:
[92mINFO [0m:      Received: evaluate message cce30cfc-af66-4521-905d-c4b64a259dba
02/08/2025 03:01:48:INFO:Received: evaluate message cce30cfc-af66-4521-905d-c4b64a259dba
[92mINFO [0m:      Sent reply
02/08/2025 03:05:57:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:06:40:INFO:
[92mINFO [0m:      Received: train message 2a3eca1e-6200-4e61-a584-8ccdd3e02845
02/08/2025 03:06:40:INFO:Received: train message 2a3eca1e-6200-4e61-a584-8ccdd3e02845
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 03:20:11:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:45:22:INFO:
[92mINFO [0m:      Received: evaluate message c71c371f-92d7-442a-94ba-e58168a099cf
02/08/2025 03:45:22:INFO:Received: evaluate message c71c371f-92d7-442a-94ba-e58168a099cf
[92mINFO [0m:      Sent reply
02/08/2025 03:49:25:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:50:14:INFO:
[92mINFO [0m:      Received: train message 993fe883-221b-4550-b126-81f14a1ea54c
02/08/2025 03:50:14:INFO:Received: train message 993fe883-221b-4550-b126-81f14a1ea54c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 04:03:42:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 04:32:40:INFO:
[92mINFO [0m:      Received: evaluate message 2038aeea-96dd-4a6d-88d7-d7db79da48e6
02/08/2025 04:32:40:INFO:Received: evaluate message 2038aeea-96dd-4a6d-88d7-d7db79da48e6
[92mINFO [0m:      Sent reply
02/08/2025 04:36:44:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 04:37:31:INFO:
[92mINFO [0m:      Received: train message 968c57fb-97af-43c4-83fd-42be19eae33b
02/08/2025 04:37:31:INFO:Received: train message 968c57fb-97af-43c4-83fd-42be19eae33b

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815]}

Step 1b: Recomputing FIM for epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657]}

Step 1b: Recomputing FIM for epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914]}

Step 1b: Recomputing FIM for epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116]}

Step 1b: Recomputing FIM for epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986]}

Step 1b: Recomputing FIM for epoch 12
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 04:49:55:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 05:20:59:INFO:
[92mINFO [0m:      Received: evaluate message 496bcaad-ac79-4912-a342-03d5733e3023
02/08/2025 05:20:59:INFO:Received: evaluate message 496bcaad-ac79-4912-a342-03d5733e3023
[92mINFO [0m:      Sent reply
02/08/2025 05:25:05:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 05:25:56:INFO:
[92mINFO [0m:      Received: train message ca54a008-1d85-453f-ab61-8f9c162cc094
02/08/2025 05:25:56:INFO:Received: train message ca54a008-1d85-453f-ab61-8f9c162cc094
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 05:38:52:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:05:46:INFO:
[92mINFO [0m:      Received: evaluate message 6b6fb8fe-df3d-4d48-9e65-49d6eeb65a15
02/08/2025 06:05:46:INFO:Received: evaluate message 6b6fb8fe-df3d-4d48-9e65-49d6eeb65a15
[92mINFO [0m:      Sent reply
02/08/2025 06:09:59:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:10:46:INFO:
[92mINFO [0m:      Received: train message 3442b6e8-1a31-4191-9ee2-14b5a7cc12ac
02/08/2025 06:10:46:INFO:Received: train message 3442b6e8-1a31-4191-9ee2-14b5a7cc12ac
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 06:23:34:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:52:00:INFO:
[92mINFO [0m:      Received: evaluate message 0eacfd45-65c5-4403-ac53-ad8fae19ef6c
02/08/2025 06:52:00:INFO:Received: evaluate message 0eacfd45-65c5-4403-ac53-ad8fae19ef6c
[92mINFO [0m:      Sent reply
02/08/2025 06:56:19:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:57:05:INFO:
[92mINFO [0m:      Received: train message 5756bc24-9288-487a-aa88-f393782f9b9c
02/08/2025 06:57:05:INFO:Received: train message 5756bc24-9288-487a-aa88-f393782f9b9c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 07:10:38:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 07:39:43:INFO:
[92mINFO [0m:      Received: evaluate message 0c3e0dec-aea0-4c1c-8990-862bbbb8a539
02/08/2025 07:39:43:INFO:Received: evaluate message 0c3e0dec-aea0-4c1c-8990-862bbbb8a539
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747]}

Step 1b: Recomputing FIM for epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504]}

Step 1b: Recomputing FIM for epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675]}

Step 1b: Recomputing FIM for epoch 15
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 07:43:37:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 07:44:25:INFO:
[92mINFO [0m:      Received: train message 3fde2afd-5d16-43c9-b59c-ade9c768fd25
02/08/2025 07:44:25:INFO:Received: train message 3fde2afd-5d16-43c9-b59c-ade9c768fd25
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 07:57:10:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 08:25:59:INFO:
[92mINFO [0m:      Received: evaluate message 21c59aea-0cbe-4cc1-945b-bf5c7f8cb1d2
02/08/2025 08:25:59:INFO:Received: evaluate message 21c59aea-0cbe-4cc1-945b-bf5c7f8cb1d2
[92mINFO [0m:      Sent reply
02/08/2025 08:30:15:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 08:30:50:INFO:
[92mINFO [0m:      Received: train message 15deea74-6b16-40fc-9491-ef382140c80f
02/08/2025 08:30:50:INFO:Received: train message 15deea74-6b16-40fc-9491-ef382140c80f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 08:43:44:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:09:58:INFO:
[92mINFO [0m:      Received: evaluate message aa5738a6-aa27-43f4-b89d-9a4ea02a61d8
02/08/2025 09:09:58:INFO:Received: evaluate message aa5738a6-aa27-43f4-b89d-9a4ea02a61d8
[92mINFO [0m:      Sent reply
02/08/2025 09:14:06:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:14:28:INFO:
[92mINFO [0m:      Received: train message be1a3652-3a88-4ff6-b65e-f90f4f2462c7
02/08/2025 09:14:28:INFO:Received: train message be1a3652-3a88-4ff6-b65e-f90f4f2462c7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 09:27:42:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:57:02:INFO:
[92mINFO [0m:      Received: evaluate message 141662a4-baae-4cf5-b46b-c8b57d6bff2f
02/08/2025 09:57:02:INFO:Received: evaluate message 141662a4-baae-4cf5-b46b-c8b57d6bff2f

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132]}

Step 1b: Recomputing FIM for epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951]}

Step 1b: Recomputing FIM for epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673]}

Step 1b: Recomputing FIM for epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 10:01:14:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:01:57:INFO:
[92mINFO [0m:      Received: train message fa9858fb-a74f-474c-a320-2b00f44eabad
02/08/2025 10:01:57:INFO:Received: train message fa9858fb-a74f-474c-a320-2b00f44eabad
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 10:14:59:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:45:04:INFO:
[92mINFO [0m:      Received: evaluate message 7e7cb950-b6f2-4a46-b4ba-347d607129f6
02/08/2025 10:45:04:INFO:Received: evaluate message 7e7cb950-b6f2-4a46-b4ba-347d607129f6
[92mINFO [0m:      Sent reply
02/08/2025 10:49:13:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:49:53:INFO:
[92mINFO [0m:      Received: train message 0746acfe-80dd-479a-a52d-ba1c5575de57
02/08/2025 10:49:53:INFO:Received: train message 0746acfe-80dd-479a-a52d-ba1c5575de57
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 11:02:44:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 11:29:50:INFO:
[92mINFO [0m:      Received: evaluate message a13d591c-2af9-4960-aefd-085b33bf245a
02/08/2025 11:29:50:INFO:Received: evaluate message a13d591c-2af9-4960-aefd-085b33bf245a

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372]}

Step 1b: Recomputing FIM for epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079]}

Step 1b: Recomputing FIM for epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 11:34:16:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 11:34:33:INFO:
[92mINFO [0m:      Received: train message 214afc72-7da8-4ab1-a19f-ecdb15171e76
02/08/2025 11:34:33:INFO:Received: train message 214afc72-7da8-4ab1-a19f-ecdb15171e76
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 11:48:31:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 12:15:01:INFO:
[92mINFO [0m:      Received: evaluate message e86c4b13-678b-498d-a1ad-5f02d4cc1a6c
02/08/2025 12:15:01:INFO:Received: evaluate message e86c4b13-678b-498d-a1ad-5f02d4cc1a6c
[92mINFO [0m:      Sent reply
02/08/2025 12:19:20:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 12:20:01:INFO:
[92mINFO [0m:      Received: train message 5c324935-53c1-438a-8925-7c01c6a92c28
02/08/2025 12:20:01:INFO:Received: train message 5c324935-53c1-438a-8925-7c01c6a92c28
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 12:33:35:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:02:42:INFO:
[92mINFO [0m:      Received: evaluate message 637f0e14-1716-4b69-9671-294bb72e4708
02/08/2025 13:02:42:INFO:Received: evaluate message 637f0e14-1716-4b69-9671-294bb72e4708

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863]}

Step 1b: Recomputing FIM for epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035]}

Step 1b: Recomputing FIM for epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 13:07:09:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:08:16:INFO:
[92mINFO [0m:      Received: train message c0c2f3cc-17d8-4d14-b44c-725cbc4728d4
02/08/2025 13:08:16:INFO:Received: train message c0c2f3cc-17d8-4d14-b44c-725cbc4728d4
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 13:21:07:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:51:45:INFO:
[92mINFO [0m:      Received: evaluate message e8cd1903-62ed-45dd-bd7e-84947e4dc6fc
02/08/2025 13:51:45:INFO:Received: evaluate message e8cd1903-62ed-45dd-bd7e-84947e4dc6fc
[92mINFO [0m:      Sent reply
02/08/2025 13:56:06:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:56:46:INFO:
[92mINFO [0m:      Received: train message f5581fc4-d854-4048-9b95-9b4a7f06cd13
02/08/2025 13:56:46:INFO:Received: train message f5581fc4-d854-4048-9b95-9b4a7f06cd13
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 14:10:02:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 14:39:32:INFO:
[92mINFO [0m:      Received: evaluate message a168363a-55a2-40b9-86ea-0954707eb21e
02/08/2025 14:39:32:INFO:Received: evaluate message a168363a-55a2-40b9-86ea-0954707eb21e

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596]}

Step 1b: Recomputing FIM for epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102]}

Step 1b: Recomputing FIM for epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 14:44:02:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 14:45:07:INFO:
[92mINFO [0m:      Received: train message ee29f298-3f4e-47cb-8669-47ef21f2fda0
02/08/2025 14:45:07:INFO:Received: train message ee29f298-3f4e-47cb-8669-47ef21f2fda0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 14:57:56:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 15:26:40:INFO:
[92mINFO [0m:      Received: evaluate message 61523db2-e1fd-46d6-81bc-1f0e064a491c
02/08/2025 15:26:40:INFO:Received: evaluate message 61523db2-e1fd-46d6-81bc-1f0e064a491c
[92mINFO [0m:      Sent reply
02/08/2025 15:30:59:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 15:32:29:INFO:
[92mINFO [0m:      Received: train message 49484790-bcab-41b0-8384-01cbc085334b
02/08/2025 15:32:29:INFO:Received: train message 49484790-bcab-41b0-8384-01cbc085334b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 15:45:21:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 16:15:07:INFO:
[92mINFO [0m:      Received: evaluate message 9251d24e-4d2a-46e4-85a2-54b08244b0b6
02/08/2025 16:15:07:INFO:Received: evaluate message 9251d24e-4d2a-46e4-85a2-54b08244b0b6

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934]}

Step 1b: Recomputing FIM for epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051]}

Step 1b: Recomputing FIM for epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 16:19:06:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 16:20:54:INFO:
[92mINFO [0m:      Received: train message abe8a3ec-11fa-4eaf-91ea-f60fd04d1494
02/08/2025 16:20:54:INFO:Received: train message abe8a3ec-11fa-4eaf-91ea-f60fd04d1494
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 16:33:46:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:03:39:INFO:
[92mINFO [0m:      Received: evaluate message 47d3cf75-e186-4362-a761-37ed3a0fa2a7
02/08/2025 17:03:39:INFO:Received: evaluate message 47d3cf75-e186-4362-a761-37ed3a0fa2a7
[92mINFO [0m:      Sent reply
02/08/2025 17:08:02:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:09:23:INFO:
[92mINFO [0m:      Received: train message eddcfba0-dbd5-4a5b-8cff-167ca266a695
02/08/2025 17:09:23:INFO:Received: train message eddcfba0-dbd5-4a5b-8cff-167ca266a695
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 17:22:10:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:53:20:INFO:
[92mINFO [0m:      Received: evaluate message 10503799-4ba7-4712-8974-cd80943ea486
02/08/2025 17:53:20:INFO:Received: evaluate message 10503799-4ba7-4712-8974-cd80943ea486

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268]}

Step 1b: Recomputing FIM for epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499]}

Step 1b: Recomputing FIM for epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 17:57:53:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:58:41:INFO:
[92mINFO [0m:      Received: train message a8f3ec8e-8e8e-4e88-bbe0-6b79d2147117
02/08/2025 17:58:41:INFO:Received: train message a8f3ec8e-8e8e-4e88-bbe0-6b79d2147117
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 18:11:21:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 18:42:05:INFO:
[92mINFO [0m:      Received: evaluate message f2120bb6-613b-4483-9626-8f0de4f54e15
02/08/2025 18:42:05:INFO:Received: evaluate message f2120bb6-613b-4483-9626-8f0de4f54e15
[92mINFO [0m:      Sent reply
02/08/2025 18:46:26:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 18:47:57:INFO:
[92mINFO [0m:      Received: train message ff07b5ee-2c71-422b-a00f-b0a81281b6a1
02/08/2025 18:47:57:INFO:Received: train message ff07b5ee-2c71-422b-a00f-b0a81281b6a1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 19:00:40:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 19:27:11:INFO:
[92mINFO [0m:      Received: evaluate message 81fec461-3426-4b61-a6ea-0ddc7d83aaf1
02/08/2025 19:27:11:INFO:Received: evaluate message 81fec461-3426-4b61-a6ea-0ddc7d83aaf1

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697, 1.2701550575211027], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748, 0.8990099129770881], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207, 0.6583154352356761], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499, 0.6458983891160318]}

Step 1b: Recomputing FIM for epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697, 1.2701550575211027, 1.2586158710144433], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748, 0.8990099129770881, 0.9004977288641947], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207, 0.6583154352356761, 0.6579979095347669], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499, 0.6458983891160318, 0.6490721132841767]}

Step 1b: Recomputing FIM for epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1807, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 19:30:36:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 19:31:59:INFO:
[92mINFO [0m:      Received: reconnect message 430018a5-218c-4370-b9d4-3236d427c484
02/08/2025 19:31:59:INFO:Received: reconnect message 430018a5-218c-4370-b9d4-3236d427c484
02/08/2025 19:31:59:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/08/2025 19:31:59:INFO:Disconnect and shut down
