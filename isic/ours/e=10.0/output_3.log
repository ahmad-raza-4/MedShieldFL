nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=10.0/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
02/07/2025 20:10:47:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 20:10:47:DEBUG:ChannelConnectivity.IDLE
02/07/2025 20:10:47:DEBUG:ChannelConnectivity.CONNECTING
02/07/2025 20:10:47:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738987847.325590 1677264 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/07/2025 20:17:04:INFO:
[92mINFO [0m:      Received: train message 8c1789d2-4dd4-4316-a439-6311144579aa
02/07/2025 20:17:04:INFO:Received: train message 8c1789d2-4dd4-4316-a439-6311144579aa
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 20:36:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 20:57:27:INFO:
[92mINFO [0m:      Received: evaluate message a6310843-28e2-4657-8440-60cf3b91407f
02/07/2025 20:57:27:INFO:Received: evaluate message a6310843-28e2-4657-8440-60cf3b91407f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 21:01:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:02:28:INFO:
[92mINFO [0m:      Received: train message 92ff44d4-5158-433b-a967-021a3a6b840d
02/07/2025 21:02:28:INFO:Received: train message 92ff44d4-5158-433b-a967-021a3a6b840d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 21:20:31:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:42:40:INFO:
[92mINFO [0m:      Received: evaluate message fd24f195-4745-4a33-bb18-8d3cd7b406db
02/07/2025 21:42:40:INFO:Received: evaluate message fd24f195-4745-4a33-bb18-8d3cd7b406db
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 21:47:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 21:48:10:INFO:
[92mINFO [0m:      Received: train message 2b0d154c-671c-4952-8d6f-43334f0281fc
02/07/2025 21:48:10:INFO:Received: train message 2b0d154c-671c-4952-8d6f-43334f0281fc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:06:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:26:22:INFO:
[92mINFO [0m:      Received: evaluate message 08d7eff5-1665-47b2-b9d7-c3e82ecf0964
02/07/2025 22:26:22:INFO:Received: evaluate message 08d7eff5-1665-47b2-b9d7-c3e82ecf0964
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 22:30:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:31:37:INFO:
[92mINFO [0m:      Received: train message 166a2bc3-2da5-4deb-9310-b739688ce50c
02/07/2025 22:31:37:INFO:Received: train message 166a2bc3-2da5-4deb-9310-b739688ce50c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:36:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 23:14:56:INFO:
[92mINFO [0m:      Received: evaluate message 384ed52c-74e2-471a-b883-ff4d22c80d15
02/07/2025 23:14:56:INFO:Received: evaluate message 384ed52c-74e2-471a-b883-ff4d22c80d15
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/07/2025 23:19:15:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 23:19:40:INFO:
[92mINFO [0m:      Received: train message 27537bc5-3ba7-4874-a1f2-bb05bf51ccfb
02/07/2025 23:19:40:INFO:Received: train message 27537bc5-3ba7-4874-a1f2-bb05bf51ccfb
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 23:38:06:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:00:44:INFO:
[92mINFO [0m:      Received: evaluate message 9fdc5165-f2cb-422b-9a2f-cff663e31811
02/08/2025 00:00:44:INFO:Received: evaluate message 9fdc5165-f2cb-422b-9a2f-cff663e31811
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/08/2025 00:05:02:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:05:34:INFO:
[92mINFO [0m:      Received: train message 229a69e1-f057-49dd-8f49-c4f40e23c1a9
02/08/2025 00:05:34:INFO:Received: train message 229a69e1-f057-49dd-8f49-c4f40e23c1a9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 00:23:29:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:44:41:INFO:
[92mINFO [0m:      Received: evaluate message fc7269c2-f2d3-42f1-ab32-1d0f74c945d9
02/08/2025 00:44:41:INFO:Received: evaluate message fc7269c2-f2d3-42f1-ab32-1d0f74c945d9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[92mINFO [0m:      Sent reply
02/08/2025 00:49:09:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 00:49:56:INFO:
[92mINFO [0m:      Received: train message c873359a-3c42-46cb-abae-6aef1ff3a745
02/08/2025 00:49:56:INFO:Received: train message c873359a-3c42-46cb-abae-6aef1ff3a745
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 01:08:59:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 01:30:24:INFO:
[92mINFO [0m:      Received: evaluate message dd8bb0ba-cb56-4686-be1b-7f0805b3c56e
02/08/2025 01:30:24:INFO:Received: evaluate message dd8bb0ba-cb56-4686-be1b-7f0805b3c56e
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=10.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/ours/e=10.0']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 18597, num_classes: 8

Privacy Params:
 epsilon: 10.0, target_epsilon: 10.0, target_delta: 1e-05

Device: cuda:0

Step 1a: Client Initialized
Step 1b: Recomputing FIM for epoch 1
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232], 'accuracy': [0.5553765606121627], 'auc': [0.7952128841995612], 'precision': [0.5630504832476843], 'recall': [0.5553765606121627], 'f1': [0.5014109976972659]}

Step 1b: Recomputing FIM for epoch 2
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068], 'accuracy': [0.5553765606121627, 0.6004832863471606], 'auc': [0.7952128841995612, 0.8346505194429128], 'precision': [0.5630504832476843, 0.588172573519457], 'recall': [0.5553765606121627, 0.6004832863471606], 'f1': [0.5014109976972659, 0.559282479633486]}

Step 1b: Recomputing FIM for epoch 3
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006]}

Step 1b: Recomputing FIM for epoch 4
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696]}

Step 1b: Recomputing FIM for epoch 5
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894]}

Step 1b: Recomputing FIM for epoch 6
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595]}

Step 1b: Recomputing FIM for epoch 7
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 01:34:50:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 01:35:20:INFO:
[92mINFO [0m:      Received: train message d3dab8d6-715f-4c35-8ead-d29f4287b5fe
02/08/2025 01:35:20:INFO:Received: train message d3dab8d6-715f-4c35-8ead-d29f4287b5fe
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 01:55:08:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 02:16:52:INFO:
[92mINFO [0m:      Received: evaluate message 5923d8e2-be3f-46da-80b1-9c718ae9553e
02/08/2025 02:16:52:INFO:Received: evaluate message 5923d8e2-be3f-46da-80b1-9c718ae9553e
[92mINFO [0m:      Sent reply
02/08/2025 02:20:58:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 02:21:26:INFO:
[92mINFO [0m:      Received: train message 5ef4726d-37f9-45f3-a3c7-90a7609c0768
02/08/2025 02:21:26:INFO:Received: train message 5ef4726d-37f9-45f3-a3c7-90a7609c0768
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 02:39:39:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:01:48:INFO:
[92mINFO [0m:      Received: evaluate message f75a9518-757e-4df4-b4ea-57ccb5670d9d
02/08/2025 03:01:48:INFO:Received: evaluate message f75a9518-757e-4df4-b4ea-57ccb5670d9d
[92mINFO [0m:      Sent reply
02/08/2025 03:05:59:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:06:39:INFO:
[92mINFO [0m:      Received: train message 0e5bf08d-11cd-4308-8a37-7795f968ba29
02/08/2025 03:06:39:INFO:Received: train message 0e5bf08d-11cd-4308-8a37-7795f968ba29
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 03:25:21:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:45:24:INFO:
[92mINFO [0m:      Received: evaluate message 0043754f-e9c8-4a56-ae7c-c46ce1937f61
02/08/2025 03:45:24:INFO:Received: evaluate message 0043754f-e9c8-4a56-ae7c-c46ce1937f61
[92mINFO [0m:      Sent reply
02/08/2025 03:49:32:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 03:50:03:INFO:
[92mINFO [0m:      Received: train message 2da7da7e-b3ba-48eb-806f-f21d0d4da390
02/08/2025 03:50:03:INFO:Received: train message 2da7da7e-b3ba-48eb-806f-f21d0d4da390
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 04:10:07:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 04:32:50:INFO:
[92mINFO [0m:      Received: evaluate message dc468e09-1df4-467d-8271-01ac348a58d0
02/08/2025 04:32:50:INFO:Received: evaluate message dc468e09-1df4-467d-8271-01ac348a58d0
[92mINFO [0m:      Sent reply
02/08/2025 04:37:09:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 04:37:41:INFO:
[92mINFO [0m:      Received: train message a59c3aaf-5b6f-41dc-845c-c68ed07f9f6e
02/08/2025 04:37:41:INFO:Received: train message a59c3aaf-5b6f-41dc-845c-c68ed07f9f6e

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815]}

Step 1b: Recomputing FIM for epoch 8
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657]}

Step 1b: Recomputing FIM for epoch 9
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914]}

Step 1b: Recomputing FIM for epoch 10
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116]}

Step 1b: Recomputing FIM for epoch 11
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986]}

Step 1b: Recomputing FIM for epoch 12
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 04:56:12:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 05:21:08:INFO:
[92mINFO [0m:      Received: evaluate message 2b8fec17-ecce-46f8-80af-35d642b0270b
02/08/2025 05:21:08:INFO:Received: evaluate message 2b8fec17-ecce-46f8-80af-35d642b0270b
[92mINFO [0m:      Sent reply
02/08/2025 05:25:19:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 05:25:47:INFO:
[92mINFO [0m:      Received: train message 8de3ad07-7425-459b-a82a-6bae082a5315
02/08/2025 05:25:47:INFO:Received: train message 8de3ad07-7425-459b-a82a-6bae082a5315
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 05:43:55:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:05:46:INFO:
[92mINFO [0m:      Received: evaluate message 179f4f5e-cba7-4461-8d0a-69241aae3d6b
02/08/2025 06:05:46:INFO:Received: evaluate message 179f4f5e-cba7-4461-8d0a-69241aae3d6b
[92mINFO [0m:      Sent reply
02/08/2025 06:10:24:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:10:59:INFO:
[92mINFO [0m:      Received: train message e2788d6a-b704-4334-ac43-9d4d1d0cc7ae
02/08/2025 06:10:59:INFO:Received: train message e2788d6a-b704-4334-ac43-9d4d1d0cc7ae
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 06:30:36:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:52:07:INFO:
[92mINFO [0m:      Received: evaluate message d06c0b7b-5b20-4f6f-a44c-cf74ba60d089
02/08/2025 06:52:07:INFO:Received: evaluate message d06c0b7b-5b20-4f6f-a44c-cf74ba60d089
[92mINFO [0m:      Sent reply
02/08/2025 06:56:24:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 06:57:01:INFO:
[92mINFO [0m:      Received: train message 47efa640-22cd-471f-87d0-1017286b3e79
02/08/2025 06:57:01:INFO:Received: train message 47efa640-22cd-471f-87d0-1017286b3e79
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 07:17:03:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 07:39:45:INFO:
[92mINFO [0m:      Received: evaluate message 67355a89-6361-461d-a8bd-be8c2ee9ed20
02/08/2025 07:39:45:INFO:Received: evaluate message 67355a89-6361-461d-a8bd-be8c2ee9ed20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747]}

Step 1b: Recomputing FIM for epoch 13
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504]}

Step 1b: Recomputing FIM for epoch 14
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675]}

Step 1b: Recomputing FIM for epoch 15
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 07:43:48:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 07:44:39:INFO:
[92mINFO [0m:      Received: train message 95db3f72-26a5-4686-b233-860c79790edc
02/08/2025 07:44:39:INFO:Received: train message 95db3f72-26a5-4686-b233-860c79790edc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 08:03:21:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 08:26:12:INFO:
[92mINFO [0m:      Received: evaluate message e9b9d642-b25f-4ceb-afd9-59f5cc6bb621
02/08/2025 08:26:12:INFO:Received: evaluate message e9b9d642-b25f-4ceb-afd9-59f5cc6bb621
[92mINFO [0m:      Sent reply
02/08/2025 08:30:32:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 08:31:08:INFO:
[92mINFO [0m:      Received: train message 492a67b8-f676-4408-b5b0-581d483e2d07
02/08/2025 08:31:08:INFO:Received: train message 492a67b8-f676-4408-b5b0-581d483e2d07
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 08:49:36:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:10:04:INFO:
[92mINFO [0m:      Received: evaluate message a431ca71-c530-4fc9-b491-a9428f5fda2a
02/08/2025 09:10:04:INFO:Received: evaluate message a431ca71-c530-4fc9-b491-a9428f5fda2a
[92mINFO [0m:      Sent reply
02/08/2025 09:14:13:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:14:49:INFO:
[92mINFO [0m:      Received: train message e2e4a6d4-71bc-4de8-99f6-f0799d850fdd
02/08/2025 09:14:49:INFO:Received: train message e2e4a6d4-71bc-4de8-99f6-f0799d850fdd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 09:35:01:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 09:57:02:INFO:
[92mINFO [0m:      Received: evaluate message 32a0a9c3-a8f5-4aae-a0c5-687da20f6193
02/08/2025 09:57:02:INFO:Received: evaluate message 32a0a9c3-a8f5-4aae-a0c5-687da20f6193

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132]}

Step 1b: Recomputing FIM for epoch 16
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951]}

Step 1b: Recomputing FIM for epoch 17
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673]}

Step 1b: Recomputing FIM for epoch 18
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 10:01:19:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:01:52:INFO:
[92mINFO [0m:      Received: train message adbe325d-8d3d-4021-ba9d-4bf6f87c5d57
02/08/2025 10:01:52:INFO:Received: train message adbe325d-8d3d-4021-ba9d-4bf6f87c5d57
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 10:20:00:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:44:52:INFO:
[92mINFO [0m:      Received: evaluate message b9fc63ee-5f67-459a-aa59-79a49c1de37b
02/08/2025 10:44:52:INFO:Received: evaluate message b9fc63ee-5f67-459a-aa59-79a49c1de37b
[92mINFO [0m:      Sent reply
02/08/2025 10:49:11:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 10:49:53:INFO:
[92mINFO [0m:      Received: train message a597e4e6-792a-4376-9d65-1d0298210609
02/08/2025 10:49:53:INFO:Received: train message a597e4e6-792a-4376-9d65-1d0298210609
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 11:08:19:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 11:29:51:INFO:
[92mINFO [0m:      Received: evaluate message df7a38f3-e706-4ffd-a54e-a523ee70cf25
02/08/2025 11:29:51:INFO:Received: evaluate message df7a38f3-e706-4ffd-a54e-a523ee70cf25

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372]}

Step 1b: Recomputing FIM for epoch 19
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079]}

Step 1b: Recomputing FIM for epoch 20
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 11:34:17:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 11:34:28:INFO:
[92mINFO [0m:      Received: train message 40898113-240f-412f-aced-de0c2157e386
02/08/2025 11:34:28:INFO:Received: train message 40898113-240f-412f-aced-de0c2157e386
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 11:54:13:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 12:15:03:INFO:
[92mINFO [0m:      Received: evaluate message d25d5af6-849e-4903-b43e-7aab08a44e98
02/08/2025 12:15:03:INFO:Received: evaluate message d25d5af6-849e-4903-b43e-7aab08a44e98
[92mINFO [0m:      Sent reply
02/08/2025 12:19:22:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 12:20:01:INFO:
[92mINFO [0m:      Received: train message 48322bd6-2734-4c55-b9ac-cc000aa918bf
02/08/2025 12:20:01:INFO:Received: train message 48322bd6-2734-4c55-b9ac-cc000aa918bf
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 12:40:10:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:03:02:INFO:
[92mINFO [0m:      Received: evaluate message e09e33b6-1927-4768-a77e-eff567ea2f5a
02/08/2025 13:03:02:INFO:Received: evaluate message e09e33b6-1927-4768-a77e-eff567ea2f5a

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863]}

Step 1b: Recomputing FIM for epoch 21
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035]}

Step 1b: Recomputing FIM for epoch 22
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 13:07:40:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:08:21:INFO:
[92mINFO [0m:      Received: train message bd1ccdf3-98dd-4932-9585-20ff813c9dcc
02/08/2025 13:08:21:INFO:Received: train message bd1ccdf3-98dd-4932-9585-20ff813c9dcc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 13:26:51:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:51:10:INFO:
[92mINFO [0m:      Received: evaluate message fd74f4fa-f5a1-4887-85c9-d46cf1d987bc
02/08/2025 13:51:10:INFO:Received: evaluate message fd74f4fa-f5a1-4887-85c9-d46cf1d987bc
[92mINFO [0m:      Sent reply
02/08/2025 13:55:58:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 13:56:54:INFO:
[92mINFO [0m:      Received: train message 6ad108d7-607f-4287-b59c-7c8ce904d79e
02/08/2025 13:56:54:INFO:Received: train message 6ad108d7-607f-4287-b59c-7c8ce904d79e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 14:15:12:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 14:39:19:INFO:
[92mINFO [0m:      Received: evaluate message 50f5083e-d6d5-428b-a709-495fb1613ed3
02/08/2025 14:39:19:INFO:Received: evaluate message 50f5083e-d6d5-428b-a709-495fb1613ed3

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596]}

Step 1b: Recomputing FIM for epoch 23
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102]}

Step 1b: Recomputing FIM for epoch 24
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 14:44:12:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 14:45:11:INFO:
[92mINFO [0m:      Received: train message 6fb2bf57-9951-45fe-adbf-3d886a340f3e
02/08/2025 14:45:11:INFO:Received: train message 6fb2bf57-9951-45fe-adbf-3d886a340f3e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 15:03:13:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 15:26:31:INFO:
[92mINFO [0m:      Received: evaluate message a3d8415b-9135-4c56-bf48-e6b0b46f14f4
02/08/2025 15:26:31:INFO:Received: evaluate message a3d8415b-9135-4c56-bf48-e6b0b46f14f4
[92mINFO [0m:      Sent reply
02/08/2025 15:31:35:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 15:32:23:INFO:
[92mINFO [0m:      Received: train message 78268ea2-4f78-4bfe-aaea-68e65dde1b04
02/08/2025 15:32:23:INFO:Received: train message 78268ea2-4f78-4bfe-aaea-68e65dde1b04
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 15:50:45:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 16:15:37:INFO:
[92mINFO [0m:      Received: evaluate message 5ce26d23-1221-4eb1-967a-80597efa2c18
02/08/2025 16:15:37:INFO:Received: evaluate message 5ce26d23-1221-4eb1-967a-80597efa2c18

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934]}

Step 1b: Recomputing FIM for epoch 25
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051]}

Step 1b: Recomputing FIM for epoch 26
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 16:20:26:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 16:21:01:INFO:
[92mINFO [0m:      Received: train message 193c3320-e383-4d8a-8c7f-2901119c215d
02/08/2025 16:21:01:INFO:Received: train message 193c3320-e383-4d8a-8c7f-2901119c215d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 16:38:47:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:03:50:INFO:
[92mINFO [0m:      Received: evaluate message 200d3e75-9838-4e0f-899e-2b9e47765241
02/08/2025 17:03:50:INFO:Received: evaluate message 200d3e75-9838-4e0f-899e-2b9e47765241
[92mINFO [0m:      Sent reply
02/08/2025 17:08:42:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:09:20:INFO:
[92mINFO [0m:      Received: train message 9c066cad-9268-4b3c-863a-c3020c2d3e34
02/08/2025 17:09:20:INFO:Received: train message 9c066cad-9268-4b3c-863a-c3020c2d3e34
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 17:27:06:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:53:09:INFO:
[92mINFO [0m:      Received: evaluate message 7a20aff6-1a9e-4f35-8c4e-d64903f2ee4c
02/08/2025 17:53:09:INFO:Received: evaluate message 7a20aff6-1a9e-4f35-8c4e-d64903f2ee4c

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268]}

Step 1b: Recomputing FIM for epoch 27
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499]}

Step 1b: Recomputing FIM for epoch 28
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 17:58:07:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 17:58:48:INFO:
[92mINFO [0m:      Received: train message 5cfda780-28e1-44f7-94b9-1d503d714ed9
02/08/2025 17:58:48:INFO:Received: train message 5cfda780-28e1-44f7-94b9-1d503d714ed9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 18:16:23:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 18:42:10:INFO:
[92mINFO [0m:      Received: evaluate message d0340782-9895-4f3e-9b7b-1d78deecc4fc
02/08/2025 18:42:10:INFO:Received: evaluate message d0340782-9895-4f3e-9b7b-1d78deecc4fc
[92mINFO [0m:      Sent reply
02/08/2025 18:47:09:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 18:47:58:INFO:
[92mINFO [0m:      Received: train message 89b19d4f-ef82-437a-a7d2-3a5ed340f1ea
02/08/2025 18:47:58:INFO:Received: train message 89b19d4f-ef82-437a-a7d2-3a5ed340f1ea
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/08/2025 19:05:25:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 19:27:29:INFO:
[92mINFO [0m:      Received: evaluate message baff38a9-cf08-418a-99ec-e07a218b5219
02/08/2025 19:27:29:INFO:Received: evaluate message baff38a9-cf08-418a-99ec-e07a218b5219

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697, 1.2701550575211027], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748, 0.8990099129770881], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207, 0.6583154352356761], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499, 0.6458983891160318]}

Step 1b: Recomputing FIM for epoch 29
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697, 1.2701550575211027, 1.2586158710144433], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748, 0.8990099129770881, 0.9004977288641947], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207, 0.6583154352356761, 0.6579979095347669], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499, 0.6458983891160318, 0.6490721132841767]}

Step 1b: Recomputing FIM for epoch 30
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 2691, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
02/08/2025 19:31:50:INFO:Sent reply
[92mINFO [0m:      
02/08/2025 19:31:59:INFO:
[92mINFO [0m:      Received: reconnect message 9c35074c-758a-49ff-93ff-4503034c157c
02/08/2025 19:31:59:INFO:Received: reconnect message 9c35074c-758a-49ff-93ff-4503034c157c
02/08/2025 19:31:59:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/08/2025 19:31:59:INFO:Disconnect and shut down

{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697, 1.2701550575211027, 1.2586158710144433, 1.3398930698309126], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812, 0.6455900120821587], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748, 0.8990099129770881, 0.9004977288641947, 0.9001085710167956], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207, 0.6583154352356761, 0.6579979095347669, 0.6540454901821245], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812, 0.6455900120821587], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499, 0.6458983891160318, 0.6490721132841767, 0.6330882930625233]}



Final client history:
{'loss': [1.4341865640660232, 1.3278700841851068, 1.3695796489523535, 1.342881513467682, 1.3157564302725606, 1.3268978310553143, 1.3512491694487634, 1.31799615891384, 1.335788213769803, 1.3390306717582254, 1.3095185295785572, 1.304992672708598, 1.3292212398408452, 1.3222316344371017, 1.3027529884767397, 1.3187947198358505, 1.2865643985464454, 1.282628777931642, 1.2753643221400026, 1.288350668301085, 1.285291568314986, 1.298678616506651, 1.296516762113936, 1.3280433489582109, 1.307151519239213, 1.310995662039535, 1.264396644987697, 1.2701550575211027, 1.2586158710144433, 1.3398930698309126], 'accuracy': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812, 0.6455900120821587], 'auc': [0.7952128841995612, 0.8346505194429128, 0.8468441987990782, 0.8583597319477125, 0.8617931561932564, 0.8640858292676156, 0.8667492739261751, 0.8712091508108861, 0.8736215597217655, 0.8753301910581146, 0.8787145521687414, 0.882201747474201, 0.8812664892747069, 0.883909522960755, 0.8848483268866959, 0.8856810268106924, 0.886416361504327, 0.8870566670104403, 0.8876330416517124, 0.8889823366780979, 0.8896010307279275, 0.8904494497573925, 0.8915276688145444, 0.8920644830300674, 0.8937551436187718, 0.8949018310594852, 0.898103397330748, 0.8990099129770881, 0.9004977288641947, 0.9001085710167956], 'precision': [0.5630504832476843, 0.588172573519457, 0.6085488469660614, 0.6117725102754475, 0.6055459689475594, 0.6070590404441935, 0.619290541861942, 0.6249222310080221, 0.6287182135820377, 0.6261179834108211, 0.6271574912917494, 0.6490016637707274, 0.64344157383758, 0.6413825884603398, 0.6461429199246976, 0.6371906649904521, 0.6394345387110894, 0.6427513067497419, 0.640485194964392, 0.6378509635129688, 0.651810234487161, 0.6475338196630815, 0.6421394068320244, 0.6447551062442161, 0.6496039439722313, 0.6584166731871604, 0.6631704669167207, 0.6583154352356761, 0.6579979095347669, 0.6540454901821245], 'recall': [0.5553765606121627, 0.6004832863471606, 0.6073298429319371, 0.6242448650825614, 0.6250503423278292, 0.6294804671768023, 0.6322996375352397, 0.6415626258558196, 0.6391461941200162, 0.6359242851389448, 0.6419653644784535, 0.6476037051953283, 0.6451872734595248, 0.644381796214257, 0.6463954893274265, 0.6435763189689891, 0.643979057591623, 0.6488119210632299, 0.6484091824405961, 0.6500201369311317, 0.6512283527990335, 0.6476037051953283, 0.6516310914216673, 0.6472009665726943, 0.6492146596858639, 0.6524365686669351, 0.657269432138542, 0.657269432138542, 0.6612968183648812, 0.6455900120821587], 'f1': [0.5014109976972659, 0.559282479633486, 0.5687876854052006, 0.5881840652338696, 0.5911347625336894, 0.5953735250780595, 0.6009719733892815, 0.6148915310497657, 0.6111155202136914, 0.6107630100981116, 0.6165766754508986, 0.6252281878793747, 0.6220516268312504, 0.6239670774238675, 0.6253015036018132, 0.6226410102278951, 0.6274442905717673, 0.6306460583809372, 0.6324613158643079, 0.6319901358287863, 0.6368903606532035, 0.6308434079905596, 0.6309898982818102, 0.6288858572714934, 0.6345255824333051, 0.6380738299672268, 0.6435018680920499, 0.6458983891160318, 0.6490721132841767, 0.6330882930625233]}

