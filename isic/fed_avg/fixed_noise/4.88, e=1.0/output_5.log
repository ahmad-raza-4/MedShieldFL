nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/fixed_noise/4.88, e=1.0/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
02/06/2025 10:10:38:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/06/2025 10:10:38:DEBUG:ChannelConnectivity.IDLE
02/06/2025 10:10:38:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738865438.401907  629483 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/06/2025 10:11:19:INFO:
[92mINFO [0m:      Received: train message e35e3453-73e7-479a-8687-060db7218ebe
02/06/2025 10:11:19:INFO:Received: train message e35e3453-73e7-479a-8687-060db7218ebe
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 10:16:11:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 10:52:16:INFO:
[92mINFO [0m:      Received: evaluate message e24d1067-0c01-4b9c-828c-6c8d3b4628b3
02/06/2025 10:52:16:INFO:Received: evaluate message e24d1067-0c01-4b9c-828c-6c8d3b4628b3
[92mINFO [0m:      Sent reply
02/06/2025 10:57:39:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 10:58:51:INFO:
[92mINFO [0m:      Received: train message 07863c2e-3bcc-4e20-9755-447568681333
02/06/2025 10:58:51:INFO:Received: train message 07863c2e-3bcc-4e20-9755-447568681333
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 11:04:18:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:38:31:INFO:
[92mINFO [0m:      Received: evaluate message 5011e552-a9a7-44b0-a905-750baae788b5
02/06/2025 11:38:31:INFO:Received: evaluate message 5011e552-a9a7-44b0-a905-750baae788b5
[92mINFO [0m:      Sent reply
02/06/2025 11:44:27:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:45:08:INFO:
[92mINFO [0m:      Received: train message e0b1d1c3-f5b4-4d68-88fb-a1c9a58d32dd
02/06/2025 11:45:08:INFO:Received: train message e0b1d1c3-f5b4-4d68-88fb-a1c9a58d32dd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 11:50:15:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 12:28:49:INFO:
[92mINFO [0m:      Received: evaluate message 27c8cc69-0434-4f6a-a8a0-5eda5050478a
02/06/2025 12:28:49:INFO:Received: evaluate message 27c8cc69-0434-4f6a-a8a0-5eda5050478a
[92mINFO [0m:      Sent reply
02/06/2025 12:34:14:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 12:35:02:INFO:
[92mINFO [0m:      Received: train message 8e12746f-1a9a-480f-93a5-1f9253fc3228
02/06/2025 12:35:02:INFO:Received: train message 8e12746f-1a9a-480f-93a5-1f9253fc3228
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 12:40:04:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 13:17:07:INFO:
[92mINFO [0m:      Received: evaluate message f04b3f19-7e94-42d2-a657-8d1eef420939
02/06/2025 13:17:07:INFO:Received: evaluate message f04b3f19-7e94-42d2-a657-8d1eef420939
[92mINFO [0m:      Sent reply
02/06/2025 13:22:31:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 13:23:11:INFO:
[92mINFO [0m:      Received: train message 40761131-25c1-41c0-b6de-9110441fc167
02/06/2025 13:23:11:INFO:Received: train message 40761131-25c1-41c0-b6de-9110441fc167
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 13:28:07:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 14:03:29:INFO:
[92mINFO [0m:      Received: evaluate message c4aacaf4-3c94-493b-8877-c80794dae5c8
02/06/2025 14:03:29:INFO:Received: evaluate message c4aacaf4-3c94-493b-8877-c80794dae5c8
[92mINFO [0m:      Sent reply
02/06/2025 14:09:05:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 14:10:12:INFO:
[92mINFO [0m:      Received: train message bd556562-eca8-4ad8-bc54-b22665e6d871
02/06/2025 14:10:12:INFO:Received: train message bd556562-eca8-4ad8-bc54-b22665e6d871
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 14:15:34:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 14:51:55:INFO:
[92mINFO [0m:      Received: evaluate message 268c4727-044e-4974-b5de-c73df19b423c
02/06/2025 14:51:55:INFO:Received: evaluate message 268c4727-044e-4974-b5de-c73df19b423c
[92mINFO [0m:      Sent reply
02/06/2025 14:57:13:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 14:57:47:INFO:
[92mINFO [0m:      Received: train message c80d5029-d641-471d-9489-b6c0dc96d52c
02/06/2025 14:57:47:INFO:Received: train message c80d5029-d641-471d-9489-b6c0dc96d52c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 15:02:58:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 15:41:21:INFO:
[92mINFO [0m:      Received: evaluate message 46cf7978-78c4-4d36-b58f-e52538ce1c5e
02/06/2025 15:41:21:INFO:Received: evaluate message 46cf7978-78c4-4d36-b58f-e52538ce1c5e
[92mINFO [0m:      Sent reply
02/06/2025 15:46:24:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 15:46:59:INFO:
[92mINFO [0m:      Received: train message 141f1c4d-c17d-450e-83bc-ead7448a1672
02/06/2025 15:46:59:INFO:Received: train message 141f1c4d-c17d-450e-83bc-ead7448a1672
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 15:52:11:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 16:29:37:INFO:
[92mINFO [0m:      Received: evaluate message c3f7e619-e845-4746-85ef-88f5be1b923d
02/06/2025 16:29:37:INFO:Received: evaluate message c3f7e619-e845-4746-85ef-88f5be1b923d
[92mINFO [0m:      Sent reply
02/06/2025 16:34:47:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 16:35:29:INFO:
[92mINFO [0m:      Received: train message 7781cfdf-647d-458f-b739-c1a65b5b26a6
02/06/2025 16:35:29:INFO:Received: train message 7781cfdf-647d-458f-b739-c1a65b5b26a6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 16:41:00:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 17:18:40:INFO:
[92mINFO [0m:      Received: evaluate message 679433ae-8479-42b9-8f32-2e815e245f2c
02/06/2025 17:18:40:INFO:Received: evaluate message 679433ae-8479-42b9-8f32-2e815e245f2c
[92mINFO [0m:      Sent reply
02/06/2025 17:24:00:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 17:24:34:INFO:
[92mINFO [0m:      Received: train message b27e9c01-b4fa-476a-87ad-044fd601468d
02/06/2025 17:24:34:INFO:Received: train message b27e9c01-b4fa-476a-87ad-044fd601468d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 17:29:38:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 18:06:17:INFO:
[92mINFO [0m:      Received: evaluate message 506295d0-dcb9-460b-bd24-d9a0ce46bb57
02/06/2025 18:06:17:INFO:Received: evaluate message 506295d0-dcb9-460b-bd24-d9a0ce46bb57
[92mINFO [0m:      Sent reply
02/06/2025 18:11:25:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 18:12:03:INFO:
[92mINFO [0m:      Received: train message 03beb33b-595a-40e6-8de4-e019e4db2a1e
02/06/2025 18:12:03:INFO:Received: train message 03beb33b-595a-40e6-8de4-e019e4db2a1e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 18:16:54:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 18:52:42:INFO:
[92mINFO [0m:      Received: evaluate message b6cbec12-6856-44d6-9271-11e3f92f1910
02/06/2025 18:52:42:INFO:Received: evaluate message b6cbec12-6856-44d6-9271-11e3f92f1910
[92mINFO [0m:      Sent reply
02/06/2025 18:57:37:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 18:58:10:INFO:
[92mINFO [0m:      Received: train message 03b66ad9-c437-4875-98b0-4f85f6ea15ea
02/06/2025 18:58:10:INFO:Received: train message 03b66ad9-c437-4875-98b0-4f85f6ea15ea
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 19:02:48:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 19:39:33:INFO:
[92mINFO [0m:      Received: evaluate message effeeedb-206f-4e83-8281-3d1d0f7a2a14
02/06/2025 19:39:33:INFO:Received: evaluate message effeeedb-206f-4e83-8281-3d1d0f7a2a14
[92mINFO [0m:      Sent reply
02/06/2025 19:44:56:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 19:45:22:INFO:
[92mINFO [0m:      Received: train message 62958b31-2139-4d0f-9987-09f204b94820
02/06/2025 19:45:22:INFO:Received: train message 62958b31-2139-4d0f-9987-09f204b94820
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 19:49:58:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:29:41:INFO:
[92mINFO [0m:      Received: evaluate message 3c62166c-19ef-40db-97c6-1b32e0b00af0
02/06/2025 20:29:41:INFO:Received: evaluate message 3c62166c-19ef-40db-97c6-1b32e0b00af0
[92mINFO [0m:      Sent reply
02/06/2025 20:35:02:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 20:35:56:INFO:
[92mINFO [0m:      Received: train message e739d180-4756-4447-adef-d7207db5240a
02/06/2025 20:35:56:INFO:Received: train message e739d180-4756-4447-adef-d7207db5240a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 20:41:04:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:23:51:INFO:
[92mINFO [0m:      Received: evaluate message 1ab803ad-851a-4c68-8cef-2f404b0a07f0
02/06/2025 21:23:51:INFO:Received: evaluate message 1ab803ad-851a-4c68-8cef-2f404b0a07f0
[92mINFO [0m:      Sent reply
02/06/2025 21:29:36:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 21:30:17:INFO:
[92mINFO [0m:      Received: train message 80d8553c-fbbb-4493-9b6d-3948f763f579
02/06/2025 21:30:17:INFO:Received: train message 80d8553c-fbbb-4493-9b6d-3948f763f579
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 21:38:06:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 22:17:27:INFO:
[92mINFO [0m:      Received: evaluate message f4549873-ca10-4f22-85ce-e03b13886249
02/06/2025 22:17:27:INFO:Received: evaluate message f4549873-ca10-4f22-85ce-e03b13886249
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/fixed_noise/4.88, e=1.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/fixed_noise/4.88, e=1.0']
Device: cuda:0
Params: {'batch_size': 32, 'local_epochs': 3, 'full_dataset_size': 18597, 'number_of_classes': 8}
Privacy Params: {'target_delta': 1e-05, 'noise_multiplier': 4.88, 'max_grad_norm': 1.0}
Epsilon = 0.28

{'loss': [1.8342378426116654], 'accuracy': [0.3568264196536448], 'auc': [0.6378223879395715]}

Epsilon = 0.40

{'loss': [1.8342378426116654, 1.8683316327370418], 'accuracy': [0.3568264196536448, 0.3898509867096255], 'auc': [0.6378223879395715, 0.6630546191375117]}

Epsilon = 0.50

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225]}

Epsilon = 0.58

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672]}

Epsilon = 0.65

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435]}

Epsilon = 0.72

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561]}

Epsilon = 0.78

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066]}

Epsilon = 0.83

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193]}

Epsilon = 0.89

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695]}

Epsilon = 0.94

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254]}

Epsilon = 0.99

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623]}

Epsilon = 1.04

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939]}

Epsilon = 1.08

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856]}

Epsilon = 1.13

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071]}

Epsilon = 1.17
[92mINFO [0m:      Sent reply
02/06/2025 22:22:25:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 22:23:25:INFO:
[92mINFO [0m:      Received: train message a24bd182-68c4-47d2-a5a5-9477440f86cb
02/06/2025 22:23:25:INFO:Received: train message a24bd182-68c4-47d2-a5a5-9477440f86cb
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 22:28:25:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 23:04:20:INFO:
[92mINFO [0m:      Received: evaluate message 9158e4e9-93a3-4419-83e8-333a474ea597
02/06/2025 23:04:20:INFO:Received: evaluate message 9158e4e9-93a3-4419-83e8-333a474ea597
[92mINFO [0m:      Sent reply
02/06/2025 23:09:32:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 23:10:06:INFO:
[92mINFO [0m:      Received: train message d659e3cf-8e6a-4341-bf88-7b5ff4218ae8
02/06/2025 23:10:06:INFO:Received: train message d659e3cf-8e6a-4341-bf88-7b5ff4218ae8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/06/2025 23:14:50:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 23:53:09:INFO:
[92mINFO [0m:      Received: evaluate message ed1b09a4-aa2a-4a64-9c9c-e461b2597e9f
02/06/2025 23:53:09:INFO:Received: evaluate message ed1b09a4-aa2a-4a64-9c9c-e461b2597e9f
[92mINFO [0m:      Sent reply
02/06/2025 23:58:13:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 23:58:48:INFO:
[92mINFO [0m:      Received: train message 5ce2f366-f9b6-47dd-a57d-7b4c3d5c08cd
02/06/2025 23:58:48:INFO:Received: train message 5ce2f366-f9b6-47dd-a57d-7b4c3d5c08cd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 00:03:17:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 00:37:51:INFO:
[92mINFO [0m:      Received: evaluate message 43f2156e-1738-4091-b7d1-e2c11bf4ced2
02/07/2025 00:37:51:INFO:Received: evaluate message 43f2156e-1738-4091-b7d1-e2c11bf4ced2
[92mINFO [0m:      Sent reply
02/07/2025 00:42:45:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 00:43:16:INFO:
[92mINFO [0m:      Received: train message 4ef55333-5ead-4f27-aaf7-1ed78e4edefc
02/07/2025 00:43:16:INFO:Received: train message 4ef55333-5ead-4f27-aaf7-1ed78e4edefc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 00:47:52:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 01:27:15:INFO:
[92mINFO [0m:      Received: evaluate message 181d31f6-2133-4718-be67-3ce1f878928b
02/07/2025 01:27:15:INFO:Received: evaluate message 181d31f6-2133-4718-be67-3ce1f878928b
[92mINFO [0m:      Sent reply
02/07/2025 01:32:09:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 01:32:44:INFO:
[92mINFO [0m:      Received: train message 8797c2c2-412f-486f-91a5-1384b23c5a07
02/07/2025 01:32:44:INFO:Received: train message 8797c2c2-412f-486f-91a5-1384b23c5a07
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 01:37:52:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 02:09:01:INFO:
[92mINFO [0m:      Received: evaluate message 68352322-7cea-4ab8-8aac-5d82a36b5a35
02/07/2025 02:09:01:INFO:Received: evaluate message 68352322-7cea-4ab8-8aac-5d82a36b5a35
[92mINFO [0m:      Sent reply
02/07/2025 02:14:18:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 02:14:36:INFO:
[92mINFO [0m:      Received: train message 513e5fdb-ffe5-465e-8b25-97a95a89676a
02/07/2025 02:14:36:INFO:Received: train message 513e5fdb-ffe5-465e-8b25-97a95a89676a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 02:19:21:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 02:50:11:INFO:
[92mINFO [0m:      Received: evaluate message cc51f524-ff44-4868-a67f-6bcdc380ed00
02/07/2025 02:50:11:INFO:Received: evaluate message cc51f524-ff44-4868-a67f-6bcdc380ed00
[92mINFO [0m:      Sent reply
02/07/2025 02:55:16:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 02:56:03:INFO:
[92mINFO [0m:      Received: train message 052f5d83-1d88-46ca-8627-3995350cf27e
02/07/2025 02:56:03:INFO:Received: train message 052f5d83-1d88-46ca-8627-3995350cf27e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 03:01:09:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 03:31:50:INFO:
[92mINFO [0m:      Received: evaluate message 61dff8eb-c1cc-4d26-814f-3064107fd44b
02/07/2025 03:31:50:INFO:Received: evaluate message 61dff8eb-c1cc-4d26-814f-3064107fd44b

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063]}

Epsilon = 1.21

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156]}

Epsilon = 1.25

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667, 1.5909703109612927], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714, 0.5670559806685461], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156, 0.7563942534777449]}

Epsilon = 1.29

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667, 1.5909703109612927, 1.5700220794769915], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714, 0.5670559806685461, 0.5682641965364479], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156, 0.7563942534777449, 0.7571726889780799]}

Epsilon = 1.33

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667, 1.5909703109612927, 1.5700220794769915, 1.5768220538436237], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714, 0.5670559806685461, 0.5682641965364479, 0.5678614579138139], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156, 0.7563942534777449, 0.7571726889780799, 0.7638949829374637]}

Epsilon = 1.37

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667, 1.5909703109612927, 1.5700220794769915, 1.5768220538436237, 1.532473687870196], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714, 0.5670559806685461, 0.5682641965364479, 0.5678614579138139, 0.5718888441401531], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156, 0.7563942534777449, 0.7571726889780799, 0.7638949829374637, 0.7678139212876993]}

Epsilon = 1.40

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667, 1.5909703109612927, 1.5700220794769915, 1.5768220538436237, 1.532473687870196, 1.5707244113045644], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714, 0.5670559806685461, 0.5682641965364479, 0.5678614579138139, 0.5718888441401531, 0.5690696737817157], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156, 0.7563942534777449, 0.7571726889780799, 0.7638949829374637, 0.7678139212876993, 0.7640438030351066]}

Epsilon = 1.44
[92mINFO [0m:      Sent reply
02/07/2025 03:37:05:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 03:37:33:INFO:
[92mINFO [0m:      Received: train message 5b24ced4-9c6e-485f-bc98-f221d5e647b6
02/07/2025 03:37:33:INFO:Received: train message 5b24ced4-9c6e-485f-bc98-f221d5e647b6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 03:42:21:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 04:16:56:INFO:
[92mINFO [0m:      Received: evaluate message 4d078bdc-5229-4e0a-b26e-319108a78d57
02/07/2025 04:16:56:INFO:Received: evaluate message 4d078bdc-5229-4e0a-b26e-319108a78d57
[92mINFO [0m:      Sent reply
02/07/2025 04:21:54:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 04:22:41:INFO:
[92mINFO [0m:      Received: train message a746230e-c372-484d-a98f-684731002272
02/07/2025 04:22:41:INFO:Received: train message a746230e-c372-484d-a98f-684731002272
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 04:27:21:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 05:03:07:INFO:
[92mINFO [0m:      Received: evaluate message 03427ecb-5a87-4e3e-a82b-95b1cc2e8caa
02/07/2025 05:03:07:INFO:Received: evaluate message 03427ecb-5a87-4e3e-a82b-95b1cc2e8caa
[92mINFO [0m:      Sent reply
02/07/2025 05:07:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 05:08:28:INFO:
[92mINFO [0m:      Received: train message 9a05c39b-69f7-4ead-8292-18ee4215e3c2
02/07/2025 05:08:28:INFO:Received: train message 9a05c39b-69f7-4ead-8292-18ee4215e3c2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 05:13:13:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 05:43:17:INFO:
[92mINFO [0m:      Received: evaluate message beee455b-eeb2-4695-b4ed-29b89a326bd5
02/07/2025 05:43:17:INFO:Received: evaluate message beee455b-eeb2-4695-b4ed-29b89a326bd5
[92mINFO [0m:      Sent reply
02/07/2025 05:48:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 05:48:25:INFO:
[92mINFO [0m:      Received: train message 982b39d9-fb4b-4b0c-b339-0b1d7e8f585c
02/07/2025 05:48:25:INFO:Received: train message 982b39d9-fb4b-4b0c-b339-0b1d7e8f585c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 05:52:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 06:23:04:INFO:
[92mINFO [0m:      Received: evaluate message d8872452-fe31-47ec-baf4-d0a037204f14
02/07/2025 06:23:04:INFO:Received: evaluate message d8872452-fe31-47ec-baf4-d0a037204f14
[92mINFO [0m:      Sent reply
02/07/2025 06:28:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 06:28:22:INFO:
[92mINFO [0m:      Received: train message 9cce705c-cb8c-409a-844a-35f85326adc3
02/07/2025 06:28:22:INFO:Received: train message 9cce705c-cb8c-409a-844a-35f85326adc3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 06:32:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 07:02:49:INFO:
[92mINFO [0m:      Received: evaluate message d2b66ade-249a-4381-aadc-f9178ee9b3fc
02/07/2025 07:02:49:INFO:Received: evaluate message d2b66ade-249a-4381-aadc-f9178ee9b3fc

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667, 1.5909703109612927, 1.5700220794769915, 1.5768220538436237, 1.532473687870196, 1.5707244113045644, 1.555787845143761], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714, 0.5670559806685461, 0.5682641965364479, 0.5678614579138139, 0.5718888441401531, 0.5690696737817157, 0.5730970600080548], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156, 0.7563942534777449, 0.7571726889780799, 0.7638949829374637, 0.7678139212876993, 0.7640438030351066, 0.7636325844697514]}

Epsilon = 1.47

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667, 1.5909703109612927, 1.5700220794769915, 1.5768220538436237, 1.532473687870196, 1.5707244113045644, 1.555787845143761, 1.5481054358457396], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714, 0.5670559806685461, 0.5682641965364479, 0.5678614579138139, 0.5718888441401531, 0.5690696737817157, 0.5730970600080548, 0.5722915827627869], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156, 0.7563942534777449, 0.7571726889780799, 0.7638949829374637, 0.7678139212876993, 0.7640438030351066, 0.7636325844697514, 0.7615975310554685]}

Epsilon = 1.51

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667, 1.5909703109612927, 1.5700220794769915, 1.5768220538436237, 1.532473687870196, 1.5707244113045644, 1.555787845143761, 1.5481054358457396, 1.5631114623741522], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714, 0.5670559806685461, 0.5682641965364479, 0.5678614579138139, 0.5718888441401531, 0.5690696737817157, 0.5730970600080548, 0.5722915827627869, 0.5739025372533226], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156, 0.7563942534777449, 0.7571726889780799, 0.7638949829374637, 0.7678139212876993, 0.7640438030351066, 0.7636325844697514, 0.7615975310554685, 0.7648399657339359]}

Epsilon = 1.54

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667, 1.5909703109612927, 1.5700220794769915, 1.5768220538436237, 1.532473687870196, 1.5707244113045644, 1.555787845143761, 1.5481054358457396, 1.5631114623741522, 1.5638424488406386], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714, 0.5670559806685461, 0.5682641965364479, 0.5678614579138139, 0.5718888441401531, 0.5690696737817157, 0.5730970600080548, 0.5722915827627869, 0.5739025372533226, 0.5771244462343939], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156, 0.7563942534777449, 0.7571726889780799, 0.7638949829374637, 0.7678139212876993, 0.7640438030351066, 0.7636325844697514, 0.7615975310554685, 0.7648399657339359, 0.7620012734762337]}

Epsilon = 1.58

{'loss': [1.8342378426116654, 1.8683316327370418, 1.7354799263236314, 1.6632475016148782, 1.6268940538924115, 1.557775464885618, 1.561690445153693, 1.5983149414815299, 1.6239720199360657, 1.5870776197577119, 1.5810816234222977, 1.5901329207218706, 1.5899515566785538, 1.5905160619710368, 1.5772926239923177, 1.6165327973006667, 1.5909703109612927, 1.5700220794769915, 1.5768220538436237, 1.532473687870196, 1.5707244113045644, 1.555787845143761, 1.5481054358457396, 1.5631114623741522, 1.5638424488406386, 1.5941555087623027], 'accuracy': [0.3568264196536448, 0.3898509867096255, 0.4571083366894885, 0.49295207410390657, 0.5219492549335482, 0.540877970197342, 0.5473217881594845, 0.5509464357631897, 0.5553765606121627, 0.5606121627064036, 0.5569875151026984, 0.5561820378574305, 0.5610149013290374, 0.5622231171969392, 0.5646395489327426, 0.5614176399516714, 0.5670559806685461, 0.5682641965364479, 0.5678614579138139, 0.5718888441401531, 0.5690696737817157, 0.5730970600080548, 0.5722915827627869, 0.5739025372533226, 0.5771244462343939, 0.576318968989126], 'auc': [0.6378223879395715, 0.6630546191375117, 0.6816686371892225, 0.7040032042312672, 0.7148911022742435, 0.725752225117561, 0.7355037975424066, 0.7443037312170193, 0.7493521095953695, 0.7574233200902254, 0.7575343239833623, 0.7596530725922939, 0.7609306801446856, 0.7578186302306071, 0.7560019610490063, 0.7544536364123156, 0.7563942534777449, 0.7571726889780799, 0.7638949829374637, 0.7678139212876993, 0.7640438030351066, 0.7636325844697514, 0.7615975310554685, 0.7648399657339359, 0.7620012734762337, 0.7601774372032728]}

Epsilon = 1.61
[92mINFO [0m:      Sent reply
02/07/2025 07:07:38:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 07:08:12:INFO:
[92mINFO [0m:      Received: train message 86e7501b-41e5-441c-8bd9-b8e2c778f945
02/07/2025 07:08:12:INFO:Received: train message 86e7501b-41e5-441c-8bd9-b8e2c778f945
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 07:12:49:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 07:42:54:INFO:
[92mINFO [0m:      Received: evaluate message 39ce814c-686a-475f-8178-d9a148ba215c
02/07/2025 07:42:54:INFO:Received: evaluate message 39ce814c-686a-475f-8178-d9a148ba215c
[92mINFO [0m:      Sent reply
02/07/2025 07:47:42:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 07:48:10:INFO:
[92mINFO [0m:      Received: train message a3e9f16a-043f-4969-81b2-63702ee759ad
02/07/2025 07:48:10:INFO:Received: train message a3e9f16a-043f-4969-81b2-63702ee759ad
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 07:52:39:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 08:22:57:INFO:
[92mINFO [0m:      Received: evaluate message 65ef25d1-a619-437b-9f7b-97c37c4ed88a
02/07/2025 08:22:57:INFO:Received: evaluate message 65ef25d1-a619-437b-9f7b-97c37c4ed88a
[92mINFO [0m:      Sent reply
02/07/2025 08:27:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 08:28:25:INFO:
[92mINFO [0m:      Received: train message c649c3d8-4e34-48d3-b6ec-9ab644840f15
02/07/2025 08:28:25:INFO:Received: train message c649c3d8-4e34-48d3-b6ec-9ab644840f15
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 08:33:13:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 09:02:58:INFO:
[92mINFO [0m:      Received: evaluate message 4b943b1d-9d2a-44a0-a48c-d399e04d5b8a
02/07/2025 09:02:58:INFO:Received: evaluate message 4b943b1d-9d2a-44a0-a48c-d399e04d5b8a
[92mINFO [0m:      Sent reply
02/07/2025 09:07:52:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 09:08:08:INFO:
[92mINFO [0m:      Received: reconnect message 17e7d656-4bf0-4e0a-b65c-5aaff35a2162
02/07/2025 09:08:08:INFO:Received: reconnect message 17e7d656-4bf0-4e0a-b65c-5aaff35a2162
02/07/2025 09:08:08:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/07/2025 09:08:08:INFO:Disconnect and shut down
F0000 00:00:1738948088.527089 1296303 thd.h:170] Check failed: state_ == FAILED 
*** Check failure stack trace: ***
