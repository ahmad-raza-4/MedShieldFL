nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.4 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/fed_avg/fixed_noise/5.0/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
02/15/2025 12:21:37:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/15/2025 12:21:37:DEBUG:ChannelConnectivity.IDLE
02/15/2025 12:21:37:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
02/15/2025 12:21:37:INFO:
[92mINFO [0m:      Received: get_parameters message 95547874-2279-4d4b-9c51-072f3af4987b
02/15/2025 12:21:37:INFO:Received: get_parameters message 95547874-2279-4d4b-9c51-072f3af4987b
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1739650897.501925 2347573 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      Sent reply
02/15/2025 12:21:41:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 12:22:20:INFO:
[92mINFO [0m:      Received: train message b94936d7-23fd-4f8d-90b1-7b99dded5020
02/15/2025 12:22:20:INFO:Received: train message b94936d7-23fd-4f8d-90b1-7b99dded5020
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 12:34:59:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 13:03:06:INFO:
[92mINFO [0m:      Received: evaluate message 38a20587-963e-4d4c-9211-90f7a05813b3
02/15/2025 13:03:06:INFO:Received: evaluate message 38a20587-963e-4d4c-9211-90f7a05813b3
[92mINFO [0m:      Sent reply
02/15/2025 13:08:32:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 13:09:07:INFO:
[92mINFO [0m:      Received: train message 314574f0-e412-4f31-81be-d0739301e443
02/15/2025 13:09:07:INFO:Received: train message 314574f0-e412-4f31-81be-d0739301e443
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 13:23:21:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 13:50:18:INFO:
[92mINFO [0m:      Received: evaluate message c0dea755-27ca-48be-86cd-ac055aed8738
02/15/2025 13:50:18:INFO:Received: evaluate message c0dea755-27ca-48be-86cd-ac055aed8738
[92mINFO [0m:      Sent reply
02/15/2025 13:55:49:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 13:57:02:INFO:
[92mINFO [0m:      Received: train message 2ca2e737-c429-423d-afde-823b5c41a28f
02/15/2025 13:57:02:INFO:Received: train message 2ca2e737-c429-423d-afde-823b5c41a28f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 14:10:55:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 14:37:33:INFO:
[92mINFO [0m:      Received: evaluate message 5a8945a6-0b08-48a3-90cd-9483ce1372c4
02/15/2025 14:37:33:INFO:Received: evaluate message 5a8945a6-0b08-48a3-90cd-9483ce1372c4
[92mINFO [0m:      Sent reply
02/15/2025 14:43:22:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 14:44:28:INFO:
[92mINFO [0m:      Received: train message 6948342c-10aa-41fc-a4d7-61005dd7bafa
02/15/2025 14:44:28:INFO:Received: train message 6948342c-10aa-41fc-a4d7-61005dd7bafa
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 14:59:09:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 15:24:14:INFO:
[92mINFO [0m:      Received: evaluate message e940ddb0-e820-4f04-bf94-ddb3f7d60bcf
02/15/2025 15:24:14:INFO:Received: evaluate message e940ddb0-e820-4f04-bf94-ddb3f7d60bcf
[92mINFO [0m:      Sent reply
02/15/2025 15:30:19:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 15:30:34:INFO:
[92mINFO [0m:      Received: train message bc95ecef-fc9d-4d00-9004-ecbf23fb622f
02/15/2025 15:30:34:INFO:Received: train message bc95ecef-fc9d-4d00-9004-ecbf23fb622f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 15:44:43:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 16:10:44:INFO:
[92mINFO [0m:      Received: evaluate message c18d61fe-15e1-4f9b-b32f-8ed49955a149
02/15/2025 16:10:44:INFO:Received: evaluate message c18d61fe-15e1-4f9b-b32f-8ed49955a149
[92mINFO [0m:      Sent reply
02/15/2025 16:16:54:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 16:17:28:INFO:
[92mINFO [0m:      Received: train message 4facfd7c-d938-4890-be47-fba7464dec6d
02/15/2025 16:17:28:INFO:Received: train message 4facfd7c-d938-4890-be47-fba7464dec6d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 16:32:07:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 16:56:46:INFO:
[92mINFO [0m:      Received: evaluate message 1b7f5608-4c99-46f6-b6b2-29ae23c73a15
02/15/2025 16:56:46:INFO:Received: evaluate message 1b7f5608-4c99-46f6-b6b2-29ae23c73a15
[92mINFO [0m:      Sent reply
02/15/2025 17:02:24:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 17:03:28:INFO:
[92mINFO [0m:      Received: train message 8da03791-7f4d-4a47-a2b7-8649f3d0432d
02/15/2025 17:03:28:INFO:Received: train message 8da03791-7f4d-4a47-a2b7-8649f3d0432d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 17:18:14:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 17:43:09:INFO:
[92mINFO [0m:      Received: evaluate message a21fdf98-4003-41d6-b805-47240b8d3473
02/15/2025 17:43:09:INFO:Received: evaluate message a21fdf98-4003-41d6-b805-47240b8d3473
[92mINFO [0m:      Sent reply
02/15/2025 17:49:14:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 17:49:51:INFO:
[92mINFO [0m:      Received: train message f09d2cac-e2e1-4a45-aadf-d536eb38e492
02/15/2025 17:49:51:INFO:Received: train message f09d2cac-e2e1-4a45-aadf-d536eb38e492
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 18:04:43:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 18:30:38:INFO:
[92mINFO [0m:      Received: evaluate message 8832f60b-0f6f-4ce0-92f5-d27416709c74
02/15/2025 18:30:38:INFO:Received: evaluate message 8832f60b-0f6f-4ce0-92f5-d27416709c74
[92mINFO [0m:      Sent reply
02/15/2025 18:36:40:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 18:37:16:INFO:
[92mINFO [0m:      Received: train message c24318c5-3fae-4eb6-a5ff-404e7f160fe9
02/15/2025 18:37:16:INFO:Received: train message c24318c5-3fae-4eb6-a5ff-404e7f160fe9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 18:51:49:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 19:16:30:INFO:
[92mINFO [0m:      Received: evaluate message e5e28f94-ea5b-466e-a4e4-5ea1bc6b495f
02/15/2025 19:16:30:INFO:Received: evaluate message e5e28f94-ea5b-466e-a4e4-5ea1bc6b495f
[92mINFO [0m:      Sent reply
02/15/2025 19:21:30:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 19:23:30:INFO:
[92mINFO [0m:      Received: train message 198090ea-6188-44f2-8fd9-95c0594122d6
02/15/2025 19:23:30:INFO:Received: train message 198090ea-6188-44f2-8fd9-95c0594122d6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 19:38:23:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 20:03:59:INFO:
[92mINFO [0m:      Received: evaluate message e49c3610-84ec-472b-92f7-1417010deb78
02/15/2025 20:03:59:INFO:Received: evaluate message e49c3610-84ec-472b-92f7-1417010deb78
[92mINFO [0m:      Sent reply
02/15/2025 20:10:02:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 20:10:16:INFO:
[92mINFO [0m:      Received: train message 6168274a-a747-433f-8c1a-1df7f579219a
02/15/2025 20:10:16:INFO:Received: train message 6168274a-a747-433f-8c1a-1df7f579219a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 20:24:44:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 20:50:26:INFO:
[92mINFO [0m:      Received: evaluate message 478965e7-a5b5-418b-9f61-899982c7b345
02/15/2025 20:50:26:INFO:Received: evaluate message 478965e7-a5b5-418b-9f61-899982c7b345
[92mINFO [0m:      Sent reply
02/15/2025 20:56:38:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 20:57:05:INFO:
[92mINFO [0m:      Received: train message 315c06cb-63b8-42de-9d92-1f9ac7a3efcd
02/15/2025 20:57:05:INFO:Received: train message 315c06cb-63b8-42de-9d92-1f9ac7a3efcd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 21:11:50:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 21:39:20:INFO:
[92mINFO [0m:      Received: evaluate message b21c924d-dc86-4a29-a683-b86e2d9e9031
02/15/2025 21:39:20:INFO:Received: evaluate message b21c924d-dc86-4a29-a683-b86e2d9e9031
[92mINFO [0m:      Sent reply
02/15/2025 21:45:21:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 21:45:55:INFO:
[92mINFO [0m:      Received: train message 4dd721b7-570a-47f1-a93e-792de2b03e21
02/15/2025 21:45:55:INFO:Received: train message 4dd721b7-570a-47f1-a93e-792de2b03e21
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 22:00:35:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 22:25:10:INFO:
[92mINFO [0m:      Received: evaluate message 7478f491-0d93-4e4a-941e-d581e56261cf
02/15/2025 22:25:10:INFO:Received: evaluate message 7478f491-0d93-4e4a-941e-d581e56261cf
[92mINFO [0m:      Sent reply
02/15/2025 22:30:58:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 22:32:14:INFO:
[92mINFO [0m:      Received: train message 54b17410-cca0-46ea-ac76-0cfedecaf8ce
02/15/2025 22:32:14:INFO:Received: train message 54b17410-cca0-46ea-ac76-0cfedecaf8ce
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 22:46:43:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 23:12:20:INFO:
[92mINFO [0m:      Received: evaluate message e7e41268-8ad4-492b-9db8-4329605bd116
02/15/2025 23:12:20:INFO:Received: evaluate message e7e41268-8ad4-492b-9db8-4329605bd116
[92mINFO [0m:      Sent reply
02/15/2025 23:18:20:INFO:Sent reply
[92mINFO [0m:      
02/15/2025 23:18:46:INFO:
[92mINFO [0m:      Received: train message 9532ba3e-9a71-4d01-a60a-aabcbd8d721d
02/15/2025 23:18:46:INFO:Received: train message 9532ba3e-9a71-4d01-a60a-aabcbd8d721d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/15/2025 23:33:01:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 00:00:57:INFO:
[92mINFO [0m:      Received: evaluate message 629e2532-91df-4e8a-b7af-f9edfed91721
02/16/2025 00:00:57:INFO:Received: evaluate message 629e2532-91df-4e8a-b7af-f9edfed91721
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/fed_avg/fixed_noise/5.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/isic/fed_avg/fixed_noise/5.0']
Device: cuda:0
Params: {'batch_size': 32, 'local_epochs': 3, 'full_dataset_size': 18597, 'number_of_classes': 8}
Privacy Params: {'target_delta': 1e-05, 'noise_multiplier': 5.0, 'max_grad_norm': 1.0}
Epsilon = 0.16

{'loss': [1.8300055247662868], 'accuracy': [0.35642368103101085], 'auc': [0.6371937363892591]}

Epsilon = 0.23

{'loss': [1.8300055247662868, 1.8672933223215842], 'accuracy': [0.35642368103101085, 0.3894482480869915], 'auc': [0.6371937363892591, 0.6626311125665002]}

Epsilon = 0.28

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665]}

Epsilon = 0.33

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356]}

Epsilon = 0.37

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513]}

Epsilon = 0.41

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064]}

Epsilon = 0.44

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955]}

Epsilon = 0.47

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295]}

Epsilon = 0.50

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765]}

Epsilon = 0.53

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682]}

Epsilon = 0.56

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789]}

Epsilon = 0.59

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775]}

Epsilon = 0.61

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948]}

Epsilon = 0.64

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993]}

Epsilon = 0.66
[92mINFO [0m:      Sent reply
02/16/2025 00:07:28:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 00:07:46:INFO:
[92mINFO [0m:      Received: train message 4e4ee25e-74c2-46f5-9b62-cb32baf281b3
02/16/2025 00:07:46:INFO:Received: train message 4e4ee25e-74c2-46f5-9b62-cb32baf281b3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 00:22:40:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 00:52:02:INFO:
[92mINFO [0m:      Received: evaluate message ebeec3fb-6384-421c-bd41-a8df587e2757
02/16/2025 00:52:02:INFO:Received: evaluate message ebeec3fb-6384-421c-bd41-a8df587e2757
[92mINFO [0m:      Sent reply
02/16/2025 00:58:36:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 00:59:14:INFO:
[92mINFO [0m:      Received: train message 796c00dc-e40b-4fcf-b452-2e43c70e393c
02/16/2025 00:59:14:INFO:Received: train message 796c00dc-e40b-4fcf-b452-2e43c70e393c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 01:14:13:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 01:43:09:INFO:
[92mINFO [0m:      Received: evaluate message 4884c2bd-4a9e-4ac5-8bff-499c582b41a6
02/16/2025 01:43:09:INFO:Received: evaluate message 4884c2bd-4a9e-4ac5-8bff-499c582b41a6
[92mINFO [0m:      Sent reply
02/16/2025 01:49:40:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 01:50:26:INFO:
[92mINFO [0m:      Received: train message c91fa90a-6b5e-4e03-8a28-cc8651035e79
02/16/2025 01:50:26:INFO:Received: train message c91fa90a-6b5e-4e03-8a28-cc8651035e79
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 02:05:39:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 02:33:50:INFO:
[92mINFO [0m:      Received: evaluate message 6f7c6fd1-fccb-4592-a440-70cb7e2fa4dc
02/16/2025 02:33:50:INFO:Received: evaluate message 6f7c6fd1-fccb-4592-a440-70cb7e2fa4dc
[92mINFO [0m:      Sent reply
02/16/2025 02:40:01:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 02:40:26:INFO:
[92mINFO [0m:      Received: train message 4de7225f-c4b3-476c-9344-64e1f943d8a7
02/16/2025 02:40:26:INFO:Received: train message 4de7225f-c4b3-476c-9344-64e1f943d8a7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 02:55:48:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 03:23:51:INFO:
[92mINFO [0m:      Received: evaluate message e49152c3-8199-465d-b96f-e4b438e13da9
02/16/2025 03:23:51:INFO:Received: evaluate message e49152c3-8199-465d-b96f-e4b438e13da9
[92mINFO [0m:      Sent reply
02/16/2025 03:30:09:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 03:31:14:INFO:
[92mINFO [0m:      Received: train message 6c1397ba-37db-44ca-b7b2-7c637798c768
02/16/2025 03:31:14:INFO:Received: train message 6c1397ba-37db-44ca-b7b2-7c637798c768
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 03:46:00:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 04:14:48:INFO:
[92mINFO [0m:      Received: evaluate message 1b47ad59-338e-4ae9-8434-a01b95466d85
02/16/2025 04:14:48:INFO:Received: evaluate message 1b47ad59-338e-4ae9-8434-a01b95466d85
[92mINFO [0m:      Sent reply
02/16/2025 04:20:40:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 04:21:37:INFO:
[92mINFO [0m:      Received: train message bd83e39b-f832-4015-9d2b-03f3ecb81ef6
02/16/2025 04:21:37:INFO:Received: train message bd83e39b-f832-4015-9d2b-03f3ecb81ef6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 04:36:56:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 05:03:26:INFO:
[92mINFO [0m:      Received: evaluate message 942ce4bd-283e-453e-b567-442a9bd992bf
02/16/2025 05:03:26:INFO:Received: evaluate message 942ce4bd-283e-453e-b567-442a9bd992bf
[92mINFO [0m:      Sent reply
02/16/2025 05:09:56:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 05:10:38:INFO:
[92mINFO [0m:      Received: train message 971dd6d2-2834-4567-bb65-fde6abc5f4fd
02/16/2025 05:10:38:INFO:Received: train message 971dd6d2-2834-4567-bb65-fde6abc5f4fd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 05:25:06:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 05:50:41:INFO:
[92mINFO [0m:      Received: evaluate message aaf59ec4-60a9-4763-83f8-40d3e0faf299
02/16/2025 05:50:41:INFO:Received: evaluate message aaf59ec4-60a9-4763-83f8-40d3e0faf299

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182]}

Epsilon = 0.68

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837]}

Epsilon = 0.71

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547, 1.5960438089701037], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036, 0.5658477648006444], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837, 0.7552034378825181]}

Epsilon = 0.73

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547, 1.5960438089701037, 1.5746417738380232], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036, 0.5658477648006444, 0.5670559806685461], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837, 0.7552034378825181, 0.75591129682418]}

Epsilon = 0.75

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547, 1.5960438089701037, 1.5746417738380232, 1.576024439946519], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036, 0.5658477648006444, 0.5670559806685461, 0.5682641965364479], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837, 0.7552034378825181, 0.75591129682418, 0.7630188268323839]}

Epsilon = 0.77

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547, 1.5960438089701037, 1.5746417738380232, 1.576024439946519, 1.5323277050768038], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036, 0.5658477648006444, 0.5670559806685461, 0.5682641965364479, 0.5714861055175191], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837, 0.7552034378825181, 0.75591129682418, 0.7630188268323839, 0.7670515480457849]}

Epsilon = 0.79

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547, 1.5960438089701037, 1.5746417738380232, 1.576024439946519, 1.5323277050768038, 1.572312726784367], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036, 0.5658477648006444, 0.5670559806685461, 0.5682641965364479, 0.5714861055175191, 0.5678614579138139], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837, 0.7552034378825181, 0.75591129682418, 0.7630188268323839, 0.7670515480457849, 0.7631696469003643]}

Epsilon = 0.81
[92mINFO [0m:      Sent reply
02/16/2025 05:56:46:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 05:57:25:INFO:
[92mINFO [0m:      Received: train message e3cd5d5b-c196-4d4d-92b0-639c407b1699
02/16/2025 05:57:25:INFO:Received: train message e3cd5d5b-c196-4d4d-92b0-639c407b1699
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 06:12:25:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 06:36:40:INFO:
[92mINFO [0m:      Received: evaluate message 476205b3-1859-42a4-bb9b-c79c71644747
02/16/2025 06:36:40:INFO:Received: evaluate message 476205b3-1859-42a4-bb9b-c79c71644747
[92mINFO [0m:      Sent reply
02/16/2025 06:42:51:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 06:43:31:INFO:
[92mINFO [0m:      Received: train message 186461c8-7b48-4b82-be76-b592441d35cf
02/16/2025 06:43:31:INFO:Received: train message 186461c8-7b48-4b82-be76-b592441d35cf
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 06:58:25:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 07:23:14:INFO:
[92mINFO [0m:      Received: evaluate message f264c864-c4a1-459c-8b28-ab5e8f1f49ba
02/16/2025 07:23:14:INFO:Received: evaluate message f264c864-c4a1-459c-8b28-ab5e8f1f49ba
[92mINFO [0m:      Sent reply
02/16/2025 07:28:42:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 07:29:53:INFO:
[92mINFO [0m:      Received: train message ea5b2bca-7b6c-480c-98de-136becf6873c
02/16/2025 07:29:53:INFO:Received: train message ea5b2bca-7b6c-480c-98de-136becf6873c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 07:44:59:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 08:09:56:INFO:
[92mINFO [0m:      Received: evaluate message abbdf0f5-8243-45f2-8e9b-2be46242d507
02/16/2025 08:09:56:INFO:Received: evaluate message abbdf0f5-8243-45f2-8e9b-2be46242d507
[92mINFO [0m:      Sent reply
02/16/2025 08:16:01:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 08:16:45:INFO:
[92mINFO [0m:      Received: train message f19de19e-6752-4568-87cf-06fd0be9fe79
02/16/2025 08:16:45:INFO:Received: train message f19de19e-6752-4568-87cf-06fd0be9fe79
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 08:31:11:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 08:55:47:INFO:
[92mINFO [0m:      Received: evaluate message b36d2d0e-e128-4daf-b5c4-cbdf6a92bde4
02/16/2025 08:55:47:INFO:Received: evaluate message b36d2d0e-e128-4daf-b5c4-cbdf6a92bde4
[92mINFO [0m:      Sent reply
02/16/2025 09:02:03:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 09:02:33:INFO:
[92mINFO [0m:      Received: train message f8cbb146-d66a-41ab-b33a-026a27e599e9
02/16/2025 09:02:33:INFO:Received: train message f8cbb146-d66a-41ab-b33a-026a27e599e9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 09:17:21:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 09:42:58:INFO:
[92mINFO [0m:      Received: evaluate message e35a43ca-2b4e-4d5a-a528-4310db56671e
02/16/2025 09:42:58:INFO:Received: evaluate message e35a43ca-2b4e-4d5a-a528-4310db56671e

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547, 1.5960438089701037, 1.5746417738380232, 1.576024439946519, 1.5323277050768038, 1.572312726784367, 1.556746344579788], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036, 0.5658477648006444, 0.5670559806685461, 0.5682641965364479, 0.5714861055175191, 0.5678614579138139, 0.5726943213854209], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837, 0.7552034378825181, 0.75591129682418, 0.7630188268323839, 0.7670515480457849, 0.7631696469003643, 0.7626365515826179]}

Epsilon = 0.83

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547, 1.5960438089701037, 1.5746417738380232, 1.576024439946519, 1.5323277050768038, 1.572312726784367, 1.556746344579788, 1.5512628935058415], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036, 0.5658477648006444, 0.5670559806685461, 0.5682641965364479, 0.5714861055175191, 0.5678614579138139, 0.5726943213854209, 0.5702778896496175], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837, 0.7552034378825181, 0.75591129682418, 0.7630188268323839, 0.7670515480457849, 0.7631696469003643, 0.7626365515826179, 0.7606125092415972]}

Epsilon = 0.85

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547, 1.5960438089701037, 1.5746417738380232, 1.576024439946519, 1.5323277050768038, 1.572312726784367, 1.556746344579788, 1.5512628935058415, 1.5675589161153478], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036, 0.5658477648006444, 0.5670559806685461, 0.5682641965364479, 0.5714861055175191, 0.5678614579138139, 0.5726943213854209, 0.5702778896496175, 0.5739025372533226], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837, 0.7552034378825181, 0.75591129682418, 0.7630188268323839, 0.7670515480457849, 0.7631696469003643, 0.7626365515826179, 0.7606125092415972, 0.763870858846809]}

Epsilon = 0.87

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547, 1.5960438089701037, 1.5746417738380232, 1.576024439946519, 1.5323277050768038, 1.572312726784367, 1.556746344579788, 1.5512628935058415, 1.5675589161153478, 1.5685171333955172], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036, 0.5658477648006444, 0.5670559806685461, 0.5682641965364479, 0.5714861055175191, 0.5678614579138139, 0.5726943213854209, 0.5702778896496175, 0.5739025372533226, 0.57672170761176], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837, 0.7552034378825181, 0.75591129682418, 0.7630188268323839, 0.7670515480457849, 0.7631696469003643, 0.7626365515826179, 0.7606125092415972, 0.763870858846809, 0.7611135376691645]}

Epsilon = 0.89

{'loss': [1.8300055247662868, 1.8672933223215842, 1.737405895226625, 1.658286473609918, 1.6263844616894179, 1.5562560092140194, 1.5585029234196743, 1.5978167219791881, 1.6205500374865829, 1.5889629395892435, 1.581395835632573, 1.594907228043134, 1.5905536124651536, 1.5923337364600063, 1.5780383712382169, 1.6206932107719547, 1.5960438089701037, 1.5746417738380232, 1.576024439946519, 1.5323277050768038, 1.572312726784367, 1.556746344579788, 1.5512628935058415, 1.5675589161153478, 1.5685171333955172, 1.5968800409158006], 'accuracy': [0.35642368103101085, 0.3894482480869915, 0.4567055980668546, 0.4941602899718083, 0.5215465163109142, 0.540877970197342, 0.5461135722915827, 0.5505436971405557, 0.5537656061216271, 0.5598066854611358, 0.5569875151026984, 0.5549738219895288, 0.5610149013290374, 0.5622231171969392, 0.563028594442207, 0.5606121627064036, 0.5658477648006444, 0.5670559806685461, 0.5682641965364479, 0.5714861055175191, 0.5678614579138139, 0.5726943213854209, 0.5702778896496175, 0.5739025372533226, 0.57672170761176, 0.5759162303664922], 'auc': [0.6371937363892591, 0.6626311125665002, 0.6811260888185665, 0.7034007875631356, 0.7141846399020513, 0.7250470659153064, 0.7348284844825955, 0.7434974703872295, 0.7488508935174765, 0.756511567519682, 0.7565983140387789, 0.7586726275444775, 0.7601447718682948, 0.756992479220993, 0.7551007516920182, 0.753278902412837, 0.7552034378825181, 0.75591129682418, 0.7630188268323839, 0.7670515480457849, 0.7631696469003643, 0.7626365515826179, 0.7606125092415972, 0.763870858846809, 0.7611135376691645, 0.7592378677245133]}

Epsilon = 0.90
[92mINFO [0m:      Sent reply
02/16/2025 09:48:59:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 09:49:22:INFO:
[92mINFO [0m:      Received: train message 8a8e921d-75d8-4226-9c10-3c39638bc8b3
02/16/2025 09:49:22:INFO:Received: train message 8a8e921d-75d8-4226-9c10-3c39638bc8b3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 10:03:56:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 10:29:56:INFO:
[92mINFO [0m:      Received: evaluate message f2c39e73-50ef-49d2-973c-d6d7191f7cb3
02/16/2025 10:29:56:INFO:Received: evaluate message f2c39e73-50ef-49d2-973c-d6d7191f7cb3
[92mINFO [0m:      Sent reply
02/16/2025 10:36:08:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 10:36:46:INFO:
[92mINFO [0m:      Received: train message 8b1fa62c-8902-47a6-9a16-8fb5d1f97a96
02/16/2025 10:36:46:INFO:Received: train message 8b1fa62c-8902-47a6-9a16-8fb5d1f97a96
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 10:51:32:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 11:17:24:INFO:
[92mINFO [0m:      Received: evaluate message b873556e-8195-4c88-b4d8-257605f86400
02/16/2025 11:17:24:INFO:Received: evaluate message b873556e-8195-4c88-b4d8-257605f86400
[92mINFO [0m:      Sent reply
02/16/2025 11:22:52:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 11:24:18:INFO:
[92mINFO [0m:      Received: train message cb8660de-e47f-4494-8429-39be611c107d
02/16/2025 11:24:18:INFO:Received: train message cb8660de-e47f-4494-8429-39be611c107d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
[92mINFO [0m:      Sent reply
02/16/2025 11:39:13:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 12:07:35:INFO:
[92mINFO [0m:      Received: evaluate message 94a8d2a8-7ebb-47f8-935b-7e67a845aa80
02/16/2025 12:07:35:INFO:Received: evaluate message 94a8d2a8-7ebb-47f8-935b-7e67a845aa80
[92mINFO [0m:      Sent reply
02/16/2025 12:14:19:INFO:Sent reply
[92mINFO [0m:      
02/16/2025 12:14:28:INFO:
[92mINFO [0m:      Received: reconnect message 8cd8eb42-908d-4246-ab66-bb36122ecf21
02/16/2025 12:14:28:INFO:Received: reconnect message 8cd8eb42-908d-4246-ab66-bb36122ecf21
02/16/2025 12:14:28:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/16/2025 12:14:28:INFO:Disconnect and shut down
