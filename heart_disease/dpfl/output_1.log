nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/06/2025 11:15:14:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/06/2025 11:15:14:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/06/2025 11:15:14:DEBUG:ChannelConnectivity.IDLE
02/06/2025 11:15:14:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738869314.221960  676524 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/06/2025 11:15:16:INFO:
[92mINFO [0m:      Received: train message d6cb9ffd-7de4-477c-97db-9ddd73df7dd3
02/06/2025 11:15:16:INFO:Received: train message d6cb9ffd-7de4-477c-97db-9ddd73df7dd3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/dpfl', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease']
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.8032495081424713
  Validation Loss: 0.6316584348678589
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.8065897077322006
  Validation Loss: 0.6303313970565796
  Val ROC-AUC: 0.8920454545454545
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.7900260537862778
  Validation Loss: 0.6289600729942322
  Val ROC-AUC: 0.8920454545454545
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.8019380420446396
  Validation Loss: 0.6276735663414001
  Val ROC-AUC: 0.8920454545454545
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.8013128340244293
  Validation Loss: 0.6263929605484009
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.8031876981258392
  Validation Loss: 0.6251107454299927
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.8063213527202606
  Validation Loss: 0.623855710029602
  Val ROC-AUC: 0.9204545454545454
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.7959633022546768
  Validation Loss: 0.6226154565811157
  Val ROC-AUC: 0.9261363636363635
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.798652783036232
  Validation Loss: 0.6214205026626587
  Val ROC-AUC: 0.9318181818181819
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.7859597951173782
  Validation Loss: 0.6202182769775391
  Val ROC-AUC: 0.9318181818181819
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.8054766356945038
  Validation Loss: 0.6190316081047058
  Val ROC-AUC: 0.9375
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.7847760021686554
  Validation Loss: 0.6178926825523376
  Val ROC-AUC: 0.9375
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7969183921813965
  Validation Loss: 0.6167800426483154
  Val ROC-AUC: 0.9431818181818181
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.7913538813591003
  Validation Loss: 0.6156840920448303
  Val ROC-AUC: 0.9431818181818181
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.7882845550775528
  Validation Loss: 0.6146447062492371
  Val ROC-AUC: 0.9488636363636362
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.7860413491725922
  Validation Loss: 0.6135851144790649
  Val ROC-AUC: 0.9488636363636362
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.7874862849712372
  Validation Loss: 0.6125349998474121
  Val ROC-AUC: 0.9488636363636362
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7894934266805649
  Validation Loss: 0.6115208864212036
  Val ROC-AUC: 0.9488636363636362
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7665205001831055
  Validation Loss: 0.6105072498321533
  Val ROC-AUC: 0.9545454545454545
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.7673884928226471
  Validation Loss: 0.6095494031906128
  Val ROC-AUC: 0.9545454545454545
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.7633597254753113
  Validation Loss: 0.608605146408081
  Val ROC-AUC: 0.9545454545454545
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.7721706926822662
  Validation Loss: 0.6076694130897522
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.7793040871620178
  Validation Loss: 0.6067806482315063
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.7671435326337814
  Validation Loss: 0.6059001088142395
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.7632156908512115
  Validation Loss: 0.6050124764442444
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7535599023103714
  Validation Loss: 0.6041353344917297
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7741096168756485
  Validation Loss: 0.6033260226249695
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.7702059596776962
  Validation Loss: 0.6024792790412903
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.7508495301008224
  Validation Loss: 0.6016493439674377
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.7522899955511093
  Validation Loss: 0.6008704304695129
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7637386471033096
  Validation Loss: 0.6001189947128296
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.7610858082771301
  Validation Loss: 0.5993545055389404
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.757951483130455
  Validation Loss: 0.598604679107666
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.7417332381010056
  Validation Loss: 0.5978880524635315
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.742470771074295
  Validation Loss: 0.5971739888191223
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.744546577334404
  Validation Loss: 0.5964827537536621
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7548509240150452
  Validation Loss: 0.5957908630371094
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7481160461902618
  Validation Loss: 0.5950968265533447
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7365069091320038
  Validation Loss: 0.5944439172744751
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.8518518805503845
Epoch 40/64:
  Train Loss: 0.7555035501718521
  Validation Loss: 0.5937812328338623
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.764097273349762
  Validation Loss: 0.5931330323219299
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.7461705058813095
  Validation Loss: 0.5925381779670715
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.7528480738401413
  Validation Loss: 0.5919499397277832
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.7468593865633011
  Validation Loss: 0.5913342237472534
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.7438053786754608
  Validation Loss: 0.590774655342102
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.7583984881639481
  Validation Loss: 0.5902227759361267
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.7402366995811462
  Validation Loss: 0.5896674394607544
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.74050472676754
  Validation Loss: 0.5891302227973938
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.7364736199378967
  Validation Loss: 0.5886016488075256
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.7361188679933548
  Validation Loss: 0.5880881547927856
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.7245361059904099
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:15:22:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:22:INFO:
[92mINFO [0m:      Received: evaluate message bfa27ad5-dfc2-4048-8eb4-5122b16268c5
02/06/2025 11:15:22:INFO:Received: evaluate message bfa27ad5-dfc2-4048-8eb4-5122b16268c5
[92mINFO [0m:      Sent reply
02/06/2025 11:15:24:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:26:INFO:
[92mINFO [0m:      Received: train message d32f524e-31ac-4041-be9f-ba4dbead552c
02/06/2025 11:15:26:INFO:Received: train message d32f524e-31ac-4041-be9f-ba4dbead552c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5875880718231201
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.7214734107255936
  Validation Loss: 0.5870792269706726
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.7401780188083649
  Validation Loss: 0.5865904092788696
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.7403150945901871
  Validation Loss: 0.5861189961433411
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.7463823407888412
  Validation Loss: 0.5856666564941406
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.7400460541248322
  Validation Loss: 0.5852231383323669
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.730235829949379
  Validation Loss: 0.5847786664962769
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.7168408632278442
  Validation Loss: 0.5843596458435059
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.7288481593132019
  Validation Loss: 0.5839253067970276
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.7288509756326675
  Validation Loss: 0.5835111737251282
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.7260393500328064
  Validation Loss: 0.5831059813499451
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.7287348508834839
  Validation Loss: 0.5827029943466187
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.717769131064415
  Validation Loss: 0.582317590713501
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.7210957258939743
  Validation Loss: 0.5819346308708191
  Val ROC-AUC: 0.9772727272727272
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.7210957258939743, 'val_roc_auc': 0.9772727272727272, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.5819346308708191}
 ROC_AUC: 0.9773|| Accuracy 0.8148 || Train Loss: 0.7211
 Val Loss: 0.5819 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.778736327471358
Test ROC-AUC: 0.6877705627705628
Test Accuracy: 0.5730337078651685
test_loss: 0.778736327471358
test_roc_auc: 0.6877705627705628
test_accuracy: 0.5730337078651685
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7655497938394547
  Validation Loss: 0.7537403702735901
  Val ROC-AUC: 0.6306818181818181
  Val Accuracy: 0.5925925970077515
Epoch 2/64:
  Train Loss: 0.7781173437833786
  Validation Loss: 0.752489447593689
  Val ROC-AUC: 0.6477272727272727
  Val Accuracy: 0.5925925970077515
Epoch 3/64:
  Train Loss: 0.7802753150463104
  Validation Loss: 0.7511730790138245
  Val ROC-AUC: 0.6534090909090908
  Val Accuracy: 0.5925925970077515
Epoch 4/64:
  Train Loss: 0.7616451680660248
  Validation Loss: 0.7498070001602173
  Val ROC-AUC: 0.6761363636363636
  Val Accuracy: 0.5925925970077515
Epoch 5/64:
  Train Loss: 0.7634357810020447
  Validation Loss: 0.748414933681488
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5555555820465088
Epoch 6/64:
  Train Loss: 0.7695411294698715
  Validation Loss: 0.7469814419746399
  Val ROC-AUC: 0.6931818181818182
  Val Accuracy: 0.5555555820465088
Epoch 7/64:
  Train Loss: 0.7688168734312057
  Validation Loss: 0.7455999851226807
  Val ROC-AUC: 0.6931818181818182
  Val Accuracy: 0.5925925970077515
Epoch 8/64:
  Train Loss: 0.7655362784862518
  Validation Loss: 0.7441943883895874
  Val ROC-AUC: 0.6988636363636364
  Val Accuracy: 0.5925925970077515
Epoch 9/64:
  Train Loss: 0.7655797451734543
  Validation Loss: 0.7428171634674072
  Val ROC-AUC: 0.7159090909090909
  Val Accuracy: 0.6296296119689941
Epoch 10/64:
  Train Loss: 0.752235010266304
  Validation Loss: 0.7414901256561279
  Val ROC-AUC: 0.7329545454545454
  Val Accuracy: 0.6296296119689941
Epoch 11/64:
  Train Loss: 0.7529591172933578
  Validation Loss: 0.7401487827301025
  Val ROC-AUC: 0.7386363636363636
  Val Accuracy: 0.6296296119689941
Epoch 12/64:
  Train Loss: 0.752250462770462
  Validation Loss: 0.7388437390327454
  Val ROC-AUC: 0.7329545454545454
  Val Accuracy: 0.6296296119689941
Epoch 13/64:
  Train Loss: 0.7544869929552078
  Validation Loss: 0.737555742263794
  Val ROC-AUC: 0.7329545454545454
  Val Accuracy: 0.6296296119689941
Epoch 14/64:
  Train Loss: 0.7348490059375763
  Validation Loss: 0.7363010048866272
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.6666666865348816
Epoch 15/64:
  Train Loss: 0.750418096780777
  Validation Loss: 0.735083281993866
  Val ROC-AUC: 0.7386363636363635
  Val Accuracy: 0.6666666865348816
Epoch 16/64:
  Train Loss: 0.7477105855941772
  Validation Loss: 0.7338862419128418
  Val ROC-AUC: 0.7556818181818181
  Val Accuracy: 0.6666666865348816
Epoch 17/64:
  Train Loss: 0.7512531876564026
  Validation Loss: 0.7326775193214417
  Val ROC-AUC: 0.7556818181818181
  Val Accuracy: 0.6666666865348816
Epoch 18/64:
  Train Loss: 0.7349433749914169
  Validation Loss: 0.7314987778663635
  Val ROC-AUC: 0.7727272727272727
  Val Accuracy: 0.6666666865348816
Epoch 19/64:
  Train Loss: 0.7305202484130859
  Validation Loss: 0.7303504347801208
  Val ROC-AUC: 0.7727272727272727
  Val Accuracy: 0.6666666865348816
Epoch 20/64:
  Train Loss: 0.744071900844574
  Validation Loss: 0.729203999042511
  Val ROC-AUC: 0.7727272727272727
  Val Accuracy: 0.6666666865348816
Epoch 21/64:
  Train Loss: 0.7331831455230713
  Validation Loss: 0.7280939221382141
  Val ROC-AUC: 0.7670454545454545
  Val Accuracy: 0.7407407760620117
Epoch 22/64:
  Train Loss: 0.7335853576660156
  Validation Loss: 0.7270370125770569
  Val ROC-AUC: 0.7670454545454545
  Val Accuracy: 0.7407407760620117
Epoch 23/64:
  Train Loss: 0.7370857745409012
  Validation Loss: 0.7259559631347656
  Val ROC-AUC: 0.7670454545454545
  Val Accuracy: 0.7407407760620117
Epoch 24/64:
  Train Loss: 0.7351273000240326
  Validation Loss: 0.7248929142951965
  Val ROC-AUC: 0.7670454545454545
  Val Accuracy: 0.7407407760620117
Epoch 25/64:
  Train Loss: 0.7251258790493011
  Validation Loss: 0.7238752841949463
  Val ROC-AUC: 0.7670454545454545
  Val Accuracy: 0.7407407760620117
Epoch 26/64:
  Train Loss: 0.7378515005111694
  Validation Loss: 0.7228494882583618
  Val ROC-AUC: 0.7840909090909091
  Val Accuracy: 0.7407407760620117
Epoch 27/64:
  Train Loss: 0.7371595352888107
  Validation Loss: 0.7218427062034607
  Val ROC-AUC: 0.7897727272727273
  Val Accuracy: 0.7407407760620117
Epoch 28/64:
  Train Loss: 0.7352246344089508
  Validation Loss: 0.7208635807037354
  Val ROC-AUC: 0.8125
  Val Accuracy: 0.7407407760620117
Epoch 29/64:
  Train Loss: 0.7280221581459045
  Validation Loss: 0.7199123501777649
  Val ROC-AUC: 0.8125
  Val Accuracy: 0.7407407760620117
Epoch 30/64:
  Train Loss: 0.7279597669839859
  Validation Loss: 0.7189587950706482
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.7407407760620117
Epoch 31/64:
  Train Loss: 0.7216485440731049
  Validation Loss: 0.7180414795875549
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.7407407760620117
Epoch 32/64:
  Train Loss: 0.7290179133415222
  Validation Loss: 0.7171335816383362
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.7407407760620117
Epoch 33/64:
  Train Loss: 0.7251603752374649
  Validation Loss: 0.7162265777587891
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.7407407760620117
Epoch 34/64:
  Train Loss: 0.7123393714427948
  Validation Loss: 0.7153369784355164
  Val ROC-AUC: 0.8238636363636364
  Val Accuracy: 0.7777777910232544
Epoch 35/64:
  Train Loss: 0.7136272042989731
  Validation Loss: 0.7144827842712402
  Val ROC-AUC: 0.8238636363636364
  Val Accuracy: 0.7777777910232544
Epoch 36/64:
  Train Loss: 0.7339615225791931
  Validation Loss: 0.7136021256446838
  Val ROC-AUC: 0.8295454545454546
  Val Accuracy: 0.7777777910232544
Epoch 37/64:
  Train Loss: 0.7184298485517502
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:15:32:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:32:INFO:
[92mINFO [0m:      Received: evaluate message e79b8884-c409-41fd-b9dc-4f5ce94f2b5b
02/06/2025 11:15:32:INFO:Received: evaluate message e79b8884-c409-41fd-b9dc-4f5ce94f2b5b
[92mINFO [0m:      Sent reply
02/06/2025 11:15:33:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:34:INFO:
[92mINFO [0m:      Received: train message ba871d1f-5224-40dc-b283-7a892dbcecc9
02/06/2025 11:15:34:INFO:Received: train message ba871d1f-5224-40dc-b283-7a892dbcecc9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.7127684950828552
  Val ROC-AUC: 0.8352272727272727
  Val Accuracy: 0.7777777910232544
Epoch 38/64:
  Train Loss: 0.7048958539962769
  Validation Loss: 0.7119200229644775
  Val ROC-AUC: 0.8352272727272727
  Val Accuracy: 0.7777777910232544
Epoch 39/64:
  Train Loss: 0.7044166475534439
  Validation Loss: 0.7111186385154724
  Val ROC-AUC: 0.8352272727272727
  Val Accuracy: 0.7777777910232544
Epoch 40/64:
  Train Loss: 0.7133494466543198
  Validation Loss: 0.7103179693222046
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.7140982151031494
  Validation Loss: 0.709522545337677
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8518518805503845
Epoch 42/64:
  Train Loss: 0.7066994160413742
  Validation Loss: 0.7087357044219971
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8518518805503845
Epoch 43/64:
  Train Loss: 0.7192585319280624
  Validation Loss: 0.7079591155052185
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8518518805503845
Epoch 44/64:
  Train Loss: 0.7103342711925507
  Validation Loss: 0.7072096467018127
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8518518805503845
Epoch 45/64:
  Train Loss: 0.7137434929609299
  Validation Loss: 0.706462025642395
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8518518805503845
Epoch 46/64:
  Train Loss: 0.7111048698425293
  Validation Loss: 0.7057283520698547
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8518518805503845
Epoch 47/64:
  Train Loss: 0.7117913514375687
  Validation Loss: 0.7050065398216248
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.7056549787521362
  Validation Loss: 0.7042807340621948
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.7051326632499695
  Validation Loss: 0.7035782337188721
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.7067327201366425
  Validation Loss: 0.7028565406799316
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.7001740038394928
  Validation Loss: 0.7021663188934326
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6989745795726776
  Validation Loss: 0.7014812231063843
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.7064617276191711
  Validation Loss: 0.7008068561553955
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.687753438949585
  Validation Loss: 0.7001640200614929
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.696370080113411
  Validation Loss: 0.699521005153656
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6907484233379364
  Validation Loss: 0.698880136013031
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.7008528113365173
  Validation Loss: 0.69825679063797
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.6933449655771255
  Validation Loss: 0.6976144909858704
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6898557096719742
  Validation Loss: 0.6970019936561584
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6941522061824799
  Validation Loss: 0.6963908672332764
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6943349689245224
  Validation Loss: 0.695783257484436
  Val ROC-AUC: 0.8465909090909091
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.6981159746646881
  Validation Loss: 0.6951853632926941
  Val ROC-AUC: 0.8465909090909091
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.6919137239456177
  Validation Loss: 0.6946007609367371
  Val ROC-AUC: 0.8465909090909091
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.6884715557098389
  Validation Loss: 0.6940115690231323
  Val ROC-AUC: 0.8409090909090908
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.6884715557098389, 'val_roc_auc': 0.8409090909090908, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.6940115690231323}
 ROC_AUC: 0.8409|| Accuracy 0.8148 || Train Loss: 0.6885
 Val Loss: 0.6940 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7746434091182237
Test ROC-AUC: 0.7159090909090909
Test Accuracy: 0.5955056179775281
test_loss: 0.7746434091182237
test_roc_auc: 0.7159090909090909
test_accuracy: 0.5955056179775281
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7739481776952744
  Validation Loss: 0.6756265759468079
  Val ROC-AUC: 0.7277777777777777
  Val Accuracy: 0.5925925970077515
Epoch 2/64:
  Train Loss: 0.7809112071990967
  Validation Loss: 0.6744967699050903
  Val ROC-AUC: 0.7277777777777777
  Val Accuracy: 0.5925925970077515
Epoch 3/64:
  Train Loss: 0.7606300264596939
  Validation Loss: 0.6731944680213928
  Val ROC-AUC: 0.7277777777777777
  Val Accuracy: 0.5925925970077515
Epoch 4/64:
  Train Loss: 0.7988466918468475
  Validation Loss: 0.6718218326568604
  Val ROC-AUC: 0.7388888888888888
  Val Accuracy: 0.6296296119689941
Epoch 5/64:
  Train Loss: 0.7782239466905594
  Validation Loss: 0.6704173684120178
  Val ROC-AUC: 0.7555555555555555
  Val Accuracy: 0.6296296119689941
Epoch 6/64:
  Train Loss: 0.7791443318128586
  Validation Loss: 0.6690071225166321
  Val ROC-AUC: 0.7666666666666666
  Val Accuracy: 0.6666666865348816
Epoch 7/64:
  Train Loss: 0.764072522521019
  Validation Loss: 0.6675999164581299
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.6666666865348816
Epoch 8/64:
  Train Loss: 0.7737105190753937
  Validation Loss: 0.6662082672119141
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.6666666865348816
Epoch 9/64:
  Train Loss: 0.7613222002983093
  Validation Loss: 0.6648319363594055
  Val ROC-AUC: 0.7833333333333333
  Val Accuracy: 0.6666666865348816
Epoch 10/64:
  Train Loss: 0.7650066614151001
  Validation Loss: 0.6634905934333801
  Val ROC-AUC: 0.7944444444444445
  Val Accuracy: 0.7037037014961243
Epoch 11/64:
  Train Loss: 0.7711046040058136
  Validation Loss: 0.6621647477149963
  Val ROC-AUC: 0.8
  Val Accuracy: 0.7037037014961243
Epoch 12/64:
  Train Loss: 0.7612317949533463
  Validation Loss: 0.6608645915985107
  Val ROC-AUC: 0.7944444444444445
  Val Accuracy: 0.7407407760620117
Epoch 13/64:
  Train Loss: 0.7681838721036911
  Validation Loss: 0.6595635414123535
  Val ROC-AUC: 0.8
  Val Accuracy: 0.7407407760620117
Epoch 14/64:
  Train Loss: 0.7595499902963638
  Validation Loss: 0.6583214998245239
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.7407407760620117
Epoch 15/64:
  Train Loss: 0.7514605671167374
  Validation Loss: 0.6570828557014465
  Val ROC-AUC: 0.8166666666666667
  Val Accuracy: 0.7407407760620117
Epoch 16/64:
  Train Loss: 0.7568192780017853
  Validation Loss: 0.6559115648269653
  Val ROC-AUC: 0.8222222222222222
  Val Accuracy: 0.7407407760620117
Epoch 17/64:
  Train Loss: 0.7595334202051163
  Validation Loss: 0.6547560691833496
  Val ROC-AUC: 0.8222222222222222
  Val Accuracy: 0.7407407760620117
Epoch 18/64:
  Train Loss: 0.750082403421402
  Validation Loss: 0.653612494468689
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.7407407760620117
Epoch 19/64:
  Train Loss: 0.7539892941713333
  Validation Loss: 0.652499794960022
  Val ROC-AUC: 0.8388888888888889
  Val Accuracy: 0.7407407760620117
Epoch 20/64:
  Train Loss: 0.7459020018577576
  Validation Loss: 0.6514177918434143
  Val ROC-AUC: 0.8388888888888889
  Val Accuracy: 0.7407407760620117
Epoch 21/64:
  Train Loss: 0.7443076819181442
  Validation Loss: 0.6503503918647766
  Val ROC-AUC: 0.8555555555555555
  Val Accuracy: 0.7407407760620117
Epoch 22/64:
  Train Loss: 0.7504435330629349
  Validation Loss: 0.6493028998374939
  Val ROC-AUC: 0.8555555555555555
  Val Accuracy: 0.7407407760620117
Epoch 23/64:
  Train Loss: 0.7425550222396851
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:15:39:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:39:INFO:
[92mINFO [0m:      Received: evaluate message c033bf57-252e-4968-af03-4885e42d1a58
02/06/2025 11:15:39:INFO:Received: evaluate message c033bf57-252e-4968-af03-4885e42d1a58
[92mINFO [0m:      Sent reply
02/06/2025 11:15:39:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:39:INFO:
[92mINFO [0m:      Received: train message a445f2a1-229b-4f97-9ab0-9c1b79851374
02/06/2025 11:15:39:INFO:Received: train message a445f2a1-229b-4f97-9ab0-9c1b79851374
  Validation Loss: 0.6482798457145691
  Val ROC-AUC: 0.8555555555555555
  Val Accuracy: 0.7407407760620117
Epoch 24/64:
  Train Loss: 0.7395093888044357
  Validation Loss: 0.647288978099823
  Val ROC-AUC: 0.8555555555555555
  Val Accuracy: 0.7407407760620117
Epoch 25/64:
  Train Loss: 0.7448419779539108
  Validation Loss: 0.6463130712509155
  Val ROC-AUC: 0.8555555555555555
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.7371149957180023
  Validation Loss: 0.6453689336776733
  Val ROC-AUC: 0.8555555555555555
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.7225925475358963
  Validation Loss: 0.6444342732429504
  Val ROC-AUC: 0.8555555555555555
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.7348107844591141
  Validation Loss: 0.6435326337814331
  Val ROC-AUC: 0.8555555555555555
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.737085372209549
  Validation Loss: 0.6426421999931335
  Val ROC-AUC: 0.8611111111111112
  Val Accuracy: 0.7777777910232544
Epoch 30/64:
  Train Loss: 0.7163610458374023
  Validation Loss: 0.6417776346206665
  Val ROC-AUC: 0.8611111111111112
  Val Accuracy: 0.7777777910232544
Epoch 31/64:
  Train Loss: 0.7353886067867279
  Validation Loss: 0.6409288644790649
  Val ROC-AUC: 0.8611111111111112
  Val Accuracy: 0.7777777910232544
Epoch 32/64:
  Train Loss: 0.7233865261077881
  Validation Loss: 0.6401093006134033
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7407407760620117
Epoch 33/64:
  Train Loss: 0.7242963910102844
  Validation Loss: 0.6392714381217957
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.7407407760620117
Epoch 34/64:
  Train Loss: 0.7182892262935638
  Validation Loss: 0.6384700536727905
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.7407407760620117
Epoch 35/64:
  Train Loss: 0.7356839179992676
  Validation Loss: 0.637665867805481
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.7407407760620117
Epoch 36/64:
  Train Loss: 0.7359824478626251
  Validation Loss: 0.6368908286094666
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.7407407760620117
Epoch 37/64:
  Train Loss: 0.7271595150232315
  Validation Loss: 0.6361417174339294
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.7407407760620117
Epoch 38/64:
  Train Loss: 0.73347407579422
  Validation Loss: 0.6353892087936401
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.7407407760620117
Epoch 39/64:
  Train Loss: 0.7152464091777802
  Validation Loss: 0.6346625089645386
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.7777777910232544
Epoch 40/64:
  Train Loss: 0.7269058227539062
  Validation Loss: 0.6339393854141235
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.7777777910232544
Epoch 41/64:
  Train Loss: 0.7274159938097
  Validation Loss: 0.6332466006278992
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.7777777910232544
Epoch 42/64:
  Train Loss: 0.7203335464000702
  Validation Loss: 0.6325679421424866
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.7777777910232544
Epoch 43/64:
  Train Loss: 0.7205744385719299
  Validation Loss: 0.631890058517456
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.7777777910232544
Epoch 44/64:
  Train Loss: 0.7292872965335846
  Validation Loss: 0.6312107443809509
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.7777777910232544
Epoch 45/64:
  Train Loss: 0.7148197144269943
  Validation Loss: 0.6305539011955261
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.7777777910232544
Epoch 46/64:
  Train Loss: 0.725248783826828
  Validation Loss: 0.6299068331718445
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.7777777910232544
Epoch 47/64:
  Train Loss: 0.7238577753305435
  Validation Loss: 0.6292740106582642
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.7777777910232544
Epoch 48/64:
  Train Loss: 0.7197667360305786
  Validation Loss: 0.6286577582359314
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.7777777910232544
Epoch 49/64:
  Train Loss: 0.7194505929946899
  Validation Loss: 0.6280452609062195
  Val ROC-AUC: 0.8944444444444445
  Val Accuracy: 0.7777777910232544
Epoch 50/64:
  Train Loss: 0.7109775543212891
  Validation Loss: 0.6274491548538208
  Val ROC-AUC: 0.8944444444444445
  Val Accuracy: 0.7777777910232544
Epoch 51/64:
  Train Loss: 0.7134560793638229
  Validation Loss: 0.6268787980079651
  Val ROC-AUC: 0.8944444444444445
  Val Accuracy: 0.7777777910232544
Epoch 52/64:
  Train Loss: 0.727796882390976
  Validation Loss: 0.626293957233429
  Val ROC-AUC: 0.8944444444444445
  Val Accuracy: 0.7777777910232544
Epoch 53/64:
  Train Loss: 0.7266481220722198
  Validation Loss: 0.6257184147834778
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 54/64:
  Train Loss: 0.7123763561248779
  Validation Loss: 0.6251581311225891
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 55/64:
  Train Loss: 0.7158709615468979
  Validation Loss: 0.624601423740387
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 56/64:
  Train Loss: 0.7052419781684875
  Validation Loss: 0.6240550875663757
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 57/64:
  Train Loss: 0.7094736397266388
  Validation Loss: 0.6235323548316956
  Val ROC-AUC: 0.9055555555555557
  Val Accuracy: 0.7777777910232544
Epoch 58/64:
  Train Loss: 0.7062762677669525
  Validation Loss: 0.6230063438415527
  Val ROC-AUC: 0.9055555555555557
  Val Accuracy: 0.7777777910232544
Epoch 59/64:
  Train Loss: 0.7037049680948257
  Validation Loss: 0.6224846839904785
  Val ROC-AUC: 0.9055555555555557
  Val Accuracy: 0.7777777910232544
Epoch 60/64:
  Train Loss: 0.7128758281469345
  Validation Loss: 0.621975302696228
  Val ROC-AUC: 0.9055555555555557
  Val Accuracy: 0.7777777910232544
Epoch 61/64:
  Train Loss: 0.7007295936346054
  Validation Loss: 0.6214742064476013
  Val ROC-AUC: 0.9055555555555557
  Val Accuracy: 0.7777777910232544
Epoch 62/64:
  Train Loss: 0.7148347944021225
  Validation Loss: 0.6209899187088013
  Val ROC-AUC: 0.9055555555555557
  Val Accuracy: 0.7777777910232544
Epoch 63/64:
  Train Loss: 0.7032239735126495
  Validation Loss: 0.6204971075057983
  Val ROC-AUC: 0.9055555555555557
  Val Accuracy: 0.7777777910232544
Epoch 64/64:
  Train Loss: 0.7085582911968231
  Validation Loss: 0.6200206875801086
  Val ROC-AUC: 0.9055555555555557
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.7085582911968231, 'val_roc_auc': 0.9055555555555557, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.6200206875801086}
 ROC_AUC: 0.9056|| Accuracy 0.8148 || Train Loss: 0.7086
 Val Loss: 0.6200 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7698561663038275
Test ROC-AUC: 0.7494588744588745
Test Accuracy: 0.5955056179775281
test_loss: 0.7698561663038275
test_roc_auc: 0.7494588744588745
test_accuracy: 0.5955056179775281
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7477412819862366
  Validation Loss: 0.7057099342346191
  Val ROC-AUC: 0.6703296703296704
  Val Accuracy: 0.7037037014961243
Epoch 2/64:
  Train Loss: 0.7620598077774048
  Validation Loss: 0.7046541571617126
  Val ROC-AUC: 0.6813186813186813
  Val Accuracy: 0.7037037014961243
Epoch 3/64:
  Train Loss: 0.7710022479295731
  Validation Loss: 0.7034346461296082
  Val ROC-AUC: 0.6813186813186813
  Val Accuracy: 0.7407407760620117
Epoch 4/64:
  Train Loss: 0.7592192590236664
  Validation Loss: 0.7021490335464478
  Val ROC-AUC: 0.6923076923076923
  Val Accuracy: 0.7407407760620117
Epoch 5/64:
  Train Loss: 0.7581501603126526
  Validation Loss: 0.7008294463157654
  Val ROC-AUC: 0.6923076923076923
  Val Accuracy: 0.7407407760620117
Epoch 6/64:
  Train Loss: 0.7630093991756439
  Validation Loss: 0.6995011568069458
  Val ROC-AUC: 0.7032967032967034
  Val Accuracy: 0.7407407760620117
Epoch 7/64:
  Train Loss: 0.7443514764308929
  Validation Loss: 0.6981730461120605
  Val ROC-AUC: 0.7142857142857143
  Val Accuracy: 0.7407407760620117
Epoch 8/64:
  Train Loss: 0.7524948716163635
  Validation Loss: 0.6968764066696167
  Val ROC-AUC: 0.7197802197802198
  Val Accuracy: 0.7407407760620117
Epoch 9/64:
  Train Loss: 0.7476720213890076
  Validation Loss: 0.6955958008766174
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.7252747252747254
  Val Accuracy: 0.7407407760620117
Epoch 10/64:
  Train Loss: 0.7535327672958374
  Validation Loss: 0.6943476796150208
  Val ROC-AUC: 0.7307692307692307
  Val Accuracy: 0.7407407760620117
Epoch 11/64:
  Train Loss: 0.7426299005746841
  Validation Loss: 0.6931139826774597
  Val ROC-AUC: 0.7417582417582418
  Val Accuracy: 0.7407407760620117
Epoch 12/64:
  Train Loss: 0.7448634505271912
  Validation Loss: 0.6919311285018921
  Val ROC-AUC: 0.7417582417582418
  Val Accuracy: 0.7407407760620117
Epoch 13/64:
  Train Loss: 0.7477167397737503
  Validation Loss: 0.6907450556755066
  Val ROC-AUC: 0.7417582417582418
  Val Accuracy: 0.7407407760620117
Epoch 14/64:
  Train Loss: 0.7405036389827728
  Validation Loss: 0.6896064281463623
  Val ROC-AUC: 0.7417582417582418
  Val Accuracy: 0.7407407760620117
Epoch 15/64:
  Train Loss: 0.75051349401474
  Validation Loss: 0.6885069608688354
  Val ROC-AUC: 0.7417582417582418
  Val Accuracy: 0.7407407760620117
Epoch 16/64:
  Train Loss: 0.7314924448728561
  Validation Loss: 0.6874182224273682
  Val ROC-AUC: 0.7417582417582418
  Val Accuracy: 0.7407407760620117
Epoch 17/64:
  Train Loss: 0.7504730820655823
  Validation Loss: 0.6863661408424377
  Val ROC-AUC: 0.7472527472527474
  Val Accuracy: 0.7407407760620117
Epoch 18/64:
  Train Loss: 0.7306580692529678
  Validation Loss: 0.6853550672531128
  Val ROC-AUC: 0.7582417582417583
  Val Accuracy: 0.7407407760620117
Epoch 19/64:
  Train Loss: 0.737647533416748
  Validation Loss: 0.6843386292457581
  Val ROC-AUC: 0.7582417582417583
  Val Accuracy: 0.7407407760620117
Epoch 20/64:
  Train Loss: 0.7228759378194809
  Validation Loss: 0.683369517326355
  Val ROC-AUC: 0.7582417582417583
  Val Accuracy: 0.7407407760620117
Epoch 21/64:
  Train Loss: 0.7329499423503876
  Validation Loss: 0.6824321150779724
  Val ROC-AUC: 0.7582417582417583
  Val Accuracy: 0.7407407760620117
Epoch 22/64:
  Train Loss: 0.7304446995258331
  Validation Loss: 0.6814994812011719
  Val ROC-AUC: 0.7637362637362638
  Val Accuracy: 0.7407407760620117
Epoch 23/64:
  Train Loss: 0.7275819927453995
  Validation Loss: 0.6805925965309143
  Val ROC-AUC: 0.7637362637362638
  Val Accuracy: 0.7407407760620117
Epoch 24/64:
  Train Loss: 0.7380856722593307
  Validation Loss: 0.6797245144844055
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.7407407760620117
Epoch 25/64:
  Train Loss: 0.7092205286026001
  Validation Loss: 0.6788738369941711
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.7407407760620117
Epoch 26/64:
  Train Loss: 0.7368051558732986
  Validation Loss: 0.6780304908752441
  Val ROC-AUC: 0.7802197802197802
  Val Accuracy: 0.7407407760620117
Epoch 27/64:
  Train Loss: 0.7292295545339584
  Validation Loss: 0.6772295832633972
  Val ROC-AUC: 0.7802197802197802
  Val Accuracy: 0.7407407760620117
Epoch 28/64:
  Train Loss: 0.7145675271749496
  Validation Loss: 0.6764445900917053
  Val ROC-AUC: 0.7802197802197802
  Val Accuracy: 0.7407407760620117
Epoch 29/64:
  Train Loss: 0.725424736738205
  Validation Loss: 0.6756678223609924
  Val ROC-AUC: 0.7857142857142857
  Val Accuracy: 0.7407407760620117
Epoch 30/64:
  Train Loss: 0.7241836488246918
  Validation Loss: 0.6749283075332642
  Val ROC-AUC: 0.7912087912087912
  Val Accuracy: 0.7407407760620117
Epoch 31/64:
  Train Loss: 0.7286082804203033
  Validation Loss: 0.6741814017295837
  Val ROC-AUC: 0.7912087912087912
  Val Accuracy: 0.7407407760620117
Epoch 32/64:
  Train Loss: 0.7235179245471954
  Validation Loss: 0.6734717488288879
  Val ROC-AUC: 0.7967032967032966
  Val Accuracy: 0.7407407760620117
Epoch 33/64:
  Train Loss: 0.7052910178899765
  Validation Loss: 0.6727735996246338
  Val ROC-AUC: 0.7967032967032966
  Val Accuracy: 0.7407407760620117
Epoch 34/64:
  Train Loss: 0.7191358208656311
  Validation Loss: 0.6720702648162842
  Val ROC-AUC: 0.8021978021978021
  Val Accuracy: 0.7407407760620117
Epoch 35/64:
  Train Loss: 0.7263432443141937
  Validation Loss: 0.6714274287223816
  Val ROC-AUC: 0.8021978021978021
  Val Accuracy: 0.7407407760620117
Epoch 36/64:
  Train Loss: 0.7174403071403503
  Validation Loss: 0.6707621216773987
  Val ROC-AUC: 0.8021978021978021
  Val Accuracy: 0.7407407760620117
Epoch 37/64:
  Train Loss: 0.7064040899276733
  Validation Loss: 0.6701279878616333
  Val ROC-AUC: 0.8076923076923077
  Val Accuracy: 0.7407407760620117
Epoch 38/64:
  Train Loss: 0.7086915373802185
  Validation Loss: 0.6694965958595276
  Val ROC-AUC: 0.8076923076923077
  Val Accuracy: 0.7407407760620117
Epoch 39/64:
  Train Loss: 0.7171604782342911
  Validation Loss: 0.6688735485076904
  Val ROC-AUC: 0.8076923076923077
  Val Accuracy: 0.7407407760620117
Epoch 40/64:
  Train Loss: 0.7180997878313065
  Validation Loss: 0.6682774424552917
  Val ROC-AUC: 0.8076923076923077
  Val Accuracy: 0.7407407760620117
Epoch 41/64:
  Train Loss: 0.7125013619661331
  Validation Loss: 0.6676912903785706
  Val ROC-AUC: 0.8076923076923077
  Val Accuracy: 0.7407407760620117
Epoch 42/64:
  Train Loss: 0.7122738063335419
  Validation Loss: 0.6671183705329895
  Val ROC-AUC: 0.8076923076923077
  Val Accuracy: 0.7407407760620117
Epoch 43/64:
  Train Loss: 0.6969742327928543
  Validation Loss: 0.6665629148483276
  Val ROC-AUC: 0.8131868131868132
  Val Accuracy: 0.7407407760620117
Epoch 44/64:
  Train Loss: 0.708778440952301
  Validation Loss: 0.6660334467887878
  Val ROC-AUC: 0.8131868131868132
  Val Accuracy: 0.7407407760620117
Epoch 45/64:
  Train Loss: 0.70233054459095
  Validation Loss: 0.665488064289093
  Val ROC-AUC: 0.8131868131868132
  Val Accuracy: 0.7407407760620117
Epoch 46/64:
  Train Loss: 0.7094840854406357
  Validation Loss: 0.6649672389030457
  Val ROC-AUC: 0.8186813186813187
  Val Accuracy: 0.7407407760620117
Epoch 47/64:
  Train Loss: 0.6960936188697815
  Validation Loss: 0.6644546389579773
  Val ROC-AUC: 0.8186813186813187
  Val Accuracy: 0.7407407760620117
Epoch 48/64:
  Train Loss: 0.6973268240690231
  Validation Loss: 0.6639493107795715
  Val ROC-AUC: 0.8186813186813187
  Val Accuracy: 0.7407407760620117
Epoch 49/64:
  Train Loss: 0.6939249783754349
  Validation Loss: 0.6634560823440552
  Val ROC-AUC: 0.8186813186813187
  Val Accuracy: 0.7407407760620117
Epoch 50/64:
  Train Loss: 0.7031255662441254
  Validation Loss: 0.6629781126976013
  Val ROC-AUC: 0.8186813186813187
  Val Accuracy: 0.7407407760620117
Epoch 51/64:
  Train Loss: 0.6892704367637634
  Validation Loss: 0.6625017523765564
  Val ROC-AUC: 0.8186813186813187
  Val Accuracy: 0.7407407760620117
Epoch 52/64:
  Train Loss: 0.6995600163936615
  Validation Loss: 0.6620323657989502
  Val ROC-AUC: 0.8186813186813187
  Val Accuracy: 0.7037037014961243
Epoch 53/64:
  Train Loss: 0.7041959464550018
  Validation Loss: 0.6615774631500244
  Val ROC-AUC: 0.8186813186813187
  Val Accuracy: 0.7037037014961243
Epoch 54/64:
  Train Loss: 0.698522537946701
  Validation Loss: 0.6611377596855164
  Val ROC-AUC: 0.8241758241758241
  Val Accuracy: 0.7037037014961243
Epoch 55/64:
  Train Loss: 0.6986197382211685
  Validation Loss: 0.6607018709182739
  Val ROC-AUC: 0.8241758241758241
  Val Accuracy: 0.7037037014961243
Epoch 56/64:
  Train Loss: 0.6948249936103821
  Validation Loss: 0.6602690815925598
  Val ROC-AUC: 0.8241758241758241
  Val Accuracy: 0.7037037014961243
Epoch 57/64:
  Train Loss: 0.6831783056259155
  Validation Loss: 0.6598488092422485
  Val ROC-AUC: 0.8241758241758241
  Val Accuracy: 0.7037037014961243
Epoch 58/64:
  Train Loss: 0.7084993273019791
  Validation Loss: 0.6594327092170715
  Val ROC-AUC: 0.8241758241758241
  Val Accuracy: 0.7407407760620117
Epoch 59/64:
  Train Loss: 0.6910938620567322
  Validation Loss: 0.6590206623077393
  Val ROC-AUC: 0.8241758241758241
  Val Accuracy: 0.7407407760620117
Epoch 60/64:
  Train Loss: 0.6986728757619858
  Validation Loss: 0.6586183905601501
  Val ROC-AUC: 0.8351648351648352
  Val Accuracy: 0.7407407760620117
Epoch 61/64:
  Train Loss: 0.7098644375801086
  Validation Loss: 0.6582304835319519
  Val ROC-AUC: 0.8406593406593407
  Val Accuracy: 0.7407407760620117
Epoch 62/64:
  Train Loss: 0.6995647549629211
  Validation Loss: 0.6578509211540222
  Val ROC-AUC: 0.8406593406593407
  Val Accuracy: 0.7407407760620117
Epoch 63/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:15:44:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:45:INFO:
[92mINFO [0m:      Received: evaluate message 074542be-f872-43e8-b8bc-c82fcc55e862
02/06/2025 11:15:45:INFO:Received: evaluate message 074542be-f872-43e8-b8bc-c82fcc55e862
[92mINFO [0m:      Sent reply
02/06/2025 11:15:46:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:46:INFO:
[92mINFO [0m:      Received: train message f72cb221-1301-47e6-a73a-15ba65719ad2
02/06/2025 11:15:46:INFO:Received: train message f72cb221-1301-47e6-a73a-15ba65719ad2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6921092718839645
  Validation Loss: 0.6574677228927612
  Val ROC-AUC: 0.8406593406593407
  Val Accuracy: 0.7407407760620117
Epoch 64/64:
  Train Loss: 0.6935500353574753
  Validation Loss: 0.6571003794670105
  Val ROC-AUC: 0.8406593406593407
  Val Accuracy: 0.7407407760620117
{'train_loss': 0.6935500353574753, 'val_roc_auc': 0.8406593406593407, 'val_accuracy': 0.7407407760620117, 'val_loss': 0.6571003794670105}
 ROC_AUC: 0.8407|| Accuracy 0.7407 || Train Loss: 0.6936
 Val Loss: 0.6571 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7647257236282478
Test ROC-AUC: 0.7765151515151515
Test Accuracy: 0.6404494382022472
test_loss: 0.7647257236282478
test_roc_auc: 0.7765151515151515
test_accuracy: 0.6404494382022472
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7634437680244446
  Validation Loss: 0.6892540454864502
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.7573592364788055
  Validation Loss: 0.6884459257125854
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.7579611986875534
  Validation Loss: 0.6875200867652893
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.7695888429880142
  Validation Loss: 0.686582088470459
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.7548628151416779
  Validation Loss: 0.685619592666626
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.766518622636795
  Validation Loss: 0.6846610307693481
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.7500375956296921
  Validation Loss: 0.6836967468261719
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.7508849799633026
  Validation Loss: 0.6827690601348877
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.7529381811618805
  Validation Loss: 0.6818384528160095
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.7486046105623245
  Validation Loss: 0.6809319257736206
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.7488584220409393
  Validation Loss: 0.6800721287727356
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.7481298595666885
  Validation Loss: 0.6792174577713013
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7291992157697678
  Validation Loss: 0.6783932447433472
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.735563337802887
  Validation Loss: 0.6775810718536377
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.7359617054462433
  Validation Loss: 0.6767924427986145
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.726685643196106
  Validation Loss: 0.6760144233703613
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.72731813788414
  Validation Loss: 0.675283670425415
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7320119440555573
  Validation Loss: 0.6745544075965881
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7337095439434052
  Validation Loss: 0.6738627552986145
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.7406380921602249
  Validation Loss: 0.6731663942337036
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.7309983372688293
  Validation Loss: 0.6724938154220581
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.7276123464107513
  Validation Loss: 0.6718314290046692
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7272126972675323
  Validation Loss: 0.6711947917938232
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.7268381416797638
  Validation Loss: 0.6705900430679321
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.7251722812652588
  Validation Loss: 0.6699844598770142
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.7078912407159805
  Validation Loss: 0.6693935990333557
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.7290573120117188
  Validation Loss: 0.6688339114189148
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.7207085341215134
  Validation Loss: 0.6682718396186829
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.7207454741001129
  Validation Loss: 0.6677291393280029
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.72427898645401
  Validation Loss: 0.6672046780586243
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7014445662498474
  Validation Loss: 0.6666853427886963
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.7122985422611237
  Validation Loss: 0.6661625504493713
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.7147940993309021
  Validation Loss: 0.6656674146652222
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.7149732410907745
  Validation Loss: 0.665189802646637
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6984647363424301
  Validation Loss: 0.6646916270256042
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7117239087820053
  Validation Loss: 0.6642293334007263
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7037067413330078
  Validation Loss: 0.6637555360794067
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6993397325277328
  Validation Loss: 0.6633098125457764
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7036575227975845
  Validation Loss: 0.6628850102424622
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7045500129461288
  Validation Loss: 0.6624550819396973
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7095208764076233
  Validation Loss: 0.6620349287986755
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.7101140022277832
  Validation Loss: 0.6616203784942627
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.7088901251554489
  Validation Loss: 0.6612222790718079
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.7038320302963257
  Validation Loss: 0.6608229279518127
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.7187453508377075
  Validation Loss: 0.6604422330856323
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.7154277861118317
  Validation Loss: 0.6600554585456848
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.706098809838295
  Validation Loss: 0.659683108329773
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.7155794650316238
  Validation Loss: 0.6593153476715088
  Val ROC-AUC: 0.9666666666666667
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:15:51:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:51:INFO:
[92mINFO [0m:      Received: evaluate message 23120fc2-64bb-44e5-8bb5-7cf33df9b55a
02/06/2025 11:15:51:INFO:Received: evaluate message 23120fc2-64bb-44e5-8bb5-7cf33df9b55a
[92mINFO [0m:      Sent reply
02/06/2025 11:15:53:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:53:INFO:
[92mINFO [0m:      Received: train message 59dda510-ed4f-4ab7-bf56-3d709f560cd0
02/06/2025 11:15:53:INFO:Received: train message 59dda510-ed4f-4ab7-bf56-3d709f560cd0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.7086815387010574
  Validation Loss: 0.6589449048042297
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.7011470198631287
  Validation Loss: 0.6586039662361145
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6927123218774796
  Validation Loss: 0.6582538485527039
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6967672407627106
  Validation Loss: 0.6579140424728394
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6990193277597427
  Validation Loss: 0.6575862169265747
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.7089362442493439
  Validation Loss: 0.6572709083557129
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6946210563182831
  Validation Loss: 0.6569476127624512
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.7002904415130615
  Validation Loss: 0.6566145420074463
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.7010293155908585
  Validation Loss: 0.6563028693199158
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6879159361124039
  Validation Loss: 0.6559897661209106
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.7012771964073181
  Validation Loss: 0.6556750535964966
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6878696233034134
  Validation Loss: 0.6553729772567749
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.688711866736412
  Validation Loss: 0.6550865173339844
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6878163367509842
  Validation Loss: 0.6548022627830505
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6873491853475571
  Validation Loss: 0.654503583908081
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6966592222452164
  Validation Loss: 0.6542220115661621
  Val ROC-AUC: 0.9666666666666667
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6966592222452164, 'val_roc_auc': 0.9666666666666667, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6542220115661621}
 ROC_AUC: 0.9667|| Accuracy 0.8889 || Train Loss: 0.6967
 Val Loss: 0.6542 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7594502096095782
Test ROC-AUC: 0.7949134199134199
Test Accuracy: 0.6853932584269663
test_loss: 0.7594502096095782
test_roc_auc: 0.7949134199134199
test_accuracy: 0.6853932584269663
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7313787192106247
  Validation Loss: 0.7620205283164978
  Val ROC-AUC: 0.7901234567901234
  Val Accuracy: 0.6666666865348816
Epoch 2/64:
  Train Loss: 0.7344232648611069
  Validation Loss: 0.7608795166015625
  Val ROC-AUC: 0.7962962962962963
  Val Accuracy: 0.7037037014961243
Epoch 3/64:
  Train Loss: 0.7198891341686249
  Validation Loss: 0.7596038579940796
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 4/64:
  Train Loss: 0.7246144115924835
  Validation Loss: 0.7582653164863586
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.7037037014961243
Epoch 5/64:
  Train Loss: 0.7282462418079376
  Validation Loss: 0.7569423317909241
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.7037037014961243
Epoch 6/64:
  Train Loss: 0.7259086221456528
  Validation Loss: 0.7555513978004456
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.7037037014961243
Epoch 7/64:
  Train Loss: 0.7260020077228546
  Validation Loss: 0.7542168498039246
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.7037037014961243
Epoch 8/64:
  Train Loss: 0.733289897441864
  Validation Loss: 0.7528601884841919
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.7037037014961243
Epoch 9/64:
  Train Loss: 0.7305016219615936
  Validation Loss: 0.7515110969543457
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.7037037014961243
Epoch 10/64:
  Train Loss: 0.7202868461608887
  Validation Loss: 0.7501901984214783
  Val ROC-AUC: 0.8456790123456789
  Val Accuracy: 0.7037037014961243
Epoch 11/64:
  Train Loss: 0.7121885418891907
  Validation Loss: 0.7489018440246582
  Val ROC-AUC: 0.8456790123456789
  Val Accuracy: 0.7037037014961243
Epoch 12/64:
  Train Loss: 0.7102420181035995
  Validation Loss: 0.747643768787384
  Val ROC-AUC: 0.8456790123456789
  Val Accuracy: 0.7407407760620117
Epoch 13/64:
  Train Loss: 0.7273453325033188
  Validation Loss: 0.7464293837547302
  Val ROC-AUC: 0.8518518518518517
  Val Accuracy: 0.7407407760620117
Epoch 14/64:
  Train Loss: 0.7174324542284012
  Validation Loss: 0.7452206015586853
  Val ROC-AUC: 0.8518518518518517
  Val Accuracy: 0.7777777910232544
Epoch 15/64:
  Train Loss: 0.7183497250080109
  Validation Loss: 0.7440221905708313
  Val ROC-AUC: 0.8518518518518517
  Val Accuracy: 0.7777777910232544
Epoch 16/64:
  Train Loss: 0.7113903015851974
  Validation Loss: 0.7428350448608398
  Val ROC-AUC: 0.8580246913580246
  Val Accuracy: 0.7777777910232544
Epoch 17/64:
  Train Loss: 0.7158428430557251
  Validation Loss: 0.7416754364967346
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7777777910232544
Epoch 18/64:
  Train Loss: 0.7059363573789597
  Validation Loss: 0.7405566573143005
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.7124470919370651
  Validation Loss: 0.7394837141036987
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.7054674178361893
  Validation Loss: 0.7383808493614197
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.7127649784088135
  Validation Loss: 0.7372990250587463
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.7134422361850739
  Validation Loss: 0.7362400889396667
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.7102552354335785
  Validation Loss: 0.7351967692375183
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.7048269212245941
  Validation Loss: 0.7341790199279785
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.7144683748483658
  Validation Loss: 0.7332099080085754
  Val ROC-AUC: 0.8765432098765432
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6894774883985519
  Validation Loss: 0.7322143912315369
  Val ROC-AUC: 0.8765432098765432
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6940862387418747
  Validation Loss: 0.7312549352645874
  Val ROC-AUC: 0.8765432098765432
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6993411183357239
  Validation Loss: 0.730293869972229
  Val ROC-AUC: 0.8765432098765432
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6901720017194748
  Validation Loss: 0.7294236421585083
  Val ROC-AUC: 0.8765432098765432
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6998498290777206
  Validation Loss: 0.7284890413284302
  Val ROC-AUC: 0.8827160493827162
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.6907306462526321
  Validation Loss: 0.7275844812393188
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.691552996635437
  Validation Loss: 0.7267237305641174
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8518518805503845
Epoch 33/64:
  Train Loss: 0.6923822313547134
  Validation Loss: 0.7258593440055847
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6976111531257629
  Validation Loss: 0.7250308990478516
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:15:58:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:15:58:INFO:
[92mINFO [0m:      Received: evaluate message 5751555e-c982-45bc-901d-c0480e1a7efe
02/06/2025 11:15:58:INFO:Received: evaluate message 5751555e-c982-45bc-901d-c0480e1a7efe
[92mINFO [0m:      Sent reply
02/06/2025 11:16:00:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:00:INFO:
[92mINFO [0m:      Received: train message fc17c1f2-fa89-49f6-bd1e-8f750dfaad0c
02/06/2025 11:16:00:INFO:Received: train message fc17c1f2-fa89-49f6-bd1e-8f750dfaad0c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.7011678367853165
  Validation Loss: 0.7241831421852112
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6859244555234909
  Validation Loss: 0.7233742475509644
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6931055784225464
  Validation Loss: 0.7225672006607056
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7008485794067383
  Validation Loss: 0.7217966318130493
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6799345165491104
  Validation Loss: 0.7210209965705872
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6986213028430939
  Validation Loss: 0.7202693223953247
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6900390982627869
  Validation Loss: 0.7195396423339844
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6977135390043259
  Validation Loss: 0.7188042402267456
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.688954696059227
  Validation Loss: 0.7180857062339783
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6972496807575226
  Validation Loss: 0.7173611521720886
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6887376010417938
  Validation Loss: 0.7166458964347839
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6912106275558472
  Validation Loss: 0.7159676551818848
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6816031783819199
  Validation Loss: 0.715290904045105
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6905559599399567
  Validation Loss: 0.7146148681640625
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.675912395119667
  Validation Loss: 0.7139571905136108
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6897589713335037
  Validation Loss: 0.7133097052574158
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6822271943092346
  Validation Loss: 0.7126675248146057
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6802695691585541
  Validation Loss: 0.7120349407196045
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6918534934520721
  Validation Loss: 0.7114123702049255
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6815146207809448
  Validation Loss: 0.7107865214347839
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6780273020267487
  Validation Loss: 0.7101843953132629
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6791595220565796
  Validation Loss: 0.7096091508865356
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.667951226234436
  Validation Loss: 0.7090288996696472
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6872095018625259
  Validation Loss: 0.7084571123123169
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6823487728834152
  Validation Loss: 0.7078902125358582
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6729496568441391
  Validation Loss: 0.7073033452033997
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6826075911521912
  Validation Loss: 0.7067630887031555
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6816079765558243
  Validation Loss: 0.7062493562698364
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6832290589809418
  Validation Loss: 0.7056987881660461
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6628828197717667
  Validation Loss: 0.7051873207092285
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6628828197717667, 'val_roc_auc': 0.9074074074074074, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.7051873207092285}
 ROC_AUC: 0.9074|| Accuracy 0.9259 || Train Loss: 0.6629
 Val Loss: 0.7052 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7540900774216384
Test ROC-AUC: 0.8122294372294373
Test Accuracy: 0.7078651685393258
test_loss: 0.7540900774216384
test_roc_auc: 0.8122294372294373
test_accuracy: 0.7078651685393258
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7358856350183487
  Validation Loss: 0.768349289894104
  Val ROC-AUC: 0.6776315789473685
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.713348850607872
  Validation Loss: 0.7673996090888977
  Val ROC-AUC: 0.6776315789473685
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7250314652919769
  Validation Loss: 0.7663528919219971
  Val ROC-AUC: 0.6842105263157895
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7278167903423309
  Validation Loss: 0.765249490737915
  Val ROC-AUC: 0.6842105263157895
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.7194686830043793
  Validation Loss: 0.7641333341598511
  Val ROC-AUC: 0.6842105263157895
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.7119206935167313
  Validation Loss: 0.7629973292350769
  Val ROC-AUC: 0.6842105263157895
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.7105040848255157
  Validation Loss: 0.7618899941444397
  Val ROC-AUC: 0.6842105263157895
  Val Accuracy: 0.7777777910232544
Epoch 8/64:
  Train Loss: 0.7319933176040649
  Validation Loss: 0.760784387588501
  Val ROC-AUC: 0.7039473684210527
  Val Accuracy: 0.7777777910232544
Epoch 9/64:
  Train Loss: 0.7244016975164413
  Validation Loss: 0.7597130537033081
  Val ROC-AUC: 0.7105263157894737
  Val Accuracy: 0.7777777910232544
Epoch 10/64:
  Train Loss: 0.7128056436777115
  Validation Loss: 0.7586380243301392
  Val ROC-AUC: 0.7105263157894737
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7208073735237122
  Validation Loss: 0.7575834393501282
  Val ROC-AUC: 0.7105263157894737
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7166761606931686
  Validation Loss: 0.7565640211105347
  Val ROC-AUC: 0.7171052631578947
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.7024613469839096
  Validation Loss: 0.7555853724479675
  Val ROC-AUC: 0.7171052631578947
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.7186414450407028
  Validation Loss: 0.7546245455741882
  Val ROC-AUC: 0.7302631578947368
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.712316021323204
  Validation Loss: 0.7536879777908325
  Val ROC-AUC: 0.743421052631579
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7084988355636597
  Validation Loss: 0.7527647018432617
  Val ROC-AUC: 0.743421052631579
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.7033266425132751
  Validation Loss: 0.7518856525421143
  Val ROC-AUC: 0.743421052631579
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6944408118724823
  Validation Loss: 0.7510178089141846
  Val ROC-AUC: 0.743421052631579
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6935535222291946
  Validation Loss: 0.7501785755157471
  Val ROC-AUC: 0.743421052631579
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.7016221284866333
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:16:05:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:05:INFO:
[92mINFO [0m:      Received: evaluate message a2d602de-35b3-4757-9f38-d92afc5feb8b
02/06/2025 11:16:05:INFO:Received: evaluate message a2d602de-35b3-4757-9f38-d92afc5feb8b
[92mINFO [0m:      Sent reply
02/06/2025 11:16:07:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:07:INFO:
[92mINFO [0m:      Received: train message 9e626d91-0bf3-43bb-8afa-969f1aebd64f
02/06/2025 11:16:07:INFO:Received: train message 9e626d91-0bf3-43bb-8afa-969f1aebd64f
  Validation Loss: 0.7493581771850586
  Val ROC-AUC: 0.743421052631579
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.7058096081018448
  Validation Loss: 0.7485687732696533
  Val ROC-AUC: 0.75
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.7017496675252914
  Validation Loss: 0.7477779984474182
  Val ROC-AUC: 0.75
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.700886532664299
  Validation Loss: 0.7470145225524902
  Val ROC-AUC: 0.756578947368421
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.7037492245435715
  Validation Loss: 0.7462802529335022
  Val ROC-AUC: 0.7631578947368421
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.6908796727657318
  Validation Loss: 0.7455511689186096
  Val ROC-AUC: 0.756578947368421
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6976732760667801
  Validation Loss: 0.7448253035545349
  Val ROC-AUC: 0.756578947368421
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6987906694412231
  Validation Loss: 0.7441233992576599
  Val ROC-AUC: 0.763157894736842
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6853830516338348
  Validation Loss: 0.743445098400116
  Val ROC-AUC: 0.763157894736842
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.7019721120595932
  Validation Loss: 0.7428010106086731
  Val ROC-AUC: 0.763157894736842
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6783517748117447
  Validation Loss: 0.742156445980072
  Val ROC-AUC: 0.7697368421052632
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6866353303194046
  Validation Loss: 0.7415179014205933
  Val ROC-AUC: 0.7697368421052632
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6830130219459534
  Validation Loss: 0.740886926651001
  Val ROC-AUC: 0.7697368421052632
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6925182044506073
  Validation Loss: 0.7402900457382202
  Val ROC-AUC: 0.7697368421052632
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6803037524223328
  Validation Loss: 0.7396994829177856
  Val ROC-AUC: 0.7697368421052632
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6786153465509415
  Validation Loss: 0.739128589630127
  Val ROC-AUC: 0.7828947368421053
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6985047459602356
  Validation Loss: 0.7385588884353638
  Val ROC-AUC: 0.7828947368421053
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6775576323270798
  Validation Loss: 0.7380024790763855
  Val ROC-AUC: 0.7828947368421053
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6896254867315292
  Validation Loss: 0.7374529242515564
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6958242207765579
  Validation Loss: 0.7369242906570435
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.677061527967453
  Validation Loss: 0.7364212274551392
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6770634651184082
  Validation Loss: 0.73590087890625
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6825233548879623
  Validation Loss: 0.7354018092155457
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6642174273729324
  Validation Loss: 0.7349178791046143
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.681402400135994
  Validation Loss: 0.73445725440979
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.6743259727954865
  Validation Loss: 0.7339667677879333
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6800156384706497
  Validation Loss: 0.7335138916969299
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.676760733127594
  Validation Loss: 0.7330501675605774
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.6967772394418716
  Validation Loss: 0.732604444026947
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6811361461877823
  Validation Loss: 0.7321723699569702
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.6651791781187057
  Validation Loss: 0.7317415475845337
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.6705552637577057
  Validation Loss: 0.7313185930252075
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.68692946434021
  Validation Loss: 0.7309393882751465
  Val ROC-AUC: 0.7960526315789473
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.6600111871957779
  Validation Loss: 0.7305309176445007
  Val ROC-AUC: 0.8026315789473685
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.6753335446119308
  Validation Loss: 0.730124294757843
  Val ROC-AUC: 0.8026315789473685
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6707311868667603
  Validation Loss: 0.7297362089157104
  Val ROC-AUC: 0.8026315789473685
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6677883863449097
  Validation Loss: 0.7293544411659241
  Val ROC-AUC: 0.8026315789473685
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.6774544268846512
  Validation Loss: 0.7289913892745972
  Val ROC-AUC: 0.8026315789473685
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.6638484597206116
  Validation Loss: 0.7286149263381958
  Val ROC-AUC: 0.8026315789473685
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6763862818479538
  Validation Loss: 0.7282512784004211
  Val ROC-AUC: 0.8026315789473685
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6667677462100983
  Validation Loss: 0.727907121181488
  Val ROC-AUC: 0.8026315789473685
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6731326133012772
  Validation Loss: 0.7275456190109253
  Val ROC-AUC: 0.8092105263157895
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.6723804622888565
  Validation Loss: 0.7272049188613892
  Val ROC-AUC: 0.8092105263157895
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.663441076874733
  Validation Loss: 0.7268601655960083
  Val ROC-AUC: 0.8092105263157895
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.67433100938797
  Validation Loss: 0.726528525352478
  Val ROC-AUC: 0.8092105263157895
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.67433100938797, 'val_roc_auc': 0.8092105263157895, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.726528525352478}
 ROC_AUC: 0.8092|| Accuracy 0.8148 || Train Loss: 0.6743
 Val Loss: 0.7265 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7487446153431796
Test ROC-AUC: 0.8235930735930737
Test Accuracy: 0.7303370786516854
test_loss: 0.7487446153431796
test_roc_auc: 0.8235930735930737
test_accuracy: 0.7303370786516854
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7230837941169739
  Validation Loss: 0.7116072177886963
  Val ROC-AUC: 0.7833333333333334
  Val Accuracy: 0.7037037014961243
Epoch 2/64:
  Train Loss: 0.7230740487575531
  Validation Loss: 0.7104864716529846
  Val ROC-AUC: 0.7888888888888889
  Val Accuracy: 0.7407407760620117
Epoch 3/64:
  Train Loss: 0.733309805393219
  Validation Loss: 0.7092389464378357
  Val ROC-AUC: 0.7944444444444445
  Val Accuracy: 0.7407407760620117
Epoch 4/64:
  Train Loss: 0.7216689884662628
  Validation Loss: 0.7079673409461975
  Val ROC-AUC: 0.7944444444444445
  Val Accuracy: 0.7407407760620117
Epoch 5/64:
  Train Loss: 0.7203877866268158
  Validation Loss: 0.7066142559051514
  Val ROC-AUC: 0.8
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.7299156486988068
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.7052979469299316
  Val ROC-AUC: 0.8
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.7363296449184418
  Validation Loss: 0.7039616703987122
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.7777777910232544
Epoch 8/64:
  Train Loss: 0.7199512422084808
  Validation Loss: 0.7026912569999695
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.7777777910232544
Epoch 9/64:
  Train Loss: 0.7270171642303467
  Validation Loss: 0.7014340162277222
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.7777777910232544
Epoch 10/64:
  Train Loss: 0.7362693846225739
  Validation Loss: 0.7001396417617798
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.7777777910232544
Epoch 11/64:
  Train Loss: 0.7017354816198349
  Validation Loss: 0.6988993883132935
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.7407407760620117
Epoch 12/64:
  Train Loss: 0.718058854341507
  Validation Loss: 0.6977015137672424
  Val ROC-AUC: 0.8166666666666667
  Val Accuracy: 0.7407407760620117
Epoch 13/64:
  Train Loss: 0.7163859158754349
  Validation Loss: 0.696533203125
  Val ROC-AUC: 0.8222222222222222
  Val Accuracy: 0.7407407760620117
Epoch 14/64:
  Train Loss: 0.7105999141931534
  Validation Loss: 0.6954039335250854
  Val ROC-AUC: 0.8222222222222222
  Val Accuracy: 0.7407407760620117
Epoch 15/64:
  Train Loss: 0.7057220488786697
  Validation Loss: 0.6942984461784363
  Val ROC-AUC: 0.8222222222222222
  Val Accuracy: 0.7407407760620117
Epoch 16/64:
  Train Loss: 0.7174358814954758
  Validation Loss: 0.6931725144386292
  Val ROC-AUC: 0.8277777777777778
  Val Accuracy: 0.7407407760620117
Epoch 17/64:
  Train Loss: 0.7087045758962631
  Validation Loss: 0.6920896768569946
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7407407760620117
Epoch 18/64:
  Train Loss: 0.7046906054019928
  Validation Loss: 0.6910762190818787
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7407407760620117
Epoch 19/64:
  Train Loss: 0.7004453390836716
  Validation Loss: 0.6900416016578674
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7407407760620117
Epoch 20/64:
  Train Loss: 0.7068623006343842
  Validation Loss: 0.6890213489532471
  Val ROC-AUC: 0.8444444444444444
  Val Accuracy: 0.7407407760620117
Epoch 21/64:
  Train Loss: 0.7110466957092285
  Validation Loss: 0.6880669593811035
  Val ROC-AUC: 0.8444444444444444
  Val Accuracy: 0.7407407760620117
Epoch 22/64:
  Train Loss: 0.6979901343584061
  Validation Loss: 0.6870676279067993
  Val ROC-AUC: 0.85
  Val Accuracy: 0.7407407760620117
Epoch 23/64:
  Train Loss: 0.7042000144720078
  Validation Loss: 0.6861492991447449
  Val ROC-AUC: 0.85
  Val Accuracy: 0.7407407760620117
Epoch 24/64:
  Train Loss: 0.6988379210233688
  Validation Loss: 0.6852243542671204
  Val ROC-AUC: 0.85
  Val Accuracy: 0.7407407760620117
Epoch 25/64:
  Train Loss: 0.7235189974308014
  Validation Loss: 0.6843209266662598
  Val ROC-AUC: 0.8555555555555556
  Val Accuracy: 0.7407407760620117
Epoch 26/64:
  Train Loss: 0.7039863020181656
  Validation Loss: 0.6834479570388794
  Val ROC-AUC: 0.8555555555555556
  Val Accuracy: 0.7407407760620117
Epoch 27/64:
  Train Loss: 0.7159180790185928
  Validation Loss: 0.6825947165489197
  Val ROC-AUC: 0.8555555555555556
  Val Accuracy: 0.7407407760620117
Epoch 28/64:
  Train Loss: 0.7153809070587158
  Validation Loss: 0.6817301511764526
  Val ROC-AUC: 0.8555555555555556
  Val Accuracy: 0.7407407760620117
Epoch 29/64:
  Train Loss: 0.7114214897155762
  Validation Loss: 0.680902898311615
  Val ROC-AUC: 0.8555555555555556
  Val Accuracy: 0.7407407760620117
Epoch 30/64:
  Train Loss: 0.706516295671463
  Validation Loss: 0.6800978183746338
  Val ROC-AUC: 0.8555555555555556
  Val Accuracy: 0.7407407760620117
Epoch 31/64:
  Train Loss: 0.700135812163353
  Validation Loss: 0.6792911291122437
  Val ROC-AUC: 0.8555555555555556
  Val Accuracy: 0.7407407760620117
Epoch 32/64:
  Train Loss: 0.7007190436124802
  Validation Loss: 0.6785011887550354
  Val ROC-AUC: 0.8555555555555556
  Val Accuracy: 0.7407407760620117
Epoch 33/64:
  Train Loss: 0.6955226957798004
  Validation Loss: 0.6777715086936951
  Val ROC-AUC: 0.8555555555555556
  Val Accuracy: 0.7407407760620117
Epoch 34/64:
  Train Loss: 0.6902130544185638
  Validation Loss: 0.6770341992378235
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.7407407760620117
Epoch 35/64:
  Train Loss: 0.6842841058969498
  Validation Loss: 0.6762902140617371
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7407407760620117
Epoch 36/64:
  Train Loss: 0.704320415854454
  Validation Loss: 0.6755810976028442
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7407407760620117
Epoch 37/64:
  Train Loss: 0.689605325460434
  Validation Loss: 0.6749014854431152
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7407407760620117
Epoch 38/64:
  Train Loss: 0.7080604881048203
  Validation Loss: 0.6741885542869568
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7407407760620117
Epoch 39/64:
  Train Loss: 0.6917418837547302
  Validation Loss: 0.6735098958015442
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7407407760620117
Epoch 40/64:
  Train Loss: 0.6865488588809967
  Validation Loss: 0.672818660736084
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7777777910232544
Epoch 41/64:
  Train Loss: 0.7059316039085388
  Validation Loss: 0.6721668243408203
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7777777910232544
Epoch 42/64:
  Train Loss: 0.6939481943845749
  Validation Loss: 0.67152339220047
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7777777910232544
Epoch 43/64:
  Train Loss: 0.6974833309650421
  Validation Loss: 0.6709207892417908
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7777777910232544
Epoch 44/64:
  Train Loss: 0.6953509002923965
  Validation Loss: 0.6703146696090698
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7777777910232544
Epoch 45/64:
  Train Loss: 0.6822383850812912
  Validation Loss: 0.669666588306427
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7777777910232544
Epoch 46/64:
  Train Loss: 0.6928362548351288
  Validation Loss: 0.6690607666969299
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7777777910232544
Epoch 47/64:
  Train Loss: 0.6868203580379486
  Validation Loss: 0.6684971451759338
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7777777910232544
Epoch 48/64:
  Train Loss: 0.6946633160114288
  Validation Loss: 0.667937695980072
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7777777910232544
Epoch 49/64:
  Train Loss: 0.6982751488685608
  Validation Loss: 0.6673708558082581
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7777777910232544
Epoch 50/64:
  Train Loss: 0.6937218457460403
  Validation Loss: 0.6668198704719543
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.7012694329023361
  Validation Loss: 0.6662877202033997
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6863933801651001
  Validation Loss: 0.6657376289367676
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.6829236745834351
  Validation Loss: 0.6652323603630066
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.6881898194551468
  Validation Loss: 0.6647042036056519
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6778934895992279
  Validation Loss: 0.6641765236854553
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6909845322370529
  Validation Loss: 0.6636645793914795
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.6795754581689835
  Validation Loss: 0.663183867931366
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.678305447101593
  Validation Loss: 0.6627121567726135
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.671954944729805
  Validation Loss: 0.6622422337532043
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6847500205039978
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:16:12:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:12:INFO:
[92mINFO [0m:      Received: evaluate message df9c3c0b-a9d9-4c2d-a20b-17d73145aa52
02/06/2025 11:16:12:INFO:Received: evaluate message df9c3c0b-a9d9-4c2d-a20b-17d73145aa52
[92mINFO [0m:      Sent reply
02/06/2025 11:16:13:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:13:INFO:
[92mINFO [0m:      Received: train message 58734402-c865-41cd-aaa5-55930b57fcfd
02/06/2025 11:16:13:INFO:Received: train message 58734402-c865-41cd-aaa5-55930b57fcfd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6617763638496399
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6868982762098312
  Validation Loss: 0.6613192558288574
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.6819882541894913
  Validation Loss: 0.6608639359474182
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.6787457764148712
  Validation Loss: 0.6604426503181458
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.6822261065244675
  Validation Loss: 0.6599988341331482
  Val ROC-AUC: 0.8944444444444445
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.6822261065244675, 'val_roc_auc': 0.8944444444444445, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.6599988341331482}
 ROC_AUC: 0.8944|| Accuracy 0.8148 || Train Loss: 0.6822
 Val Loss: 0.6600 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7433420654093281
Test ROC-AUC: 0.8371212121212122
Test Accuracy: 0.7303370786516854
test_loss: 0.7433420654093281
test_roc_auc: 0.8371212121212122
test_accuracy: 0.7303370786516854
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7297475934028625
  Validation Loss: 0.6838859915733337
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.7336208075284958
  Validation Loss: 0.683179497718811
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.7259735763072968
  Validation Loss: 0.6823298931121826
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.7271666377782822
  Validation Loss: 0.6814343333244324
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.7230415046215057
  Validation Loss: 0.6805212497711182
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.7219115793704987
  Validation Loss: 0.6795884370803833
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.7290365844964981
  Validation Loss: 0.6786662936210632
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.7318495810031891
  Validation Loss: 0.6777502298355103
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.7096170336008072
  Validation Loss: 0.6768311858177185
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.7205827683210373
  Validation Loss: 0.6759180426597595
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.7203728705644608
  Validation Loss: 0.675072193145752
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.7232827991247177
  Validation Loss: 0.6742281317710876
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7141934037208557
  Validation Loss: 0.6734157800674438
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.7098746448755264
  Validation Loss: 0.6726104021072388
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.7164060920476913
  Validation Loss: 0.671816349029541
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.7118303924798965
  Validation Loss: 0.6710891723632812
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.7186477184295654
  Validation Loss: 0.6703442931175232
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7108548730611801
  Validation Loss: 0.6696547269821167
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7031336575746536
  Validation Loss: 0.6689460277557373
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.7112870365381241
  Validation Loss: 0.6682456135749817
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.7045424729585648
  Validation Loss: 0.6675783395767212
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.7083392441272736
  Validation Loss: 0.6669591069221497
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.7053367346525192
  Validation Loss: 0.6663322448730469
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.7041526734828949
  Validation Loss: 0.6657302975654602
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.7024895548820496
  Validation Loss: 0.6651363968849182
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7044166922569275
  Validation Loss: 0.6645470261573792
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6987345218658447
  Validation Loss: 0.663999617099762
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.7059310376644135
  Validation Loss: 0.6634390354156494
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.7083008140325546
  Validation Loss: 0.6629089117050171
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6873754560947418
  Validation Loss: 0.6623802185058594
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7037095576524734
  Validation Loss: 0.6618720293045044
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6943186968564987
  Validation Loss: 0.6613787412643433
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.698582112789154
  Validation Loss: 0.6608962416648865
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6991803646087646
  Validation Loss: 0.6604555249214172
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6896020472049713
  Validation Loss: 0.6599928140640259
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6956271231174469
  Validation Loss: 0.6595368385314941
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7012043595314026
  Validation Loss: 0.6591038703918457
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6893261820077896
  Validation Loss: 0.6586769223213196
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7004723995923996
  Validation Loss: 0.6582751870155334
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6860968768596649
  Validation Loss: 0.6578612327575684
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7041350454092026
  Validation Loss: 0.657461941242218
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.686523050069809
  Validation Loss: 0.6570616960525513
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6863749176263809
  Validation Loss: 0.656668484210968
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6904655992984772
  Validation Loss: 0.6562915444374084
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6945713609457016
  Validation Loss: 0.6559332609176636
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:16:18:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:18:INFO:
[92mINFO [0m:      Received: evaluate message 61ef4e39-d4e6-40ee-bd06-1757e81237a4
02/06/2025 11:16:18:INFO:Received: evaluate message 61ef4e39-d4e6-40ee-bd06-1757e81237a4
[92mINFO [0m:      Sent reply
02/06/2025 11:16:20:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:20:INFO:
[92mINFO [0m:      Received: train message 7be34568-5305-47da-aac2-d5b37dad469a
02/06/2025 11:16:20:INFO:Received: train message 7be34568-5305-47da-aac2-d5b37dad469a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6829705834388733
  Validation Loss: 0.6555729508399963
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6843370646238327
  Validation Loss: 0.6552417278289795
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6764421164989471
  Validation Loss: 0.6549026966094971
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.698372483253479
  Validation Loss: 0.6545732617378235
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6662831604480743
  Validation Loss: 0.6542375683784485
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6777772754430771
  Validation Loss: 0.6539204120635986
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6852845698595047
  Validation Loss: 0.6535914540290833
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6788870692253113
  Validation Loss: 0.6532937288284302
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6792535781860352
  Validation Loss: 0.6529890894889832
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6966777294874191
  Validation Loss: 0.6526824235916138
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6800950020551682
  Validation Loss: 0.6523879766464233
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6840324401855469
  Validation Loss: 0.6520980596542358
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6920629888772964
  Validation Loss: 0.6518259644508362
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.672605499625206
  Validation Loss: 0.6515501737594604
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6818551421165466
  Validation Loss: 0.6513016223907471
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6686969995498657
  Validation Loss: 0.6510457396507263
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6921696960926056
  Validation Loss: 0.650780975818634
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6891868263483047
  Validation Loss: 0.6505204439163208
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.681549921631813
  Validation Loss: 0.6502783298492432
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.681549921631813, 'val_roc_auc': 0.9166666666666667, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6502783298492432}
 ROC_AUC: 0.9167|| Accuracy 0.8889 || Train Loss: 0.6815
 Val Loss: 0.6503 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7380394533778845
Test ROC-AUC: 0.856060606060606
Test Accuracy: 0.7415730337078652
test_loss: 0.7380394533778845
test_roc_auc: 0.856060606060606
test_accuracy: 0.7415730337078652
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7116041332483292
  Validation Loss: 0.7676031589508057
  Val ROC-AUC: 0.8642857142857142
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.7048918455839157
  Validation Loss: 0.7667537331581116
  Val ROC-AUC: 0.8642857142857142
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.7138295024633408
  Validation Loss: 0.765839695930481
  Val ROC-AUC: 0.8642857142857142
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.7046065181493759
  Validation Loss: 0.7648558020591736
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6939211040735245
  Validation Loss: 0.7638684511184692
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.7019274085760117
  Validation Loss: 0.7628717422485352
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6901013255119324
  Validation Loss: 0.761886715888977
  Val ROC-AUC: 0.8642857142857142
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6859983056783676
  Validation Loss: 0.7609095573425293
  Val ROC-AUC: 0.8642857142857142
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6840872168540955
  Validation Loss: 0.7599425315856934
  Val ROC-AUC: 0.8642857142857142
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.672311320900917
  Validation Loss: 0.7590014338493347
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6977203637361526
  Validation Loss: 0.7580814361572266
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.698851466178894
  Validation Loss: 0.7571765780448914
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.676440104842186
  Validation Loss: 0.7563132047653198
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6933566629886627
  Validation Loss: 0.7554277777671814
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6806752532720566
  Validation Loss: 0.7545784115791321
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6857756823301315
  Validation Loss: 0.7537426352500916
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6980836689472198
  Validation Loss: 0.7529069185256958
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6752472668886185
  Validation Loss: 0.7521198391914368
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6760905385017395
  Validation Loss: 0.7513337135314941
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6818155646324158
  Validation Loss: 0.750551164150238
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6866995543241501
  Validation Loss: 0.7498087286949158
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.673390731215477
  Validation Loss: 0.7490695118904114
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6754124164581299
  Validation Loss: 0.7483180165290833
  Val ROC-AUC: 0.8714285714285713
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.697435736656189
  Validation Loss: 0.7476124167442322
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6707190573215485
  Validation Loss: 0.7469139099121094
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6797197312116623
  Validation Loss: 0.7462405562400818
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.669207364320755
  Validation Loss: 0.7455657720565796
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6775555610656738
  Validation Loss: 0.7449233531951904
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.669753909111023
  Validation Loss: 0.7442629337310791
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6823735684156418
  Validation Loss: 0.7436380386352539
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6766677051782608
  Validation Loss: 0.7429936528205872
  Val ROC-AUC: 0.8714285714285714
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:16:25:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:25:INFO:
[92mINFO [0m:      Received: evaluate message 2f2c751a-211f-4390-92bb-1fb8f52e28a1
02/06/2025 11:16:25:INFO:Received: evaluate message 2f2c751a-211f-4390-92bb-1fb8f52e28a1
[92mINFO [0m:      Sent reply
02/06/2025 11:16:27:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:27:INFO:
[92mINFO [0m:      Received: train message 344e3b9b-448d-42b4-ae9a-5661d19b345d
02/06/2025 11:16:27:INFO:Received: train message 344e3b9b-448d-42b4-ae9a-5661d19b345d
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.661500483751297
  Validation Loss: 0.7423686385154724
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6517240703105927
  Validation Loss: 0.7417688369750977
  Val ROC-AUC: 0.8642857142857142
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.670696958899498
  Validation Loss: 0.7411983013153076
  Val ROC-AUC: 0.8642857142857142
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6682209670543671
  Validation Loss: 0.7405999302864075
  Val ROC-AUC: 0.8642857142857142
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6707505583763123
  Validation Loss: 0.7400457859039307
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.661284551024437
  Validation Loss: 0.7394888401031494
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6827312111854553
  Validation Loss: 0.7389248609542847
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6596581637859344
  Validation Loss: 0.738407552242279
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6770671159029007
  Validation Loss: 0.7378977537155151
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.672083243727684
  Validation Loss: 0.7373932600021362
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6700920164585114
  Validation Loss: 0.7368687987327576
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6749120205640793
  Validation Loss: 0.7363794445991516
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6597855985164642
  Validation Loss: 0.7358742952346802
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6613407284021378
  Validation Loss: 0.7354122400283813
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6751807183027267
  Validation Loss: 0.7349402904510498
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6703579872846603
  Validation Loss: 0.7344570755958557
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6695641875267029
  Validation Loss: 0.7339854836463928
  Val ROC-AUC: 0.8714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.667603075504303
  Validation Loss: 0.7335349917411804
  Val ROC-AUC: 0.8785714285714286
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6716633290052414
  Validation Loss: 0.7331075072288513
  Val ROC-AUC: 0.8785714285714286
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6702878326177597
  Validation Loss: 0.7326589822769165
  Val ROC-AUC: 0.8785714285714286
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6720098108053207
  Validation Loss: 0.7322322726249695
  Val ROC-AUC: 0.8785714285714286
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6589390188455582
  Validation Loss: 0.7317847013473511
  Val ROC-AUC: 0.8785714285714286
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6474604904651642
  Validation Loss: 0.7313666343688965
  Val ROC-AUC: 0.8785714285714286
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6860394924879074
  Validation Loss: 0.7309665083885193
  Val ROC-AUC: 0.8785714285714286
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6447542309761047
  Validation Loss: 0.730550229549408
  Val ROC-AUC: 0.8785714285714286
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6521831452846527
  Validation Loss: 0.7301692366600037
  Val ROC-AUC: 0.8857142857142857
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6658916026353836
  Validation Loss: 0.729786217212677
  Val ROC-AUC: 0.8857142857142857
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6568959951400757
  Validation Loss: 0.7293772101402283
  Val ROC-AUC: 0.8857142857142857
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6631782799959183
  Validation Loss: 0.7290093302726746
  Val ROC-AUC: 0.8857142857142857
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6546758115291595
  Validation Loss: 0.7286337018013
  Val ROC-AUC: 0.8857142857142857
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.652837336063385
  Validation Loss: 0.7282702922821045
  Val ROC-AUC: 0.8857142857142857
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.653517559170723
  Validation Loss: 0.7279092073440552
  Val ROC-AUC: 0.8857142857142857
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6585438847541809
  Validation Loss: 0.7275633811950684
  Val ROC-AUC: 0.8857142857142857
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6585438847541809, 'val_roc_auc': 0.8857142857142857, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.7275633811950684}
 ROC_AUC: 0.8857|| Accuracy 0.8889 || Train Loss: 0.6585
 Val Loss: 0.7276 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7329352826214908
Test ROC-AUC: 0.8614718614718615
Test Accuracy: 0.7640449438202247
test_loss: 0.7329352826214908
test_roc_auc: 0.8614718614718615
test_accuracy: 0.7640449438202247
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6920447498559952
  Validation Loss: 0.706780731678009
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.7254067063331604
  Validation Loss: 0.7060900330543518
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.7007454335689545
  Validation Loss: 0.7053125500679016
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.7202028036117554
  Validation Loss: 0.7044861316680908
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.7198753207921982
  Validation Loss: 0.7036223411560059
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.7121220827102661
  Validation Loss: 0.7027562260627747
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.7013510316610336
  Validation Loss: 0.7019051313400269
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.7020134478807449
  Validation Loss: 0.7010616660118103
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7065506428480148
  Validation Loss: 0.7002502083778381
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6988782733678818
  Validation Loss: 0.6994363069534302
  Val ROC-AUC: 0.9382716049382717
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.7111191302537918
  Validation Loss: 0.6986399292945862
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.711490586400032
  Validation Loss: 0.6978749632835388
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.6863712817430496
  Validation Loss: 0.6971120238304138
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6996993869543076
  Validation Loss: 0.6963673830032349
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6845846921205521
  Validation Loss: 0.6956580281257629
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.7031025737524033
  Validation Loss: 0.6949615478515625
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6864745616912842
  Validation Loss: 0.6942715048789978
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:16:32:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:32:INFO:
[92mINFO [0m:      Received: evaluate message ff3b696a-a5b5-4415-a19e-6a3a0f8acf2d
02/06/2025 11:16:32:INFO:Received: evaluate message ff3b696a-a5b5-4415-a19e-6a3a0f8acf2d
[92mINFO [0m:      Sent reply
02/06/2025 11:16:34:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:34:INFO:
[92mINFO [0m:      Received: train message 72221025-e21e-4f9d-8494-748dc91389c2
02/06/2025 11:16:34:INFO:Received: train message 72221025-e21e-4f9d-8494-748dc91389c2
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6945504695177078
  Validation Loss: 0.6936109662055969
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6941158473491669
  Validation Loss: 0.6929569244384766
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.7011718451976776
  Validation Loss: 0.6923335194587708
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6860416084527969
  Validation Loss: 0.6917378306388855
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6826011091470718
  Validation Loss: 0.6911444664001465
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7054741382598877
  Validation Loss: 0.6905636191368103
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.6825173944234848
  Validation Loss: 0.6900036334991455
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6921815425157547
  Validation Loss: 0.6894378662109375
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.686412125825882
  Validation Loss: 0.6889011263847351
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.686090812087059
  Validation Loss: 0.6883900761604309
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6892134100198746
  Validation Loss: 0.687885582447052
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6883818358182907
  Validation Loss: 0.687400758266449
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6796660721302032
  Validation Loss: 0.6869224309921265
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6778508573770523
  Validation Loss: 0.6864467859268188
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6963813304901123
  Validation Loss: 0.6860009431838989
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6875952184200287
  Validation Loss: 0.6855608820915222
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.687064915895462
  Validation Loss: 0.6851288080215454
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6808511316776276
  Validation Loss: 0.6847094893455505
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6936143040657043
  Validation Loss: 0.6842975616455078
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6827960163354874
  Validation Loss: 0.683891773223877
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.680585652589798
  Validation Loss: 0.6834883689880371
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6648417264223099
  Validation Loss: 0.6830883622169495
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6689953953027725
  Validation Loss: 0.682717502117157
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6824584752321243
  Validation Loss: 0.682341992855072
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6851840019226074
  Validation Loss: 0.6819824576377869
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6871898025274277
  Validation Loss: 0.6816311478614807
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6707612574100494
  Validation Loss: 0.6812885999679565
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6733474135398865
  Validation Loss: 0.6809391379356384
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.684203565120697
  Validation Loss: 0.6806201934814453
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6680186688899994
  Validation Loss: 0.6802963018417358
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6698834747076035
  Validation Loss: 0.6799716949462891
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6753485053777695
  Validation Loss: 0.6796607971191406
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6655381470918655
  Validation Loss: 0.6793510913848877
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6827827543020248
  Validation Loss: 0.6790570020675659
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.667007178068161
  Validation Loss: 0.6787739396095276
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6800314337015152
  Validation Loss: 0.6785004138946533
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6695068627595901
  Validation Loss: 0.6782320141792297
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6705856621265411
  Validation Loss: 0.6779587268829346
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6702203005552292
  Validation Loss: 0.6776905655860901
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6710337996482849
  Validation Loss: 0.6774202585220337
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6674259901046753
  Validation Loss: 0.6771514415740967
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6801886707544327
  Validation Loss: 0.6769030690193176
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6733668446540833
  Validation Loss: 0.6766666769981384
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6720389723777771
  Validation Loss: 0.6764277815818787
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6739553660154343
  Validation Loss: 0.6761809587478638
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6680046170949936
  Validation Loss: 0.6759382486343384
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6656437069177628
  Validation Loss: 0.6757113337516785
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6656437069177628, 'val_roc_auc': 0.9691358024691359, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6757113337516785}
 ROC_AUC: 0.9691|| Accuracy 0.8889 || Train Loss: 0.6656
 Val Loss: 0.6757 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7282201955827434
Test ROC-AUC: 0.8695887445887446
Test Accuracy: 0.7528089887640449
test_loss: 0.7282201955827434
test_roc_auc: 0.8695887445887446
test_accuracy: 0.7528089887640449
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7024795264005661
  Validation Loss: 0.6594348549842834
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.7184021174907684
  Validation Loss: 0.6585915088653564
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.7075363248586655
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6576452851295471
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.7101797759532928
  Validation Loss: 0.6566070318222046
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.7230406701564789
  Validation Loss: 0.6555695533752441
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.7064393758773804
  Validation Loss: 0.6545113921165466
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.6999531686306
  Validation Loss: 0.6534846425056458
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.7254043221473694
  Validation Loss: 0.6524559259414673
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.7102373242378235
  Validation Loss: 0.6514601707458496
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.7066569030284882
  Validation Loss: 0.6504616737365723
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.7011140733957291
  Validation Loss: 0.6494772434234619
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.6952056735754013
  Validation Loss: 0.6485304832458496
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.7052551209926605
  Validation Loss: 0.6476002335548401
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.7055588513612747
  Validation Loss: 0.6467028260231018
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6999943852424622
  Validation Loss: 0.6458339095115662
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.7004291862249374
  Validation Loss: 0.6449620127677917
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.692993238568306
  Validation Loss: 0.6440920233726501
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.7108835875988007
  Validation Loss: 0.6432713866233826
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.7073342055082321
  Validation Loss: 0.6424523591995239
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.7016309350728989
  Validation Loss: 0.6416528820991516
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.7019030898809433
  Validation Loss: 0.6408824920654297
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.700230211019516
  Validation Loss: 0.6401360630989075
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.7019711881875992
  Validation Loss: 0.6393923759460449
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6982017159461975
  Validation Loss: 0.6386849284172058
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.7030830830335617
  Validation Loss: 0.637946367263794
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.7015111893415451
  Validation Loss: 0.6372495889663696
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.7060365527868271
  Validation Loss: 0.636572003364563
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.694489136338234
  Validation Loss: 0.6359249353408813
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6890702992677689
  Validation Loss: 0.6352783441543579
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6974733620882034
  Validation Loss: 0.6346678733825684
  Val ROC-AUC: 0.9833333333333334
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6938811838626862
  Validation Loss: 0.6340441107749939
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6953924745321274
  Validation Loss: 0.6334356665611267
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6892855167388916
  Validation Loss: 0.6328476667404175
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.7003906071186066
  Validation Loss: 0.6322654485702515
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6833119690418243
  Validation Loss: 0.631685733795166
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6919269859790802
  Validation Loss: 0.6311253905296326
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.7055177986621857
  Validation Loss: 0.6305950880050659
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.695623129606247
  Validation Loss: 0.6300800442695618
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6954960376024246
  Validation Loss: 0.6295638084411621
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6832687109708786
  Validation Loss: 0.629039466381073
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6881555020809174
  Validation Loss: 0.628534197807312
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6838065385818481
  Validation Loss: 0.6280482411384583
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6863554418087006
  Validation Loss: 0.6275554299354553
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6870575696229935
  Validation Loss: 0.6270802617073059
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6921276599168777
  Validation Loss: 0.6266169548034668
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6904203742742538
  Validation Loss: 0.6261479258537292
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6834466308355331
  Validation Loss: 0.625710129737854
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6875943541526794
  Validation Loss: 0.6252872943878174
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6791781634092331
  Validation Loss: 0.6248405575752258
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6826229095458984
  Validation Loss: 0.624409556388855
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6791110038757324
  Validation Loss: 0.623988926410675
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6738491058349609
  Validation Loss: 0.6235830783843994
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.688892737030983
  Validation Loss: 0.6232116222381592
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6819196194410324
  Validation Loss: 0.6228164434432983
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.688541904091835
  Validation Loss: 0.6224356889724731
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6714465320110321
  Validation Loss: 0.6220711469650269
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:16:39:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:39:INFO:
[92mINFO [0m:      Received: evaluate message 7c51326e-6535-4306-a562-6fab7b686feb
02/06/2025 11:16:39:INFO:Received: evaluate message 7c51326e-6535-4306-a562-6fab7b686feb
[92mINFO [0m:      Sent reply
02/06/2025 11:16:41:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:41:INFO:
[92mINFO [0m:      Received: train message 62038463-31a0-4584-80ad-71af605a3fea
02/06/2025 11:16:41:INFO:Received: train message 62038463-31a0-4584-80ad-71af605a3fea
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

Epoch 57/64:
  Train Loss: 0.6861704140901566
  Validation Loss: 0.6217039823532104
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6734104752540588
  Validation Loss: 0.621321439743042
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.68312107026577
  Validation Loss: 0.6209789514541626
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6967554241418839
  Validation Loss: 0.6206343770027161
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6755776703357697
  Validation Loss: 0.6202823519706726
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6658062785863876
  Validation Loss: 0.6199436187744141
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6844604909420013
  Validation Loss: 0.6196030378341675
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6699021011590958
  Validation Loss: 0.6192694902420044
  Val ROC-AUC: 0.9888888888888889
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6699021011590958, 'val_roc_auc': 0.9888888888888889, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6192694902420044}
 ROC_AUC: 0.9889|| Accuracy 0.9630 || Train Loss: 0.6699
 Val Loss: 0.6193 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7237803785318739
Test ROC-AUC: 0.8722943722943722
Test Accuracy: 0.7528089887640449
test_loss: 0.7237803785318739
test_roc_auc: 0.8722943722943722
test_accuracy: 0.7528089887640449
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7277605831623077
  Validation Loss: 0.648832380771637
  Val ROC-AUC: 0.8956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.703061044216156
  Validation Loss: 0.6482258439064026
  Val ROC-AUC: 0.8956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.702528104186058
  Validation Loss: 0.6475468277931213
  Val ROC-AUC: 0.8956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6964977085590363
  Validation Loss: 0.6468697786331177
  Val ROC-AUC: 0.8956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6979113668203354
  Validation Loss: 0.646155595779419
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.7141149491071701
  Validation Loss: 0.6454546451568604
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.7118913680315018
  Validation Loss: 0.6447340250015259
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6993514001369476
  Validation Loss: 0.644018828868866
  Val ROC-AUC: 0.9065934065934066
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7085386663675308
  Validation Loss: 0.6433365941047668
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.708514466881752
  Validation Loss: 0.6426661610603333
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.7004148215055466
  Validation Loss: 0.6420055031776428
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6956256628036499
  Validation Loss: 0.6413308382034302
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.7090591192245483
  Validation Loss: 0.6406862735748291
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6975647658109665
  Validation Loss: 0.6400775909423828
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.7115346193313599
  Validation Loss: 0.6394706964492798
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.703531414270401
  Validation Loss: 0.6388726234436035
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.7022440880537033
  Validation Loss: 0.6382945775985718
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6952896565198898
  Validation Loss: 0.6377368569374084
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6884397566318512
  Validation Loss: 0.6372050642967224
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.6977109313011169
  Validation Loss: 0.6366642713546753
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.688539057970047
  Validation Loss: 0.636132001876831
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6897492557764053
  Validation Loss: 0.6356235146522522
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.6866466701030731
  Validation Loss: 0.6351348757743835
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.6837902814149857
  Validation Loss: 0.6346500515937805
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.7012908756732941
  Validation Loss: 0.6341582536697388
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6962146162986755
  Validation Loss: 0.6336870789527893
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.6838360577821732
  Validation Loss: 0.6332272291183472
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6756850183010101
  Validation Loss: 0.6327975392341614
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6848653107881546
  Validation Loss: 0.6323496699333191
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.6897496581077576
  Validation Loss: 0.6319281458854675
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.6934547424316406
  Validation Loss: 0.6315003633499146
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6815867573022842
  Validation Loss: 0.6310825347900391
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6693531721830368
  Validation Loss: 0.6306747794151306
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6920375674962997
  Validation Loss: 0.6302769184112549
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6895435005426407
  Validation Loss: 0.6298972368240356
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6992650479078293
  Validation Loss: 0.6295100450515747
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6795789003372192
  Validation Loss: 0.6291358470916748
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6832662224769592
  Validation Loss: 0.6287742853164673
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6995618343353271
  Validation Loss: 0.6284093260765076
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6807176470756531
  Validation Loss: 0.6280611157417297
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6864804178476334
  Validation Loss: 0.6277018189430237
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6855887621641159
  Validation Loss: 0.6273723244667053
  Val ROC-AUC: 0.9175824175824177
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:16:46:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:46:INFO:
[92mINFO [0m:      Received: evaluate message 471c6b84-54c7-47ca-852a-1a4ad6968593
02/06/2025 11:16:46:INFO:Received: evaluate message 471c6b84-54c7-47ca-852a-1a4ad6968593
[92mINFO [0m:      Sent reply
02/06/2025 11:16:48:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:48:INFO:
[92mINFO [0m:      Received: train message 0b2e2bbb-5a28-46c8-82ba-6691f7c8d8ae
02/06/2025 11:16:48:INFO:Received: train message 0b2e2bbb-5a28-46c8-82ba-6691f7c8d8ae
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8518518805503845
Epoch 43/64:
  Train Loss: 0.6794266700744629
  Validation Loss: 0.6270400881767273
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8518518805503845
Epoch 44/64:
  Train Loss: 0.6907654851675034
  Validation Loss: 0.6266975402832031
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8518518805503845
Epoch 45/64:
  Train Loss: 0.6717092841863632
  Validation Loss: 0.6263825297355652
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 46/64:
  Train Loss: 0.6776552796363831
  Validation Loss: 0.6260803937911987
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 47/64:
  Train Loss: 0.679242730140686
  Validation Loss: 0.625791072845459
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.6862940341234207
  Validation Loss: 0.6254806518554688
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.6812757700681686
  Validation Loss: 0.6251773834228516
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.6732763946056366
  Validation Loss: 0.6248874068260193
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6763333529233932
  Validation Loss: 0.6245899200439453
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.6845689564943314
  Validation Loss: 0.6243256330490112
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.6736928820610046
  Validation Loss: 0.6240615248680115
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6779497116804123
  Validation Loss: 0.623790442943573
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.6593637019395828
  Validation Loss: 0.6235412955284119
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6900511533021927
  Validation Loss: 0.6232768893241882
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6872324347496033
  Validation Loss: 0.623013973236084
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6702313721179962
  Validation Loss: 0.6227548718452454
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.6788658052682877
  Validation Loss: 0.6224966645240784
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.6868021935224533
  Validation Loss: 0.6222649216651917
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6718761026859283
  Validation Loss: 0.6220145225524902
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.667802631855011
  Validation Loss: 0.621788501739502
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6748816072940826
  Validation Loss: 0.6215563416481018
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.6762261688709259
  Validation Loss: 0.6213141679763794
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
{'train_loss': 0.6762261688709259, 'val_roc_auc': 0.9230769230769231, 'val_accuracy': 0.8518518805503845, 'val_loss': 0.6213141679763794}
 ROC_AUC: 0.9231|| Accuracy 0.8519 || Train Loss: 0.6762
 Val Loss: 0.6213 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7196591590227706
Test ROC-AUC: 0.8755411255411255
Test Accuracy: 0.7640449438202247
test_loss: 0.7196591590227706
test_roc_auc: 0.8755411255411255
test_accuracy: 0.7640449438202247
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.7224260419607162
  Validation Loss: 0.6172747015953064
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 2/64:
  Train Loss: 0.7060604691505432
  Validation Loss: 0.6168070435523987
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 3/64:
  Train Loss: 0.7009393572807312
  Validation Loss: 0.6162846684455872
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 4/64:
  Train Loss: 0.7177851796150208
  Validation Loss: 0.6157323122024536
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.6929494738578796
  Validation Loss: 0.6151553392410278
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.719971776008606
  Validation Loss: 0.6145745515823364
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.7106611877679825
  Validation Loss: 0.6140299439430237
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.7021456807851791
  Validation Loss: 0.6134490966796875
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.7006852626800537
  Validation Loss: 0.6129270792007446
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6942119151353836
  Validation Loss: 0.6123778820037842
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6954271197319031
  Validation Loss: 0.6118244528770447
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.7009527385234833
  Validation Loss: 0.6113138794898987
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.710486888885498
  Validation Loss: 0.6107882857322693
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.6964220553636551
  Validation Loss: 0.6103050708770752
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6930407881736755
  Validation Loss: 0.609811007976532
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.7010061591863632
  Validation Loss: 0.6093205809593201
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6867669969797134
  Validation Loss: 0.6088711619377136
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.7031012028455734
  Validation Loss: 0.6084556579589844
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6954616159200668
  Validation Loss: 0.6080085039138794
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.686522901058197
  Validation Loss: 0.6076183915138245
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6845169812440872
  Validation Loss: 0.6072047352790833
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.7036966681480408
  Validation Loss: 0.6067990064620972
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.7031467258930206
  Validation Loss: 0.6064065098762512
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 24/64:
  Train Loss: 0.6990366876125336
  Validation Loss: 0.6060134172439575
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 25/64:
  Train Loss: 0.7011662274599075
  Validation Loss: 0.6056561470031738
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 26/64:
  Train Loss: 0.6883326023817062
  Validation Loss: 0.6052845120429993
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 27/64:
  Train Loss: 0.6913967579603195
  Validation Loss: 0.6049187183380127
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 28/64:
  Train Loss: 0.6898992359638214
  Validation Loss: 0.6045846343040466
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 29/64:
  Train Loss: 0.6886324137449265
  Validation Loss: 0.6042662262916565
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 30/64:
  Train Loss: 0.6950322836637497
  Validation Loss: 0.6039441227912903
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 31/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:16:53:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:53:INFO:
[92mINFO [0m:      Received: evaluate message e534e818-62a3-4353-aac8-755fc731c66f
02/06/2025 11:16:53:INFO:Received: evaluate message e534e818-62a3-4353-aac8-755fc731c66f
[92mINFO [0m:      Sent reply
02/06/2025 11:16:55:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:16:55:INFO:
[92mINFO [0m:      Received: train message 8f7d45bd-6121-4c73-bc4a-4d35355ce90e
02/06/2025 11:16:55:INFO:Received: train message 8f7d45bd-6121-4c73-bc4a-4d35355ce90e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6908089816570282
  Validation Loss: 0.6036339402198792
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 32/64:
  Train Loss: 0.6786021739244461
  Validation Loss: 0.6033404469490051
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 33/64:
  Train Loss: 0.6887302547693253
  Validation Loss: 0.6030356884002686
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 34/64:
  Train Loss: 0.6950912177562714
  Validation Loss: 0.6027392745018005
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 35/64:
  Train Loss: 0.7011983096599579
  Validation Loss: 0.602441132068634
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 36/64:
  Train Loss: 0.6891235113143921
  Validation Loss: 0.6021518111228943
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 37/64:
  Train Loss: 0.6889976859092712
  Validation Loss: 0.6018734574317932
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 38/64:
  Train Loss: 0.6878116428852081
  Validation Loss: 0.6015961170196533
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 39/64:
  Train Loss: 0.6791814863681793
  Validation Loss: 0.601344645023346
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 40/64:
  Train Loss: 0.6832229197025299
  Validation Loss: 0.6010721921920776
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 41/64:
  Train Loss: 0.6944633722305298
  Validation Loss: 0.6008183360099792
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 42/64:
  Train Loss: 0.6718999296426773
  Validation Loss: 0.6005638837814331
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 43/64:
  Train Loss: 0.6852826178073883
  Validation Loss: 0.600315511226654
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 44/64:
  Train Loss: 0.6970232725143433
  Validation Loss: 0.6000564098358154
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 45/64:
  Train Loss: 0.6877703219652176
  Validation Loss: 0.5998314619064331
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 46/64:
  Train Loss: 0.6833218336105347
  Validation Loss: 0.5996165871620178
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 47/64:
  Train Loss: 0.6783078461885452
  Validation Loss: 0.5993939638137817
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 48/64:
  Train Loss: 0.6927396804094315
  Validation Loss: 0.5991762280464172
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 49/64:
  Train Loss: 0.6763646900653839
  Validation Loss: 0.5989633798599243
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 50/64:
  Train Loss: 0.681185394525528
  Validation Loss: 0.5987438559532166
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 51/64:
  Train Loss: 0.6804052293300629
  Validation Loss: 0.5985495448112488
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 52/64:
  Train Loss: 0.6766480952501297
  Validation Loss: 0.5983390808105469
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 53/64:
  Train Loss: 0.6713967025279999
  Validation Loss: 0.598159909248352
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 54/64:
  Train Loss: 0.6885902285575867
  Validation Loss: 0.5979653596878052
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 55/64:
  Train Loss: 0.6900879889726639
  Validation Loss: 0.5977908372879028
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 56/64:
  Train Loss: 0.6728695183992386
  Validation Loss: 0.5976137518882751
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 57/64:
  Train Loss: 0.6822684109210968
  Validation Loss: 0.5974231362342834
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 58/64:
  Train Loss: 0.685517892241478
  Validation Loss: 0.597235918045044
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 59/64:
  Train Loss: 0.6864380836486816
  Validation Loss: 0.5970599055290222
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 60/64:
  Train Loss: 0.677561491727829
  Validation Loss: 0.5968949198722839
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 61/64:
  Train Loss: 0.6759374141693115
  Validation Loss: 0.5967025756835938
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 62/64:
  Train Loss: 0.6785992383956909
  Validation Loss: 0.5965343117713928
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 63/64:
  Train Loss: 0.6771606653928757
  Validation Loss: 0.5963869690895081
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 64/64:
  Train Loss: 0.6826851665973663
  Validation Loss: 0.5962363481521606
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
{'train_loss': 0.6826851665973663, 'val_roc_auc': 1.0, 'val_accuracy': 1.0, 'val_loss': 0.5962363481521606}
 ROC_AUC: 1.0000|| Accuracy 1.0000 || Train Loss: 0.6827
 Val Loss: 0.5962 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7159066464793816
Test ROC-AUC: 0.8760822510822511
Test Accuracy: 0.7640449438202247
test_loss: 0.7159066464793816
test_roc_auc: 0.8760822510822511
test_accuracy: 0.7640449438202247
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6739135980606079
  Validation Loss: 0.7597004771232605
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6576573699712753
  Validation Loss: 0.7590852975845337
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6711902320384979
  Validation Loss: 0.7584185004234314
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6653052866458893
  Validation Loss: 0.7577283978462219
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6687797158956528
  Validation Loss: 0.7570483684539795
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6761753410100937
  Validation Loss: 0.7563461661338806
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6773308217525482
  Validation Loss: 0.7556435465812683
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6733545958995819
  Validation Loss: 0.754948079586029
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6632740944623947
  Validation Loss: 0.7542740702629089
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6762505620718002
  Validation Loss: 0.7536232471466064
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6757031977176666
  Validation Loss: 0.7529696226119995
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.655167818069458
  Validation Loss: 0.7523611187934875
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6700908839702606
  Validation Loss: 0.7517469525337219
  Val ROC-AUC: 0.9714285714285714
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6670145094394684
  Validation Loss: 0.7511573433876038
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6658743619918823
  Validation Loss: 0.7505819797515869
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6734320819377899
  Validation Loss: 0.7500075697898865
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6587947010993958
  Validation Loss: 0.7494825720787048
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6632205545902252
  Validation Loss: 0.7489491105079651
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6569518446922302
  Validation Loss: 0.7484166026115417
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6613992750644684
  Validation Loss: 0.7479107975959778
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6511644124984741
  Validation Loss: 0.7474108338356018
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6543861329555511
  Validation Loss: 0.7469217777252197
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6540940254926682
  Validation Loss: 0.7464370727539062
  Val ROC-AUC: 0.9785714285714285
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:17:00:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:00:INFO:
[92mINFO [0m:      Received: evaluate message 17eb6b2b-0bd6-4729-980f-27b25a8347dd
02/06/2025 11:17:00:INFO:Received: evaluate message 17eb6b2b-0bd6-4729-980f-27b25a8347dd
[92mINFO [0m:      Sent reply
02/06/2025 11:17:01:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:02:INFO:
[92mINFO [0m:      Received: train message f9faccbd-a1bd-47b7-939e-2e43c2cf9510
02/06/2025 11:17:02:INFO:Received: train message f9faccbd-a1bd-47b7-939e-2e43c2cf9510
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6567710936069489
  Validation Loss: 0.7459960579872131
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.66289983689785
  Validation Loss: 0.7455372214317322
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6569862514734268
  Validation Loss: 0.7451119422912598
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.665170431137085
  Validation Loss: 0.7446934580802917
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6587228775024414
  Validation Loss: 0.744279682636261
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6518189162015915
  Validation Loss: 0.7438834309577942
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6536902636289597
  Validation Loss: 0.7434850931167603
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6531703919172287
  Validation Loss: 0.743087112903595
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6706834584474564
  Validation Loss: 0.7427464127540588
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6644670963287354
  Validation Loss: 0.7423662543296814
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6396984457969666
  Validation Loss: 0.7420158386230469
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6563916504383087
  Validation Loss: 0.7416670918464661
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6538514196872711
  Validation Loss: 0.7413361668586731
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6467517465353012
  Validation Loss: 0.7409846186637878
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6506170183420181
  Validation Loss: 0.7406562566757202
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6521272510290146
  Validation Loss: 0.7403582334518433
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6509492993354797
  Validation Loss: 0.7400592565536499
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6526016294956207
  Validation Loss: 0.7397547364234924
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6483290493488312
  Validation Loss: 0.7394589781761169
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6408727467060089
  Validation Loss: 0.7391765117645264
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6570960432291031
  Validation Loss: 0.7388916015625
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6603774130344391
  Validation Loss: 0.7386180758476257
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6562797725200653
  Validation Loss: 0.7383513450622559
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6433719545602798
  Validation Loss: 0.7380931973457336
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6475731730461121
  Validation Loss: 0.7378290295600891
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6554689109325409
  Validation Loss: 0.7375891208648682
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.65055051445961
  Validation Loss: 0.7373397946357727
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6456461846828461
  Validation Loss: 0.737089216709137
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6502847969532013
  Validation Loss: 0.7368558049201965
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6535536795854568
  Validation Loss: 0.7366228699684143
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6346728354692459
  Validation Loss: 0.73639976978302
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6508370488882065
  Validation Loss: 0.7361742258071899
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6442843973636627
  Validation Loss: 0.7359774708747864
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6329295486211777
  Validation Loss: 0.7357663512229919
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6334185004234314
  Validation Loss: 0.7355613112449646
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6521829813718796
  Validation Loss: 0.7353584170341492
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6474925577640533
  Validation Loss: 0.7351691722869873
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6385847479104996
  Validation Loss: 0.7349748015403748
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6355798542499542
  Validation Loss: 0.7347752451896667
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6466778069734573
  Validation Loss: 0.7345871329307556
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6444108933210373
  Validation Loss: 0.7344165444374084
  Val ROC-AUC: 0.9785714285714285
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6444108933210373, 'val_roc_auc': 0.9785714285714285, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.7344165444374084}
 ROC_AUC: 0.9786|| Accuracy 0.9630 || Train Loss: 0.6444
 Val Loss: 0.7344 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7124098254723495
Test ROC-AUC: 0.8777056277056277
Test Accuracy: 0.7865168539325843
test_loss: 0.7124098254723495
test_roc_auc: 0.8777056277056277
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.69709911942482
  Validation Loss: 0.6079129576683044
  Val ROC-AUC: 0.9450549450549451
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6996045559644699
  Validation Loss: 0.6074987649917603
  Val ROC-AUC: 0.9450549450549451
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.7095372676849365
  Validation Loss: 0.6070474982261658
  Val ROC-AUC: 0.9450549450549451
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6940628290176392
  Validation Loss: 0.6065465211868286
  Val ROC-AUC: 0.9450549450549451
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6956448554992676
  Validation Loss: 0.6060110330581665
  Val ROC-AUC: 0.9450549450549451
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.7055479884147644
  Validation Loss: 0.6054736971855164
  Val ROC-AUC: 0.9450549450549451
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6908644884824753
  Validation Loss: 0.6049505472183228
  Val ROC-AUC: 0.9450549450549451
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.7089025378227234
  Validation Loss: 0.6044344305992126
  Val ROC-AUC: 0.9450549450549451
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6967794001102448
  Validation Loss: 0.6039260029792786
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9450549450549451
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6986856758594513
  Validation Loss: 0.6033970713615417
  Val ROC-AUC: 0.9450549450549451
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.7057512253522873
  Validation Loss: 0.6029037237167358
  Val ROC-AUC: 0.9505494505494506
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6953456252813339
  Validation Loss: 0.6024268865585327
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6958463191986084
  Validation Loss: 0.6019688844680786
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.697603166103363
  Validation Loss: 0.601516842842102
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.7050222009420395
  Validation Loss: 0.6010800004005432
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6886022239923477
  Validation Loss: 0.6006299257278442
  Val ROC-AUC: 0.967032967032967
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.685319185256958
  Validation Loss: 0.6002048850059509
  Val ROC-AUC: 0.967032967032967
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.7017670273780823
  Validation Loss: 0.5997990965843201
  Val ROC-AUC: 0.967032967032967
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6933458000421524
  Validation Loss: 0.5993906855583191
  Val ROC-AUC: 0.967032967032967
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.7010471224784851
  Validation Loss: 0.5990026593208313
  Val ROC-AUC: 0.967032967032967
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6831416040658951
  Validation Loss: 0.5986421704292297
  Val ROC-AUC: 0.967032967032967
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6997475773096085
  Validation Loss: 0.5982628464698792
  Val ROC-AUC: 0.967032967032967
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.689217135310173
  Validation Loss: 0.5979045033454895
  Val ROC-AUC: 0.967032967032967
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6966313570737839
  Validation Loss: 0.5975603461265564
  Val ROC-AUC: 0.967032967032967
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6906003355979919
  Validation Loss: 0.5972216725349426
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6914384663105011
  Validation Loss: 0.5968949198722839
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6885695904493332
  Validation Loss: 0.5965849161148071
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6872206777334213
  Validation Loss: 0.5962656140327454
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6820773035287857
  Validation Loss: 0.5959697365760803
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6864686757326126
  Validation Loss: 0.5956745743751526
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6828494518995285
  Validation Loss: 0.5953865647315979
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6904727965593338
  Validation Loss: 0.5951023697853088
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6927476823329926
  Validation Loss: 0.5948240756988525
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6891355812549591
  Validation Loss: 0.5945748090744019
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6946577578783035
  Validation Loss: 0.5943160653114319
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6911665797233582
  Validation Loss: 0.5940551161766052
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6702636927366257
  Validation Loss: 0.5938075184822083
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6968459188938141
  Validation Loss: 0.593557596206665
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6807766556739807
  Validation Loss: 0.5933018326759338
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6743687391281128
  Validation Loss: 0.5930739641189575
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6768393367528915
  Validation Loss: 0.5928527116775513
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.692500963807106
  Validation Loss: 0.5926252603530884
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6835917830467224
  Validation Loss: 0.5924073457717896
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6830435246229172
  Validation Loss: 0.5922073721885681
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6768946796655655
  Validation Loss: 0.5920022130012512
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6912404000759125
  Validation Loss: 0.5918081998825073
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6902623921632767
  Validation Loss: 0.5915998816490173
  Val ROC-AUC: 0.9725274725274726
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.67976975440979
  Validation Loss: 0.5914017558097839
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6805281639099121
  Validation Loss: 0.5912244915962219
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6716381013393402
  Validation Loss: 0.5910459756851196
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6818534731864929
  Validation Loss: 0.5908627510070801
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6887459456920624
  Validation Loss: 0.5907056927680969
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6883240193128586
  Validation Loss: 0.5905343294143677
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6742734462022781
  Validation Loss: 0.5903671979904175
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6657682508230209
  Validation Loss: 0.5902049541473389
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6809274405241013
  Validation Loss: 0.590047299861908
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6834227293729782
  Validation Loss: 0.5898902416229248
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6673454344272614
  Validation Loss: 0.5897420048713684
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6630806922912598
  Validation Loss: 0.5896003842353821
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6780849099159241
  Validation Loss: 0.5894539952278137
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.676261380314827
  Validation Loss: 0.5893076062202454
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.663223996758461
  Validation Loss: 0.5891676545143127
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:17:07:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:07:INFO:
[92mINFO [0m:      Received: evaluate message 2d2224c3-6595-43cd-a9ad-28700e2f2858
02/06/2025 11:17:07:INFO:Received: evaluate message 2d2224c3-6595-43cd-a9ad-28700e2f2858
[92mINFO [0m:      Sent reply
02/06/2025 11:17:08:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:08:INFO:
[92mINFO [0m:      Received: train message ba1456fa-2538-4a54-945c-7dc6e9cd0531
02/06/2025 11:17:08:INFO:Received: train message ba1456fa-2538-4a54-945c-7dc6e9cd0531
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.681342139840126
  Validation Loss: 0.5890326499938965
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6636193990707397
  Validation Loss: 0.5889033675193787
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6636193990707397, 'val_roc_auc': 0.9780219780219781, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.5889033675193787}
 ROC_AUC: 0.9780|| Accuracy 0.9630 || Train Loss: 0.6636
 Val Loss: 0.5889 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7091932916239406
Test ROC-AUC: 0.8760822510822511
Test Accuracy: 0.797752808988764
test_loss: 0.7091932916239406
test_roc_auc: 0.8760822510822511
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6851627826690674
  Validation Loss: 0.6348440647125244
  Val ROC-AUC: 0.8846153846153847
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.699773371219635
  Validation Loss: 0.6344470381736755
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6958112716674805
  Validation Loss: 0.6340002417564392
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6989391446113586
  Validation Loss: 0.6334971189498901
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6893417835235596
  Validation Loss: 0.6329830884933472
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6857635825872421
  Validation Loss: 0.6324772238731384
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6894782930612564
  Validation Loss: 0.6319565773010254
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6915245652198792
  Validation Loss: 0.6314373016357422
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7039141058921814
  Validation Loss: 0.6309344172477722
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6993147432804108
  Validation Loss: 0.6304499506950378
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6829068511724472
  Validation Loss: 0.6299622654914856
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.68592369556427
  Validation Loss: 0.6295029520988464
  Val ROC-AUC: 0.8901098901098902
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.6843215972185135
  Validation Loss: 0.6290367841720581
  Val ROC-AUC: 0.8956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6943229734897614
  Validation Loss: 0.6285765767097473
  Val ROC-AUC: 0.8956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.693127766251564
  Validation Loss: 0.6281288266181946
  Val ROC-AUC: 0.8956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.6992214471101761
  Validation Loss: 0.6277275681495667
  Val ROC-AUC: 0.8956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6912422627210617
  Validation Loss: 0.6272956132888794
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6800121068954468
  Validation Loss: 0.6268962025642395
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6718814969062805
  Validation Loss: 0.6264960765838623
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.6931916326284409
  Validation Loss: 0.6261287331581116
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6812768876552582
  Validation Loss: 0.6257491707801819
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.679467648267746
  Validation Loss: 0.6253852844238281
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.6874756067991257
  Validation Loss: 0.6250395178794861
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.6816160827875137
  Validation Loss: 0.6246902942657471
  Val ROC-AUC: 0.9175824175824177
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.6774774342775345
  Validation Loss: 0.6243504881858826
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6802876442670822
  Validation Loss: 0.6240186095237732
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.6764762699604034
  Validation Loss: 0.6236985325813293
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6866339147090912
  Validation Loss: 0.6233810186386108
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6887369304895401
  Validation Loss: 0.6230747103691101
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.6914821267127991
  Validation Loss: 0.622780978679657
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.6805445998907089
  Validation Loss: 0.6224948763847351
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.6813213229179382
  Validation Loss: 0.6222072839736938
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8518518805503845
Epoch 33/64:
  Train Loss: 0.6664053201675415
  Validation Loss: 0.6219363212585449
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8518518805503845
Epoch 34/64:
  Train Loss: 0.6833678930997849
  Validation Loss: 0.6216554045677185
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8518518805503845
Epoch 35/64:
  Train Loss: 0.6711717247962952
  Validation Loss: 0.6213927268981934
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8518518805503845
Epoch 36/64:
  Train Loss: 0.6797295659780502
  Validation Loss: 0.6211361289024353
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6687026470899582
  Validation Loss: 0.6208758354187012
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6729674637317657
  Validation Loss: 0.6206262707710266
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6727336496114731
  Validation Loss: 0.6203946471214294
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6731239706277847
  Validation Loss: 0.620154619216919
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6833684891462326
  Validation Loss: 0.6199401617050171
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6756555140018463
  Validation Loss: 0.6197152137756348
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6743727475404739
  Validation Loss: 0.6194846034049988
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6686933487653732
  Validation Loss: 0.6192629933357239
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6782440394163132
  Validation Loss: 0.6190393567085266
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6758730262517929
  Validation Loss: 0.6188395023345947
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6604994237422943
  Validation Loss: 0.6186354160308838
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6776718348264694
  Validation Loss: 0.6184393763542175
  Val ROC-AUC: 0.945054945054945
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:17:13:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:13:INFO:
[92mINFO [0m:      Received: evaluate message eeb2340c-2cd4-44e7-959c-08b7b4a5257e
02/06/2025 11:17:13:INFO:Received: evaluate message eeb2340c-2cd4-44e7-959c-08b7b4a5257e
[92mINFO [0m:      Sent reply
02/06/2025 11:17:15:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:15:INFO:
[92mINFO [0m:      Received: train message be7f0e77-068d-4ac0-be5f-66352bcd024e
02/06/2025 11:17:15:INFO:Received: train message be7f0e77-068d-4ac0-be5f-66352bcd024e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6653430461883545
  Validation Loss: 0.6182430386543274
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6711001992225647
  Validation Loss: 0.618044376373291
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6837510913610458
  Validation Loss: 0.6178614497184753
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6657680571079254
  Validation Loss: 0.6176779866218567
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6774400621652603
  Validation Loss: 0.6175017356872559
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.665607824921608
  Validation Loss: 0.6173247694969177
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6659160554409027
  Validation Loss: 0.6171526312828064
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6732137948274612
  Validation Loss: 0.6169826984405518
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.662857249379158
  Validation Loss: 0.6168262362480164
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6679258942604065
  Validation Loss: 0.6166653037071228
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.675921618938446
  Validation Loss: 0.6165143251419067
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6722117513418198
  Validation Loss: 0.6163584589958191
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6658698469400406
  Validation Loss: 0.6162109375
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6683354675769806
  Validation Loss: 0.6160663962364197
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6724398583173752
  Validation Loss: 0.6159179210662842
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6587309390306473
  Validation Loss: 0.6157694458961487
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6587309390306473, 'val_roc_auc': 0.9505494505494505, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6157694458961487}
 ROC_AUC: 0.9505|| Accuracy 0.8889 || Train Loss: 0.6587
 Val Loss: 0.6158 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7063231156783157
Test ROC-AUC: 0.8777056277056278
Test Accuracy: 0.797752808988764
test_loss: 0.7063231156783157
test_roc_auc: 0.8777056277056278
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6769750565290451
  Validation Loss: 0.6526724100112915
  Val ROC-AUC: 0.8722222222222222
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.6923832893371582
  Validation Loss: 0.6522881388664246
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.6945698708295822
  Validation Loss: 0.6518250703811646
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.6942774653434753
  Validation Loss: 0.651358425617218
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.6885142028331757
  Validation Loss: 0.6508488655090332
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.6847891807556152
  Validation Loss: 0.650351345539093
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.69361612200737
  Validation Loss: 0.6498701572418213
  Val ROC-AUC: 0.8777777777777778
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.6907558143138885
  Validation Loss: 0.6493614315986633
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.6804207265377045
  Validation Loss: 0.6488722562789917
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6726449280977249
  Validation Loss: 0.6483878493309021
  Val ROC-AUC: 0.8944444444444445
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.6639055907726288
  Validation Loss: 0.6479170322418213
  Val ROC-AUC: 0.8944444444444445
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.6733713448047638
  Validation Loss: 0.6474514007568359
  Val ROC-AUC: 0.8944444444444445
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.6745644360780716
  Validation Loss: 0.6470105051994324
  Val ROC-AUC: 0.8944444444444445
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.6802305579185486
  Validation Loss: 0.6465733647346497
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.6776642799377441
  Validation Loss: 0.6461490392684937
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.6854036003351212
  Validation Loss: 0.6457342505455017
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.6747264415025711
  Validation Loss: 0.6453284621238708
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.6838825643062592
  Validation Loss: 0.6449392437934875
  Val ROC-AUC: 0.9055555555555556
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.669854000210762
  Validation Loss: 0.6445594429969788
  Val ROC-AUC: 0.9055555555555556
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.6751940846443176
  Validation Loss: 0.6441878080368042
  Val ROC-AUC: 0.9055555555555556
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.6755643784999847
  Validation Loss: 0.6438112854957581
  Val ROC-AUC: 0.9055555555555556
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.6703257709741592
  Validation Loss: 0.6434553861618042
  Val ROC-AUC: 0.9055555555555556
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.679019033908844
  Validation Loss: 0.6431106328964233
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6736526042222977
  Validation Loss: 0.6427798271179199
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.6770438551902771
  Validation Loss: 0.6424639821052551
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6822943836450577
  Validation Loss: 0.6421151161193848
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6739024519920349
  Validation Loss: 0.6417973041534424
  Val ROC-AUC: 0.9111111111111111
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6785645633935928
  Validation Loss: 0.6414963603019714
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6664135903120041
  Validation Loss: 0.6411973237991333
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6668545603752136
  Validation Loss: 0.6409041881561279
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6650849133729935
  Validation Loss: 0.640613853931427
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.690088078379631
  Validation Loss: 0.6403322815895081
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6666756868362427
  Validation Loss: 0.6400432586669922
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6648361384868622
  Validation Loss: 0.6397808194160461
  Val ROC-AUC: 0.9222222222222223
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:17:20:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:20:INFO:
[92mINFO [0m:      Received: evaluate message 884f33c1-1ee6-4af4-aaf5-53438eb52f4b
02/06/2025 11:17:20:INFO:Received: evaluate message 884f33c1-1ee6-4af4-aaf5-53438eb52f4b
[92mINFO [0m:      Sent reply
02/06/2025 11:17:22:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:22:INFO:
[92mINFO [0m:      Received: train message 307b2c86-3933-4f5a-be6b-aa0b2a6e64c7
02/06/2025 11:17:22:INFO:Received: train message 307b2c86-3933-4f5a-be6b-aa0b2a6e64c7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6619312614202499
  Validation Loss: 0.6395062804222107
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6599456369876862
  Validation Loss: 0.6392577886581421
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6698542237281799
  Validation Loss: 0.6390188336372375
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6640158593654633
  Validation Loss: 0.6387779712677002
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6634354442358017
  Validation Loss: 0.6385284662246704
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6721908897161484
  Validation Loss: 0.6382956504821777
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6574715822935104
  Validation Loss: 0.6380648612976074
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6736158132553101
  Validation Loss: 0.6378334164619446
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6569267958402634
  Validation Loss: 0.6376169323921204
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6785949170589447
  Validation Loss: 0.6374067664146423
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.675634890794754
  Validation Loss: 0.6371852159500122
  Val ROC-AUC: 0.9277777777777778
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6709942817687988
  Validation Loss: 0.6369860768318176
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.6579837650060654
  Validation Loss: 0.6367819905281067
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.6746026873588562
  Validation Loss: 0.6365664601325989
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6732091307640076
  Validation Loss: 0.6363642811775208
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.6616235673427582
  Validation Loss: 0.6361674666404724
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.6593319475650787
  Validation Loss: 0.635990560054779
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6602974385023117
  Validation Loss: 0.6358069777488708
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.6634274572134018
  Validation Loss: 0.6356204152107239
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.6607513576745987
  Validation Loss: 0.6354526877403259
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6678145378828049
  Validation Loss: 0.6352752447128296
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6613888889551163
  Validation Loss: 0.6351006627082825
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.6658736318349838
  Validation Loss: 0.6349299550056458
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.6631163507699966
  Validation Loss: 0.6347687840461731
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6674447804689407
  Validation Loss: 0.6346219182014465
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6635298728942871
  Validation Loss: 0.6344688534736633
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6589275449514389
  Validation Loss: 0.6343241930007935
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.6528975814580917
  Validation Loss: 0.6341641545295715
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.656524732708931
  Validation Loss: 0.6340072154998779
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.6583944410085678
  Validation Loss: 0.6338648796081543
  Val ROC-AUC: 0.938888888888889
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.6583944410085678, 'val_roc_auc': 0.938888888888889, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.6338648796081543}
 ROC_AUC: 0.9389|| Accuracy 0.8148 || Train Loss: 0.6584
 Val Loss: 0.6339 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7037799803728468
Test ROC-AUC: 0.8782467532467532
Test Accuracy: 0.797752808988764
test_loss: 0.7037799803728468
test_roc_auc: 0.8782467532467532
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6747164577245712
  Validation Loss: 0.69499671459198
  Val ROC-AUC: 0.9276315789473684
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6788744181394577
  Validation Loss: 0.6945983171463013
  Val ROC-AUC: 0.9276315789473684
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6706179827451706
  Validation Loss: 0.6941784620285034
  Val ROC-AUC: 0.9276315789473684
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.67835833132267
  Validation Loss: 0.6937134265899658
  Val ROC-AUC: 0.9276315789473684
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.666619062423706
  Validation Loss: 0.6932459473609924
  Val ROC-AUC: 0.9276315789473684
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.659758672118187
  Validation Loss: 0.692748486995697
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6730408221483231
  Validation Loss: 0.6922426819801331
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6778102070093155
  Validation Loss: 0.6917914748191833
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6718470901250839
  Validation Loss: 0.6913148164749146
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6633116900920868
  Validation Loss: 0.6908600330352783
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6612220257520676
  Validation Loss: 0.6904118061065674
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6685969233512878
  Validation Loss: 0.689980149269104
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6642298996448517
  Validation Loss: 0.6895594000816345
  Val ROC-AUC: 0.9473684210526316
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6560334861278534
  Validation Loss: 0.6891581416130066
  Val ROC-AUC: 0.9473684210526316
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6658868044614792
  Validation Loss: 0.6887383460998535
  Val ROC-AUC: 0.9473684210526316
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6608913391828537
  Validation Loss: 0.6883242726325989
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6699459552764893
  Validation Loss: 0.6879685521125793
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6633096635341644
  Validation Loss: 0.6876040697097778
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6576680392026901
  Validation Loss: 0.6872366070747375
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6736236214637756
  Validation Loss: 0.6868756413459778
  Val ROC-AUC: 0.9539473684210527
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:17:27:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:27:INFO:
[92mINFO [0m:      Received: evaluate message e9b2b845-7913-48ef-8333-ae0083b9e63b
02/06/2025 11:17:27:INFO:Received: evaluate message e9b2b845-7913-48ef-8333-ae0083b9e63b
[92mINFO [0m:      Sent reply
02/06/2025 11:17:28:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:28:INFO:
[92mINFO [0m:      Received: train message a4fe1958-1196-4983-b890-a6b7a2844570
02/06/2025 11:17:28:INFO:Received: train message a4fe1958-1196-4983-b890-a6b7a2844570
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6778932511806488
  Validation Loss: 0.6865421533584595
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.6565840691328049
  Validation Loss: 0.6862459778785706
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6708333045244217
  Validation Loss: 0.6859245896339417
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.676273986697197
  Validation Loss: 0.6856173872947693
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6586940437555313
  Validation Loss: 0.6852871775627136
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.670012816786766
  Validation Loss: 0.684984564781189
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6599491536617279
  Validation Loss: 0.6847158670425415
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6616240590810776
  Validation Loss: 0.6844335794448853
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6586601287126541
  Validation Loss: 0.684158205986023
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6627086400985718
  Validation Loss: 0.6838876008987427
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6734661608934402
  Validation Loss: 0.6836125254631042
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6674546301364899
  Validation Loss: 0.6833614706993103
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6569271385669708
  Validation Loss: 0.6831189393997192
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6671726107597351
  Validation Loss: 0.6828770637512207
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6444366872310638
  Validation Loss: 0.6826295256614685
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6652826964855194
  Validation Loss: 0.6824142336845398
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.670645147562027
  Validation Loss: 0.6822018027305603
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.661276787519455
  Validation Loss: 0.6819870471954346
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6724948585033417
  Validation Loss: 0.6817774772644043
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6514459103345871
  Validation Loss: 0.6815841794013977
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6636244505643845
  Validation Loss: 0.6813639998435974
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6595678180456161
  Validation Loss: 0.6811710000038147
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6631575971841812
  Validation Loss: 0.6809708476066589
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.657873272895813
  Validation Loss: 0.6808146834373474
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6552076488733292
  Validation Loss: 0.6806212067604065
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6619209051132202
  Validation Loss: 0.6804501414299011
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6529226005077362
  Validation Loss: 0.680290937423706
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6542566418647766
  Validation Loss: 0.6801115274429321
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6533723920583725
  Validation Loss: 0.6799718141555786
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6637084186077118
  Validation Loss: 0.6798012256622314
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6697106808423996
  Validation Loss: 0.6796407103538513
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6621440500020981
  Validation Loss: 0.6794906854629517
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6558811515569687
  Validation Loss: 0.6793497204780579
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6684632450342178
  Validation Loss: 0.6792229413986206
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6537269055843353
  Validation Loss: 0.6790894269943237
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6564959585666656
  Validation Loss: 0.6789236664772034
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6542597264051437
  Validation Loss: 0.6787688732147217
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6606312245130539
  Validation Loss: 0.6786537766456604
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6471425890922546
  Validation Loss: 0.6785005927085876
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6640946418046951
  Validation Loss: 0.6783818602561951
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6534435003995895
  Validation Loss: 0.6782658696174622
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6523240357637405
  Validation Loss: 0.6781269311904907
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6526105403900146
  Validation Loss: 0.6779887080192566
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6449881345033646
  Validation Loss: 0.6778574585914612
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6449881345033646, 'val_roc_auc': 0.9802631578947367, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6778574585914612}
 ROC_AUC: 0.9803|| Accuracy 0.9630 || Train Loss: 0.6450
 Val Loss: 0.6779 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7015891985946827
Test ROC-AUC: 0.8782467532467532
Test Accuracy: 0.797752808988764
test_loss: 0.7015891985946827
test_roc_auc: 0.8782467532467532
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6763991117477417
  Validation Loss: 0.6429569721221924
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.9629629850387573
Epoch 2/64:
  Train Loss: 0.6897680312395096
  Validation Loss: 0.642711877822876
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.9629629850387573
Epoch 3/64:
  Train Loss: 0.6911545991897583
  Validation Loss: 0.6424383521080017
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.9629629850387573
Epoch 4/64:
  Train Loss: 0.6677052825689316
  Validation Loss: 0.6421231627464294
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.6770309060811996
  Validation Loss: 0.641792893409729
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.6847347766160965
  Validation Loss: 0.6414657235145569
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.6784000247716904
  Validation Loss: 0.641151487827301
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.6870433241128922
  Validation Loss: 0.6408425569534302
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.6779290288686752
  Validation Loss: 0.6405391097068787
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6760564148426056
  Validation Loss: 0.6402264833450317
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6738831102848053
  Validation Loss: 0.6399298310279846
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.6814519017934799
  Validation Loss: 0.6396381258964539
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.6757628619670868
  Validation Loss: 0.6393560767173767
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.6702290922403336
  Validation Loss: 0.6390964388847351
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6748110800981522
  Validation Loss: 0.6388271450996399
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.683899849653244
  Validation Loss: 0.6385663151741028
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6719567328691483
  Validation Loss: 0.638323187828064
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.6810462921857834
  Validation Loss: 0.6380676627159119
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6774148195981979
  Validation Loss: 0.6378269791603088
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6690223813056946
  Validation Loss: 0.6375865340232849
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.671986848115921
  Validation Loss: 0.6373384594917297
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.6712694764137268
  Validation Loss: 0.6371305584907532
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6692936718463898
  Validation Loss: 0.6369034051895142
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.670883059501648
  Validation Loss: 0.6366878151893616
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6688999831676483
  Validation Loss: 0.6364741921424866
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6719991266727448
  Validation Loss: 0.6363047361373901
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6758019775152206
  Validation Loss: 0.6361168622970581
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6665796935558319
  Validation Loss: 0.6359005570411682
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6770126074552536
  Validation Loss: 0.6357232332229614
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6620835512876511
  Validation Loss: 0.6355443000793457
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.676684096455574
  Validation Loss: 0.6353676319122314
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6607974767684937
  Validation Loss: 0.6351826190948486
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6686297506093979
  Validation Loss: 0.6350024342536926
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6667884737253189
  Validation Loss: 0.6348558664321899
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6715236157178879
  Validation Loss: 0.6346859335899353
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6733853220939636
  Validation Loss: 0.6345168352127075
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6738117933273315
  Validation Loss: 0.6343526244163513
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6650540679693222
  Validation Loss: 0.6341888308525085
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.675337553024292
  Validation Loss: 0.6340324878692627
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6700417399406433
  Validation Loss: 0.6338889598846436
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6646870970726013
  Validation Loss: 0.6337317228317261
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6727093160152435
  Validation Loss: 0.6335986852645874
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6634490340948105
  Validation Loss: 0.6334518194198608
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6714716106653214
  Validation Loss: 0.6333153247833252
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6702157706022263
  Validation Loss: 0.6331776976585388
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6563694179058075
  Validation Loss: 0.63306725025177
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6587544530630112
  Validation Loss: 0.6329367160797119
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6636281460523605
  Validation Loss: 0.6328160166740417
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6734419912099838
  Validation Loss: 0.632685124874115
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6496764868497849
  Validation Loss: 0.632555365562439
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6601844727993011
  Validation Loss: 0.6324298977851868
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.663104236125946
  Validation Loss: 0.6323221325874329
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6602651923894882
  Validation Loss: 0.63221675157547
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6604255735874176
  Validation Loss: 0.6320887804031372
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6593595892190933
  Validation Loss: 0.6319663524627686
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6550255566835403
  Validation Loss: 0.6318491101264954
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6668727993965149
  Validation Loss: 0.6317428946495056
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6571249216794968
  Validation Loss: 0.6316364407539368
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6576607376337051
  Validation Loss: 0.6315464377403259
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:17:33:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:34:INFO:
[92mINFO [0m:      Received: evaluate message ca90d460-6493-4517-8e2c-9be70ebda841
02/06/2025 11:17:34:INFO:Received: evaluate message ca90d460-6493-4517-8e2c-9be70ebda841
[92mINFO [0m:      Sent reply
02/06/2025 11:17:35:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:35:INFO:
[92mINFO [0m:      Received: train message d29eb3e9-ff83-4dd4-af05-d12b2e41e43d
02/06/2025 11:17:35:INFO:Received: train message d29eb3e9-ff83-4dd4-af05-d12b2e41e43d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.668949693441391
  Validation Loss: 0.6314470767974854
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6601090729236603
  Validation Loss: 0.6313236355781555
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6647827923297882
  Validation Loss: 0.6312082409858704
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6642184257507324
  Validation Loss: 0.631121039390564
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6658805310726166
  Validation Loss: 0.6310166716575623
  Val ROC-AUC: 0.9829545454545454
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6658805310726166, 'val_roc_auc': 0.9829545454545454, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6310166716575623}
 ROC_AUC: 0.9830|| Accuracy 0.9630 || Train Loss: 0.6659
 Val Loss: 0.6310 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6997011909993847
Test ROC-AUC: 0.8782467532467533
Test Accuracy: 0.8202247191011236
test_loss: 0.6997011909993847
test_roc_auc: 0.8782467532467533
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6957560777664185
  Validation Loss: 0.6277439594268799
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6845810860395432
  Validation Loss: 0.6274425387382507
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6941622942686081
  Validation Loss: 0.627087414264679
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6887013167142868
  Validation Loss: 0.6266916394233704
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6755931824445724
  Validation Loss: 0.6262931823730469
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6796208173036575
  Validation Loss: 0.6258984208106995
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6794339567422867
  Validation Loss: 0.6254898905754089
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6932029128074646
  Validation Loss: 0.625091552734375
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.6788129508495331
  Validation Loss: 0.6247004866600037
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6675672084093094
  Validation Loss: 0.6243263483047485
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6825933903455734
  Validation Loss: 0.6239684820175171
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6816359162330627
  Validation Loss: 0.6236148476600647
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.6867243200540543
  Validation Loss: 0.6232784390449524
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6763604134321213
  Validation Loss: 0.62293541431427
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6765399724245071
  Validation Loss: 0.6225994229316711
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.6909894198179245
  Validation Loss: 0.6222887635231018
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6793317943811417
  Validation Loss: 0.6219765543937683
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6598192453384399
  Validation Loss: 0.6216916441917419
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6663340479135513
  Validation Loss: 0.6213944554328918
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6756664365530014
  Validation Loss: 0.6211161613464355
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6709119379520416
  Validation Loss: 0.6208428144454956
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6573905348777771
  Validation Loss: 0.6205756664276123
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.675933226943016
  Validation Loss: 0.6203169822692871
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6722182333469391
  Validation Loss: 0.62007737159729
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6715981364250183
  Validation Loss: 0.6198391914367676
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6654656231403351
  Validation Loss: 0.6195971369743347
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.677740141749382
  Validation Loss: 0.6193737983703613
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6695303469896317
  Validation Loss: 0.6191468238830566
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6784809827804565
  Validation Loss: 0.618939995765686
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.670837789773941
  Validation Loss: 0.6187393665313721
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6718436628580093
  Validation Loss: 0.618531346321106
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6679278463125229
  Validation Loss: 0.618327796459198
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6705176681280136
  Validation Loss: 0.6181292533874512
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.673720121383667
  Validation Loss: 0.6179333329200745
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6702013611793518
  Validation Loss: 0.6177584528923035
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6641222685575485
  Validation Loss: 0.617561936378479
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6651560664176941
  Validation Loss: 0.617384672164917
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6623312830924988
  Validation Loss: 0.6172194480895996
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6709502637386322
  Validation Loss: 0.6170520186424255
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6589667946100235
  Validation Loss: 0.6168750524520874
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.666711151599884
  Validation Loss: 0.61672043800354
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6728807985782623
  Validation Loss: 0.6165719032287598
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6710240542888641
  Validation Loss: 0.6164166331291199
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6838577389717102
  Validation Loss: 0.6162682175636292
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6638915538787842
  Validation Loss: 0.6161379218101501
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:17:40:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:40:INFO:
[92mINFO [0m:      Received: evaluate message adea855d-8565-4f2f-b73c-c359947ec5d6
02/06/2025 11:17:40:INFO:Received: evaluate message adea855d-8565-4f2f-b73c-c359947ec5d6
[92mINFO [0m:      Sent reply
02/06/2025 11:17:42:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:42:INFO:
[92mINFO [0m:      Received: train message 60a2b195-81d8-4190-9ef2-0f38cdcc7bc0
02/06/2025 11:17:42:INFO:Received: train message 60a2b195-81d8-4190-9ef2-0f38cdcc7bc0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 46/64:
  Train Loss: 0.6608907580375671
  Validation Loss: 0.6159898042678833
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6576040685176849
  Validation Loss: 0.615843653678894
  Val ROC-AUC: 0.9285714285714285
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6766532361507416
  Validation Loss: 0.6157123446464539
  Val ROC-AUC: 0.923076923076923
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6733198314905167
  Validation Loss: 0.6155859231948853
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6629020422697067
  Validation Loss: 0.6154690384864807
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6703561544418335
  Validation Loss: 0.6153420209884644
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6747724413871765
  Validation Loss: 0.6152185797691345
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6670286059379578
  Validation Loss: 0.6150975227355957
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6638969480991364
  Validation Loss: 0.6149793863296509
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6602102816104889
  Validation Loss: 0.6148691773414612
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6604515165090561
  Validation Loss: 0.6147555708885193
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6621964424848557
  Validation Loss: 0.6146550178527832
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6614155471324921
  Validation Loss: 0.6145366430282593
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.677940309047699
  Validation Loss: 0.6144281625747681
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6653865873813629
  Validation Loss: 0.6143216490745544
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6618006527423859
  Validation Loss: 0.614223837852478
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6584586054086685
  Validation Loss: 0.6141330599784851
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6682580858469009
  Validation Loss: 0.6140421032905579
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6578688025474548
  Validation Loss: 0.613946795463562
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6578688025474548, 'val_roc_auc': 0.9285714285714286, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.613946795463562}
 ROC_AUC: 0.9286|| Accuracy 0.8889 || Train Loss: 0.6579
 Val Loss: 0.6139 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6980717054913553
Test ROC-AUC: 0.8782467532467533
Test Accuracy: 0.8314606741573034
test_loss: 0.6980717054913553
test_roc_auc: 0.8782467532467533
test_accuracy: 0.8314606741573034
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.689346969127655
  Validation Loss: 0.609536349773407
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6846467554569244
  Validation Loss: 0.6091774106025696
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6922503113746643
  Validation Loss: 0.6087886691093445
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6650289446115494
  Validation Loss: 0.6083664298057556
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6892190873622894
  Validation Loss: 0.6079431772232056
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.67934650182724
  Validation Loss: 0.607502281665802
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6807180494070053
  Validation Loss: 0.6070595383644104
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6911302655935287
  Validation Loss: 0.606622576713562
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6804882287979126
  Validation Loss: 0.6061810851097107
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6813409924507141
  Validation Loss: 0.6057666540145874
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6773349195718765
  Validation Loss: 0.6053515076637268
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6689645349979401
  Validation Loss: 0.60494065284729
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6837930232286453
  Validation Loss: 0.6045684218406677
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6870176494121552
  Validation Loss: 0.6041824817657471
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6910727620124817
  Validation Loss: 0.6038222312927246
  Val ROC-AUC: 0.9725274725274725
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6798144727945328
  Validation Loss: 0.6034466624259949
  Val ROC-AUC: 0.9725274725274725
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6806841492652893
  Validation Loss: 0.6030846834182739
  Val ROC-AUC: 0.9725274725274725
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6797275543212891
  Validation Loss: 0.602750837802887
  Val ROC-AUC: 0.9725274725274725
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6772465407848358
  Validation Loss: 0.6024194955825806
  Val ROC-AUC: 0.9725274725274725
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6707673370838165
  Validation Loss: 0.6020985245704651
  Val ROC-AUC: 0.9725274725274725
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6710857450962067
  Validation Loss: 0.601782500743866
  Val ROC-AUC: 0.9725274725274725
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6737663894891739
  Validation Loss: 0.6014793515205383
  Val ROC-AUC: 0.9725274725274725
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6866443306207657
  Validation Loss: 0.6011785864830017
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6798373758792877
  Validation Loss: 0.600882351398468
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6771671324968338
  Validation Loss: 0.6005843877792358
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6802895814180374
  Validation Loss: 0.6002896428108215
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6778784394264221
  Validation Loss: 0.6000164151191711
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6900409311056137
  Validation Loss: 0.5997627973556519
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6726912558078766
  Validation Loss: 0.5994969010353088
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6668867617845535
  Validation Loss: 0.5992422699928284
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6704374849796295
  Validation Loss: 0.5989900827407837
  Val ROC-AUC: 0.9835164835164835
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:17:47:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:47:INFO:
[92mINFO [0m:      Received: evaluate message 5821ad30-2dfc-42a2-a095-1aa887d263a7
02/06/2025 11:17:47:INFO:Received: evaluate message 5821ad30-2dfc-42a2-a095-1aa887d263a7
[92mINFO [0m:      Sent reply
02/06/2025 11:17:48:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:48:INFO:
[92mINFO [0m:      Received: train message 3429dfc3-9a27-47e2-92ab-d78a7e00a549
02/06/2025 11:17:48:INFO:Received: train message 3429dfc3-9a27-47e2-92ab-d78a7e00a549
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6648143082857132
  Validation Loss: 0.5987509489059448
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6671393066644669
  Validation Loss: 0.5985191464424133
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6804113537073135
  Validation Loss: 0.5982739329338074
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6744643747806549
  Validation Loss: 0.5980414748191833
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6805907934904099
  Validation Loss: 0.5978221893310547
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6593370288610458
  Validation Loss: 0.5976093411445618
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.667940229177475
  Validation Loss: 0.5974040627479553
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.669066846370697
  Validation Loss: 0.5971811413764954
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6661818474531174
  Validation Loss: 0.5969841480255127
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6674168407917023
  Validation Loss: 0.5967756509780884
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6680728197097778
  Validation Loss: 0.5965713262557983
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6741092354059219
  Validation Loss: 0.5963860750198364
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.668528363108635
  Validation Loss: 0.5962023138999939
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.665120080113411
  Validation Loss: 0.5960269570350647
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6716751307249069
  Validation Loss: 0.5958524942398071
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6643063873052597
  Validation Loss: 0.5956802368164062
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6804032325744629
  Validation Loss: 0.5955026745796204
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6819436401128769
  Validation Loss: 0.5953383445739746
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6683169603347778
  Validation Loss: 0.5951703190803528
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.675153449177742
  Validation Loss: 0.595009982585907
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6732898056507111
  Validation Loss: 0.5948595404624939
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6743881404399872
  Validation Loss: 0.5947080850601196
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6619303673505783
  Validation Loss: 0.5945561528205872
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6737218648195267
  Validation Loss: 0.5944131016731262
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6689358949661255
  Validation Loss: 0.5942601561546326
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6711288094520569
  Validation Loss: 0.5941188931465149
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6712386906147003
  Validation Loss: 0.5939728617668152
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6621280312538147
  Validation Loss: 0.5938302278518677
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6810189634561539
  Validation Loss: 0.5936961770057678
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6553846448659897
  Validation Loss: 0.5935629606246948
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6743222624063492
  Validation Loss: 0.5934370160102844
  Val ROC-AUC: 0.9835164835164835
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6602233648300171
  Validation Loss: 0.5933051109313965
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6690974533557892
  Validation Loss: 0.5931817293167114
  Val ROC-AUC: 0.9780219780219781
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6690974533557892, 'val_roc_auc': 0.9780219780219781, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.5931817293167114}
 ROC_AUC: 0.9780|| Accuracy 0.9259 || Train Loss: 0.6691
 Val Loss: 0.5932 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6966537277350265
Test ROC-AUC: 0.8793290043290043
Test Accuracy: 0.8202247191011236
test_loss: 0.6966537277350265
test_roc_auc: 0.8793290043290043
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6772390455007553
  Validation Loss: 0.6436894536018372
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6706555932760239
  Validation Loss: 0.6433258056640625
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6654448807239532
  Validation Loss: 0.6429272890090942
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6698599606752396
  Validation Loss: 0.6424833536148071
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6899183839559555
  Validation Loss: 0.6420267820358276
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6848819851875305
  Validation Loss: 0.6415846347808838
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6763424724340439
  Validation Loss: 0.6411163806915283
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.665973573923111
  Validation Loss: 0.6406435370445251
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.6767853498458862
  Validation Loss: 0.6401867270469666
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6675353646278381
  Validation Loss: 0.6397183537483215
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6691780835390091
  Validation Loss: 0.639281690120697
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6650601774454117
  Validation Loss: 0.638848066329956
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.6620729118585587
  Validation Loss: 0.6384397745132446
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6804705262184143
  Validation Loss: 0.6380431652069092
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6662833839654922
  Validation Loss: 0.6376652717590332
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.6733906716108322
  Validation Loss: 0.6372553706169128
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6717045307159424
  Validation Loss: 0.6368913054466248
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:17:53:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:53:INFO:
[92mINFO [0m:      Received: evaluate message ae118032-0937-4180-9737-141d1f951555
02/06/2025 11:17:53:INFO:Received: evaluate message ae118032-0937-4180-9737-141d1f951555
[92mINFO [0m:      Sent reply
02/06/2025 11:17:55:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:17:55:INFO:
[92mINFO [0m:      Received: train message b53f3677-674f-4d27-9631-aba8775bd172
02/06/2025 11:17:55:INFO:Received: train message b53f3677-674f-4d27-9631-aba8775bd172
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.681558296084404
  Validation Loss: 0.6365104913711548
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6567523032426834
  Validation Loss: 0.6361541748046875
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.669418215751648
  Validation Loss: 0.6358194947242737
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6791399568319321
  Validation Loss: 0.6354765892028809
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6684419214725494
  Validation Loss: 0.6351438760757446
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.6698543578386307
  Validation Loss: 0.6348283886909485
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.661500945687294
  Validation Loss: 0.6344956159591675
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.6708193719387054
  Validation Loss: 0.6341899037361145
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6701501607894897
  Validation Loss: 0.6338984966278076
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.6705425530672073
  Validation Loss: 0.6336197853088379
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6666868329048157
  Validation Loss: 0.633340060710907
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6575416773557663
  Validation Loss: 0.633070707321167
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.6653514802455902
  Validation Loss: 0.6327968239784241
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.670841172337532
  Validation Loss: 0.6325156688690186
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.6588600426912308
  Validation Loss: 0.6322749853134155
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6660977900028229
  Validation Loss: 0.6320223212242126
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6587241291999817
  Validation Loss: 0.6317805051803589
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.662197545170784
  Validation Loss: 0.6315426230430603
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6677410155534744
  Validation Loss: 0.6313230991363525
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6601524353027344
  Validation Loss: 0.6311054825782776
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6575309932231903
  Validation Loss: 0.6308832764625549
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6726648658514023
  Validation Loss: 0.6306769847869873
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6497172713279724
  Validation Loss: 0.6304768919944763
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6645630896091461
  Validation Loss: 0.6302729249000549
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6617833077907562
  Validation Loss: 0.6300865411758423
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6660935282707214
  Validation Loss: 0.6299007534980774
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6708554476499557
  Validation Loss: 0.6297194957733154
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6648908406496048
  Validation Loss: 0.6295254826545715
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6714952439069748
  Validation Loss: 0.6293585896492004
  Val ROC-AUC: 0.9611111111111111
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6599565893411636
  Validation Loss: 0.6291815638542175
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.664407417178154
  Validation Loss: 0.6290083527565002
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6450441479682922
  Validation Loss: 0.6288555264472961
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6734020262956619
  Validation Loss: 0.6286882758140564
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6571728587150574
  Validation Loss: 0.6285334229469299
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6576401144266129
  Validation Loss: 0.628371000289917
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6656471937894821
  Validation Loss: 0.628230631351471
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6700934618711472
  Validation Loss: 0.628067135810852
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6668672412633896
  Validation Loss: 0.627920389175415
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6478795558214188
  Validation Loss: 0.6277743577957153
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.663675993680954
  Validation Loss: 0.6276342868804932
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6549601852893829
  Validation Loss: 0.6274924278259277
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6634615808725357
  Validation Loss: 0.6273576021194458
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.658531978726387
  Validation Loss: 0.6272426843643188
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6717571765184402
  Validation Loss: 0.6271102428436279
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6650378704071045
  Validation Loss: 0.6269934177398682
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6581434458494186
  Validation Loss: 0.626876711845398
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6549362242221832
  Validation Loss: 0.62677001953125
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6549362242221832, 'val_roc_auc': 0.9666666666666668, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.62677001953125}
 ROC_AUC: 0.9667|| Accuracy 0.8889 || Train Loss: 0.6549
 Val Loss: 0.6268 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6954775553071098
Test ROC-AUC: 0.8782467532467533
Test Accuracy: 0.8202247191011236
test_loss: 0.6954775553071098
test_roc_auc: 0.8782467532467533
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6689839214086533
  Validation Loss: 0.6732611656188965
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.66954405605793
  Validation Loss: 0.6730369329452515
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6721989512443542
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6727790236473083
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.665531113743782
  Validation Loss: 0.6725167036056519
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6667815148830414
  Validation Loss: 0.6722440123558044
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6562813073396683
  Validation Loss: 0.671937108039856
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6726614683866501
  Validation Loss: 0.6716728210449219
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6548865884542465
  Validation Loss: 0.671401858329773
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6756033152341843
  Validation Loss: 0.6711344122886658
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.653828427195549
  Validation Loss: 0.6708911061286926
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6531706005334854
  Validation Loss: 0.6706249713897705
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6756739020347595
  Validation Loss: 0.6703912019729614
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6471952944993973
  Validation Loss: 0.6701329350471497
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6662954539060593
  Validation Loss: 0.6698867082595825
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6650866866111755
  Validation Loss: 0.6696621775627136
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6590579301118851
  Validation Loss: 0.6694372892379761
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.651672750711441
  Validation Loss: 0.6692484021186829
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6613159328699112
  Validation Loss: 0.6690390706062317
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6592679619789124
  Validation Loss: 0.6688311100006104
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.653636708855629
  Validation Loss: 0.6686220765113831
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6585859656333923
  Validation Loss: 0.6684296131134033
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6621284782886505
  Validation Loss: 0.6682335138320923
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6544576287269592
  Validation Loss: 0.6680183410644531
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6597845703363419
  Validation Loss: 0.6678333282470703
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6552959680557251
  Validation Loss: 0.6676287651062012
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6582184135913849
  Validation Loss: 0.6674408316612244
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6638789772987366
  Validation Loss: 0.6672672629356384
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6563423126935959
  Validation Loss: 0.667121946811676
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6529593765735626
  Validation Loss: 0.667000412940979
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6531471014022827
  Validation Loss: 0.6668401956558228
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6512348651885986
  Validation Loss: 0.6666809320449829
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6521840244531631
  Validation Loss: 0.6665040254592896
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6365914642810822
  Validation Loss: 0.6663448214530945
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6564964056015015
  Validation Loss: 0.6661936044692993
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6474946588277817
  Validation Loss: 0.6660422086715698
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6518857479095459
  Validation Loss: 0.665894627571106
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6630667150020599
  Validation Loss: 0.6657652258872986
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6510678082704544
  Validation Loss: 0.6656530499458313
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.661998987197876
  Validation Loss: 0.6654914617538452
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6523492634296417
  Validation Loss: 0.6653673648834229
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.660327211022377
  Validation Loss: 0.6652378439903259
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.659279927611351
  Validation Loss: 0.6650959253311157
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6523601710796356
  Validation Loss: 0.66500324010849
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6603451073169708
  Validation Loss: 0.664864718914032
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6598264873027802
  Validation Loss: 0.6647242903709412
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6584656238555908
  Validation Loss: 0.6646166443824768
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.654682844877243
  Validation Loss: 0.6644798517227173
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6431096643209457
  Validation Loss: 0.6643725037574768
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6517173498868942
  Validation Loss: 0.6642943620681763
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6521661579608917
  Validation Loss: 0.6641896367073059
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6622662097215652
  Validation Loss: 0.6640692949295044
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6475241631269455
  Validation Loss: 0.6639644503593445
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6536219120025635
  Validation Loss: 0.6638810038566589
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.639763668179512
  Validation Loss: 0.6637783646583557
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6488755792379379
  Validation Loss: 0.6636858582496643
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.636265218257904
  Validation Loss: 0.6635767817497253
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8888888955116272
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:18:00:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:00:INFO:
[92mINFO [0m:      Received: evaluate message f69cd952-5846-4584-b8d2-ab7d17713d7a
02/06/2025 11:18:00:INFO:Received: evaluate message f69cd952-5846-4584-b8d2-ab7d17713d7a
[92mINFO [0m:      Sent reply
02/06/2025 11:18:01:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:01:INFO:
[92mINFO [0m:      Received: train message 1cbbc066-d728-4909-bae2-e8f03572b363
02/06/2025 11:18:01:INFO:Received: train message 1cbbc066-d728-4909-bae2-e8f03572b363
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 57/64:
  Train Loss: 0.6579670906066895
  Validation Loss: 0.6634712815284729
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6395769417285919
  Validation Loss: 0.6633738875389099
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6504102051258087
  Validation Loss: 0.66329425573349
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6519459784030914
  Validation Loss: 0.6632316708564758
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6476673036813736
  Validation Loss: 0.6631256341934204
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.660048633813858
  Validation Loss: 0.6630226969718933
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6409060657024384
  Validation Loss: 0.6629531979560852
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6448076516389847
  Validation Loss: 0.6628950238227844
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6448076516389847, 'val_roc_auc': 0.9294117647058823, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6628950238227844}
 ROC_AUC: 0.9294|| Accuracy 0.8889 || Train Loss: 0.6448
 Val Loss: 0.6629 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6945051852236973
Test ROC-AUC: 0.8782467532467534
Test Accuracy: 0.8202247191011236
test_loss: 0.6945051852236973
test_roc_auc: 0.8782467532467534
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6684914827346802
  Validation Loss: 0.6367263197898865
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.6703176647424698
  Validation Loss: 0.6363998651504517
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.6795137971639633
  Validation Loss: 0.6360336542129517
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.6675913333892822
  Validation Loss: 0.6356298923492432
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.6653821617364883
  Validation Loss: 0.635232150554657
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.6728382706642151
  Validation Loss: 0.6348002552986145
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.6743822991847992
  Validation Loss: 0.6343877911567688
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.7777777910232544
Epoch 8/64:
  Train Loss: 0.6759540438652039
  Validation Loss: 0.6339618563652039
  Val ROC-AUC: 0.8626373626373626
  Val Accuracy: 0.7777777910232544
Epoch 9/64:
  Train Loss: 0.6640563309192657
  Validation Loss: 0.6335777044296265
  Val ROC-AUC: 0.8736263736263736
  Val Accuracy: 0.7777777910232544
Epoch 10/64:
  Train Loss: 0.6783844977617264
  Validation Loss: 0.6332011222839355
  Val ROC-AUC: 0.8736263736263736
  Val Accuracy: 0.7777777910232544
Epoch 11/64:
  Train Loss: 0.6802183538675308
  Validation Loss: 0.6328268647193909
  Val ROC-AUC: 0.8736263736263736
  Val Accuracy: 0.7777777910232544
Epoch 12/64:
  Train Loss: 0.6650852113962173
  Validation Loss: 0.6324286460876465
  Val ROC-AUC: 0.8736263736263736
  Val Accuracy: 0.7777777910232544
Epoch 13/64:
  Train Loss: 0.659827321767807
  Validation Loss: 0.6320788264274597
  Val ROC-AUC: 0.8791208791208791
  Val Accuracy: 0.7777777910232544
Epoch 14/64:
  Train Loss: 0.6683412343263626
  Validation Loss: 0.6317452192306519
  Val ROC-AUC: 0.8791208791208791
  Val Accuracy: 0.7777777910232544
Epoch 15/64:
  Train Loss: 0.6682730913162231
  Validation Loss: 0.63140869140625
  Val ROC-AUC: 0.8791208791208791
  Val Accuracy: 0.7777777910232544
Epoch 16/64:
  Train Loss: 0.6668803244829178
  Validation Loss: 0.631085991859436
  Val ROC-AUC: 0.8791208791208791
  Val Accuracy: 0.7777777910232544
Epoch 17/64:
  Train Loss: 0.6648838520050049
  Validation Loss: 0.6307456493377686
  Val ROC-AUC: 0.8791208791208791
  Val Accuracy: 0.7777777910232544
Epoch 18/64:
  Train Loss: 0.6680614501237869
  Validation Loss: 0.630424439907074
  Val ROC-AUC: 0.8846153846153846
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.6751463860273361
  Validation Loss: 0.6301497220993042
  Val ROC-AUC: 0.8846153846153846
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.6691408455371857
  Validation Loss: 0.6298659443855286
  Val ROC-AUC: 0.8901098901098901
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.6547598987817764
  Validation Loss: 0.629594087600708
  Val ROC-AUC: 0.8901098901098901
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.6697440594434738
  Validation Loss: 0.6293259859085083
  Val ROC-AUC: 0.8901098901098901
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.6677059382200241
  Validation Loss: 0.6290654540061951
  Val ROC-AUC: 0.8956043956043955
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.6780812740325928
  Validation Loss: 0.6288045048713684
  Val ROC-AUC: 0.8901098901098901
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.6633395850658417
  Validation Loss: 0.6285496354103088
  Val ROC-AUC: 0.8956043956043955
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.6647898554801941
  Validation Loss: 0.6283079981803894
  Val ROC-AUC: 0.8956043956043955
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.6702208369970322
  Validation Loss: 0.6280834078788757
  Val ROC-AUC: 0.8956043956043955
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.6651732325553894
  Validation Loss: 0.6278602480888367
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.6589901298284531
  Validation Loss: 0.6276572942733765
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.7777777910232544
Epoch 30/64:
  Train Loss: 0.6630457490682602
  Validation Loss: 0.6274471282958984
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.7777777910232544
Epoch 31/64:
  Train Loss: 0.6592163443565369
  Validation Loss: 0.6272434592247009
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.7777777910232544
Epoch 32/64:
  Train Loss: 0.6629648953676224
  Validation Loss: 0.6270250678062439
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.7777777910232544
Epoch 33/64:
  Train Loss: 0.6585906445980072
  Validation Loss: 0.6268278956413269
  Val ROC-AUC: 0.9010989010989011
  Val Accuracy: 0.7777777910232544
Epoch 34/64:
  Train Loss: 0.6634870618581772
  Validation Loss: 0.6266554594039917
  Val ROC-AUC: 0.9065934065934065
  Val Accuracy: 0.7777777910232544
Epoch 35/64:
  Train Loss: 0.6652235835790634
  Validation Loss: 0.6264776587486267
  Val ROC-AUC: 0.9065934065934065
  Val Accuracy: 0.7777777910232544
Epoch 36/64:
  Train Loss: 0.6526652425527573
  Validation Loss: 0.626301109790802
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.7777777910232544
Epoch 37/64:
  Train Loss: 0.6645937561988831
  Validation Loss: 0.6261332035064697
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.7777777910232544
Epoch 38/64:
  Train Loss: 0.6606620997190475
  Validation Loss: 0.6259655952453613
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.7777777910232544
Epoch 39/64:
  Train Loss: 0.6621584445238113
  Validation Loss: 0.6257959604263306
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.7777777910232544
Epoch 40/64:
  Train Loss: 0.6681443601846695
  Validation Loss: 0.6256396174430847
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.7777777910232544
Epoch 41/64:
  Train Loss: 0.6651089042425156
  Validation Loss: 0.6254998445510864
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 42/64:
  Train Loss: 0.6587298810482025
  Validation Loss: 0.6253467798233032
  Val ROC-AUC: 0.9175824175824175
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:18:06:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:06:INFO:
[92mINFO [0m:      Received: evaluate message 15f6d727-8131-4f41-87fd-02240dd38037
02/06/2025 11:18:06:INFO:Received: evaluate message 15f6d727-8131-4f41-87fd-02240dd38037
[92mINFO [0m:      Sent reply
02/06/2025 11:18:07:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:07:INFO:
[92mINFO [0m:      Received: train message f96f3310-228e-4c83-afe7-b44c46fa7a17
02/06/2025 11:18:07:INFO:Received: train message f96f3310-228e-4c83-afe7-b44c46fa7a17
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.7777777910232544
Epoch 43/64:
  Train Loss: 0.6661515533924103
  Validation Loss: 0.6252066493034363
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 44/64:
  Train Loss: 0.6741353273391724
  Validation Loss: 0.6250615119934082
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 45/64:
  Train Loss: 0.6490670144557953
  Validation Loss: 0.6249237060546875
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 46/64:
  Train Loss: 0.6503459215164185
  Validation Loss: 0.6247851252555847
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 47/64:
  Train Loss: 0.6615650653839111
  Validation Loss: 0.6246810555458069
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 48/64:
  Train Loss: 0.6563395708799362
  Validation Loss: 0.6245678067207336
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 49/64:
  Train Loss: 0.661436915397644
  Validation Loss: 0.6244409680366516
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 50/64:
  Train Loss: 0.6553189307451248
  Validation Loss: 0.6243298053741455
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 51/64:
  Train Loss: 0.6636375039815903
  Validation Loss: 0.6242057681083679
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 52/64:
  Train Loss: 0.6603543311357498
  Validation Loss: 0.6240884065628052
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 53/64:
  Train Loss: 0.6513129770755768
  Validation Loss: 0.6239745616912842
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 54/64:
  Train Loss: 0.6565695703029633
  Validation Loss: 0.6238869428634644
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 55/64:
  Train Loss: 0.6622439622879028
  Validation Loss: 0.6237809062004089
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 56/64:
  Train Loss: 0.6545282602310181
  Validation Loss: 0.6236903071403503
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 57/64:
  Train Loss: 0.6582135707139969
  Validation Loss: 0.6235957145690918
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 58/64:
  Train Loss: 0.6524279415607452
  Validation Loss: 0.6235026717185974
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 59/64:
  Train Loss: 0.6588250398635864
  Validation Loss: 0.6234291791915894
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 60/64:
  Train Loss: 0.6595050096511841
  Validation Loss: 0.6233425736427307
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 61/64:
  Train Loss: 0.6543205082416534
  Validation Loss: 0.6232560276985168
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 62/64:
  Train Loss: 0.6521267592906952
  Validation Loss: 0.6231693029403687
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 63/64:
  Train Loss: 0.6598930656909943
  Validation Loss: 0.6230781078338623
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
Epoch 64/64:
  Train Loss: 0.654037818312645
  Validation Loss: 0.6230055689811707
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.7777777910232544
{'train_loss': 0.654037818312645, 'val_roc_auc': 0.9175824175824175, 'val_accuracy': 0.7777777910232544, 'val_loss': 0.6230055689811707}
 ROC_AUC: 0.9176|| Accuracy 0.7778 || Train Loss: 0.6540
 Val Loss: 0.6230 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6937165005823199
Test ROC-AUC: 0.8777056277056278
Test Accuracy: 0.8202247191011236
test_loss: 0.6937165005823199
test_roc_auc: 0.8777056277056278
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6529232561588287
  Validation Loss: 0.7102683782577515
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6532706320285797
  Validation Loss: 0.7100281715393066
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.646518275141716
  Validation Loss: 0.7098024487495422
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6508971303701401
  Validation Loss: 0.7095344066619873
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6440102458000183
  Validation Loss: 0.7092815041542053
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6497256308794022
  Validation Loss: 0.7090150117874146
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6461407691240311
  Validation Loss: 0.7087342143058777
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6555110663175583
  Validation Loss: 0.7085058689117432
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6650639027357101
  Validation Loss: 0.7082651257514954
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6513851881027222
  Validation Loss: 0.7080223560333252
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6511218547821045
  Validation Loss: 0.7078015208244324
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.651642382144928
  Validation Loss: 0.7075689435005188
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.648392528295517
  Validation Loss: 0.7073574662208557
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6559075713157654
  Validation Loss: 0.7071609497070312
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6574704200029373
  Validation Loss: 0.7069591879844666
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6430279910564423
  Validation Loss: 0.7067400217056274
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6585504710674286
  Validation Loss: 0.70656418800354
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6480610817670822
  Validation Loss: 0.7064079642295837
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6522993743419647
  Validation Loss: 0.706230640411377
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6439039260149002
  Validation Loss: 0.7060922980308533
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6350284516811371
  Validation Loss: 0.705912709236145
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6526143699884415
  Validation Loss: 0.7057567238807678
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6502645611763
  Validation Loss: 0.7056118845939636
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6452447772026062
  Validation Loss: 0.7054796814918518
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.661832258105278
  Validation Loss: 0.7053118348121643
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6474446505308151
  Validation Loss: 0.7051860690116882
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6399953961372375
  Validation Loss: 0.70506352186203
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6357228010892868
  Validation Loss: 0.7049607038497925
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:18:12:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:12:INFO:
[92mINFO [0m:      Received: evaluate message db14c618-8f1c-439a-aa06-43e44af94648
02/06/2025 11:18:12:INFO:Received: evaluate message db14c618-8f1c-439a-aa06-43e44af94648
[92mINFO [0m:      Sent reply
02/06/2025 11:18:14:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:14:INFO:
[92mINFO [0m:      Received: train message 1e96b8d3-12be-49bc-a5cf-2319f94fb1ad
02/06/2025 11:18:14:INFO:Received: train message 1e96b8d3-12be-49bc-a5cf-2319f94fb1ad
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6502576023340225
  Validation Loss: 0.7048255205154419
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6517948806285858
  Validation Loss: 0.7046956419944763
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6373834609985352
  Validation Loss: 0.7045924067497253
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6361118704080582
  Validation Loss: 0.7044821977615356
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6510709375143051
  Validation Loss: 0.7043688893318176
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6483464241027832
  Validation Loss: 0.7042765021324158
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6352686733007431
  Validation Loss: 0.7041727900505066
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6412151157855988
  Validation Loss: 0.7040721774101257
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6277674287557602
  Validation Loss: 0.7039949893951416
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.641177237033844
  Validation Loss: 0.7038795948028564
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6349076628684998
  Validation Loss: 0.7038048505783081
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6513828039169312
  Validation Loss: 0.7037231922149658
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6470290869474411
  Validation Loss: 0.7036358118057251
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6307974010705948
  Validation Loss: 0.7035411596298218
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6438275873661041
  Validation Loss: 0.7034740447998047
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6488295644521713
  Validation Loss: 0.7034099698066711
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.63787941634655
  Validation Loss: 0.7033371925354004
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6354402452707291
  Validation Loss: 0.703273355960846
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6496637761592865
  Validation Loss: 0.7032013535499573
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6439134329557419
  Validation Loss: 0.7031373381614685
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6577565371990204
  Validation Loss: 0.7030929923057556
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6434030830860138
  Validation Loss: 0.7030335664749146
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6326521337032318
  Validation Loss: 0.7029728889465332
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.628768265247345
  Validation Loss: 0.7029208540916443
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6382941901683807
  Validation Loss: 0.7028640508651733
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6394669264554977
  Validation Loss: 0.7028089761734009
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6574712097644806
  Validation Loss: 0.7027546167373657
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6319071352481842
  Validation Loss: 0.7027319669723511
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6257205009460449
  Validation Loss: 0.7026869654655457
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.640242263674736
  Validation Loss: 0.7026404142379761
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6512272953987122
  Validation Loss: 0.7025935053825378
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6376548409461975
  Validation Loss: 0.7025390267372131
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6374401152133942
  Validation Loss: 0.7024803161621094
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6528159976005554
  Validation Loss: 0.7024248242378235
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6276211440563202
  Validation Loss: 0.7023491859436035
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6459978520870209
  Validation Loss: 0.7023069858551025
  Val ROC-AUC: 0.9682539682539681
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6459978520870209, 'val_roc_auc': 0.9682539682539681, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.7023069858551025}
 ROC_AUC: 0.9683|| Accuracy 0.9259 || Train Loss: 0.6460
 Val Loss: 0.7023 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6931209480494596
Test ROC-AUC: 0.8782467532467533
Test Accuracy: 0.8202247191011236
test_loss: 0.6931209480494596
test_roc_auc: 0.8782467532467533
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6629945188760757
  Validation Loss: 0.6624794006347656
  Val ROC-AUC: 0.9647058823529412
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6610468029975891
  Validation Loss: 0.6624295115470886
  Val ROC-AUC: 0.9647058823529412
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6652801930904388
  Validation Loss: 0.6623347997665405
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6689023077487946
  Validation Loss: 0.6622307896614075
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6489129960536957
  Validation Loss: 0.6621228456497192
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6650393605232239
  Validation Loss: 0.66202312707901
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6706792563199997
  Validation Loss: 0.6619282960891724
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6754607707262039
  Validation Loss: 0.6618176102638245
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.658968910574913
  Validation Loss: 0.6617540717124939
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6497749835252762
  Validation Loss: 0.6616742014884949
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6624171733856201
  Validation Loss: 0.6615776419639587
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6624309420585632
  Validation Loss: 0.6615012884140015
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.6637866348028183
  Validation Loss: 0.6614235639572144
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.668147549033165
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:18:19:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:19:INFO:
[92mINFO [0m:      Received: evaluate message aaeb79d6-89f0-41d8-a9ad-dd71ed2a67e0
02/06/2025 11:18:19:INFO:Received: evaluate message aaeb79d6-89f0-41d8-a9ad-dd71ed2a67e0
  Validation Loss: 0.6613425612449646
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6644322276115417
  Validation Loss: 0.661284863948822
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.669734537601471
  Validation Loss: 0.6612315773963928
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6524189859628677
  Validation Loss: 0.6611855626106262
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6559431552886963
  Validation Loss: 0.6611428260803223
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6487275063991547
  Validation Loss: 0.6611148118972778
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.657655730843544
  Validation Loss: 0.6610903739929199
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6486921608448029
  Validation Loss: 0.6610512733459473
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6565383523702621
  Validation Loss: 0.6610232591629028
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.6531217247247696
  Validation Loss: 0.6609916687011719
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.6568257659673691
  Validation Loss: 0.6609798073768616
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.645738959312439
  Validation Loss: 0.6609505414962769
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6575068533420563
  Validation Loss: 0.6609345078468323
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.6503033339977264
  Validation Loss: 0.6609187722206116
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6629041433334351
  Validation Loss: 0.6608786582946777
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6576034426689148
  Validation Loss: 0.660860538482666
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.6465106755495071
  Validation Loss: 0.6608337759971619
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.6520001590251923
  Validation Loss: 0.6608425974845886
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.6512542515993118
  Validation Loss: 0.6608290672302246
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 33/64:
  Train Loss: 0.669273242354393
  Validation Loss: 0.6608416438102722
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 34/64:
  Train Loss: 0.6529317051172256
  Validation Loss: 0.6608259677886963
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 35/64:
  Train Loss: 0.6552413105964661
  Validation Loss: 0.6608344316482544
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 36/64:
  Train Loss: 0.6487389802932739
  Validation Loss: 0.6608249545097351
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 37/64:
  Train Loss: 0.6560731083154678
  Validation Loss: 0.6608137488365173
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 38/64:
  Train Loss: 0.6610728204250336
  Validation Loss: 0.6607983708381653
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 39/64:
  Train Loss: 0.6464283168315887
  Validation Loss: 0.6607991456985474
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 40/64:
  Train Loss: 0.6562868058681488
  Validation Loss: 0.6607974767684937
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 41/64:
  Train Loss: 0.6451797783374786
  Validation Loss: 0.6608014106750488
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.647917777299881
  Validation Loss: 0.6608099341392517
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6551690697669983
  Validation Loss: 0.6607971787452698
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6425314843654633
  Validation Loss: 0.6608012318611145
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6470232605934143
  Validation Loss: 0.6608275771141052
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6602094173431396
  Validation Loss: 0.6608182191848755
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 47/64:
  Train Loss: 0.6483246833086014
  Validation Loss: 0.6608048677444458
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.6470553874969482
  Validation Loss: 0.6608272790908813
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.6447746157646179
  Validation Loss: 0.6608324646949768
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.648666262626648
  Validation Loss: 0.6608321070671082
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6483327597379684
  Validation Loss: 0.6608389616012573
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.656097799539566
  Validation Loss: 0.66084223985672
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.6533055156469345
  Validation Loss: 0.6608549952507019
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6443095803260803
  Validation Loss: 0.6608569622039795
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.6408429443836212
  Validation Loss: 0.660857617855072
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6527162194252014
  Validation Loss: 0.6608604192733765
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6403429806232452
  Validation Loss: 0.6608636975288391
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6489047110080719
  Validation Loss: 0.6608796119689941
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.659943625330925
  Validation Loss: 0.6609060764312744
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.6526679992675781
  Validation Loss: 0.6608943939208984
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6509272158145905
  Validation Loss: 0.6609028577804565
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.6476188004016876
  Validation Loss: 0.6609233021736145
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6575175821781158
  Validation Loss: 0.6609285473823547
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.6434736549854279
  Validation Loss: 0.660910427570343
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
{'train_loss': 0.6434736549854279, 'val_roc_auc': 0.9352941176470588, 'val_accuracy': 0.8518518805503845, 'val_loss': 0.660910427570343}
 ROC_AUC: 0.9353|| Accuracy 0.8519 || Train Loss: 0.6435
 Val Loss: 0.6609 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6926544713840056
Test ROC-AUC: 0.8782467532467533
Test Accuracy: 0.8314606741573034
test_loss: 0.6926544713840056
test_roc_auc: 0.8782467532467533
[92mINFO [0m:      Sent reply
02/06/2025 11:18:20:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:20:INFO:
[92mINFO [0m:      Received: train message 104505e8-e5fb-4854-930a-5d9f9edce2f2
02/06/2025 11:18:20:INFO:Received: train message 104505e8-e5fb-4854-930a-5d9f9edce2f2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
test_accuracy: 0.8314606741573034
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6481717526912689
  Validation Loss: 0.6591002345085144
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6603523045778275
  Validation Loss: 0.658843457698822
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6646794080734253
  Validation Loss: 0.6585571765899658
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.679073303937912
  Validation Loss: 0.6582356095314026
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6597412377595901
  Validation Loss: 0.6579006314277649
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6702488511800766
  Validation Loss: 0.6575720906257629
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6600651890039444
  Validation Loss: 0.657248318195343
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6691950410604477
  Validation Loss: 0.656914472579956
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6648794412612915
  Validation Loss: 0.6565933227539062
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6698351204395294
  Validation Loss: 0.656277596950531
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6675189733505249
  Validation Loss: 0.6559582948684692
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6621719747781754
  Validation Loss: 0.6556707620620728
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6568284630775452
  Validation Loss: 0.6553856730461121
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6619708985090256
  Validation Loss: 0.6550908088684082
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6567499190568924
  Validation Loss: 0.6548225283622742
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6593786329030991
  Validation Loss: 0.6545692086219788
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.663061797618866
  Validation Loss: 0.6543165445327759
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.6580567508935928
  Validation Loss: 0.6540611982345581
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6666485220193863
  Validation Loss: 0.6538436412811279
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6541094481945038
  Validation Loss: 0.6536160111427307
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6609004586935043
  Validation Loss: 0.6533870100975037
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.6618974059820175
  Validation Loss: 0.6531707644462585
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6529375463724136
  Validation Loss: 0.6529644131660461
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6467481702566147
  Validation Loss: 0.6527774333953857
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6598919779062271
  Validation Loss: 0.6525908708572388
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6560189574956894
  Validation Loss: 0.6523754000663757
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6685177683830261
  Validation Loss: 0.6521769762039185
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6670671701431274
  Validation Loss: 0.6520112156867981
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6466531306505203
  Validation Loss: 0.6518217325210571
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6613728106021881
  Validation Loss: 0.6516499519348145
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6567677110433578
  Validation Loss: 0.6515024304389954
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6566181033849716
  Validation Loss: 0.6513507962226868
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6492155939340591
  Validation Loss: 0.6511986255645752
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6567561328411102
  Validation Loss: 0.6510488986968994
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6668775677680969
  Validation Loss: 0.6509100198745728
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6628752946853638
  Validation Loss: 0.6507689356803894
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6693302541971207
  Validation Loss: 0.6506210565567017
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.660761147737503
  Validation Loss: 0.650488018989563
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6649017930030823
  Validation Loss: 0.6503640413284302
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6542496085166931
  Validation Loss: 0.6502314209938049
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6504701524972916
  Validation Loss: 0.6501160264015198
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6477442681789398
  Validation Loss: 0.6499840617179871
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.64571113884449
  Validation Loss: 0.6498528718948364
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6521280258893967
  Validation Loss: 0.6497337818145752
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6625315696001053
  Validation Loss: 0.6496303677558899
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6488755643367767
  Validation Loss: 0.649523138999939
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6473862826824188
  Validation Loss: 0.6494241952896118
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6448194980621338
  Validation Loss: 0.6493129134178162
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6511249542236328
  Validation Loss: 0.6492230296134949
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6570960581302643
  Validation Loss: 0.6491232514381409
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6551580727100372
  Validation Loss: 0.6490361094474792
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6532504111528397
  Validation Loss: 0.6489394903182983
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6581963747739792
  Validation Loss: 0.6488642692565918
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:18:25:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:25:INFO:
[92mINFO [0m:      Received: evaluate message c2c95e9b-e64b-493b-a9d3-44e1c76fb35a
02/06/2025 11:18:25:INFO:Received: evaluate message c2c95e9b-e64b-493b-a9d3-44e1c76fb35a
[92mINFO [0m:      Sent reply
02/06/2025 11:18:27:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:27:INFO:
[92mINFO [0m:      Received: train message f92c412b-a137-4504-91fb-ec22bfbfc462
02/06/2025 11:18:27:INFO:Received: train message f92c412b-a137-4504-91fb-ec22bfbfc462
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6492414325475693
  Validation Loss: 0.6487421989440918
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6616314053535461
  Validation Loss: 0.648659348487854
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6598678827285767
  Validation Loss: 0.6485846042633057
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.665969967842102
  Validation Loss: 0.6485002636909485
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6538299322128296
  Validation Loss: 0.6484257578849792
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6480530500411987
  Validation Loss: 0.6483332514762878
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6479378491640091
  Validation Loss: 0.648261308670044
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6568040251731873
  Validation Loss: 0.6481977701187134
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6445357799530029
  Validation Loss: 0.6481273770332336
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6567865759134293
  Validation Loss: 0.6480488777160645
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6621528416872025
  Validation Loss: 0.6479818820953369
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6621528416872025, 'val_roc_auc': 0.9876543209876543, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6479818820953369}
 ROC_AUC: 0.9877|| Accuracy 0.9630 || Train Loss: 0.6622
 Val Loss: 0.6480 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6922850381122546
Test ROC-AUC: 0.8782467532467532
Test Accuracy: 0.8202247191011236
test_loss: 0.6922850381122546
test_roc_auc: 0.8782467532467532
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6472164392471313
  Validation Loss: 0.7551363110542297
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6433326900005341
  Validation Loss: 0.7549811005592346
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6454558372497559
  Validation Loss: 0.7547857761383057
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6267435252666473
  Validation Loss: 0.7545933127403259
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6404620260000229
  Validation Loss: 0.7543887495994568
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6432475000619888
  Validation Loss: 0.7541804909706116
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6535598933696747
  Validation Loss: 0.7539928555488586
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6336513310670853
  Validation Loss: 0.753816545009613
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6389856338500977
  Validation Loss: 0.7536436915397644
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6340438723564148
  Validation Loss: 0.7534748315811157
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6341984868049622
  Validation Loss: 0.7533131241798401
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6382391899824142
  Validation Loss: 0.7531607151031494
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6376921236515045
  Validation Loss: 0.7530224919319153
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6392852216959
  Validation Loss: 0.7528911232948303
  Val ROC-AUC: 0.9
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6426799297332764
  Validation Loss: 0.7527792453765869
  Val ROC-AUC: 0.9
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6374625414609909
  Validation Loss: 0.7526554465293884
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6382499486207962
  Validation Loss: 0.7525349259376526
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6347785443067551
  Validation Loss: 0.7524375915527344
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6248893290758133
  Validation Loss: 0.752345085144043
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6392303258180618
  Validation Loss: 0.7522587180137634
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6320127248764038
  Validation Loss: 0.752162516117096
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6335942149162292
  Validation Loss: 0.7520763874053955
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6359447687864304
  Validation Loss: 0.7519993185997009
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6335288286209106
  Validation Loss: 0.7519109845161438
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6326618045568466
  Validation Loss: 0.751850426197052
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6209127455949783
  Validation Loss: 0.7517787218093872
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6295492947101593
  Validation Loss: 0.7517423629760742
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6376875638961792
  Validation Loss: 0.7517052292823792
  Val ROC-AUC: 0.8909090909090909
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6309065222740173
  Validation Loss: 0.7516323924064636
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6418671607971191
  Validation Loss: 0.751577615737915
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6330349147319794
  Validation Loss: 0.7515441179275513
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6383595317602158
  Validation Loss: 0.751484751701355
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6351446211338043
  Validation Loss: 0.7514274716377258
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.622716873884201
  Validation Loss: 0.7513835430145264
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6356712579727173
  Validation Loss: 0.7513508796691895
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6274403631687164
  Validation Loss: 0.7513148188591003
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6567996740341187
  Validation Loss: 0.7512937784194946
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.637240007519722
  Validation Loss: 0.7512820363044739
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6381108909845352
  Validation Loss: 0.7512526512145996
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:18:31:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:31:INFO:
[92mINFO [0m:      Received: evaluate message 007e84ac-787e-46b1-b49a-bdef9d09aadb
02/06/2025 11:18:31:INFO:Received: evaluate message 007e84ac-787e-46b1-b49a-bdef9d09aadb
[92mINFO [0m:      Sent reply
02/06/2025 11:18:33:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:33:INFO:
[92mINFO [0m:      Received: train message 3db0ee0a-14eb-40d9-897b-1445cbe81399
02/06/2025 11:18:33:INFO:Received: train message 3db0ee0a-14eb-40d9-897b-1445cbe81399
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6268147528171539
  Validation Loss: 0.7512152194976807
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6313418298959732
  Validation Loss: 0.7512006759643555
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6282510459423065
  Validation Loss: 0.7511671781539917
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6289821714162827
  Validation Loss: 0.7511565089225769
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6239757090806961
  Validation Loss: 0.7511330246925354
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6165628135204315
  Validation Loss: 0.7510939836502075
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6173692345619202
  Validation Loss: 0.75107342004776
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6304641664028168
  Validation Loss: 0.751085638999939
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.620377391576767
  Validation Loss: 0.751072883605957
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6313908249139786
  Validation Loss: 0.7510565519332886
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6314610093832016
  Validation Loss: 0.751057505607605
  Val ROC-AUC: 0.8727272727272728
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6241022050380707
  Validation Loss: 0.7510327100753784
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6161101162433624
  Validation Loss: 0.7510234117507935
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6307726949453354
  Validation Loss: 0.7510207891464233
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6245131194591522
  Validation Loss: 0.7510244846343994
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6218613982200623
  Validation Loss: 0.7510111927986145
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6187845319509506
  Validation Loss: 0.7510069608688354
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.618817999958992
  Validation Loss: 0.7509886026382446
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6207979023456573
  Validation Loss: 0.7509796023368835
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6389801502227783
  Validation Loss: 0.7509873509407043
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6303246766328812
  Validation Loss: 0.7509930729866028
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6234783679246902
  Validation Loss: 0.7509779334068298
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6161930710077286
  Validation Loss: 0.7509576082229614
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6328663676977158
  Validation Loss: 0.7509593367576599
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6284159123897552
  Validation Loss: 0.7509583234786987
  Val ROC-AUC: 0.8818181818181818
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6284159123897552, 'val_roc_auc': 0.8818181818181818, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.7509583234786987}
 ROC_AUC: 0.8818|| Accuracy 0.8889 || Train Loss: 0.6284
 Val Loss: 0.7510 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.692028784350063
Test ROC-AUC: 0.8777056277056278
Test Accuracy: 0.8089887640449438
test_loss: 0.692028784350063
test_roc_auc: 0.8777056277056278
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
Training for 64 epochs...
Epoch 1/64:
  Train Loss: 0.6436932384967804
  Validation Loss: 0.7333070039749146
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 2/64:
  Train Loss: 0.6363214552402496
  Validation Loss: 0.733073890209198
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 3/64:
  Train Loss: 0.6304486691951752
  Validation Loss: 0.732814610004425
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 4/64:
  Train Loss: 0.6453165262937546
  Validation Loss: 0.7325380444526672
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.6382356137037277
  Validation Loss: 0.7322517037391663
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.6539662778377533
  Validation Loss: 0.7319523692131042
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.6283252388238907
  Validation Loss: 0.7316486239433289
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.6518649011850357
  Validation Loss: 0.7313575744628906
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.6283661723136902
  Validation Loss: 0.7310711741447449
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6344773918390274
  Validation Loss: 0.7308050394058228
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6378635466098785
  Validation Loss: 0.73054039478302
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.6493502706289291
  Validation Loss: 0.7303194403648376
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.6455956846475601
  Validation Loss: 0.7300766110420227
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.6376434117555618
  Validation Loss: 0.7298423647880554
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6492798626422882
  Validation Loss: 0.7296122312545776
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.6499821096658707
  Validation Loss: 0.7293869853019714
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6321925222873688
  Validation Loss: 0.7291792631149292
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.652351126074791
  Validation Loss: 0.7290067076683044
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6559306085109711
  Validation Loss: 0.7288282513618469
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6395938694477081
  Validation Loss: 0.7286285758018494
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6362395286560059
  Validation Loss: 0.72845458984375
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.6403467059135437
  Validation Loss: 0.7283046841621399
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6303379237651825
  Validation Loss: 0.7281367778778076
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6447089910507202
  Validation Loss: 0.7279842495918274
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6385261118412018
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/06/2025 11:18:38:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:38:INFO:
[92mINFO [0m:      Received: evaluate message c9d8def0-946a-4cd7-987b-6adb4f0685a2
02/06/2025 11:18:38:INFO:Received: evaluate message c9d8def0-946a-4cd7-987b-6adb4f0685a2
[92mINFO [0m:      Sent reply
02/06/2025 11:18:39:INFO:Sent reply
[92mINFO [0m:      
02/06/2025 11:18:39:INFO:
[92mINFO [0m:      Received: reconnect message a4985cae-bfb3-438f-b686-9bca535e21e1
02/06/2025 11:18:39:INFO:Received: reconnect message a4985cae-bfb3-438f-b686-9bca535e21e1
02/06/2025 11:18:39:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/06/2025 11:18:39:INFO:Disconnect and shut down
  Validation Loss: 0.7278164625167847
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6442332714796066
  Validation Loss: 0.7276759743690491
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6239639073610306
  Validation Loss: 0.727547287940979
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6427478790283203
  Validation Loss: 0.7274311184883118
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6437533497810364
  Validation Loss: 0.7273162007331848
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6352804601192474
  Validation Loss: 0.7272006869316101
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.639679878950119
  Validation Loss: 0.7270914316177368
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6327006369829178
  Validation Loss: 0.7269755005836487
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6433903574943542
  Validation Loss: 0.726883590221405
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6424161344766617
  Validation Loss: 0.7267780900001526
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6504390090703964
  Validation Loss: 0.726706326007843
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6325413733720779
  Validation Loss: 0.7266064286231995
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6472724974155426
  Validation Loss: 0.7265211939811707
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6311469078063965
  Validation Loss: 0.7264195084571838
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6333420276641846
  Validation Loss: 0.7263182401657104
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6231925785541534
  Validation Loss: 0.7262314558029175
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6416748315095901
  Validation Loss: 0.7261598706245422
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6474617570638657
  Validation Loss: 0.7260878086090088
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6352444440126419
  Validation Loss: 0.7260121703147888
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6408842504024506
  Validation Loss: 0.7259486317634583
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6322898715734482
  Validation Loss: 0.7258963584899902
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6289839148521423
  Validation Loss: 0.7258052825927734
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6308254152536392
  Validation Loss: 0.7257493138313293
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6390575170516968
  Validation Loss: 0.7256943583488464
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6374594867229462
  Validation Loss: 0.725623607635498
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6369881182909012
  Validation Loss: 0.725570797920227
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6291086971759796
  Validation Loss: 0.7255150079727173
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6300297677516937
  Validation Loss: 0.7254590392112732
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.623646691441536
  Validation Loss: 0.7254089117050171
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6353556215763092
  Validation Loss: 0.7253521084785461
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6352056860923767
  Validation Loss: 0.7253212928771973
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6299710273742676
  Validation Loss: 0.7252761125564575
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6397822946310043
  Validation Loss: 0.7252434492111206
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6247196942567825
  Validation Loss: 0.7251940965652466
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6347143203020096
  Validation Loss: 0.7251598238945007
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6335761398077011
  Validation Loss: 0.7251238822937012
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6324045807123184
  Validation Loss: 0.7250712513923645
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6281089186668396
  Validation Loss: 0.7250373959541321
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6339973360300064
  Validation Loss: 0.725002110004425
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6363620758056641
  Validation Loss: 0.7249789834022522
  Val ROC-AUC: 0.9818181818181818
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6363620758056641, 'val_roc_auc': 0.9818181818181818, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.7249789834022522}
 ROC_AUC: 0.9818|| Accuracy 0.9259 || Train Loss: 0.6364
 Val Loss: 0.7250 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6918410260355874
Test ROC-AUC: 0.8782467532467534
Test Accuracy: 0.8089887640449438
test_loss: 0.6918410260355874
test_roc_auc: 0.8782467532467534
test_accuracy: 0.8089887640449438
eval_cid: 1
CPU Time: 152.189492 seconds
Elapsed Time: 208.34915280342102 seconds
RAM Usage: 0.31005859375 megabytes
Logs saved in current directory
