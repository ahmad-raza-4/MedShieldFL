nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:42:22:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:42:22:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 22:42:22:DEBUG:ChannelConnectivity.IDLE
02/07/2025 22:42:22:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738996942.254071 1769817 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/07/2025 22:42:23:INFO:
[92mINFO [0m:      Received: train message 32c9fadf-b98f-4264-9ed2-c7a2f8d5b765
02/07/2025 22:42:23:INFO:Received: train message 32c9fadf-b98f-4264-9ed2-c7a2f8d5b765
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours/10.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours']
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.5410298812785186
Epoch 1/64:
  Train Loss: 0.5509706437587738
  Validation Loss: 0.6018645167350769
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 2/64:
  Train Loss: 0.5599161386489868
  Validation Loss: 0.6019138097763062
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 3/64:
  Train Loss: 0.5559892952442169
  Validation Loss: 0.6020039916038513
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 4/64:
  Train Loss: 0.5512255430221558
  Validation Loss: 0.6021159291267395
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 5/64:
  Train Loss: 0.5581762790679932
  Validation Loss: 0.6022233963012695
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 6/64:
  Train Loss: 0.556025892496109
  Validation Loss: 0.6023087501525879
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 7/64:
  Train Loss: 0.5511497557163239
  Validation Loss: 0.6023721098899841
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 8/64:
  Train Loss: 0.552471250295639
  Validation Loss: 0.6024556159973145
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 9/64:
  Train Loss: 0.5501358509063721
  Validation Loss: 0.6025175452232361
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 10/64:
  Train Loss: 0.5489709973335266
  Validation Loss: 0.6025716662406921
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 11/64:
  Train Loss: 0.5550372898578644
  Validation Loss: 0.602649986743927
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 12/64:
  Train Loss: 0.5510843694210052
  Validation Loss: 0.6027398705482483
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 13/64:
  Train Loss: 0.5536901652812958
  Validation Loss: 0.602824866771698
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 14/64:
  Train Loss: 0.5571788847446442
  Validation Loss: 0.602904200553894
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 15/64:
  Train Loss: 0.5518282949924469
  Validation Loss: 0.6029911637306213
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 16/64:
  Train Loss: 0.5517570376396179
  Validation Loss: 0.6030656099319458
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 17/64:
  Train Loss: 0.551882416009903
  Validation Loss: 0.6031425595283508
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 18/64:
  Train Loss: 0.5583250224590302
  Validation Loss: 0.6032483577728271
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 19/64:
  Train Loss: 0.564320832490921
  Validation Loss: 0.6033370494842529
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 20/64:
  Train Loss: 0.5457545816898346
  Validation Loss: 0.603442370891571
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 21/64:
  Train Loss: 0.5543663501739502
  Validation Loss: 0.60358065366745
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 22/64:
  Train Loss: 0.5614756196737289
  Validation Loss: 0.6036953926086426
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 23/64:
  Train Loss: 0.5509353578090668
  Validation Loss: 0.6038062572479248
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 24/64:
  Train Loss: 0.5498953759670258
  Validation Loss: 0.603918194770813
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 25/64:
  Train Loss: 0.5446204245090485
  Validation Loss: 0.6040237545967102
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 26/64:
  Train Loss: 0.551691323518753
  Validation Loss: 0.6041350960731506
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 27/64:
  Train Loss: 0.5560657382011414
  Validation Loss: 0.6042903661727905
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 28/64:
  Train Loss: 0.5524194836616516
  Validation Loss: 0.6044495701789856
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 29/64:
  Train Loss: 0.5568472743034363
  Validation Loss: 0.6046225428581238
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 30/64:
  Train Loss: 0.5487292408943176
  Validation Loss: 0.604755163192749
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 31/64:
  Train Loss: 0.5456190407276154
  Validation Loss: 0.6048809289932251
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 32/64:
  Train Loss: 0.5532956719398499
  Validation Loss: 0.6049810647964478
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 33/64:
  Train Loss: 0.5420573055744171
  Validation Loss: 0.6050626039505005
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 34/64:
  Train Loss: 0.5420120805501938
  Validation Loss: 0.6051306128501892
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 35/64:
  Train Loss: 0.5566653609275818
  Validation Loss: 0.6051811575889587
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 36/64:
  Train Loss: 0.541518434882164
  Validation Loss: 0.6052858829498291
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 37/64:
  Train Loss: 0.5418955385684967
  Validation Loss: 0.6053450107574463
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 38/64:
  Train Loss: 0.5551257133483887
  Validation Loss: 0.6054205894470215
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 39/64:
  Train Loss: 0.5457401871681213
  Validation Loss: 0.6054793000221252
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 40/64:
  Train Loss: 0.5424003899097443
  Validation Loss: 0.605552613735199
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 41/64:
  Train Loss: 0.5472175478935242
  Validation Loss: 0.605649471282959
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 42/64:
  Train Loss: 0.548912912607193
  Validation Loss: 0.6057661175727844
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 43/64:
  Train Loss: 0.5484764575958252
  Validation Loss: 0.605912983417511
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 44/64:
  Train Loss: 0.5417422950267792
  Validation Loss: 0.6060771942138672
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 45/64:
  Train Loss: 0.5503669679164886
  Validation Loss: 0.6062347292900085
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 46/64:
  Train Loss: 0.5442053079605103
  Validation Loss: 0.6063619256019592
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 47/64:
  Train Loss: 0.5499107837677002
  Validation Loss: 0.606518030166626
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 48/64:
  Train Loss: 0.5436660349369049
  Validation Loss: 0.6066843867301941
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 49/64:
  Train Loss: 0.5438253879547119
  Validation Loss: 0.606850266456604
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 50/64:
  Train Loss: 0.5429315567016602
  Validation Loss: 0.6070406436920166
  Val ROC-AUC: 0.7777777777777778
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:42:43:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:42:48:INFO:
[92mINFO [0m:      Received: evaluate message a57448a3-aca5-4f06-b22b-75f883526d73
02/07/2025 22:42:48:INFO:Received: evaluate message a57448a3-aca5-4f06-b22b-75f883526d73
[92mINFO [0m:      Sent reply
02/07/2025 22:42:50:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:42:53:INFO:
[92mINFO [0m:      Received: train message 38ed7e5b-a91a-4800-a62a-1c4c817f9d0c
02/07/2025 22:42:53:INFO:Received: train message 38ed7e5b-a91a-4800-a62a-1c4c817f9d0c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8461538553237915
Epoch 51/64:
  Train Loss: 0.5487969517707825
  Validation Loss: 0.6072341203689575
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 52/64:
  Train Loss: 0.5436773896217346
  Validation Loss: 0.6074091792106628
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 53/64:
  Train Loss: 0.5394124686717987
  Validation Loss: 0.6075513958930969
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 54/64:
  Train Loss: 0.5428457856178284
  Validation Loss: 0.6076834201812744
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 55/64:
  Train Loss: 0.5421720147132874
  Validation Loss: 0.6078101396560669
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 56/64:
  Train Loss: 0.5477179884910583
  Validation Loss: 0.607936441898346
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 57/64:
  Train Loss: 0.549049586057663
  Validation Loss: 0.6080420613288879
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 58/64:
  Train Loss: 0.5431113243103027
  Validation Loss: 0.6081749796867371
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 59/64:
  Train Loss: 0.5423003137111664
  Validation Loss: 0.6083407998085022
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 60/64:
  Train Loss: 0.5415831804275513
  Validation Loss: 0.6085105538368225
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 61/64:
  Train Loss: 0.5429896712303162
  Validation Loss: 0.6086906790733337
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 62/64:
  Train Loss: 0.5444185137748718
  Validation Loss: 0.6088448762893677
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 63/64:
  Train Loss: 0.5421664714813232
  Validation Loss: 0.6090343594551086
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 64/64:
  Train Loss: 0.5401759743690491
  Validation Loss: 0.6092211604118347
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
{'train_loss': 0.5401759743690491, 'val_roc_auc': 0.7777777777777778, 'val_accuracy': 0.8461538553237915, 'val_loss': 0.6092211604118347}
 ROC_AUC: 0.7778|| Accuracy 0.8462 || Train Loss: 0.5402
 Val Loss: 0.6092 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5801422297954559
Test ROC-AUC: 0.5914285714285714
Test Accuracy: 0.6222222222222222
test_loss: 0.5801422297954559
test_roc_auc: 0.5914285714285714
test_accuracy: 0.6222222222222222
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.4548999138933141
Epoch 1/64:
  Train Loss: 0.5848453044891357
  Validation Loss: 0.49518725275993347
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5672744363546371
  Validation Loss: 0.4951331317424774
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5843615233898163
  Validation Loss: 0.4950104057788849
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5847133696079254
  Validation Loss: 0.4949001371860504
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5793206095695496
  Validation Loss: 0.494795560836792
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.580940842628479
  Validation Loss: 0.49468204379081726
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5826579332351685
  Validation Loss: 0.494570791721344
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5717146396636963
  Validation Loss: 0.49448162317276
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.573964387178421
  Validation Loss: 0.49439355731010437
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5779947340488434
  Validation Loss: 0.4943101704120636
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5782585144042969
  Validation Loss: 0.49419519305229187
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5775080025196075
  Validation Loss: 0.4940640926361084
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5855238437652588
  Validation Loss: 0.4939373731613159
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5815594494342804
  Validation Loss: 0.4938294589519501
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5673331320285797
  Validation Loss: 0.4936980605125427
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5837958753108978
  Validation Loss: 0.4935920536518097
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.577816367149353
  Validation Loss: 0.4934958815574646
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.578026533126831
  Validation Loss: 0.493396520614624
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5837055742740631
  Validation Loss: 0.4932679533958435
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.5776094198226929
  Validation Loss: 0.49312835931777954
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.5785500705242157
  Validation Loss: 0.49302104115486145
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 22/64:
  Train Loss: 0.5810853242874146
  Validation Loss: 0.4929187595844269
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 23/64:
  Train Loss: 0.5757292807102203
  Validation Loss: 0.4928094744682312
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 24/64:
  Train Loss: 0.5718403458595276
  Validation Loss: 0.4927137494087219
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 25/64:
  Train Loss: 0.5873429775238037
  Validation Loss: 0.4926344156265259
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 26/64:
  Train Loss: 0.5750860571861267
  Validation Loss: 0.4925521910190582
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 27/64:
  Train Loss: 0.5738452672958374
  Validation Loss: 0.49245598912239075
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 28/64:
  Train Loss: 0.5782906413078308
  Validation Loss: 0.4923272430896759
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 29/64:
  Train Loss: 0.5740676522254944
  Validation Loss: 0.4921729266643524
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 30/64:
  Train Loss: 0.5675539970397949
  Validation Loss: 0.492053747177124
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 31/64:
  Train Loss: 0.5738379657268524
  Validation Loss: 0.49195319414138794
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 32/64:
  Train Loss: 0.57515749335289
  Validation Loss: 0.4918145537376404
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 33/64:
  Train Loss: 0.5692666471004486
  Validation Loss: 0.4916819930076599
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 34/64:
  Train Loss: 0.5676650702953339
  Validation Loss: 0.49153071641921997
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 35/64:
  Train Loss: 0.5627634078264236
  Validation Loss: 0.49138644337654114
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 36/64:
  Train Loss: 0.575216144323349
  Validation Loss: 0.49121615290641785
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 37/64:
  Train Loss: 0.5856200158596039
  Validation Loss: 0.49105748534202576
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 38/64:
  Train Loss: 0.5735382437705994
  Validation Loss: 0.49090635776519775
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 39/64:
  Train Loss: 0.5685508847236633
  Validation Loss: 0.4907739758491516
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 22:43:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:19:INFO:
[92mINFO [0m:      Received: evaluate message 08af3d21-9cb6-427c-8e7a-abda61192706
02/07/2025 22:43:19:INFO:Received: evaluate message 08af3d21-9cb6-427c-8e7a-abda61192706
[92mINFO [0m:      Sent reply
02/07/2025 22:43:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:23:INFO:
[92mINFO [0m:      Received: train message 0181c75b-fecf-4b68-965f-6b8c2373a751
02/07/2025 22:43:23:INFO:Received: train message 0181c75b-fecf-4b68-965f-6b8c2373a751
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 40/64:
  Train Loss: 0.575446367263794
  Validation Loss: 0.4906616806983948
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5596913844347
  Validation Loss: 0.49057257175445557
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.5737568736076355
  Validation Loss: 0.49045878648757935
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.5698508620262146
  Validation Loss: 0.49033424258232117
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5756423771381378
  Validation Loss: 0.49018603563308716
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5718250870704651
  Validation Loss: 0.4900560677051544
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5658977925777435
  Validation Loss: 0.48992273211479187
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5698915421962738
  Validation Loss: 0.48979511857032776
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5673814415931702
  Validation Loss: 0.4896795153617859
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5683415532112122
  Validation Loss: 0.48957496881484985
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5811378359794617
  Validation Loss: 0.4894564747810364
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5687011778354645
  Validation Loss: 0.48935848474502563
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5761946439743042
  Validation Loss: 0.48927485942840576
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5706253349781036
  Validation Loss: 0.4892030358314514
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5727268755435944
  Validation Loss: 0.48913854360580444
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5698297619819641
  Validation Loss: 0.4891066253185272
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5796880722045898
  Validation Loss: 0.48906460404396057
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5619582831859589
  Validation Loss: 0.48901644349098206
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5759419798851013
  Validation Loss: 0.4889349639415741
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.56580650806427
  Validation Loss: 0.4888538718223572
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5750153958797455
  Validation Loss: 0.4887804687023163
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5752177536487579
  Validation Loss: 0.48870888352394104
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5716887712478638
  Validation Loss: 0.48864448070526123
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5680812895298004
  Validation Loss: 0.4885864555835724
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5696417093276978
  Validation Loss: 0.4885079562664032
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5696417093276978, 'val_roc_auc': nan, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.4885079562664032}
 ROC_AUC: nan|| Accuracy 0.6154 || Train Loss: 0.5696
 Val Loss: 0.4885 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5797164731555515
Test ROC-AUC: 0.6
Test Accuracy: 0.6222222222222222
test_loss: 0.5797164731555515
test_roc_auc: 0.6
test_accuracy: 0.6222222222222222
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.21895944366406184
Epoch 1/64:
  Train Loss: 0.549828439950943
  Validation Loss: 0.6047964692115784
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 2/64:
  Train Loss: 0.55096834897995
  Validation Loss: 0.6047515869140625
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 3/64:
  Train Loss: 0.5522687137126923
  Validation Loss: 0.6047278642654419
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 4/64:
  Train Loss: 0.556659072637558
  Validation Loss: 0.6047289371490479
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 5/64:
  Train Loss: 0.5518845617771149
  Validation Loss: 0.6047601699829102
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 6/64:
  Train Loss: 0.5510949194431305
  Validation Loss: 0.6048150062561035
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 7/64:
  Train Loss: 0.5476199686527252
  Validation Loss: 0.6048585772514343
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 8/64:
  Train Loss: 0.556183934211731
  Validation Loss: 0.6049095392227173
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 9/64:
  Train Loss: 0.5535350739955902
  Validation Loss: 0.6049602627754211
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 10/64:
  Train Loss: 0.5515937805175781
  Validation Loss: 0.6050252914428711
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 11/64:
  Train Loss: 0.5425806045532227
  Validation Loss: 0.6050777435302734
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 12/64:
  Train Loss: 0.5473900139331818
  Validation Loss: 0.6051351428031921
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 13/64:
  Train Loss: 0.5554541945457458
  Validation Loss: 0.605195939540863
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 14/64:
  Train Loss: 0.55289626121521
  Validation Loss: 0.6052243113517761
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 15/64:
  Train Loss: 0.5480666756629944
  Validation Loss: 0.6052672266960144
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 16/64:
  Train Loss: 0.5565795302391052
  Validation Loss: 0.6053242683410645
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 17/64:
  Train Loss: 0.5534277260303497
  Validation Loss: 0.6053908467292786
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 18/64:
  Train Loss: 0.5491236448287964
  Validation Loss: 0.6054477095603943
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 19/64:
  Train Loss: 0.552543967962265
  Validation Loss: 0.6054905652999878
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 20/64:
  Train Loss: 0.5556774735450745
  Validation Loss: 0.6055375933647156
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 21/64:
  Train Loss: 0.553994208574295
  Validation Loss: 0.6055919528007507
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 22/64:
  Train Loss: 0.539870873093605
  Validation Loss: 0.6056438684463501
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 23/64:
  Train Loss: 0.5455513000488281
  Validation Loss: 0.6057087779045105
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 24/64:
  Train Loss: 0.5533745288848877
  Validation Loss: 0.6057690978050232
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 25/64:
  Train Loss: 0.5470675528049469
  Validation Loss: 0.6058245301246643
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 26/64:
  Train Loss: 0.5472646057605743
  Validation Loss: 0.6058782935142517
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 27/64:
  Train Loss: 0.5518404245376587
  Validation Loss: 0.6059229969978333
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 28/64:
  Train Loss: 0.5466156005859375
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:43:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:49:INFO:
[92mINFO [0m:      Received: evaluate message 6f587d52-71c4-42c1-bfb0-a9b1d3134754
02/07/2025 22:43:49:INFO:Received: evaluate message 6f587d52-71c4-42c1-bfb0-a9b1d3134754
[92mINFO [0m:      Sent reply
02/07/2025 22:43:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:53:INFO:
[92mINFO [0m:      Received: train message 6cc472b3-64bf-437f-a968-9b5d70473e28
02/07/2025 22:43:53:INFO:Received: train message 6cc472b3-64bf-437f-a968-9b5d70473e28
  Validation Loss: 0.6059755682945251
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 29/64:
  Train Loss: 0.5457354187965393
  Validation Loss: 0.6060134172439575
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 30/64:
  Train Loss: 0.5546407103538513
  Validation Loss: 0.6060392260551453
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 31/64:
  Train Loss: 0.5332570374011993
  Validation Loss: 0.6060649156570435
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 32/64:
  Train Loss: 0.5427822172641754
  Validation Loss: 0.6060920357704163
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 33/64:
  Train Loss: 0.5435391366481781
  Validation Loss: 0.6061239838600159
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 34/64:
  Train Loss: 0.5433259308338165
  Validation Loss: 0.6061406135559082
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 35/64:
  Train Loss: 0.5510342717170715
  Validation Loss: 0.6061744689941406
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 36/64:
  Train Loss: 0.539232075214386
  Validation Loss: 0.606207549571991
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 37/64:
  Train Loss: 0.5453163683414459
  Validation Loss: 0.6062323451042175
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 38/64:
  Train Loss: 0.539615124464035
  Validation Loss: 0.6062859892845154
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 39/64:
  Train Loss: 0.5431658625602722
  Validation Loss: 0.6063498854637146
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 40/64:
  Train Loss: 0.542026937007904
  Validation Loss: 0.6064032316207886
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 41/64:
  Train Loss: 0.5483593642711639
  Validation Loss: 0.6064738631248474
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 42/64:
  Train Loss: 0.5370934158563614
  Validation Loss: 0.6065186858177185
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 43/64:
  Train Loss: 0.5458365976810455
  Validation Loss: 0.6065877079963684
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 44/64:
  Train Loss: 0.5407832562923431
  Validation Loss: 0.6066320538520813
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 45/64:
  Train Loss: 0.5450999140739441
  Validation Loss: 0.6066974997520447
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 46/64:
  Train Loss: 0.5479788780212402
  Validation Loss: 0.6067695617675781
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 47/64:
  Train Loss: 0.5417273938655853
  Validation Loss: 0.6068182587623596
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 48/64:
  Train Loss: 0.5383116006851196
  Validation Loss: 0.6068536043167114
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 49/64:
  Train Loss: 0.5483298003673553
  Validation Loss: 0.6068779230117798
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 50/64:
  Train Loss: 0.5417684614658356
  Validation Loss: 0.6069105267524719
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 51/64:
  Train Loss: 0.5385298728942871
  Validation Loss: 0.6069243550300598
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 52/64:
  Train Loss: 0.5394716560840607
  Validation Loss: 0.6069575548171997
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 53/64:
  Train Loss: 0.5398276746273041
  Validation Loss: 0.6069880723953247
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 54/64:
  Train Loss: 0.5469999611377716
  Validation Loss: 0.6070215702056885
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 55/64:
  Train Loss: 0.5452502369880676
  Validation Loss: 0.6070511937141418
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 56/64:
  Train Loss: 0.5432149171829224
  Validation Loss: 0.6070559620857239
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 57/64:
  Train Loss: 0.5337494015693665
  Validation Loss: 0.6070510149002075
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 58/64:
  Train Loss: 0.5461558699607849
  Validation Loss: 0.607051432132721
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 59/64:
  Train Loss: 0.5368059575557709
  Validation Loss: 0.607068657875061
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 60/64:
  Train Loss: 0.540700376033783
  Validation Loss: 0.6070685386657715
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 61/64:
  Train Loss: 0.5358773767948151
  Validation Loss: 0.6070623397827148
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 62/64:
  Train Loss: 0.5380990505218506
  Validation Loss: 0.6070610284805298
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 63/64:
  Train Loss: 0.5418345630168915
  Validation Loss: 0.6070734858512878
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 64/64:
  Train Loss: 0.5440264046192169
  Validation Loss: 0.607068657875061
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
{'train_loss': 0.5440264046192169, 'val_roc_auc': 0.4, 'val_accuracy': 0.46153849363327026, 'val_loss': 0.607068657875061}
 ROC_AUC: 0.4000|| Accuracy 0.4615 || Train Loss: 0.5440
 Val Loss: 0.6071 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5793775406148699
Test ROC-AUC: 0.6142857142857143
Test Accuracy: 0.6222222222222222
test_loss: 0.5793775406148699
test_roc_auc: 0.6142857142857143
test_accuracy: 0.6222222222222222
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.3762116268626414
Epoch 1/64:
  Train Loss: 0.5611042678356171
  Validation Loss: 0.5542718768119812
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5737329125404358
  Validation Loss: 0.5540199279785156
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5637468695640564
  Validation Loss: 0.5537915825843811
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.568181723356247
  Validation Loss: 0.55359947681427
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.5552174150943756
  Validation Loss: 0.5534037351608276
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5668991506099701
  Validation Loss: 0.5532305240631104
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5594311654567719
  Validation Loss: 0.5530303716659546
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5665571391582489
  Validation Loss: 0.5528397560119629
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.5690953135490417
  Validation Loss: 0.552647590637207
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.5690960884094238
  Validation Loss: 0.5524911880493164
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.5578548312187195
  Validation Loss: 0.5523266792297363
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5609667003154755
  Validation Loss: 0.5521481037139893
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5640890598297119
  Validation Loss: 0.5519878268241882
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5647795498371124
  Validation Loss: 0.5518503785133362
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 15/64:
  Train Loss: 0.5570824444293976
  Validation Loss: 0.5517023205757141
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 16/64:
  Train Loss: 0.5690582394599915
  Validation Loss: 0.5515624284744263
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 17/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:44:12:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:18:INFO:
[92mINFO [0m:      Received: evaluate message 6937f146-8cdd-49a8-8572-e21a85ff0ef6
02/07/2025 22:44:18:INFO:Received: evaluate message 6937f146-8cdd-49a8-8572-e21a85ff0ef6
[92mINFO [0m:      Sent reply
02/07/2025 22:44:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:22:INFO:
[92mINFO [0m:      Received: train message 6842060b-f443-40bd-9545-ec9bb1865c00
02/07/2025 22:44:22:INFO:Received: train message 6842060b-f443-40bd-9545-ec9bb1865c00
  Train Loss: 0.5617530643939972
  Validation Loss: 0.5514064431190491
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 18/64:
  Train Loss: 0.5681068301200867
  Validation Loss: 0.5512624979019165
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 19/64:
  Train Loss: 0.5537075996398926
  Validation Loss: 0.5511125326156616
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.5669347643852234
  Validation Loss: 0.5509644746780396
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.5589054822921753
  Validation Loss: 0.5508085489273071
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 22/64:
  Train Loss: 0.5630093514919281
  Validation Loss: 0.5506393313407898
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 23/64:
  Train Loss: 0.5610228776931763
  Validation Loss: 0.5504584908485413
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 24/64:
  Train Loss: 0.5610207319259644
  Validation Loss: 0.550247848033905
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 25/64:
  Train Loss: 0.5581416487693787
  Validation Loss: 0.5500553250312805
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 26/64:
  Train Loss: 0.5607505142688751
  Validation Loss: 0.5498713254928589
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 27/64:
  Train Loss: 0.5557248592376709
  Validation Loss: 0.5496950149536133
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 28/64:
  Train Loss: 0.5607755184173584
  Validation Loss: 0.5495100021362305
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 29/64:
  Train Loss: 0.5622700452804565
  Validation Loss: 0.5493230223655701
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 30/64:
  Train Loss: 0.5588427782058716
  Validation Loss: 0.549149215221405
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 31/64:
  Train Loss: 0.5644423067569733
  Validation Loss: 0.5489693284034729
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 32/64:
  Train Loss: 0.5626672208309174
  Validation Loss: 0.548806369304657
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 33/64:
  Train Loss: 0.5587916672229767
  Validation Loss: 0.5486577749252319
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 34/64:
  Train Loss: 0.5649742484092712
  Validation Loss: 0.5484835505485535
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 35/64:
  Train Loss: 0.5578893423080444
  Validation Loss: 0.5483269691467285
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 36/64:
  Train Loss: 0.5570258498191833
  Validation Loss: 0.548192024230957
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 37/64:
  Train Loss: 0.5622313022613525
  Validation Loss: 0.5480491518974304
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 38/64:
  Train Loss: 0.5586709976196289
  Validation Loss: 0.547886848449707
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 39/64:
  Train Loss: 0.5616933703422546
  Validation Loss: 0.5477460026741028
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 40/64:
  Train Loss: 0.5572871565818787
  Validation Loss: 0.5476041436195374
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5643181502819061
  Validation Loss: 0.5474448204040527
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.5583612620830536
  Validation Loss: 0.5473034381866455
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.559990406036377
  Validation Loss: 0.5471588969230652
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5524702370166779
  Validation Loss: 0.5470191240310669
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5585732758045197
  Validation Loss: 0.546867847442627
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5614228844642639
  Validation Loss: 0.5466984510421753
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5490436404943466
  Validation Loss: 0.5465432405471802
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.551171213388443
  Validation Loss: 0.5463910698890686
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5511516630649567
  Validation Loss: 0.5462562441825867
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5556895732879639
  Validation Loss: 0.5461195707321167
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5481930375099182
  Validation Loss: 0.5459790825843811
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5535231232643127
  Validation Loss: 0.545846700668335
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5617099106311798
  Validation Loss: 0.5457151532173157
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.551102489233017
  Validation Loss: 0.5456088185310364
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5477776825428009
  Validation Loss: 0.5455099940299988
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.555881530046463
  Validation Loss: 0.5454176068305969
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5555583834648132
  Validation Loss: 0.5453149676322937
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5648165345191956
  Validation Loss: 0.5452190041542053
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5528368353843689
  Validation Loss: 0.5451068878173828
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5586150288581848
  Validation Loss: 0.5449807047843933
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5477975010871887
  Validation Loss: 0.5448643565177917
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5548762679100037
  Validation Loss: 0.5447601079940796
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5530446767807007
  Validation Loss: 0.544660210609436
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5559077858924866
  Validation Loss: 0.5445321202278137
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5559077858924866, 'val_roc_auc': 0.4545454545454546, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5445321202278137}
 ROC_AUC: 0.4545|| Accuracy 0.6923 || Train Loss: 0.5559
 Val Loss: 0.5445 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5790208001931508
Test ROC-AUC: 0.6285714285714286
Test Accuracy: 0.6
test_loss: 0.5790208001931508
test_roc_auc: 0.6285714285714286
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.3862862511596177
Epoch 1/64:
  Train Loss: 0.5738407671451569
  Validation Loss: 0.5252865552902222
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5701936483383179
  Validation Loss: 0.5252630710601807
  Val ROC-AUC: 0.08333333333333333
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5819330811500549
  Validation Loss: 0.5252386927604675
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5706543028354645
  Validation Loss: 0.5252293348312378
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5747685134410858
  Validation Loss: 0.5251771807670593
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5666146278381348
  Validation Loss: 0.5251299142837524
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5680475831031799
  Validation Loss: 0.5250641703605652
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5769088864326477
  Validation Loss: 0.5249824523925781
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5642543435096741
  Validation Loss: 0.5249193906784058
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5745664834976196
  Validation Loss: 0.5248531103134155
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5692799687385559
  Validation Loss: 0.5247961282730103
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5711168944835663
  Validation Loss: 0.5247449278831482
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5670602321624756
  Validation Loss: 0.5246813297271729
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5740617215633392
  Validation Loss: 0.5245987176895142
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5708002746105194
  Validation Loss: 0.5245108604431152
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5659634172916412
  Validation Loss: 0.5244344472885132
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5705048739910126
  Validation Loss: 0.5243644714355469
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5643215775489807
  Validation Loss: 0.5242900252342224
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5627346932888031
  Validation Loss: 0.5242112278938293
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5598776340484619
  Validation Loss: 0.5241201519966125
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5711531937122345
  Validation Loss: 0.5240316390991211
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5682177543640137
  Validation Loss: 0.5239474177360535
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5718069970607758
  Validation Loss: 0.5238827466964722
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5634857416152954
  Validation Loss: 0.5238360166549683
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5672934055328369
  Validation Loss: 0.5237835049629211
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5808212757110596
  Validation Loss: 0.5237522125244141
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5699335336685181
  Validation Loss: 0.5237270593643188
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5743969082832336
  Validation Loss: 0.5237011909484863
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5624632239341736
  Validation Loss: 0.5236770510673523
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5693621337413788
  Validation Loss: 0.5236555337905884
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5683197379112244
  Validation Loss: 0.5236341953277588
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.572134256362915
  Validation Loss: 0.5236142873764038
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5641586482524872
  Validation Loss: 0.5235886573791504
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5757870674133301
  Validation Loss: 0.5235431790351868
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5584053099155426
  Validation Loss: 0.5235050320625305
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5597976744174957
  Validation Loss: 0.5234622955322266
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5626050233840942
  Validation Loss: 0.5234041213989258
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5623100101947784
  Validation Loss: 0.5233717560768127
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5619530379772186
  Validation Loss: 0.5233350992202759
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5678191781044006
  Validation Loss: 0.5232843160629272
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5560059249401093
  Validation Loss: 0.5232173800468445
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.561555027961731
  Validation Loss: 0.5231329202651978
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5647933185100555
  Validation Loss: 0.5230438709259033
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5592568516731262
  Validation Loss: 0.5229705572128296
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5733970403671265
  Validation Loss: 0.5229119062423706
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5637264251708984
  Validation Loss: 0.5228416919708252
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5672188997268677
  Validation Loss: 0.5227859616279602
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5586279928684235
  Validation Loss: 0.5227375030517578
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5614178776741028
  Validation Loss: 0.5227031707763672
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5615516901016235
  Validation Loss: 0.5226514339447021
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5661037564277649
  Validation Loss: 0.5225886702537537
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5604159832000732
  Validation Loss: 0.5225251913070679
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5560792684555054
  Validation Loss: 0.5224785804748535
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5607682764530182
  Validation Loss: 0.522412121295929
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5645041167736053
  Validation Loss: 0.5223546028137207
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:44:42:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:50:INFO:
[92mINFO [0m:      Received: evaluate message 7141d89e-1bdc-4ca5-b080-e0fe3e27127e
02/07/2025 22:44:50:INFO:Received: evaluate message 7141d89e-1bdc-4ca5-b080-e0fe3e27127e
[92mINFO [0m:      Sent reply
02/07/2025 22:44:52:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:53:INFO:
[92mINFO [0m:      Received: train message 29cef4b8-c200-47b9-b581-bce69c322a52
02/07/2025 22:44:53:INFO:Received: train message 29cef4b8-c200-47b9-b581-bce69c322a52
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 56/64:
  Train Loss: 0.5615721940994263
  Validation Loss: 0.5222898721694946
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5645805895328522
  Validation Loss: 0.5222250819206238
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.552764356136322
  Validation Loss: 0.5221840739250183
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5581634938716888
  Validation Loss: 0.5221327543258667
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5627312064170837
  Validation Loss: 0.5220832228660583
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5577906668186188
  Validation Loss: 0.5220389366149902
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5577996969223022
  Validation Loss: 0.5219793319702148
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5655709505081177
  Validation Loss: 0.5219294428825378
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5553381443023682
  Validation Loss: 0.5218790173530579
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5553381443023682, 'val_roc_auc': 0.08333333333333333, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5218790173530579}
 ROC_AUC: 0.0833|| Accuracy 0.5385 || Train Loss: 0.5553
 Val Loss: 0.5219 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5786822352144453
Test ROC-AUC: 0.6428571428571428
Test Accuracy: 0.6
test_loss: 0.5786822352144453
test_roc_auc: 0.6428571428571428
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.43262077582767233
Epoch 1/64:
  Train Loss: 0.564787745475769
  Validation Loss: 0.542283296585083
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5640275180339813
  Validation Loss: 0.5422852039337158
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.572758138179779
  Validation Loss: 0.5422078371047974
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5615140497684479
  Validation Loss: 0.5420756340026855
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5750494301319122
  Validation Loss: 0.541972815990448
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5659809112548828
  Validation Loss: 0.5418931841850281
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5643146932125092
  Validation Loss: 0.5418250560760498
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5633638203144073
  Validation Loss: 0.5417496562004089
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5654287040233612
  Validation Loss: 0.5416430234909058
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5759345293045044
  Validation Loss: 0.5415380597114563
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.567622184753418
  Validation Loss: 0.5414050817489624
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.568115621805191
  Validation Loss: 0.5412607192993164
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5683107078075409
  Validation Loss: 0.5411506295204163
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5643923580646515
  Validation Loss: 0.5410313606262207
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.564708024263382
  Validation Loss: 0.5409062504768372
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5661706328392029
  Validation Loss: 0.5407589077949524
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5670371055603027
  Validation Loss: 0.54060959815979
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5678057074546814
  Validation Loss: 0.5404546856880188
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5621109008789062
  Validation Loss: 0.5403074026107788
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5609800517559052
  Validation Loss: 0.5401678085327148
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5629973411560059
  Validation Loss: 0.5400522947311401
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5652585029602051
  Validation Loss: 0.5399558544158936
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5566028654575348
  Validation Loss: 0.5398602485656738
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5605824589729309
  Validation Loss: 0.5397694706916809
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5625376403331757
  Validation Loss: 0.5396791100502014
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5614587962627411
  Validation Loss: 0.5395888090133667
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5631493330001831
  Validation Loss: 0.5394774675369263
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5574887692928314
  Validation Loss: 0.5393756031990051
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5590163171291351
  Validation Loss: 0.5392798781394958
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5664899051189423
  Validation Loss: 0.539199948310852
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5630005300045013
  Validation Loss: 0.5391120910644531
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5588998198509216
  Validation Loss: 0.5390240550041199
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5688556730747223
  Validation Loss: 0.5389378666877747
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5628495514392853
  Validation Loss: 0.5388545989990234
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5660272240638733
  Validation Loss: 0.538787841796875
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5535131394863129
  Validation Loss: 0.5387169122695923
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5509932786226273
  Validation Loss: 0.5386332869529724
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5676237940788269
  Validation Loss: 0.5385391116142273
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5523216426372528
  Validation Loss: 0.5384247899055481
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5566859841346741
  Validation Loss: 0.5383298993110657
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5654294192790985
  Validation Loss: 0.5382472276687622
  Val ROC-AUC: 0.7272727272727273
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:13:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:20:INFO:
[92mINFO [0m:      Received: evaluate message 19f79435-6027-47d5-94ec-d91611bd57a9
02/07/2025 22:45:20:INFO:Received: evaluate message 19f79435-6027-47d5-94ec-d91611bd57a9
[92mINFO [0m:      Sent reply
02/07/2025 22:45:20:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:22:INFO:
[92mINFO [0m:      Received: train message e2ea551c-fce8-4903-aa75-45d04fa167e0
02/07/2025 22:45:22:INFO:Received: train message e2ea551c-fce8-4903-aa75-45d04fa167e0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5625444948673248
  Validation Loss: 0.5381804704666138
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5620869398117065
  Validation Loss: 0.5381352305412292
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5647041499614716
  Validation Loss: 0.538076639175415
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5589616894721985
  Validation Loss: 0.53801029920578
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5539557635784149
  Validation Loss: 0.5379588007926941
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5594339668750763
  Validation Loss: 0.5378922820091248
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5619355738162994
  Validation Loss: 0.5378147959709167
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5616413950920105
  Validation Loss: 0.5377582907676697
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5627745687961578
  Validation Loss: 0.5376984477043152
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5570507049560547
  Validation Loss: 0.5376513004302979
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5554775595664978
  Validation Loss: 0.5375756025314331
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5590528547763824
  Validation Loss: 0.5375038981437683
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5605689585208893
  Validation Loss: 0.5374137759208679
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5665174722671509
  Validation Loss: 0.5373121500015259
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5599851012229919
  Validation Loss: 0.5372012257575989
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5591537952423096
  Validation Loss: 0.5371198058128357
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5549825727939606
  Validation Loss: 0.5370578169822693
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5554828345775604
  Validation Loss: 0.5369950532913208
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5591541230678558
  Validation Loss: 0.5369057655334473
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5593444406986237
  Validation Loss: 0.5368107557296753
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5631877183914185
  Validation Loss: 0.5367091298103333
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5592563450336456
  Validation Loss: 0.5366072654724121
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5621250867843628
  Validation Loss: 0.5364974141120911
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5621250867843628, 'val_roc_auc': 0.7272727272727273, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5364974141120911}
 ROC_AUC: 0.7273|| Accuracy 0.6923 || Train Loss: 0.5621
 Val Loss: 0.5365 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5783185296588473
Test ROC-AUC: 0.6542857142857144
Test Accuracy: 0.6
test_loss: 0.5783185296588473
test_roc_auc: 0.6542857142857144
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.4686301123001613
Epoch 1/64:
  Train Loss: 0.549656867980957
  Validation Loss: 0.6136550903320312
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 2/64:
  Train Loss: 0.5513582825660706
  Validation Loss: 0.6139267086982727
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 3/64:
  Train Loss: 0.5441203117370605
  Validation Loss: 0.6141631603240967
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 4/64:
  Train Loss: 0.5442312359809875
  Validation Loss: 0.6143394708633423
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 5/64:
  Train Loss: 0.5395444184541702
  Validation Loss: 0.614510178565979
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 6/64:
  Train Loss: 0.5455546379089355
  Validation Loss: 0.6146603226661682
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 7/64:
  Train Loss: 0.5452917218208313
  Validation Loss: 0.6147738695144653
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 8/64:
  Train Loss: 0.5448601245880127
  Validation Loss: 0.6149047613143921
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 9/64:
  Train Loss: 0.5457835495471954
  Validation Loss: 0.6150055527687073
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 10/64:
  Train Loss: 0.5519123375415802
  Validation Loss: 0.615130603313446
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 11/64:
  Train Loss: 0.5417299568653107
  Validation Loss: 0.6152917742729187
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 12/64:
  Train Loss: 0.5394648611545563
  Validation Loss: 0.615434467792511
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 13/64:
  Train Loss: 0.5518709123134613
  Validation Loss: 0.6155401468276978
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 14/64:
  Train Loss: 0.5509016215801239
  Validation Loss: 0.6156501770019531
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 15/64:
  Train Loss: 0.5505695641040802
  Validation Loss: 0.6157596707344055
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 16/64:
  Train Loss: 0.544565349817276
  Validation Loss: 0.6158849596977234
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 17/64:
  Train Loss: 0.5414711833000183
  Validation Loss: 0.6160160899162292
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 18/64:
  Train Loss: 0.5440469682216644
  Validation Loss: 0.6161471605300903
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 19/64:
  Train Loss: 0.549055278301239
  Validation Loss: 0.6163133978843689
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 20/64:
  Train Loss: 0.5478768646717072
  Validation Loss: 0.6164411902427673
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 21/64:
  Train Loss: 0.5379618704319
  Validation Loss: 0.6165369749069214
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 22/64:
  Train Loss: 0.5349948108196259
  Validation Loss: 0.6166643500328064
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 23/64:
  Train Loss: 0.5457641184329987
  Validation Loss: 0.6168012619018555
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 24/64:
  Train Loss: 0.548302173614502
  Validation Loss: 0.6169505715370178
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 25/64:
  Train Loss: 0.5495035648345947
  Validation Loss: 0.617087185382843
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 26/64:
  Train Loss: 0.54706671833992
  Validation Loss: 0.6172265410423279
  Val ROC-AUC: 0.3666666666666667
  Val Accuracy: 0.38461539149284363
Epoch 27/64:
  Train Loss: 0.5450115501880646
  Validation Loss: 0.6173602342605591
  Val ROC-AUC: 0.3666666666666667
  Val Accuracy: 0.38461539149284363
Epoch 28/64:
  Train Loss: 0.5413399338722229
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:43:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:50:INFO:
[92mINFO [0m:      Received: evaluate message f5020e30-bb40-4f25-bef4-dfcc7b61485c
02/07/2025 22:45:50:INFO:Received: evaluate message f5020e30-bb40-4f25-bef4-dfcc7b61485c
[92mINFO [0m:      Sent reply
02/07/2025 22:45:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:52:INFO:
[92mINFO [0m:      Received: train message 9c4004d6-769b-4bcb-a61d-5c45bf60164f
02/07/2025 22:45:52:INFO:Received: train message 9c4004d6-769b-4bcb-a61d-5c45bf60164f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6174850463867188
  Val ROC-AUC: 0.3666666666666667
  Val Accuracy: 0.38461539149284363
Epoch 29/64:
  Train Loss: 0.5437003076076508
  Validation Loss: 0.6175991892814636
  Val ROC-AUC: 0.3666666666666667
  Val Accuracy: 0.38461539149284363
Epoch 30/64:
  Train Loss: 0.5383722186088562
  Validation Loss: 0.6177042722702026
  Val ROC-AUC: 0.3666666666666667
  Val Accuracy: 0.38461539149284363
Epoch 31/64:
  Train Loss: 0.5501243472099304
  Validation Loss: 0.6177965402603149
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 32/64:
  Train Loss: 0.5341061651706696
  Validation Loss: 0.6178752183914185
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 33/64:
  Train Loss: 0.5334590524435043
  Validation Loss: 0.6179744601249695
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 34/64:
  Train Loss: 0.5418950021266937
  Validation Loss: 0.6180752515792847
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 35/64:
  Train Loss: 0.5338131338357925
  Validation Loss: 0.618185818195343
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 36/64:
  Train Loss: 0.5406465530395508
  Validation Loss: 0.6182940006256104
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 37/64:
  Train Loss: 0.5304239839315414
  Validation Loss: 0.6183891296386719
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 38/64:
  Train Loss: 0.5387943387031555
  Validation Loss: 0.6184495091438293
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 39/64:
  Train Loss: 0.5419975221157074
  Validation Loss: 0.6185105443000793
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 40/64:
  Train Loss: 0.5350581109523773
  Validation Loss: 0.6185476183891296
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 41/64:
  Train Loss: 0.5445463955402374
  Validation Loss: 0.6185928583145142
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 42/64:
  Train Loss: 0.5454874336719513
  Validation Loss: 0.6186407804489136
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 43/64:
  Train Loss: 0.5412186682224274
  Validation Loss: 0.6187011003494263
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 44/64:
  Train Loss: 0.5406787693500519
  Validation Loss: 0.6187832355499268
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 45/64:
  Train Loss: 0.538021445274353
  Validation Loss: 0.6188725829124451
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 46/64:
  Train Loss: 0.5364218056201935
  Validation Loss: 0.6189364194869995
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 47/64:
  Train Loss: 0.5365070104598999
  Validation Loss: 0.6189669966697693
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 48/64:
  Train Loss: 0.5367713570594788
  Validation Loss: 0.6189898252487183
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 49/64:
  Train Loss: 0.54439777135849
  Validation Loss: 0.6189898252487183
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 50/64:
  Train Loss: 0.5403449237346649
  Validation Loss: 0.6189966201782227
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 51/64:
  Train Loss: 0.5398718118667603
  Validation Loss: 0.6189981698989868
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 52/64:
  Train Loss: 0.5444327890872955
  Validation Loss: 0.6189849972724915
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 53/64:
  Train Loss: 0.5317517071962357
  Validation Loss: 0.6190260648727417
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 54/64:
  Train Loss: 0.5372574925422668
  Validation Loss: 0.6190899610519409
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 55/64:
  Train Loss: 0.5320198088884354
  Validation Loss: 0.6191521883010864
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 56/64:
  Train Loss: 0.5314200818538666
  Validation Loss: 0.6192193627357483
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 57/64:
  Train Loss: 0.5354827642440796
  Validation Loss: 0.6192418336868286
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 58/64:
  Train Loss: 0.5349318385124207
  Validation Loss: 0.619239091873169
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 59/64:
  Train Loss: 0.536750078201294
  Validation Loss: 0.6192114949226379
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 60/64:
  Train Loss: 0.5358989834785461
  Validation Loss: 0.6192028522491455
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 61/64:
  Train Loss: 0.5323764681816101
  Validation Loss: 0.6191986799240112
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 62/64:
  Train Loss: 0.5427579581737518
  Validation Loss: 0.6191895008087158
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 63/64:
  Train Loss: 0.5332650244235992
  Validation Loss: 0.6192306876182556
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 64/64:
  Train Loss: 0.5353035032749176
  Validation Loss: 0.6192575693130493
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
{'train_loss': 0.5353035032749176, 'val_roc_auc': 0.4, 'val_accuracy': 0.38461539149284363, 'val_loss': 0.6192575693130493}
 ROC_AUC: 0.4000|| Accuracy 0.3846 || Train Loss: 0.5353
 Val Loss: 0.6193 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5780328234036763
Test ROC-AUC: 0.6628571428571429
Test Accuracy: 0.6
test_loss: 0.5780328234036763
test_roc_auc: 0.6628571428571429
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.38159053823619615
Epoch 1/64:
  Train Loss: 0.5679586827754974
  Validation Loss: 0.5370667576789856
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5687938034534454
  Validation Loss: 0.5370844006538391
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5638050734996796
  Validation Loss: 0.5370466113090515
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5593531131744385
  Validation Loss: 0.537015974521637
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5641261339187622
  Validation Loss: 0.5369922518730164
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5575834214687347
  Validation Loss: 0.5369691848754883
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5545670688152313
  Validation Loss: 0.536950409412384
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5594677329063416
  Validation Loss: 0.5369413495063782
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5601032972335815
  Validation Loss: 0.536952018737793
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5594345331192017
  Validation Loss: 0.536933422088623
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5681724548339844
  Validation Loss: 0.5369100570678711
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5695095360279083
  Validation Loss: 0.5368465185165405
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5581258833408356
  Validation Loss: 0.5367664098739624
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5648888647556305
  Validation Loss: 0.5366628170013428
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.569925844669342
  Validation Loss: 0.5365869402885437
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.56767937541008
  Validation Loss: 0.5365557670593262
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5629207789897919
  Validation Loss: 0.5365123152732849
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5616306662559509
  Validation Loss: 0.536465585231781
  Val ROC-AUC: 0.5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:19:INFO:
[92mINFO [0m:      Received: evaluate message d7d51721-24aa-4f1f-8fe9-5eaba894c1af
02/07/2025 22:46:19:INFO:Received: evaluate message d7d51721-24aa-4f1f-8fe9-5eaba894c1af
[92mINFO [0m:      Sent reply
02/07/2025 22:46:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:20:INFO:
[92mINFO [0m:      Received: train message ae229e0c-3c1c-4e0d-be2b-47859750545a
02/07/2025 22:46:20:INFO:Received: train message ae229e0c-3c1c-4e0d-be2b-47859750545a
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5608488917350769
  Validation Loss: 0.5364060401916504
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5612848699092865
  Validation Loss: 0.5363668203353882
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5666116178035736
  Validation Loss: 0.5363504886627197
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.554911345243454
  Validation Loss: 0.5363410115242004
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.565345823764801
  Validation Loss: 0.5363144874572754
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5587342381477356
  Validation Loss: 0.5362799763679504
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5608926713466644
  Validation Loss: 0.5362473726272583
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5592710971832275
  Validation Loss: 0.5362338423728943
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5583995878696442
  Validation Loss: 0.5361897349357605
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5700086057186127
  Validation Loss: 0.5361437797546387
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.560686856508255
  Validation Loss: 0.5360969305038452
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5611453056335449
  Validation Loss: 0.5360735058784485
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5707944631576538
  Validation Loss: 0.5360481142997742
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5579414367675781
  Validation Loss: 0.5359901785850525
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5551885068416595
  Validation Loss: 0.5359659194946289
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5579766035079956
  Validation Loss: 0.535918116569519
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5662193298339844
  Validation Loss: 0.5358830094337463
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5674245357513428
  Validation Loss: 0.535881519317627
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5646678805351257
  Validation Loss: 0.5358891487121582
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5629667043685913
  Validation Loss: 0.5358819961547852
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5609421730041504
  Validation Loss: 0.5358559489250183
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5511135458946228
  Validation Loss: 0.5358107686042786
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5575059056282043
  Validation Loss: 0.5357638001441956
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5579290390014648
  Validation Loss: 0.5356768369674683
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5610723793506622
  Validation Loss: 0.535588264465332
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5688279271125793
  Validation Loss: 0.5355213284492493
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5593477487564087
  Validation Loss: 0.5354578495025635
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5645635426044464
  Validation Loss: 0.535398542881012
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5603358447551727
  Validation Loss: 0.535356342792511
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5617910325527191
  Validation Loss: 0.5353103876113892
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5522735416889191
  Validation Loss: 0.5352668762207031
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5595641136169434
  Validation Loss: 0.5352228879928589
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5509019792079926
  Validation Loss: 0.5351710915565491
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5533435940742493
  Validation Loss: 0.5350990295410156
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5608470737934113
  Validation Loss: 0.5350348353385925
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5564336180686951
  Validation Loss: 0.5349705815315247
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5600608289241791
  Validation Loss: 0.5348764061927795
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5570513904094696
  Validation Loss: 0.5347675085067749
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5546527802944183
  Validation Loss: 0.5346687436103821
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5584942698478699
  Validation Loss: 0.5345929265022278
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5524144768714905
  Validation Loss: 0.534524142742157
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5561719238758087
  Validation Loss: 0.5344463586807251
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5560720860958099
  Validation Loss: 0.53439861536026
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.556824803352356
  Validation Loss: 0.5343440771102905
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5583145022392273
  Validation Loss: 0.534275233745575
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5599495768547058
  Validation Loss: 0.5342000722885132
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5599495768547058, 'val_roc_auc': 0.4166666666666667, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5342000722885132}
 ROC_AUC: 0.4167|| Accuracy 0.5385 || Train Loss: 0.5599
 Val Loss: 0.5342 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5777974188327789
Test ROC-AUC: 0.6714285714285715
Test Accuracy: 0.5777777777777777
test_loss: 0.5777974188327789
test_roc_auc: 0.6714285714285715
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.4838331563223619
Epoch 1/64:
  Train Loss: 0.5779172778129578
  Validation Loss: 0.5016862154006958
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5655674636363983
  Validation Loss: 0.5015276670455933
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5797971785068512
  Validation Loss: 0.5013298392295837
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5679707527160645
  Validation Loss: 0.5011881589889526
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 5/64:
  Train Loss: 0.5771632492542267
  Validation Loss: 0.5010206699371338
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5693885684013367
  Validation Loss: 0.5008965730667114
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5778062343597412
  Validation Loss: 0.5007858276367188
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5720302164554596
  Validation Loss: 0.5006636381149292
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5794015228748322
  Validation Loss: 0.5005544424057007
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5659633874893188
  Validation Loss: 0.5004477500915527
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5778250694274902
  Validation Loss: 0.5003578662872314
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5745000839233398
  Validation Loss: 0.5002622604370117
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5757950246334076
  Validation Loss: 0.5001598000526428
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5761581063270569
  Validation Loss: 0.5000594258308411
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5749270021915436
  Validation Loss: 0.4999516010284424
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5845580697059631
  Validation Loss: 0.49985215067863464
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5707409381866455
  Validation Loss: 0.49975669384002686
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5605211406946182
  Validation Loss: 0.49964335560798645
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5698025226593018
  Validation Loss: 0.4995186924934387
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5748284459114075
  Validation Loss: 0.4993932545185089
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5644953846931458
  Validation Loss: 0.4992627501487732
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5731064677238464
  Validation Loss: 0.4991168677806854
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5705800950527191
  Validation Loss: 0.4989698529243469
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5698742568492889
  Validation Loss: 0.49882036447525024
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.575354814529419
  Validation Loss: 0.4986490309238434
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5686415433883667
  Validation Loss: 0.4984734058380127
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5760553181171417
  Validation Loss: 0.49829617142677307
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5737873911857605
  Validation Loss: 0.4981118142604828
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5704227983951569
  Validation Loss: 0.49794381856918335
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5723134875297546
  Validation Loss: 0.49777933955192566
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5727758705615997
  Validation Loss: 0.4976339638233185
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5677157938480377
  Validation Loss: 0.49750345945358276
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5723696351051331
  Validation Loss: 0.4973839521408081
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5745453536510468
  Validation Loss: 0.4972522556781769
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5698484480381012
  Validation Loss: 0.49713537096977234
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5778320729732513
  Validation Loss: 0.4970094561576843
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5707075893878937
  Validation Loss: 0.49687549471855164
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5758326053619385
  Validation Loss: 0.49672406911849976
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5755346417427063
  Validation Loss: 0.496578186750412
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5714705586433411
  Validation Loss: 0.49643474817276
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5649894773960114
  Validation Loss: 0.4962764382362366
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5746639370918274
  Validation Loss: 0.49611958861351013
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5686673521995544
  Validation Loss: 0.4960062801837921
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5616518557071686
  Validation Loss: 0.49589401483535767
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.572275847196579
  Validation Loss: 0.49577105045318604
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5692336559295654
  Validation Loss: 0.4956764876842499
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5722588896751404
  Validation Loss: 0.49558499455451965
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5775454342365265
  Validation Loss: 0.49548643827438354
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5704909265041351
  Validation Loss: 0.49541088938713074
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.576318234205246
  Validation Loss: 0.4953146278858185
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5647132098674774
  Validation Loss: 0.49520596861839294
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5602152943611145
  Validation Loss: 0.495100736618042
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5721525549888611
  Validation Loss: 0.4949790835380554
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5647833347320557
  Validation Loss: 0.4948917031288147
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5698437094688416
  Validation Loss: 0.4948170781135559
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5718236863613129
  Validation Loss: 0.4947211444377899
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5699074566364288
  Validation Loss: 0.4946456551551819
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5739284455776215
  Validation Loss: 0.4945647716522217
  Val ROC-AUC: 0.6666666666666666
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:40:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:49:INFO:
[92mINFO [0m:      Received: evaluate message 897b2f2e-d31c-4008-bbbd-7d4502c03f2e
02/07/2025 22:46:49:INFO:Received: evaluate message 897b2f2e-d31c-4008-bbbd-7d4502c03f2e
[92mINFO [0m:      Sent reply
02/07/2025 22:46:49:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:49:INFO:
[92mINFO [0m:      Received: train message 2e55b17b-8bee-4ea9-9779-3aad8b38b384
02/07/2025 22:46:49:INFO:Received: train message 2e55b17b-8bee-4ea9-9779-3aad8b38b384
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.567175418138504
  Validation Loss: 0.494465708732605
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5680984258651733
  Validation Loss: 0.49438053369522095
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5623362064361572
  Validation Loss: 0.49426591396331787
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5672941207885742
  Validation Loss: 0.49415305256843567
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.570385605096817
  Validation Loss: 0.49404269456863403
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.570090264081955
  Validation Loss: 0.4939272999763489
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.570090264081955, 'val_roc_auc': 0.6666666666666666, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.4939272999763489}
 ROC_AUC: 0.6667|| Accuracy 0.6154 || Train Loss: 0.5701
 Val Loss: 0.4939 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5775576896137662
Test ROC-AUC: 0.6799999999999999
Test Accuracy: 0.5777777777777777
test_loss: 0.5775576896137662
test_roc_auc: 0.6799999999999999
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.5006310525641311
Epoch 1/64:
  Train Loss: 0.5437912940979004
  Validation Loss: 0.6189185380935669
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5362313985824585
  Validation Loss: 0.6189889907836914
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5439810156822205
  Validation Loss: 0.6190492510795593
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5483562052249908
  Validation Loss: 0.6190567016601562
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5441061556339264
  Validation Loss: 0.6190345883369446
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5380054265260696
  Validation Loss: 0.6190215945243835
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5416879951953888
  Validation Loss: 0.6190052032470703
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.542504221200943
  Validation Loss: 0.6189895868301392
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5423982739448547
  Validation Loss: 0.6190008521080017
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.55028235912323
  Validation Loss: 0.6190022826194763
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5410147607326508
  Validation Loss: 0.6190029382705688
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5429720878601074
  Validation Loss: 0.6189981698989868
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5396992564201355
  Validation Loss: 0.6189980506896973
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5403721630573273
  Validation Loss: 0.6189975142478943
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5483293235301971
  Validation Loss: 0.6190222501754761
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5403463244438171
  Validation Loss: 0.619046151638031
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5460456907749176
  Validation Loss: 0.6190590858459473
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5434033870697021
  Validation Loss: 0.6190641522407532
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5399544835090637
  Validation Loss: 0.6190779805183411
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5466630160808563
  Validation Loss: 0.6191043853759766
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5379805564880371
  Validation Loss: 0.6191086769104004
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5400334298610687
  Validation Loss: 0.6190921068191528
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5434124767780304
  Validation Loss: 0.6191067695617676
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5451361536979675
  Validation Loss: 0.6191074252128601
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5446068346500397
  Validation Loss: 0.6190817952156067
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5405619144439697
  Validation Loss: 0.619073212146759
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5342031270265579
  Validation Loss: 0.6190603971481323
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5459948778152466
  Validation Loss: 0.619079053401947
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5459288954734802
  Validation Loss: 0.6191073656082153
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5389533340930939
  Validation Loss: 0.6191259622573853
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5459407269954681
  Validation Loss: 0.6191673278808594
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5393872857093811
  Validation Loss: 0.6192376017570496
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5464891195297241
  Validation Loss: 0.6193049550056458
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5443394184112549
  Validation Loss: 0.6193347573280334
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5491620600223541
  Validation Loss: 0.6193484663963318
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5399922728538513
  Validation Loss: 0.6193566918373108
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.544087827205658
  Validation Loss: 0.619396984577179
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5372922420501709
  Validation Loss: 0.6194135546684265
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5439408123493195
  Validation Loss: 0.6194358468055725
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5425218939781189
  Validation Loss: 0.6194620132446289
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5431987643241882
  Validation Loss: 0.6195007562637329
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5367900133132935
  Validation Loss: 0.6195378303527832
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5477721691131592
  Validation Loss: 0.6195441484451294
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.531685009598732
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:13:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:18:INFO:
[92mINFO [0m:      Received: evaluate message 73a7c725-deef-4e98-acda-435b5bf37367
02/07/2025 22:47:18:INFO:Received: evaluate message 73a7c725-deef-4e98-acda-435b5bf37367
[92mINFO [0m:      Sent reply
02/07/2025 22:47:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:19:INFO:
[92mINFO [0m:      Received: train message b17c5c56-ff32-4e6f-9173-4f391ab4e975
02/07/2025 22:47:19:INFO:Received: train message b17c5c56-ff32-4e6f-9173-4f391ab4e975
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6195505857467651
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5372833013534546
  Validation Loss: 0.619522213935852
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5456784963607788
  Validation Loss: 0.6195278167724609
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5340135097503662
  Validation Loss: 0.619518518447876
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5357303023338318
  Validation Loss: 0.6195381283760071
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.536231279373169
  Validation Loss: 0.6195683479309082
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5393759310245514
  Validation Loss: 0.6195931434631348
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5436895191669464
  Validation Loss: 0.6196113228797913
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5365800857543945
  Validation Loss: 0.6196287870407104
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5387664139270782
  Validation Loss: 0.6197056770324707
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5344443619251251
  Validation Loss: 0.6197776794433594
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5378755331039429
  Validation Loss: 0.6198417544364929
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5429669320583344
  Validation Loss: 0.6198996901512146
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5318698287010193
  Validation Loss: 0.6199913024902344
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5284913331270218
  Validation Loss: 0.6200893521308899
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5383637547492981
  Validation Loss: 0.6201770901679993
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5413874685764313
  Validation Loss: 0.6202464699745178
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5375460982322693
  Validation Loss: 0.6203040480613708
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5362960994243622
  Validation Loss: 0.6203721165657043
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.539921909570694
  Validation Loss: 0.6204357147216797
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5396259129047394
  Validation Loss: 0.6204897165298462
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5396259129047394, 'val_roc_auc': 0.6111111111111112, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.6204897165298462}
 ROC_AUC: 0.6111|| Accuracy 0.6154 || Train Loss: 0.5396
 Val Loss: 0.6205 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5773384822739496
Test ROC-AUC: 0.6771428571428572
Test Accuracy: 0.5555555555555556
test_loss: 0.5773384822739496
test_roc_auc: 0.6771428571428572
test_accuracy: 0.5555555555555556
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.3204527783964295
Epoch 1/64:
  Train Loss: 0.5663651525974274
  Validation Loss: 0.5228305459022522
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5685218274593353
  Validation Loss: 0.5227842926979065
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5624518096446991
  Validation Loss: 0.522741973400116
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.5713248550891876
  Validation Loss: 0.5226984024047852
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.560171365737915
  Validation Loss: 0.5226486325263977
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5690187513828278
  Validation Loss: 0.5226001143455505
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5723679661750793
  Validation Loss: 0.5225595831871033
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5611764192581177
  Validation Loss: 0.52253657579422
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.5739896595478058
  Validation Loss: 0.5224894285202026
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.5695266127586365
  Validation Loss: 0.5224487781524658
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.5670400559902191
  Validation Loss: 0.5224074721336365
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5656741857528687
  Validation Loss: 0.5223776698112488
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5634588897228241
  Validation Loss: 0.5223441123962402
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5626404583454132
  Validation Loss: 0.5223228335380554
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 15/64:
  Train Loss: 0.569288969039917
  Validation Loss: 0.5222839117050171
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 16/64:
  Train Loss: 0.5645342171192169
  Validation Loss: 0.5222574472427368
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 17/64:
  Train Loss: 0.5683045089244843
  Validation Loss: 0.5222148299217224
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 18/64:
  Train Loss: 0.5636293590068817
  Validation Loss: 0.5221837759017944
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 19/64:
  Train Loss: 0.5715911090373993
  Validation Loss: 0.5221460461616516
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.5638492107391357
  Validation Loss: 0.522105872631073
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.5695712268352509
  Validation Loss: 0.522074282169342
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5630304515361786
  Validation Loss: 0.5220397710800171
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5634518563747406
  Validation Loss: 0.5219995975494385
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5575643479824066
  Validation Loss: 0.5219618082046509
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.562189906835556
  Validation Loss: 0.5219328999519348
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5689389109611511
  Validation Loss: 0.5219106078147888
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.561183363199234
  Validation Loss: 0.5218638181686401
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5637610852718353
  Validation Loss: 0.5217942595481873
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5685707032680511
  Validation Loss: 0.5217263102531433
  Val ROC-AUC: 0.3333333333333333
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:38:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:45:INFO:
[92mINFO [0m:      Received: evaluate message ffe789d3-8d92-4ea0-b4e4-7fa2ab89ece0
02/07/2025 22:47:45:INFO:Received: evaluate message ffe789d3-8d92-4ea0-b4e4-7fa2ab89ece0
[92mINFO [0m:      Sent reply
02/07/2025 22:47:46:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:47:INFO:
[92mINFO [0m:      Received: train message 1937857b-269b-4f36-b5e2-9ba40a1f323a
02/07/2025 22:47:47:INFO:Received: train message 1937857b-269b-4f36-b5e2-9ba40a1f323a
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5664805173873901
  Validation Loss: 0.5216554999351501
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5659325420856476
  Validation Loss: 0.5215921401977539
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5595917999744415
  Validation Loss: 0.5215392112731934
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5609881579875946
  Validation Loss: 0.5214754343032837
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5666042268276215
  Validation Loss: 0.5214298367500305
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5570554435253143
  Validation Loss: 0.5213896036148071
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5588009357452393
  Validation Loss: 0.5213507413864136
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5690756142139435
  Validation Loss: 0.5213152170181274
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5667078197002411
  Validation Loss: 0.5212754607200623
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5626616477966309
  Validation Loss: 0.5212447047233582
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5599172413349152
  Validation Loss: 0.5212151408195496
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5561860799789429
  Validation Loss: 0.5211769342422485
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5701149702072144
  Validation Loss: 0.5211317539215088
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5578199326992035
  Validation Loss: 0.5211058855056763
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5669378936290741
  Validation Loss: 0.521068274974823
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5648162364959717
  Validation Loss: 0.5210191607475281
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5587080121040344
  Validation Loss: 0.5209764838218689
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5588361024856567
  Validation Loss: 0.5209353566169739
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5593670010566711
  Validation Loss: 0.520897626876831
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5649552047252655
  Validation Loss: 0.5208479166030884
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5548537373542786
  Validation Loss: 0.5207999348640442
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5614968836307526
  Validation Loss: 0.5207419395446777
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5660822093486786
  Validation Loss: 0.520693838596344
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5515100061893463
  Validation Loss: 0.5206507444381714
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5620352625846863
  Validation Loss: 0.5205956697463989
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5553233325481415
  Validation Loss: 0.5205420851707458
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5647458732128143
  Validation Loss: 0.5204933285713196
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5546680092811584
  Validation Loss: 0.5204402208328247
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5648659765720367
  Validation Loss: 0.5203922390937805
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5575919449329376
  Validation Loss: 0.520334005355835
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.550316572189331
  Validation Loss: 0.5202775001525879
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5610260665416718
  Validation Loss: 0.5202265977859497
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5591467320919037
  Validation Loss: 0.5201858282089233
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5583157241344452
  Validation Loss: 0.5201420187950134
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.558610200881958
  Validation Loss: 0.5201013684272766
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.558610200881958, 'val_roc_auc': 0.3333333333333333, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5201013684272766}
 ROC_AUC: 0.3333|| Accuracy 0.5385 || Train Loss: 0.5586
 Val Loss: 0.5201 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5771131760544247
Test ROC-AUC: 0.6771428571428572
Test Accuracy: 0.5555555555555556
test_loss: 0.5771131760544247
test_roc_auc: 0.6771428571428572
test_accuracy: 0.5555555555555556
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.3884578771976521
Epoch 1/64:
  Train Loss: 0.5558712482452393
  Validation Loss: 0.5840101838111877
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 2/64:
  Train Loss: 0.5525977909564972
  Validation Loss: 0.5841163992881775
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 3/64:
  Train Loss: 0.5604334473609924
  Validation Loss: 0.5841492414474487
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 4/64:
  Train Loss: 0.5546469986438751
  Validation Loss: 0.5841652750968933
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 5/64:
  Train Loss: 0.5577832758426666
  Validation Loss: 0.5842238068580627
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 6/64:
  Train Loss: 0.5537289679050446
  Validation Loss: 0.5842710137367249
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 7/64:
  Train Loss: 0.5488632321357727
  Validation Loss: 0.5842973589897156
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 8/64:
  Train Loss: 0.5515353083610535
  Validation Loss: 0.5843222737312317
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 9/64:
  Train Loss: 0.5514777600765228
  Validation Loss: 0.5843654870986938
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 10/64:
  Train Loss: 0.5413692444562912
  Validation Loss: 0.5843743085861206
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 11/64:
  Train Loss: 0.5429001152515411
  Validation Loss: 0.5843927264213562
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 12/64:
  Train Loss: 0.5555616617202759
  Validation Loss: 0.5844185948371887
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 13/64:
  Train Loss: 0.5532591938972473
  Validation Loss: 0.5844563841819763
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 14/64:
  Train Loss: 0.5431375354528427
  Validation Loss: 0.5844817161560059
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 15/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:14:INFO:
[92mINFO [0m:      Received: evaluate message 4d99c869-39d2-404a-a623-96562a3c37b9
02/07/2025 22:48:14:INFO:Received: evaluate message 4d99c869-39d2-404a-a623-96562a3c37b9
[92mINFO [0m:      Sent reply
02/07/2025 22:48:15:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:17:INFO:
[92mINFO [0m:      Received: train message 11ffdfcf-7ad5-470f-acd2-7ef64eb7f011
02/07/2025 22:48:17:INFO:Received: train message 11ffdfcf-7ad5-470f-acd2-7ef64eb7f011
  Train Loss: 0.5622664391994476
  Validation Loss: 0.5845276117324829
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 16/64:
  Train Loss: 0.5470419526100159
  Validation Loss: 0.5845634937286377
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 17/64:
  Train Loss: 0.547143816947937
  Validation Loss: 0.5845766067504883
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 18/64:
  Train Loss: 0.5476714968681335
  Validation Loss: 0.5845876336097717
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 19/64:
  Train Loss: 0.5650166422128677
  Validation Loss: 0.5845870971679688
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 20/64:
  Train Loss: 0.5547981560230255
  Validation Loss: 0.5845711827278137
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 21/64:
  Train Loss: 0.552004873752594
  Validation Loss: 0.5845777988433838
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 22/64:
  Train Loss: 0.5519680082798004
  Validation Loss: 0.5845972895622253
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 23/64:
  Train Loss: 0.5542177557945251
  Validation Loss: 0.5846412777900696
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 24/64:
  Train Loss: 0.5431241393089294
  Validation Loss: 0.5846834182739258
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 25/64:
  Train Loss: 0.5542652010917664
  Validation Loss: 0.5847128629684448
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 26/64:
  Train Loss: 0.5554847121238708
  Validation Loss: 0.5847412347793579
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 27/64:
  Train Loss: 0.5574430227279663
  Validation Loss: 0.5847678184509277
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 28/64:
  Train Loss: 0.5499296188354492
  Validation Loss: 0.5848258137702942
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 29/64:
  Train Loss: 0.5431192815303802
  Validation Loss: 0.5848695635795593
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 30/64:
  Train Loss: 0.5532110929489136
  Validation Loss: 0.5849003195762634
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 31/64:
  Train Loss: 0.5389875173568726
  Validation Loss: 0.5849336981773376
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 32/64:
  Train Loss: 0.5503409206867218
  Validation Loss: 0.5849717855453491
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 33/64:
  Train Loss: 0.5457299947738647
  Validation Loss: 0.5850194096565247
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 34/64:
  Train Loss: 0.5527416169643402
  Validation Loss: 0.5850765705108643
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 35/64:
  Train Loss: 0.5557772815227509
  Validation Loss: 0.5851045846939087
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 36/64:
  Train Loss: 0.5408452749252319
  Validation Loss: 0.5851083993911743
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 37/64:
  Train Loss: 0.54517662525177
  Validation Loss: 0.5851074457168579
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 38/64:
  Train Loss: 0.548085629940033
  Validation Loss: 0.585116982460022
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 39/64:
  Train Loss: 0.5448780059814453
  Validation Loss: 0.5851474404335022
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 40/64:
  Train Loss: 0.5504160523414612
  Validation Loss: 0.5851834416389465
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 41/64:
  Train Loss: 0.54812091588974
  Validation Loss: 0.5852218270301819
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 42/64:
  Train Loss: 0.5538352727890015
  Validation Loss: 0.5852380990982056
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 43/64:
  Train Loss: 0.5465118288993835
  Validation Loss: 0.5852606892585754
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 44/64:
  Train Loss: 0.5482257008552551
  Validation Loss: 0.5852820873260498
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 45/64:
  Train Loss: 0.5482867062091827
  Validation Loss: 0.5853177905082703
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 46/64:
  Train Loss: 0.5438994765281677
  Validation Loss: 0.5853528380393982
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 47/64:
  Train Loss: 0.5486483573913574
  Validation Loss: 0.5854112505912781
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 48/64:
  Train Loss: 0.5363105833530426
  Validation Loss: 0.5854744911193848
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 49/64:
  Train Loss: 0.550940066576004
  Validation Loss: 0.5855342745780945
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 50/64:
  Train Loss: 0.5476016402244568
  Validation Loss: 0.5855757594108582
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 51/64:
  Train Loss: 0.5459252893924713
  Validation Loss: 0.5856027007102966
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 52/64:
  Train Loss: 0.5433059632778168
  Validation Loss: 0.5856106281280518
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 53/64:
  Train Loss: 0.5415913164615631
  Validation Loss: 0.5856212973594666
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 54/64:
  Train Loss: 0.5486468970775604
  Validation Loss: 0.585648775100708
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 55/64:
  Train Loss: 0.5430358946323395
  Validation Loss: 0.585668683052063
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 56/64:
  Train Loss: 0.544469565153122
  Validation Loss: 0.5857119560241699
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 57/64:
  Train Loss: 0.5504458248615265
  Validation Loss: 0.5857408046722412
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 58/64:
  Train Loss: 0.5462687015533447
  Validation Loss: 0.5857537984848022
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 59/64:
  Train Loss: 0.53793965280056
  Validation Loss: 0.5857580304145813
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 60/64:
  Train Loss: 0.5484683513641357
  Validation Loss: 0.585761308670044
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 61/64:
  Train Loss: 0.543032169342041
  Validation Loss: 0.5857629776000977
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 62/64:
  Train Loss: 0.54710653424263
  Validation Loss: 0.585774302482605
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 63/64:
  Train Loss: 0.5454114377498627
  Validation Loss: 0.5857897400856018
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 64/64:
  Train Loss: 0.5406682193279266
  Validation Loss: 0.5858039259910583
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
{'train_loss': 0.5406682193279266, 'val_roc_auc': 0.36363636363636365, 'val_accuracy': 0.3076923191547394, 'val_loss': 0.5858039259910583}
 ROC_AUC: 0.3636|| Accuracy 0.3077 || Train Loss: 0.5407
 Val Loss: 0.5858 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5767964171038733
Test ROC-AUC: 0.6942857142857143
Test Accuracy: 0.5555555555555556
test_loss: 0.5767964171038733
test_roc_auc: 0.6942857142857143
test_accuracy: 0.5555555555555556
eval_cid: 3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.2878246336331358
Epoch 1/64:
  Train Loss: 0.5495389699935913
  Validation Loss: 0.5868050456047058
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 2/64:
  Train Loss: 0.5600705146789551
  Validation Loss: 0.5868977904319763
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 3/64:
  Train Loss: 0.5436317920684814
  Validation Loss: 0.5870366096496582
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 4/64:
  Train Loss: 0.5602742731571198
  Validation Loss: 0.5871375203132629
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 5/64:
  Train Loss: 0.5499274730682373
  Validation Loss: 0.5872353315353394
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 6/64:
  Train Loss: 0.5495088994503021
  Validation Loss: 0.5873519778251648
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 7/64:
  Train Loss: 0.5490696430206299
  Validation Loss: 0.5874794721603394
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 8/64:
  Train Loss: 0.552750438451767
  Validation Loss: 0.5876030325889587
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 9/64:
  Train Loss: 0.5460812151432037
  Validation Loss: 0.5877221822738647
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 10/64:
  Train Loss: 0.5549878180027008
  Validation Loss: 0.5878525972366333
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 11/64:
  Train Loss: 0.5574195384979248
  Validation Loss: 0.588001549243927
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 12/64:
  Train Loss: 0.5535574555397034
  Validation Loss: 0.5881589651107788
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 13/64:
  Train Loss: 0.5540149807929993
  Validation Loss: 0.5883041620254517
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 14/64:
  Train Loss: 0.5397723019123077
  Validation Loss: 0.5884525179862976
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 15/64:
  Train Loss: 0.5494553446769714
  Validation Loss: 0.5885851383209229
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 16/64:
  Train Loss: 0.5471155345439911
  Validation Loss: 0.5887386798858643
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 17/64:
  Train Loss: 0.5493546426296234
  Validation Loss: 0.5888951420783997
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 18/64:
  Train Loss: 0.5487845242023468
  Validation Loss: 0.5890489816665649
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 19/64:
  Train Loss: 0.5470701158046722
  Validation Loss: 0.5891894698143005
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 20/64:
  Train Loss: 0.5468720197677612
  Validation Loss: 0.5893082618713379
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 21/64:
  Train Loss: 0.5477297902107239
  Validation Loss: 0.589420735836029
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 22/64:
  Train Loss: 0.5534422695636749
  Validation Loss: 0.5895093083381653
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 23/64:
  Train Loss: 0.5557159185409546
  Validation Loss: 0.5895995497703552
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 24/64:
  Train Loss: 0.5482871830463409
  Validation Loss: 0.58968186378479
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 25/64:
  Train Loss: 0.5456450879573822
  Validation Loss: 0.5897814035415649
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 26/64:
  Train Loss: 0.5437053740024567
  Validation Loss: 0.5899304747581482
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 27/64:
  Train Loss: 0.5451395213603973
  Validation Loss: 0.5900763273239136
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 28/64:
  Train Loss: 0.5514265894889832
  Validation Loss: 0.5902121067047119
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 29/64:
  Train Loss: 0.5449647605419159
  Validation Loss: 0.5903509855270386
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 30/64:
  Train Loss: 0.5507293343544006
  Validation Loss: 0.5904641151428223
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 31/64:
  Train Loss: 0.5553158223628998
  Validation Loss: 0.5905665159225464
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 32/64:
  Train Loss: 0.548783153295517
  Validation Loss: 0.5906939506530762
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 33/64:
  Train Loss: 0.5489597916603088
  Validation Loss: 0.590815007686615
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 34/64:
  Train Loss: 0.5513642728328705
  Validation Loss: 0.5909647345542908
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 35/64:
  Train Loss: 0.5454667210578918
  Validation Loss: 0.5911092758178711
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 36/64:
  Train Loss: 0.5463238060474396
  Validation Loss: 0.5912083387374878
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 37/64:
  Train Loss: 0.553351640701294
  Validation Loss: 0.5913246870040894
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 38/64:
  Train Loss: 0.5514113306999207
  Validation Loss: 0.5914633870124817
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 39/64:
  Train Loss: 0.5434573292732239
  Validation Loss: 0.5916143655776978
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 40/64:
  Train Loss: 0.5496474802494049
  Validation Loss: 0.5917380452156067
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 41/64:
  Train Loss: 0.5557981133460999
  Validation Loss: 0.5918484926223755
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 42/64:
  Train Loss: 0.5482788383960724
  Validation Loss: 0.591968834400177
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 43/64:
  Train Loss: 0.5385745763778687
  Validation Loss: 0.5920664668083191
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 44/64:
  Train Loss: 0.5422481000423431
  Validation Loss: 0.5921498537063599
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 45/64:
  Train Loss: 0.5388828068971634
  Validation Loss: 0.5922195315361023
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 46/64:
  Train Loss: 0.5411510467529297
  Validation Loss: 0.592289388179779
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 47/64:
  Train Loss: 0.5448580980300903
  Validation Loss: 0.5923532843589783
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 48/64:
  Train Loss: 0.5457540452480316
  Validation Loss: 0.5924164056777954
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 49/64:
  Train Loss: 0.547227531671524
  Validation Loss: 0.5924765467643738
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 50/64:
  Train Loss: 0.5483236312866211
  Validation Loss: 0.5925690531730652
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 51/64:
  Train Loss: 0.5534504354000092
  Validation Loss: 0.5926392674446106
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 52/64:
  Train Loss: 0.5487269163131714
  Validation Loss: 0.5927168130874634
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 53/64:
  Train Loss: 0.5491387248039246
  Validation Loss: 0.5927948355674744
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:41:INFO:
[92mINFO [0m:      Received: evaluate message 78795f50-6799-4b4c-bc09-68edb6bdf45e
02/07/2025 22:48:41:INFO:Received: evaluate message 78795f50-6799-4b4c-bc09-68edb6bdf45e
[92mINFO [0m:      Sent reply
02/07/2025 22:48:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:44:INFO:
[92mINFO [0m:      Received: train message ff942fa2-ae9f-4ecb-bb63-627439fae2da
02/07/2025 22:48:44:INFO:Received: train message ff942fa2-ae9f-4ecb-bb63-627439fae2da
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 54/64:
  Train Loss: 0.5445670187473297
  Validation Loss: 0.5928712487220764
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 55/64:
  Train Loss: 0.551068127155304
  Validation Loss: 0.5929574370384216
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 56/64:
  Train Loss: 0.5526915192604065
  Validation Loss: 0.5930483341217041
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 57/64:
  Train Loss: 0.5471160709857941
  Validation Loss: 0.5931507349014282
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 58/64:
  Train Loss: 0.5433421432971954
  Validation Loss: 0.5932534337043762
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 59/64:
  Train Loss: 0.5492564737796783
  Validation Loss: 0.5933894515037537
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 60/64:
  Train Loss: 0.5407608449459076
  Validation Loss: 0.593529224395752
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 61/64:
  Train Loss: 0.5397665202617645
  Validation Loss: 0.5936662554740906
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 62/64:
  Train Loss: 0.5402979552745819
  Validation Loss: 0.5938184857368469
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 63/64:
  Train Loss: 0.5473357141017914
  Validation Loss: 0.5939513444900513
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 64/64:
  Train Loss: 0.5483324229717255
  Validation Loss: 0.5940859913825989
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
{'train_loss': 0.5483324229717255, 'val_roc_auc': 0.8055555555555556, 'val_accuracy': 0.8461538553237915, 'val_loss': 0.5940859913825989}
 ROC_AUC: 0.8056|| Accuracy 0.8462 || Train Loss: 0.5483
 Val Loss: 0.5941 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.576515523592631
Test ROC-AUC: 0.7000000000000001
Test Accuracy: 0.5111111111111111
test_loss: 0.576515523592631
test_roc_auc: 0.7000000000000001
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.4971974312502425
Epoch 1/64:
  Train Loss: 0.5587240755558014
  Validation Loss: 0.5654864311218262
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.554060310125351
  Validation Loss: 0.5655236840248108
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5556926131248474
  Validation Loss: 0.5655507445335388
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5569027364253998
  Validation Loss: 0.5655811429023743
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5554120540618896
  Validation Loss: 0.5656138062477112
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5475728958845139
  Validation Loss: 0.5656445026397705
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5625078678131104
  Validation Loss: 0.5656694769859314
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5574665665626526
  Validation Loss: 0.5656953454017639
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5596382915973663
  Validation Loss: 0.5657249689102173
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5546310544013977
  Validation Loss: 0.5657423734664917
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5514884293079376
  Validation Loss: 0.5657602548599243
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5517185926437378
  Validation Loss: 0.5657841563224792
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5614289343357086
  Validation Loss: 0.5658093094825745
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.552819699048996
  Validation Loss: 0.5658310055732727
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5585126280784607
  Validation Loss: 0.5658429265022278
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.551878035068512
  Validation Loss: 0.5658451318740845
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.548966109752655
  Validation Loss: 0.5658380389213562
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5476900041103363
  Validation Loss: 0.5658289790153503
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5501555502414703
  Validation Loss: 0.5658143162727356
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.55729740858078
  Validation Loss: 0.5657920241355896
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5521192252635956
  Validation Loss: 0.5657818913459778
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5548691749572754
  Validation Loss: 0.5657908320426941
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5547818839550018
  Validation Loss: 0.56580650806427
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5562213361263275
  Validation Loss: 0.5658195614814758
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5579089820384979
  Validation Loss: 0.5658233761787415
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5498203933238983
  Validation Loss: 0.5658198595046997
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5492222607135773
  Validation Loss: 0.5658069849014282
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5500800311565399
  Validation Loss: 0.565786600112915
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5601594150066376
  Validation Loss: 0.5657745003700256
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5552743971347809
  Validation Loss: 0.5657684206962585
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 31/64:
  Train Loss: 0.5520135164260864
  Validation Loss: 0.5657677054405212
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 32/64:
  Train Loss: 0.5568698644638062
  Validation Loss: 0.5657555460929871
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 33/64:
  Train Loss: 0.5547828376293182
  Validation Loss: 0.5657392740249634
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 34/64:
  Train Loss: 0.5528176128864288
  Validation Loss: 0.5657268762588501
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 35/64:
  Train Loss: 0.557853490114212
  Validation Loss: 0.5657051801681519
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 36/64:
  Train Loss: 0.5582742094993591
  Validation Loss: 0.56568843126297
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 37/64:
  Train Loss: 0.548753559589386
  Validation Loss: 0.5656648278236389
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 38/64:
  Train Loss: 0.5488657653331757
  Validation Loss: 0.5656389594078064
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 39/64:
  Train Loss: 0.5481555759906769
  Validation Loss: 0.5656358003616333
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 40/64:
  Train Loss: 0.5485057234764099
  Validation Loss: 0.5656200051307678
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:11:INFO:
[92mINFO [0m:      Received: evaluate message 5e6448c2-1d2a-4dcc-bdd8-4ad797a07798
02/07/2025 22:49:11:INFO:Received: evaluate message 5e6448c2-1d2a-4dcc-bdd8-4ad797a07798
[92mINFO [0m:      Sent reply
02/07/2025 22:49:12:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:12:INFO:
[92mINFO [0m:      Received: train message 845464be-569e-4e4b-a48f-b12d347ab66c
02/07/2025 22:49:12:INFO:Received: train message 845464be-569e-4e4b-a48f-b12d347ab66c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 41/64:
  Train Loss: 0.5482623875141144
  Validation Loss: 0.5656095147132874
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 42/64:
  Train Loss: 0.5562088787555695
  Validation Loss: 0.5656007528305054
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 43/64:
  Train Loss: 0.5528544485569
  Validation Loss: 0.5655820965766907
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 44/64:
  Train Loss: 0.5527858436107635
  Validation Loss: 0.5655773878097534
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 45/64:
  Train Loss: 0.5534640848636627
  Validation Loss: 0.5655750632286072
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 46/64:
  Train Loss: 0.5534718930721283
  Validation Loss: 0.5655679702758789
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 47/64:
  Train Loss: 0.5522937476634979
  Validation Loss: 0.5655680298805237
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 48/64:
  Train Loss: 0.5421568304300308
  Validation Loss: 0.5655767321586609
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 49/64:
  Train Loss: 0.5475263297557831
  Validation Loss: 0.5655921101570129
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 50/64:
  Train Loss: 0.5512047708034515
  Validation Loss: 0.5655995011329651
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 51/64:
  Train Loss: 0.5460103154182434
  Validation Loss: 0.565609872341156
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 52/64:
  Train Loss: 0.5487377941608429
  Validation Loss: 0.5656222701072693
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 53/64:
  Train Loss: 0.5470836460590363
  Validation Loss: 0.5656399726867676
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 54/64:
  Train Loss: 0.5518250465393066
  Validation Loss: 0.5656636357307434
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 55/64:
  Train Loss: 0.5494769811630249
  Validation Loss: 0.5656858086585999
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 56/64:
  Train Loss: 0.549648106098175
  Validation Loss: 0.5657076835632324
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 57/64:
  Train Loss: 0.5556994676589966
  Validation Loss: 0.5657274723052979
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 58/64:
  Train Loss: 0.5495045483112335
  Validation Loss: 0.5657399296760559
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 59/64:
  Train Loss: 0.5491278171539307
  Validation Loss: 0.5657564401626587
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 60/64:
  Train Loss: 0.5488751232624054
  Validation Loss: 0.5657693147659302
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 61/64:
  Train Loss: 0.553888589143753
  Validation Loss: 0.565793514251709
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 62/64:
  Train Loss: 0.547001838684082
  Validation Loss: 0.5658234357833862
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 63/64:
  Train Loss: 0.5514434576034546
  Validation Loss: 0.5658500790596008
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 64/64:
  Train Loss: 0.5556685924530029
  Validation Loss: 0.5658726692199707
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
{'train_loss': 0.5556685924530029, 'val_roc_auc': 0.5, 'val_accuracy': 0.46153849363327026, 'val_loss': 0.5658726692199707}
 ROC_AUC: 0.5000|| Accuracy 0.4615 || Train Loss: 0.5557
 Val Loss: 0.5659 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5762261668841044
Test ROC-AUC: 0.7114285714285714
Test Accuracy: 0.5111111111111111
test_loss: 0.5762261668841044
test_roc_auc: 0.7114285714285714
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.32500480963790324
Epoch 1/64:
  Train Loss: 0.5505376756191254
  Validation Loss: 0.6220232844352722
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 2/64:
  Train Loss: 0.5401893854141235
  Validation Loss: 0.6221766471862793
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 3/64:
  Train Loss: 0.5424814224243164
  Validation Loss: 0.6223790049552917
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 4/64:
  Train Loss: 0.5425308346748352
  Validation Loss: 0.6225603818893433
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 5/64:
  Train Loss: 0.54289710521698
  Validation Loss: 0.6227082014083862
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 6/64:
  Train Loss: 0.5457771420478821
  Validation Loss: 0.6228528618812561
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 7/64:
  Train Loss: 0.5376999974250793
  Validation Loss: 0.6229754686355591
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 8/64:
  Train Loss: 0.5398096740245819
  Validation Loss: 0.6231051683425903
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 9/64:
  Train Loss: 0.5472596883773804
  Validation Loss: 0.6232024431228638
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 10/64:
  Train Loss: 0.5391058027744293
  Validation Loss: 0.6233051419258118
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 11/64:
  Train Loss: 0.5419157147407532
  Validation Loss: 0.6234060525894165
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 12/64:
  Train Loss: 0.5437698066234589
  Validation Loss: 0.6235162615776062
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 13/64:
  Train Loss: 0.5444116294384003
  Validation Loss: 0.6236125826835632
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 14/64:
  Train Loss: 0.5425960421562195
  Validation Loss: 0.623727023601532
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 15/64:
  Train Loss: 0.5340861678123474
  Validation Loss: 0.6238623857498169
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 16/64:
  Train Loss: 0.5455555617809296
  Validation Loss: 0.6239883303642273
  Val ROC-AUC: 0.825
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.543873518705368
  Validation Loss: 0.6241194009780884
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5425072908401489
  Validation Loss: 0.6242592334747314
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5397254228591919
  Validation Loss: 0.6244047284126282
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5422039330005646
  Validation Loss: 0.6245440244674683
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5530921816825867
  Validation Loss: 0.6247000098228455
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5357041358947754
  Validation Loss: 0.6248383522033691
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5443819463253021
  Validation Loss: 0.6249735951423645
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5426632463932037
  Validation Loss: 0.6251035332679749
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5424882173538208
  Validation Loss: 0.6252517700195312
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.54169100522995
  Validation Loss: 0.6254017353057861
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5423965752124786
  Validation Loss: 0.6255548596382141
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.542168915271759
  Validation Loss: 0.6256851553916931
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5422618389129639
  Validation Loss: 0.6257856488227844
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5388364195823669
  Validation Loss: 0.6258695721626282
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 31/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:38:INFO:
[92mINFO [0m:      Received: evaluate message 338c91c0-b39e-49c8-a226-618f10f379d1
02/07/2025 22:49:38:INFO:Received: evaluate message 338c91c0-b39e-49c8-a226-618f10f379d1
[92mINFO [0m:      Sent reply
02/07/2025 22:49:38:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:38:INFO:
[92mINFO [0m:      Received: train message b127d703-3714-42c6-a18e-0696c8879a67
02/07/2025 22:49:38:INFO:Received: train message b127d703-3714-42c6-a18e-0696c8879a67
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.5389326810836792
  Validation Loss: 0.6259586811065674
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5388307869434357
  Validation Loss: 0.6260651350021362
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5391739010810852
  Validation Loss: 0.6261785626411438
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5381595492362976
  Validation Loss: 0.6262915134429932
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5370666086673737
  Validation Loss: 0.6263942718505859
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5467841029167175
  Validation Loss: 0.6265024542808533
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5389216840267181
  Validation Loss: 0.6266157627105713
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5431316792964935
  Validation Loss: 0.6267266273498535
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5418472290039062
  Validation Loss: 0.6268458962440491
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5345679819583893
  Validation Loss: 0.626977264881134
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5331782251596451
  Validation Loss: 0.6271082162857056
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5348446369171143
  Validation Loss: 0.6272464394569397
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5405236482620239
  Validation Loss: 0.6273818612098694
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5362149178981781
  Validation Loss: 0.6275070309638977
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5348811745643616
  Validation Loss: 0.6276070475578308
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5336253345012665
  Validation Loss: 0.6277150511741638
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5270606577396393
  Validation Loss: 0.6278285980224609
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5379875600337982
  Validation Loss: 0.6279438138008118
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.532423347234726
  Validation Loss: 0.6280655860900879
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5374977290630341
  Validation Loss: 0.6282033920288086
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5376438200473785
  Validation Loss: 0.6283326745033264
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.537422388792038
  Validation Loss: 0.6284621357917786
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5335438251495361
  Validation Loss: 0.6285898685455322
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5328239798545837
  Validation Loss: 0.6287100315093994
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5290168225765228
  Validation Loss: 0.6288461685180664
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5327682495117188
  Validation Loss: 0.628987729549408
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.542353630065918
  Validation Loss: 0.6291219592094421
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5294836610555649
  Validation Loss: 0.6292555332183838
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5351632833480835
  Validation Loss: 0.6293849349021912
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5409214794635773
  Validation Loss: 0.6294782757759094
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5318330824375153
  Validation Loss: 0.629551887512207
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.538781613111496
  Validation Loss: 0.6296595335006714
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5379611849784851
  Validation Loss: 0.629788339138031
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5357825756072998
  Validation Loss: 0.6299015879631042
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5357825756072998, 'val_roc_auc': 0.8, 'val_accuracy': 0.692307710647583, 'val_loss': 0.6299015879631042}
 ROC_AUC: 0.8000|| Accuracy 0.6923 || Train Loss: 0.5358
 Val Loss: 0.6299 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5760161664750841
Test ROC-AUC: 0.72
Test Accuracy: 0.5111111111111111
test_loss: 0.5760161664750841
test_roc_auc: 0.72
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.47342564136488363
Epoch 1/64:
  Train Loss: 0.5699920058250427
  Validation Loss: 0.5142089128494263
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5686373114585876
  Validation Loss: 0.5141416192054749
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5677973031997681
  Validation Loss: 0.5140886306762695
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5727007985115051
  Validation Loss: 0.5140566825866699
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5652574002742767
  Validation Loss: 0.5140412449836731
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5712330639362335
  Validation Loss: 0.5140243768692017
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5718804895877838
  Validation Loss: 0.51398104429245
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.573266327381134
  Validation Loss: 0.5139404535293579
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5645449757575989
  Validation Loss: 0.5139195322990417
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5700737833976746
  Validation Loss: 0.513881504535675
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5673609673976898
  Validation Loss: 0.5138465166091919
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5694125890731812
  Validation Loss: 0.5138177871704102
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5663013160228729
  Validation Loss: 0.5137966871261597
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.573142021894455
  Validation Loss: 0.5137583017349243
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5680029094219208
  Validation Loss: 0.5137045979499817
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5702859163284302
  Validation Loss: 0.5136445164680481
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5698480904102325
  Validation Loss: 0.513608455657959
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.563453733921051
  Validation Loss: 0.5135793685913086
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5620925426483154
  Validation Loss: 0.5135335922241211
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.570836991071701
  Validation Loss: 0.5135052800178528/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:05:INFO:
[92mINFO [0m:      Received: evaluate message c81fd1c8-a30d-400c-94bf-cc2d5391961f
02/07/2025 22:50:05:INFO:Received: evaluate message c81fd1c8-a30d-400c-94bf-cc2d5391961f
[92mINFO [0m:      Sent reply
02/07/2025 22:50:07:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:08:INFO:
[92mINFO [0m:      Received: train message 69839754-c1e9-473d-9c1e-3f33fb9c59ac
02/07/2025 22:50:08:INFO:Received: train message 69839754-c1e9-473d-9c1e-3f33fb9c59ac

  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5682602226734161
  Validation Loss: 0.5134894847869873
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5718483924865723
  Validation Loss: 0.5134792923927307
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5710340440273285
  Validation Loss: 0.5134537816047668
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5723553001880646
  Validation Loss: 0.5134232640266418
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5636169612407684
  Validation Loss: 0.5134022235870361
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5654316544532776
  Validation Loss: 0.5133732557296753
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5681199133396149
  Validation Loss: 0.5133332014083862
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5562738925218582
  Validation Loss: 0.5132828950881958
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5734719038009644
  Validation Loss: 0.513218879699707
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5722997188568115
  Validation Loss: 0.5131592750549316
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5655479431152344
  Validation Loss: 0.5131046772003174
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5757512748241425
  Validation Loss: 0.5130489468574524
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5681541562080383
  Validation Loss: 0.513005256652832
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5680837333202362
  Validation Loss: 0.5129528045654297
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.568355530500412
  Validation Loss: 0.5129110813140869
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5621976554393768
  Validation Loss: 0.5128846168518066
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5677129626274109
  Validation Loss: 0.5128566026687622
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5640282928943634
  Validation Loss: 0.5128366351127625
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5663489103317261
  Validation Loss: 0.5128390192985535
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5631740391254425
  Validation Loss: 0.5128359794616699
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5621559321880341
  Validation Loss: 0.5128458142280579
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5637777745723724
  Validation Loss: 0.5128467679023743
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5637291967868805
  Validation Loss: 0.5128425359725952
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5620976388454437
  Validation Loss: 0.5128588676452637
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5695741176605225
  Validation Loss: 0.5128819942474365
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5635132789611816
  Validation Loss: 0.5129054188728333
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5674204230308533
  Validation Loss: 0.5129332542419434
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5672866106033325
  Validation Loss: 0.5129410028457642
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5688562989234924
  Validation Loss: 0.5129500031471252
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5678265392780304
  Validation Loss: 0.5129645466804504
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5741610527038574
  Validation Loss: 0.5129783749580383
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5701605379581451
  Validation Loss: 0.5129861831665039
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5615593791007996
  Validation Loss: 0.5129846930503845
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5745331346988678
  Validation Loss: 0.5129709243774414
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.55998095870018
  Validation Loss: 0.5129646062850952
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5629083514213562
  Validation Loss: 0.5129445195198059
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5585453510284424
  Validation Loss: 0.5129349827766418
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5678780972957611
  Validation Loss: 0.5129181146621704
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5625128448009491
  Validation Loss: 0.5128952860832214
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5665886998176575
  Validation Loss: 0.5128806829452515
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5652356147766113
  Validation Loss: 0.5128880739212036
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5638732612133026
  Validation Loss: 0.5128795504570007
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5615577697753906
  Validation Loss: 0.5128703117370605
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5629698932170868
  Validation Loss: 0.512852668762207
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5629698932170868, 'val_roc_auc': 0.9545454545454546, 'val_accuracy': 0.692307710647583, 'val_loss': 0.512852668762207}
 ROC_AUC: 0.9545|| Accuracy 0.6923 || Train Loss: 0.5630
 Val Loss: 0.5129 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5758141411675347
Test ROC-AUC: 0.7257142857142858
Test Accuracy: 0.5111111111111111
test_loss: 0.5758141411675347
test_roc_auc: 0.7257142857142858
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.35872444709336077
Epoch 1/64:
  Train Loss: 0.5844613909721375
  Validation Loss: 0.45872652530670166
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5849028527736664
  Validation Loss: 0.458566814661026
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5794360041618347
  Validation Loss: 0.4584968388080597
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.579743355512619
  Validation Loss: 0.4584121108055115
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5821567475795746
  Validation Loss: 0.45834043622016907
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5830510258674622
  Validation Loss: 0.458252876996994
  Val ROC-AUC: nan
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 22:50:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:35:INFO:
[92mINFO [0m:      Received: evaluate message 82a8be97-b34c-4384-990b-dee0447caff0
02/07/2025 22:50:35:INFO:Received: evaluate message 82a8be97-b34c-4384-990b-dee0447caff0
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5808627605438232
  Validation Loss: 0.4581698775291443
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5842458009719849
  Validation Loss: 0.4581054747104645
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.582495391368866
  Validation Loss: 0.45807722210884094
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5836556851863861
  Validation Loss: 0.45802903175354004
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5798039734363556
  Validation Loss: 0.45797598361968994
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5745232701301575
  Validation Loss: 0.45790234208106995
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5757263600826263
  Validation Loss: 0.45783498883247375
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.587493509054184
  Validation Loss: 0.4577621519565582
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5777896642684937
  Validation Loss: 0.45768943428993225
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5754883289337158
  Validation Loss: 0.457645446062088
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5829135179519653
  Validation Loss: 0.4576075077056885
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5817402303218842
  Validation Loss: 0.45757344365119934
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5870770812034607
  Validation Loss: 0.457539439201355
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5918984413146973
  Validation Loss: 0.4574878513813019
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5804545879364014
  Validation Loss: 0.4574131667613983
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5728780925273895
  Validation Loss: 0.4573363661766052
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5751304626464844
  Validation Loss: 0.4572683572769165
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5823619365692139
  Validation Loss: 0.4571881890296936
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5817364752292633
  Validation Loss: 0.45709067583084106
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5839299261569977
  Validation Loss: 0.4570126235485077
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5753814280033112
  Validation Loss: 0.45695388317108154
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5794254541397095
  Validation Loss: 0.45692357420921326
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5846115946769714
  Validation Loss: 0.45687922835350037
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5795881152153015
  Validation Loss: 0.45681706070899963
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5798613131046295
  Validation Loss: 0.45673003792762756
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5821560621261597
  Validation Loss: 0.4566352367401123
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.577972799539566
  Validation Loss: 0.4565478265285492
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5831630527973175
  Validation Loss: 0.45644909143447876
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.580022543668747
  Validation Loss: 0.4563508629798889
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5771335959434509
  Validation Loss: 0.4562736749649048
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5765582919120789
  Validation Loss: 0.4562077820301056
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5859394967556
  Validation Loss: 0.4561668038368225
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5832409560680389
  Validation Loss: 0.4561070203781128
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.589782327413559
  Validation Loss: 0.456027090549469
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5851635932922363
  Validation Loss: 0.45595815777778625
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5689795911312103
  Validation Loss: 0.45588377118110657
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.588761031627655
  Validation Loss: 0.45579230785369873
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5784712731838226
  Validation Loss: 0.45570018887519836
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5853298604488373
  Validation Loss: 0.4555929899215698
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5796581506729126
  Validation Loss: 0.4554824233055115
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5780667066574097
  Validation Loss: 0.4553833305835724
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5814104974269867
  Validation Loss: 0.4552817940711975
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5841271579265594
  Validation Loss: 0.45518603920936584
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5768407583236694
  Validation Loss: 0.4551142454147339
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5861028432846069
  Validation Loss: 0.4550454616546631
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5763767659664154
  Validation Loss: 0.45499736070632935
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5834702849388123
  Validation Loss: 0.4549535810947418
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5771566927433014
  Validation Loss: 0.45491674542427063
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5783174335956573
  Validation Loss: 0.4548548758029938
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5803637206554413
  Validation Loss: 0.45478588342666626
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5833543539047241
  Validation Loss: 0.45470869541168213
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5794749557971954
  Validation Loss: 0.45462214946746826
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5716825425624847
  Validation Loss: 0.45452311635017395
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5778479874134064
  Validation Loss: 0.45441797375679016
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5751287639141083
  Validation Loss: 0.4542892575263977
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5757474899291992
  Validation Loss: 0.4541673958301544
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5737688541412354
  Validation Loss: 0.45405495166778564
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5792405307292938
  Validation Loss: 0.4539566934108734
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5792405307292938, 'val_roc_auc': nan, 'val_accuracy': 0.692307710647583, 'val_loss': 0.4539566934108734}
 ROC_AUC: nan|| Accuracy 0.6923 || Train Loss: 0.5792
 Val Loss: 0.4540 
[92mINFO [0m:      Sent reply
02/07/2025 22:50:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:35:INFO:
[92mINFO [0m:      Received: train message 2d5c4149-ed54-4a2b-8052-861db55abb0b
02/07/2025 22:50:35:INFO:Received: train message 2d5c4149-ed54-4a2b-8052-861db55abb0b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5755259169472589
Test ROC-AUC: 0.7285714285714286
Test Accuracy: 0.5111111111111111
test_loss: 0.5755259169472589
test_roc_auc: 0.7285714285714286
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.3364685704000294
Epoch 1/64:
  Train Loss: 0.5566935837268829
  Validation Loss: 0.5903674960136414
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5583390295505524
  Validation Loss: 0.5903960466384888
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5567456781864166
  Validation Loss: 0.5904501080513
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5542532503604889
  Validation Loss: 0.5905197858810425
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5486763417720795
  Validation Loss: 0.5905985236167908
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5541560053825378
  Validation Loss: 0.5906815528869629
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.556922197341919
  Validation Loss: 0.5907588601112366
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5435476452112198
  Validation Loss: 0.5908339619636536
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5516432821750641
  Validation Loss: 0.5908756852149963
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5534315407276154
  Validation Loss: 0.5909276008605957
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5479304492473602
  Validation Loss: 0.5909760594367981
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5527000725269318
  Validation Loss: 0.5910329818725586
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5550840497016907
  Validation Loss: 0.5910480618476868
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5481131970882416
  Validation Loss: 0.5910746455192566
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5548029541969299
  Validation Loss: 0.5910971760749817
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5451596677303314
  Validation Loss: 0.5911270976066589
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5515216588973999
  Validation Loss: 0.5911566615104675
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5452340841293335
  Validation Loss: 0.5911941528320312
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5452889800071716
  Validation Loss: 0.5912368893623352
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5517354607582092
  Validation Loss: 0.5912836194038391
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.550510972738266
  Validation Loss: 0.5913370847702026
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5440291464328766
  Validation Loss: 0.5913826823234558
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5483049750328064
  Validation Loss: 0.5914178490638733
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5481475591659546
  Validation Loss: 0.5914449095726013
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5535295605659485
  Validation Loss: 0.5914620161056519
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5482900440692902
  Validation Loss: 0.5914972424507141
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5456036329269409
  Validation Loss: 0.591559112071991
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5440638959407806
  Validation Loss: 0.59162837266922
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5473908185958862
  Validation Loss: 0.5917060971260071
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5386691987514496
  Validation Loss: 0.5917961001396179
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.552986741065979
  Validation Loss: 0.5918757319450378
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5500233769416809
  Validation Loss: 0.5919373035430908
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5525351762771606
  Validation Loss: 0.5919926762580872
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5546770393848419
  Validation Loss: 0.5920313596725464
  Val ROC-AUC: 0.7777777777777777
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.55173259973526
  Validation Loss: 0.592061460018158
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.548828125
  Validation Loss: 0.5920844078063965
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5504403412342072
  Validation Loss: 0.59211266040802
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5460703372955322
  Validation Loss: 0.5921412706375122
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.546293705701828
  Validation Loss: 0.5921682715415955
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5457309186458588
  Validation Loss: 0.5921960473060608
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5483013391494751
  Validation Loss: 0.5922455191612244
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.545507401227951
  Validation Loss: 0.5923003554344177
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5499866902828217
  Validation Loss: 0.5923604965209961
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5406933128833771
  Validation Loss: 0.5924239158630371
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.543493241071701
  Validation Loss: 0.5924814939498901
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5468790531158447
  Validation Loss: 0.5925387740135193
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5539228916168213
  Validation Loss: 0.5925880074501038
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5517930686473846
  Validation Loss: 0.5926464200019836
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5491248965263367
  Validation Loss: 0.5926951169967651
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5384362936019897
  Validation Loss: 0.592747151851654
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5539670288562775
  Validation Loss: 0.5927801132202148
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.543949544429779
  Validation Loss: 0.592827320098877
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5423018336296082
  Validation Loss: 0.5928813815116882
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:04:INFO:
[92mINFO [0m:      Received: evaluate message b1536dcc-19e2-4aa9-81fc-5a1d6d20413b
02/07/2025 22:51:04:INFO:Received: evaluate message b1536dcc-19e2-4aa9-81fc-5a1d6d20413b
[92mINFO [0m:      Sent reply
02/07/2025 22:51:05:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:06:INFO:
[92mINFO [0m:      Received: train message 6094beaf-efe3-4e33-9bd1-de581f31514b
02/07/2025 22:51:06:INFO:Received: train message 6094beaf-efe3-4e33-9bd1-de581f31514b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 54/64:
  Train Loss: 0.54119011759758
  Validation Loss: 0.592919647693634
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5483787059783936
  Validation Loss: 0.5929608941078186
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5454411506652832
  Validation Loss: 0.5929922461509705
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5499260723590851
  Validation Loss: 0.5930235385894775
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5494135320186615
  Validation Loss: 0.5930644869804382
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5516708195209503
  Validation Loss: 0.5931353569030762
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5462676584720612
  Validation Loss: 0.593205451965332
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5440367162227631
  Validation Loss: 0.5932652950286865
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5467909276485443
  Validation Loss: 0.59331214427948
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5428048372268677
  Validation Loss: 0.5933728814125061
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5470190942287445
  Validation Loss: 0.5934237837791443
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5470190942287445, 'val_roc_auc': 0.75, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5934237837791443}
 ROC_AUC: 0.7500|| Accuracy 0.6923 || Train Loss: 0.5470
 Val Loss: 0.5934 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5752932555145688
Test ROC-AUC: 0.7285714285714285
Test Accuracy: 0.5111111111111111
test_loss: 0.5752932555145688
test_roc_auc: 0.7285714285714285
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.35297404254864284
Epoch 1/64:
  Train Loss: 0.5693577826023102
  Validation Loss: 0.53926020860672
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 2/64:
  Train Loss: 0.5673019886016846
  Validation Loss: 0.5392909049987793
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 3/64:
  Train Loss: 0.5657521784305573
  Validation Loss: 0.5393034815788269
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 4/64:
  Train Loss: 0.5609686970710754
  Validation Loss: 0.5393092036247253
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 5/64:
  Train Loss: 0.5739250779151917
  Validation Loss: 0.5393155813217163
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 6/64:
  Train Loss: 0.5621580183506012
  Validation Loss: 0.5393059849739075
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 7/64:
  Train Loss: 0.5680303573608398
  Validation Loss: 0.5392926931381226
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 8/64:
  Train Loss: 0.5571515560150146
  Validation Loss: 0.5392740964889526
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8461538553237915
Epoch 9/64:
  Train Loss: 0.564544290304184
  Validation Loss: 0.5392481088638306
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8461538553237915
Epoch 10/64:
  Train Loss: 0.5637820363044739
  Validation Loss: 0.5392199158668518
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 11/64:
  Train Loss: 0.5663736462593079
  Validation Loss: 0.5392093062400818
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 12/64:
  Train Loss: 0.5588718056678772
  Validation Loss: 0.5392299294471741
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 13/64:
  Train Loss: 0.5604333281517029
  Validation Loss: 0.5392616391181946
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 14/64:
  Train Loss: 0.5610945522785187
  Validation Loss: 0.5393272042274475
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 15/64:
  Train Loss: 0.5691594183444977
  Validation Loss: 0.5393844842910767
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 16/64:
  Train Loss: 0.5619271993637085
  Validation Loss: 0.5394539833068848
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
Epoch 17/64:
  Train Loss: 0.5558261275291443
  Validation Loss: 0.5395102500915527
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 18/64:
  Train Loss: 0.5671771168708801
  Validation Loss: 0.5395635366439819
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 19/64:
  Train Loss: 0.5696541368961334
  Validation Loss: 0.5396088361740112
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5606019794940948
  Validation Loss: 0.5396734476089478
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5606462061405182
  Validation Loss: 0.5397480130195618
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5606116652488708
  Validation Loss: 0.5398207902908325
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5649563372135162
  Validation Loss: 0.539880096912384
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5599075853824615
  Validation Loss: 0.5398983955383301
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5630269944667816
  Validation Loss: 0.5399028062820435
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5549061596393585
  Validation Loss: 0.5398961901664734
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5650041997432709
  Validation Loss: 0.5398746728897095
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5592620074748993
  Validation Loss: 0.5398501753807068
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5626478791236877
  Validation Loss: 0.5398334860801697
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.556530237197876
  Validation Loss: 0.5398082137107849
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5664917528629303
  Validation Loss: 0.5397712588310242
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5606879591941833
  Validation Loss: 0.5397554636001587
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5562364459037781
  Validation Loss: 0.5397471785545349
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5624684393405914
  Validation Loss: 0.539757251739502
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5595943331718445
  Validation Loss: 0.5397812724113464
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5666609704494476
  Validation Loss: 0.5398284792900085
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5593584775924683
  Validation Loss: 0.5398654341697693
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5630775094032288
  Validation Loss: 0.5398908257484436
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5726763606071472
  Validation Loss: 0.5399020314216614
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5630888938903809
  Validation Loss: 0.5399276614189148
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5689011514186859
  Validation Loss: 0.5399454832077026
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5664268434047699
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:51:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:37:INFO:
[92mINFO [0m:      Received: evaluate message fcb289fa-109c-4ddd-9981-6319d4765111
02/07/2025 22:51:37:INFO:Received: evaluate message fcb289fa-109c-4ddd-9981-6319d4765111
[92mINFO [0m:      Sent reply
02/07/2025 22:51:37:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:37:INFO:
[92mINFO [0m:      Received: train message 5dc5821d-bb18-435e-bd49-dff212e7c03d
02/07/2025 22:51:37:INFO:Received: train message 5dc5821d-bb18-435e-bd49-dff212e7c03d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5399395227432251
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 43/64:
  Train Loss: 0.5618402659893036
  Validation Loss: 0.5399549603462219
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 44/64:
  Train Loss: 0.5542735755443573
  Validation Loss: 0.5399832725524902
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 45/64:
  Train Loss: 0.5654450953006744
  Validation Loss: 0.5400180816650391
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 46/64:
  Train Loss: 0.5605139434337616
  Validation Loss: 0.5400567054748535
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 47/64:
  Train Loss: 0.5621099472045898
  Validation Loss: 0.5400894284248352
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 48/64:
  Train Loss: 0.5560563802719116
  Validation Loss: 0.5401168465614319
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 49/64:
  Train Loss: 0.5672765374183655
  Validation Loss: 0.5401867628097534
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 50/64:
  Train Loss: 0.5620573461055756
  Validation Loss: 0.5402531623840332
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 51/64:
  Train Loss: 0.560880720615387
  Validation Loss: 0.5402758717536926
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 52/64:
  Train Loss: 0.5582826435565948
  Validation Loss: 0.5403165817260742
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 53/64:
  Train Loss: 0.5689587891101837
  Validation Loss: 0.5403541922569275
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 54/64:
  Train Loss: 0.5583689510822296
  Validation Loss: 0.5403981804847717
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 55/64:
  Train Loss: 0.566232293844223
  Validation Loss: 0.5404214859008789
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 56/64:
  Train Loss: 0.5636386871337891
  Validation Loss: 0.5404456853866577
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7692307829856873
Epoch 57/64:
  Train Loss: 0.5609977543354034
  Validation Loss: 0.5404725074768066
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7692307829856873
Epoch 58/64:
  Train Loss: 0.5559123158454895
  Validation Loss: 0.540501058101654
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7692307829856873
Epoch 59/64:
  Train Loss: 0.5624991059303284
  Validation Loss: 0.5405327081680298
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7692307829856873
Epoch 60/64:
  Train Loss: 0.554391622543335
  Validation Loss: 0.54053795337677
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7692307829856873
Epoch 61/64:
  Train Loss: 0.5589342713356018
  Validation Loss: 0.5405594110488892
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7692307829856873
Epoch 62/64:
  Train Loss: 0.5611095428466797
  Validation Loss: 0.5405798554420471
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7692307829856873
Epoch 63/64:
  Train Loss: 0.5577583312988281
  Validation Loss: 0.5406163930892944
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7692307829856873
Epoch 64/64:
  Train Loss: 0.5531553328037262
  Validation Loss: 0.5406683087348938
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.7692307829856873
{'train_loss': 0.5531553328037262, 'val_roc_auc': 0.8333333333333334, 'val_accuracy': 0.7692307829856873, 'val_loss': 0.5406683087348938}
 ROC_AUC: 0.8333|| Accuracy 0.7692 || Train Loss: 0.5532
 Val Loss: 0.5407 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5751874327659607
Test ROC-AUC: 0.7314285714285714
Test Accuracy: 0.5111111111111111
test_loss: 0.5751874327659607
test_roc_auc: 0.7314285714285714
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.25968297307069105
Epoch 1/64:
  Train Loss: 0.5722712874412537
  Validation Loss: 0.5279432535171509
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5720131099224091
  Validation Loss: 0.5281277894973755
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5664656460285187
  Validation Loss: 0.5282517075538635
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5694594383239746
  Validation Loss: 0.5284530520439148
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.566148966550827
  Validation Loss: 0.528598964214325
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5684355795383453
  Validation Loss: 0.5287567973136902
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5663533806800842
  Validation Loss: 0.5288844704627991
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5606228411197662
  Validation Loss: 0.5290495157241821
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5708353221416473
  Validation Loss: 0.5292027592658997
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.559996485710144
  Validation Loss: 0.5293814539909363
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5667719841003418
  Validation Loss: 0.5295512080192566
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5648344159126282
  Validation Loss: 0.5297378301620483
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5673554241657257
  Validation Loss: 0.5298943519592285
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5743491053581238
  Validation Loss: 0.5300766825675964
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5643711090087891
  Validation Loss: 0.5302878022193909
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5621320307254791
  Validation Loss: 0.5304949879646301
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5698618292808533
  Validation Loss: 0.5306689143180847
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5726011097431183
  Validation Loss: 0.53080153465271
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5601173639297485
  Validation Loss: 0.5309478044509888
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5587565302848816
  Validation Loss: 0.5310825705528259
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.562647819519043
  Validation Loss: 0.5312216877937317
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5608397424221039
  Validation Loss: 0.5313697457313538
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5684210658073425
  Validation Loss: 0.5315116047859192
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5632068514823914
  Validation Loss: 0.5316847562789917
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5705224573612213
  Validation Loss: 0.531880259513855
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5647416114807129
  Validation Loss: 0.5320817232131958
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5726716220378876
  Validation Loss: 0.53226637840271
  Val ROC-AUC: 0.8181818181818181
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:06:INFO:
[92mINFO [0m:      Received: evaluate message 9f2f62a8-69f9-4666-b067-0241365c2b23
02/07/2025 22:52:06:INFO:Received: evaluate message 9f2f62a8-69f9-4666-b067-0241365c2b23
[92mINFO [0m:      Sent reply
02/07/2025 22:52:07:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:08:INFO:
[92mINFO [0m:      Received: train message a22188a9-be4d-4f43-8dd8-9ef25d6e9c25
02/07/2025 22:52:08:INFO:Received: train message a22188a9-be4d-4f43-8dd8-9ef25d6e9c25
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5637814402580261
  Validation Loss: 0.5324195027351379
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.565976619720459
  Validation Loss: 0.5325689911842346
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5736069679260254
  Validation Loss: 0.5327103137969971
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5582806169986725
  Validation Loss: 0.5328572988510132
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5563047230243683
  Validation Loss: 0.5330355167388916
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5637612640857697
  Validation Loss: 0.5332273840904236
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5568768680095673
  Validation Loss: 0.5334084630012512
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5624789595603943
  Validation Loss: 0.5335411429405212
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5668038427829742
  Validation Loss: 0.53369140625
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5666822791099548
  Validation Loss: 0.5338528156280518
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5618017315864563
  Validation Loss: 0.5340129733085632
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5631968080997467
  Validation Loss: 0.534193217754364
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5642062425613403
  Validation Loss: 0.5343700647354126
  Val ROC-AUC: 0.8181818181818181
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5617147386074066
  Validation Loss: 0.5345456004142761
  Val ROC-AUC: 0.7727272727272727
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.562652975320816
  Validation Loss: 0.5347215533256531
  Val ROC-AUC: 0.7727272727272727
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5617432594299316
  Validation Loss: 0.534883975982666
  Val ROC-AUC: 0.7727272727272727
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.562423437833786
  Validation Loss: 0.535060703754425
  Val ROC-AUC: 0.7727272727272727
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5566292405128479
  Validation Loss: 0.5352627038955688
  Val ROC-AUC: 0.7727272727272727
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5655171275138855
  Validation Loss: 0.5354616045951843
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5638629794120789
  Validation Loss: 0.5356588363647461
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5562200844287872
  Validation Loss: 0.5358834266662598
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.561219334602356
  Validation Loss: 0.536109983921051
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5561287701129913
  Validation Loss: 0.536343514919281
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5642007887363434
  Validation Loss: 0.5365403294563293
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5637989938259125
  Validation Loss: 0.5367023348808289
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5600549578666687
  Validation Loss: 0.5368531942367554
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5588351786136627
  Validation Loss: 0.5369958877563477
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5579946935176849
  Validation Loss: 0.5371343493461609
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5568728744983673
  Validation Loss: 0.5372846722602844
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5670435130596161
  Validation Loss: 0.5374322533607483
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.559804230928421
  Validation Loss: 0.5375825762748718
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5630882680416107
  Validation Loss: 0.5377381443977356
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5547798573970795
  Validation Loss: 0.5379130244255066
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5574634075164795
  Validation Loss: 0.5380476117134094
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5663030743598938
  Validation Loss: 0.5381943583488464
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5577333271503448
  Validation Loss: 0.5383479595184326
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5600210726261139
  Validation Loss: 0.5385143756866455
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5600210726261139, 'val_roc_auc': 0.7272727272727273, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5385143756866455}
 ROC_AUC: 0.7273|| Accuracy 0.6923 || Train Loss: 0.5600
 Val Loss: 0.5385 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5750969429810842
Test ROC-AUC: 0.7371428571428571
Test Accuracy: 0.5111111111111111
test_loss: 0.5750969429810842
test_roc_auc: 0.7371428571428571
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.18207852823252324
Epoch 1/64:
  Train Loss: 0.5614327788352966
  Validation Loss: 0.5759846568107605
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5476960241794586
  Validation Loss: 0.5761198401451111
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5522777438163757
  Validation Loss: 0.5762279629707336
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.5575000047683716
  Validation Loss: 0.5763349533081055
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.555689126253128
  Validation Loss: 0.5764337778091431
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5612155497074127
  Validation Loss: 0.5765167474746704
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5639748573303223
  Validation Loss: 0.5765655636787415
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5527763962745667
  Validation Loss: 0.5766345858573914
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.5549211204051971
  Validation Loss: 0.5767077207565308
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.5629498362541199
  Validation Loss: 0.5767898559570312
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.556212455034256
  Validation Loss: 0.5768665671348572
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5492480397224426
  Validation Loss: 0.5769438147544861
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5535353422164917
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:35:INFO:
[92mINFO [0m:      Received: evaluate message ec7e4456-b7a2-4697-ab0a-c8eef252a70a
02/07/2025 22:52:35:INFO:Received: evaluate message ec7e4456-b7a2-4697-ab0a-c8eef252a70a
  Validation Loss: 0.5770288705825806
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5561752319335938
  Validation Loss: 0.5770991444587708
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5534202754497528
  Validation Loss: 0.5771833062171936
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5603793561458588
  Validation Loss: 0.5772573947906494
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5670457035303116
  Validation Loss: 0.5773307681083679
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5568642914295197
  Validation Loss: 0.5774049162864685
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5562104880809784
  Validation Loss: 0.5774862170219421
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5507432818412781
  Validation Loss: 0.5775692462921143
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5521411597728729
  Validation Loss: 0.5776721835136414
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5607362985610962
  Validation Loss: 0.5777525305747986
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5509879291057587
  Validation Loss: 0.5778296589851379
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5536633729934692
  Validation Loss: 0.5779067277908325
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5469368994235992
  Validation Loss: 0.5779899954795837
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.54962357878685
  Validation Loss: 0.5780738592147827
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5499103367328644
  Validation Loss: 0.5781428813934326
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5544053912162781
  Validation Loss: 0.578199028968811
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5479373335838318
  Validation Loss: 0.5782604217529297
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.546645998954773
  Validation Loss: 0.5783362984657288
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5598017275333405
  Validation Loss: 0.5783953070640564
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5538861453533173
  Validation Loss: 0.5784458518028259
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.556586891412735
  Validation Loss: 0.5785069465637207
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.547007828950882
  Validation Loss: 0.5785675048828125
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5487137138843536
  Validation Loss: 0.5786213874816895
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5524434447288513
  Validation Loss: 0.5786792635917664
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5455211997032166
  Validation Loss: 0.5787392854690552
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5546197891235352
  Validation Loss: 0.5788037180900574
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5461213290691376
  Validation Loss: 0.5788735747337341
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5482056438922882
  Validation Loss: 0.578946053981781
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5535114407539368
  Validation Loss: 0.5790188908576965
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5590325891971588
  Validation Loss: 0.5790810585021973
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5549983084201813
  Validation Loss: 0.5791441798210144
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5458627939224243
  Validation Loss: 0.5792000889778137
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.556023508310318
  Validation Loss: 0.5792734026908875
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5591893494129181
  Validation Loss: 0.5793513655662537
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5511003732681274
  Validation Loss: 0.579426109790802
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5472866594791412
  Validation Loss: 0.5794803500175476
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.545417994260788
  Validation Loss: 0.5795512199401855
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5459452271461487
  Validation Loss: 0.5796144604682922
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5533165633678436
  Validation Loss: 0.579674243927002
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5545012652873993
  Validation Loss: 0.579714834690094
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5421359091997147
  Validation Loss: 0.5797607898712158
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5500154793262482
  Validation Loss: 0.5798187255859375
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5532234311103821
  Validation Loss: 0.5798905491828918
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5482229888439178
  Validation Loss: 0.5799316763877869
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5450323820114136
  Validation Loss: 0.5799707770347595
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.551815539598465
  Validation Loss: 0.5800259709358215
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5437256097793579
  Validation Loss: 0.5800864100456238
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5447335243225098
  Validation Loss: 0.5801497101783752
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5503250062465668
  Validation Loss: 0.5802290439605713
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5410994440317154
  Validation Loss: 0.5803247690200806
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5441161692142487
  Validation Loss: 0.5804094672203064
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5491849184036255
  Validation Loss: 0.5804769992828369
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5491849184036255, 'val_roc_auc': 0.6333333333333333, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5804769992828369}
 ROC_AUC: 0.6333|| Accuracy 0.5385 || Train Loss: 0.5492
 Val Loss: 0.5805 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5750781324174669
[92mINFO [0m:      Sent reply
02/07/2025 22:52:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:35:INFO:
[92mINFO [0m:      Received: train message 749b0f7b-0c37-4fd1-831a-3171e3b9a52b
02/07/2025 22:52:35:INFO:Received: train message 749b0f7b-0c37-4fd1-831a-3171e3b9a52b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5111111111111111
test_loss: 0.5750781324174669
test_roc_auc: 0.7428571428571429
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.12810748031673333
Epoch 1/64:
  Train Loss: 0.5594213902950287
  Validation Loss: 0.5734370350837708
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 2/64:
  Train Loss: 0.5670122802257538
  Validation Loss: 0.5735460519790649
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 3/64:
  Train Loss: 0.560679703950882
  Validation Loss: 0.5736509561538696
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 4/64:
  Train Loss: 0.5542648434638977
  Validation Loss: 0.5737683773040771
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 5/64:
  Train Loss: 0.5620449781417847
  Validation Loss: 0.5739009976387024
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 6/64:
  Train Loss: 0.5569803416728973
  Validation Loss: 0.5740301012992859
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 7/64:
  Train Loss: 0.5593849718570709
  Validation Loss: 0.5741540789604187
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 8/64:
  Train Loss: 0.5572744905948639
  Validation Loss: 0.5742973685264587
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 9/64:
  Train Loss: 0.5644848048686981
  Validation Loss: 0.5744230151176453
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 10/64:
  Train Loss: 0.5484371334314346
  Validation Loss: 0.574561595916748
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 11/64:
  Train Loss: 0.5576799511909485
  Validation Loss: 0.5746720433235168
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 12/64:
  Train Loss: 0.5561478137969971
  Validation Loss: 0.574807345867157
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 13/64:
  Train Loss: 0.5527860820293427
  Validation Loss: 0.5749265551567078
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 14/64:
  Train Loss: 0.5557622313499451
  Validation Loss: 0.5750585794448853
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 15/64:
  Train Loss: 0.5620162487030029
  Validation Loss: 0.5751875042915344
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 16/64:
  Train Loss: 0.5579488575458527
  Validation Loss: 0.5752976536750793
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 17/64:
  Train Loss: 0.5577408969402313
  Validation Loss: 0.5753999948501587
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 18/64:
  Train Loss: 0.5555810928344727
  Validation Loss: 0.5755240321159363
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 19/64:
  Train Loss: 0.5569125711917877
  Validation Loss: 0.575658917427063
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 20/64:
  Train Loss: 0.5508060455322266
  Validation Loss: 0.5757843255996704
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 21/64:
  Train Loss: 0.5589523017406464
  Validation Loss: 0.5759239196777344
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 22/64:
  Train Loss: 0.5575855672359467
  Validation Loss: 0.5760397911071777
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 23/64:
  Train Loss: 0.5606327652931213
  Validation Loss: 0.5761566162109375
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 24/64:
  Train Loss: 0.558528482913971
  Validation Loss: 0.5762723088264465
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 25/64:
  Train Loss: 0.5562691986560822
  Validation Loss: 0.5763621926307678
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 26/64:
  Train Loss: 0.5625099241733551
  Validation Loss: 0.5764591097831726
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 27/64:
  Train Loss: 0.5515032410621643
  Validation Loss: 0.5765666961669922
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 28/64:
  Train Loss: 0.5572399199008942
  Validation Loss: 0.576665997505188
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 29/64:
  Train Loss: 0.5564639270305634
  Validation Loss: 0.5767928957939148
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 30/64:
  Train Loss: 0.5568077862262726
  Validation Loss: 0.5768823027610779
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 31/64:
  Train Loss: 0.5517331063747406
  Validation Loss: 0.5769681334495544
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 32/64:
  Train Loss: 0.5509916245937347
  Validation Loss: 0.5770533084869385
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 33/64:
  Train Loss: 0.5598375797271729
  Validation Loss: 0.5771288871765137
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 34/64:
  Train Loss: 0.5519391596317291
  Validation Loss: 0.5772019624710083
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 35/64:
  Train Loss: 0.5553478598594666
  Validation Loss: 0.5772911310195923
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 36/64:
  Train Loss: 0.5581097304821014
  Validation Loss: 0.5773563385009766
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 37/64:
  Train Loss: 0.5508997440338135
  Validation Loss: 0.5774461627006531
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 38/64:
  Train Loss: 0.5463588833808899
  Validation Loss: 0.577549159526825
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 39/64:
  Train Loss: 0.5516671538352966
  Validation Loss: 0.5776597857475281
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 40/64:
  Train Loss: 0.5554198622703552
  Validation Loss: 0.5777666568756104
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 41/64:
  Train Loss: 0.5584529638290405
  Validation Loss: 0.5778449177742004
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 42/64:
  Train Loss: 0.5571514070034027
  Validation Loss: 0.5779390335083008
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 43/64:
  Train Loss: 0.5523718297481537
  Validation Loss: 0.5780364871025085
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 44/64:
  Train Loss: 0.5514323711395264
  Validation Loss: 0.5781561136245728
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 45/64:
  Train Loss: 0.5551930665969849
  Validation Loss: 0.5782818794250488
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 46/64:
  Train Loss: 0.5516119599342346
  Validation Loss: 0.5783912539482117
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 47/64:
  Train Loss: 0.5500872433185577
  Validation Loss: 0.5785133242607117
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 48/64:
  Train Loss: 0.5527980029582977
  Validation Loss: 0.578616738319397
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 49/64:
  Train Loss: 0.5580221116542816
  Validation Loss: 0.5787330865859985
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 50/64:
  Train Loss: 0.5502387881278992
  Validation Loss: 0.5788618922233582
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 51/64:
  Train Loss: 0.5580870509147644
  Validation Loss: 0.5789705514907837
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 52/64:
  Train Loss: 0.54994997382164
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:01:INFO:
[92mINFO [0m:      Received: evaluate message 8b268886-d5fa-496a-b685-d4621c5e9aaa
02/07/2025 22:53:01:INFO:Received: evaluate message 8b268886-d5fa-496a-b685-d4621c5e9aaa
[92mINFO [0m:      Sent reply
02/07/2025 22:53:03:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: train message 73892e3f-baf0-4c76-9399-17c27cba079a
02/07/2025 22:53:04:INFO:Received: train message 73892e3f-baf0-4c76-9399-17c27cba079a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5790956616401672
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 53/64:
  Train Loss: 0.554450273513794
  Validation Loss: 0.5792306065559387
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 54/64:
  Train Loss: 0.5443180650472641
  Validation Loss: 0.5793523192405701
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 55/64:
  Train Loss: 0.5574581623077393
  Validation Loss: 0.5794772505760193
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 56/64:
  Train Loss: 0.5503518283367157
  Validation Loss: 0.5795915722846985
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 57/64:
  Train Loss: 0.5571216940879822
  Validation Loss: 0.579695999622345
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 58/64:
  Train Loss: 0.5498721301555634
  Validation Loss: 0.5798110961914062
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 59/64:
  Train Loss: 0.5500659048557281
  Validation Loss: 0.5799382328987122
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 60/64:
  Train Loss: 0.5518824458122253
  Validation Loss: 0.5800636410713196
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 61/64:
  Train Loss: 0.5555306077003479
  Validation Loss: 0.5801867246627808
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 62/64:
  Train Loss: 0.5507795214653015
  Validation Loss: 0.5803154110908508
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 63/64:
  Train Loss: 0.5508734285831451
  Validation Loss: 0.5804304480552673
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 64/64:
  Train Loss: 0.5515550374984741
  Validation Loss: 0.5805671811103821
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
{'train_loss': 0.5515550374984741, 'val_roc_auc': 0.5666666666666668, 'val_accuracy': 0.7692307829856873, 'val_loss': 0.5805671811103821}
 ROC_AUC: 0.5667|| Accuracy 0.7692 || Train Loss: 0.5516
 Val Loss: 0.5806 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5751190265019734
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5111111111111111
test_loss: 0.5751190265019734
test_roc_auc: 0.7428571428571429
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.25603188811025274
Epoch 1/64:
  Train Loss: 0.5623995363712311
  Validation Loss: 0.5573458075523376
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.567914754152298
  Validation Loss: 0.5574752688407898
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5641799867153168
  Validation Loss: 0.5575661659240723
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5594939887523651
  Validation Loss: 0.5576573610305786
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5663196742534637
  Validation Loss: 0.5577093958854675
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5647324919700623
  Validation Loss: 0.5577967762947083
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5650357604026794
  Validation Loss: 0.5578742027282715
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5567178130149841
  Validation Loss: 0.5579185485839844
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.558588296175003
  Validation Loss: 0.5579279065132141
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5595993995666504
  Validation Loss: 0.5579339861869812
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5692403018474579
  Validation Loss: 0.557935893535614
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.565890371799469
  Validation Loss: 0.5579495429992676
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5660215318202972
  Validation Loss: 0.557961106300354
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5642837882041931
  Validation Loss: 0.5579850077629089
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5650941729545593
  Validation Loss: 0.5579924583435059
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5612767934799194
  Validation Loss: 0.5580201745033264
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.553851842880249
  Validation Loss: 0.5580514669418335
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5600024163722992
  Validation Loss: 0.5580676794052124
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5610479116439819
  Validation Loss: 0.5580808520317078
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.566532552242279
  Validation Loss: 0.5580894351005554
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.556493729352951
  Validation Loss: 0.5581099987030029
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5547856390476227
  Validation Loss: 0.558128297328949
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5561510324478149
  Validation Loss: 0.5581324696540833
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.556767076253891
  Validation Loss: 0.5581150650978088
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5620623528957367
  Validation Loss: 0.5581151843070984
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5510534197092056
  Validation Loss: 0.558114230632782
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.554698646068573
  Validation Loss: 0.5581225156784058
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.555864155292511
  Validation Loss: 0.5581536293029785
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.560606837272644
  Validation Loss: 0.5581842064857483
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 30/64:
  Train Loss: 0.5594827234745026
  Validation Loss: 0.5582369565963745
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 31/64:
  Train Loss: 0.5548746883869171
  Validation Loss: 0.5582897067070007
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 32/64:
  Train Loss: 0.5525672733783722
  Validation Loss: 0.5583410263061523
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 33/64:
  Train Loss: 0.5600289702415466
  Validation Loss: 0.5583758354187012
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 34/64:
  Train Loss: 0.5525599122047424
  Validation Loss: 0.5584126710891724
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 35/64:
  Train Loss: 0.5613070428371429
  Validation Loss: 0.5584146976470947
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 36/64:
  Train Loss: 0.5536240637302399
  Validation Loss: 0.5584340691566467
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 37/64:
  Train Loss: 0.5656736493110657
  Validation Loss: 0.5584483742713928
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:24:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:29:INFO:
[92mINFO [0m:      Received: evaluate message c75b3d53-b699-42f0-8a2f-7d1bb323399e
02/07/2025 22:53:29:INFO:Received: evaluate message c75b3d53-b699-42f0-8a2f-7d1bb323399e
[92mINFO [0m:      Sent reply
02/07/2025 22:53:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:32:INFO:
[92mINFO [0m:      Received: train message a0e43b41-3d20-43c8-b5c8-fe4106826705
02/07/2025 22:53:32:INFO:Received: train message a0e43b41-3d20-43c8-b5c8-fe4106826705
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 38/64:
  Train Loss: 0.5562463998794556
  Validation Loss: 0.5584681034088135
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 39/64:
  Train Loss: 0.5518962144851685
  Validation Loss: 0.5585068464279175
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 40/64:
  Train Loss: 0.5613657236099243
  Validation Loss: 0.5585356950759888
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 41/64:
  Train Loss: 0.5664463639259338
  Validation Loss: 0.558539092540741
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 42/64:
  Train Loss: 0.5607703626155853
  Validation Loss: 0.5585440993309021
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 43/64:
  Train Loss: 0.556008905172348
  Validation Loss: 0.5585348606109619
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 44/64:
  Train Loss: 0.5574992001056671
  Validation Loss: 0.558530330657959
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 45/64:
  Train Loss: 0.5625649988651276
  Validation Loss: 0.5585585236549377
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 46/64:
  Train Loss: 0.5516921281814575
  Validation Loss: 0.5585851669311523
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 47/64:
  Train Loss: 0.5588802099227905
  Validation Loss: 0.5585963129997253
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 48/64:
  Train Loss: 0.5530179738998413
  Validation Loss: 0.5585806369781494
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 49/64:
  Train Loss: 0.5625575184822083
  Validation Loss: 0.5585614442825317
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 50/64:
  Train Loss: 0.5514017343521118
  Validation Loss: 0.5585334897041321
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 51/64:
  Train Loss: 0.5563141405582428
  Validation Loss: 0.5585231781005859
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 52/64:
  Train Loss: 0.5603416562080383
  Validation Loss: 0.5585001111030579
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 53/64:
  Train Loss: 0.5565087497234344
  Validation Loss: 0.5584964752197266
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 54/64:
  Train Loss: 0.5605752170085907
  Validation Loss: 0.5584959983825684
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 55/64:
  Train Loss: 0.5555865466594696
  Validation Loss: 0.558497965335846
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 56/64:
  Train Loss: 0.5490785241127014
  Validation Loss: 0.5584960579872131
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 57/64:
  Train Loss: 0.5554233491420746
  Validation Loss: 0.5584762692451477
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 58/64:
  Train Loss: 0.550952672958374
  Validation Loss: 0.5584515929222107
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 59/64:
  Train Loss: 0.559047669172287
  Validation Loss: 0.5584263801574707
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 60/64:
  Train Loss: 0.5585266649723053
  Validation Loss: 0.5584107637405396
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 61/64:
  Train Loss: 0.5546557307243347
  Validation Loss: 0.558401346206665
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 62/64:
  Train Loss: 0.5459201335906982
  Validation Loss: 0.5583937168121338
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 63/64:
  Train Loss: 0.5582228600978851
  Validation Loss: 0.5583928227424622
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
Epoch 64/64:
  Train Loss: 0.5538680553436279
  Validation Loss: 0.5583763718605042
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.46153849363327026
{'train_loss': 0.5538680553436279, 'val_roc_auc': 0.6818181818181819, 'val_accuracy': 0.46153849363327026, 'val_loss': 0.5583763718605042}
 ROC_AUC: 0.6818|| Accuracy 0.4615 || Train Loss: 0.5539
 Val Loss: 0.5584 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5751745104789734
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5333333333333333
test_loss: 0.5751745104789734
test_roc_auc: 0.7428571428571429
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.14937070588348433
Epoch 1/64:
  Train Loss: 0.5628701150417328
  Validation Loss: 0.5675917863845825
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5594231486320496
  Validation Loss: 0.5676275491714478
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5577541589736938
  Validation Loss: 0.5676512718200684
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5597154498100281
  Validation Loss: 0.5676704049110413
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5670069754123688
  Validation Loss: 0.5676794052124023
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5578414499759674
  Validation Loss: 0.5677091479301453
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5623337924480438
  Validation Loss: 0.5677382946014404
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5653132498264313
  Validation Loss: 0.5677748918533325
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5575899183750153
  Validation Loss: 0.567808985710144
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5611129105091095
  Validation Loss: 0.5678521394729614
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5538807511329651
  Validation Loss: 0.5678825378417969
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5541013777256012
  Validation Loss: 0.5679079294204712
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.558840274810791
  Validation Loss: 0.567935585975647
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5634070634841919
  Validation Loss: 0.5679568648338318
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5578576624393463
  Validation Loss: 0.567982017993927
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5539621412754059
  Validation Loss: 0.5680022835731506
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5653900802135468
  Validation Loss: 0.5680177807807922
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5511969327926636
  Validation Loss: 0.568046510219574
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5600171983242035
  Validation Loss: 0.5680575370788574
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5577499568462372
  Validation Loss: 0.5680792331695557
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5597792863845825
  Validation Loss: 0.568095862865448
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5587296187877655
  Validation Loss: 0.5681199431419373
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5648318827152252
  Validation Loss: 0.568146288394928
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5549778044223785
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:59:INFO:
[92mINFO [0m:      Received: evaluate message df6b470a-f063-439c-ace2-a77d598b58c1
02/07/2025 22:53:59:INFO:Received: evaluate message df6b470a-f063-439c-ace2-a77d598b58c1
[92mINFO [0m:      Sent reply
02/07/2025 22:53:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:59:INFO:
[92mINFO [0m:      Received: train message 9b2e90a5-9605-4e9c-8338-2ebfeef55a24
02/07/2025 22:53:59:INFO:Received: train message 9b2e90a5-9605-4e9c-8338-2ebfeef55a24
  Validation Loss: 0.5681713223457336
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5621827840805054
  Validation Loss: 0.5681943893432617
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5616481304168701
  Validation Loss: 0.5682126879692078
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5596031248569489
  Validation Loss: 0.5682324171066284
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5579603612422943
  Validation Loss: 0.5682508945465088
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.559754878282547
  Validation Loss: 0.5682746171951294
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5528840720653534
  Validation Loss: 0.5683015584945679
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5534554123878479
  Validation Loss: 0.568341076374054
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5550180375576019
  Validation Loss: 0.5683864951133728
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5534748136997223
  Validation Loss: 0.5684376358985901
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5580840408802032
  Validation Loss: 0.568475067615509
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5579773187637329
  Validation Loss: 0.5685175061225891
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5550693869590759
  Validation Loss: 0.5685603022575378
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5600622296333313
  Validation Loss: 0.5685931444168091
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5590395331382751
  Validation Loss: 0.5686284303665161
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5486931800842285
  Validation Loss: 0.5686640739440918
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5503109991550446
  Validation Loss: 0.5686928033828735
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5448715686798096
  Validation Loss: 0.5687277317047119
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5531988739967346
  Validation Loss: 0.5687505602836609
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5563054084777832
  Validation Loss: 0.568773090839386
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5579175651073456
  Validation Loss: 0.5687853097915649
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5631525814533234
  Validation Loss: 0.5688055753707886
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5567730963230133
  Validation Loss: 0.5688396096229553
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5663454383611679
  Validation Loss: 0.5688698887825012
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5548473596572876
  Validation Loss: 0.5689062476158142
  Val ROC-AUC: 0.7
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5558861196041107
  Validation Loss: 0.5689466595649719
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5563869178295135
  Validation Loss: 0.5689713954925537
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5518613755702972
  Validation Loss: 0.5690042972564697
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5576904118061066
  Validation Loss: 0.5690310597419739
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5483984351158142
  Validation Loss: 0.569047212600708
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5518387258052826
  Validation Loss: 0.5690690875053406
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5546452701091766
  Validation Loss: 0.5690814256668091
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5561339855194092
  Validation Loss: 0.5691010355949402
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5521515309810638
  Validation Loss: 0.5691218972206116
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.55104860663414
  Validation Loss: 0.5691292881965637
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5576610267162323
  Validation Loss: 0.5691492557525635
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5506382882595062
  Validation Loss: 0.5691670775413513
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5532649159431458
  Validation Loss: 0.5691759586334229
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5569753050804138
  Validation Loss: 0.5691817998886108
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5505816340446472
  Validation Loss: 0.5691996216773987
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5567908883094788
  Validation Loss: 0.5692199468612671
  Val ROC-AUC: 0.7
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5567908883094788, 'val_roc_auc': 0.7, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.5692199468612671}
 ROC_AUC: 0.7000|| Accuracy 0.6154 || Train Loss: 0.5568
 Val Loss: 0.5692 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5752578569783104
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5333333333333333
test_loss: 0.5752578569783104
test_roc_auc: 0.7428571428571429
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.11471491539850832
Epoch 1/64:
  Train Loss: 0.5693035423755646
  Validation Loss: 0.5291732549667358
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5709067583084106
  Validation Loss: 0.5291087031364441
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5616631507873535
  Validation Loss: 0.529066264629364
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 4/64:
  Train Loss: 0.564135879278183
  Validation Loss: 0.5290161967277527
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 5/64:
  Train Loss: 0.5657602548599243
  Validation Loss: 0.5289645195007324
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 6/64:
  Train Loss: 0.5754886865615845
  Validation Loss: 0.5289171934127808
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 7/64:
  Train Loss: 0.5642627477645874
  Validation Loss: 0.5288690328598022
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 8/64:
  Train Loss: 0.5643786489963531
  Validation Loss: 0.5288320779800415
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 9/64:
  Train Loss: 0.5670591592788696
  Validation Loss: 0.5287891030311584
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 10/64:
  Train Loss: 0.5741088092327118
  Validation Loss: 0.5287512540817261
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 11/64:
  Train Loss: 0.572098970413208
  Validation Loss: 0.5287237167358398
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 12/64:
  Train Loss: 0.5682563483715057
  Validation Loss: 0.5286927223205566
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 13/64:
  Train Loss: 0.5533164143562317
  Validation Loss: 0.5286526083946228
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 14/64:
  Train Loss: 0.5721927881240845
  Validation Loss: 0.5286065340042114
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 15/64:
  Train Loss: 0.5693316757678986
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:54:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:23:INFO:
[92mINFO [0m:      Received: evaluate message b9e05978-8fa7-4353-b932-30e348f71190
02/07/2025 22:54:23:INFO:Received: evaluate message b9e05978-8fa7-4353-b932-30e348f71190
[92mINFO [0m:      Sent reply
02/07/2025 22:54:25:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:26:INFO:
[92mINFO [0m:      Received: train message 34bbd0ee-f33a-4a71-9513-b224853c9fac
02/07/2025 22:54:26:INFO:Received: train message 34bbd0ee-f33a-4a71-9513-b224853c9fac
  Validation Loss: 0.5285691022872925
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 16/64:
  Train Loss: 0.5661596059799194
  Validation Loss: 0.5285207033157349
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 17/64:
  Train Loss: 0.5584413111209869
  Validation Loss: 0.5284908413887024
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 18/64:
  Train Loss: 0.5657401978969574
  Validation Loss: 0.528452455997467
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 19/64:
  Train Loss: 0.5649261474609375
  Validation Loss: 0.5284242630004883
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 20/64:
  Train Loss: 0.570805013179779
  Validation Loss: 0.528387188911438
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 21/64:
  Train Loss: 0.5585739314556122
  Validation Loss: 0.5283554792404175
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 22/64:
  Train Loss: 0.5665635168552399
  Validation Loss: 0.5283367037773132
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 23/64:
  Train Loss: 0.5690172016620636
  Validation Loss: 0.5283132195472717
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 24/64:
  Train Loss: 0.5643648505210876
  Validation Loss: 0.5282911062240601
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 25/64:
  Train Loss: 0.5613691210746765
  Validation Loss: 0.5282674431800842
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 26/64:
  Train Loss: 0.5573142021894455
  Validation Loss: 0.5282478332519531
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 27/64:
  Train Loss: 0.5617797672748566
  Validation Loss: 0.5282149910926819
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 28/64:
  Train Loss: 0.5668989717960358
  Validation Loss: 0.5281702876091003
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 29/64:
  Train Loss: 0.5648864805698395
  Validation Loss: 0.5281128287315369
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 30/64:
  Train Loss: 0.567683219909668
  Validation Loss: 0.528071403503418
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 31/64:
  Train Loss: 0.5612598061561584
  Validation Loss: 0.5280253887176514
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 32/64:
  Train Loss: 0.5602893829345703
  Validation Loss: 0.5279840230941772
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 33/64:
  Train Loss: 0.5623030066490173
  Validation Loss: 0.5279245972633362
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 34/64:
  Train Loss: 0.5620174705982208
  Validation Loss: 0.5278628468513489
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 35/64:
  Train Loss: 0.5657275915145874
  Validation Loss: 0.5277977585792542
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 36/64:
  Train Loss: 0.5613141357898712
  Validation Loss: 0.5277535319328308
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 37/64:
  Train Loss: 0.5626620948314667
  Validation Loss: 0.5277051329612732
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 38/64:
  Train Loss: 0.5636924207210541
  Validation Loss: 0.5276734232902527
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 39/64:
  Train Loss: 0.5693199038505554
  Validation Loss: 0.5276501178741455
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 40/64:
  Train Loss: 0.5624946653842926
  Validation Loss: 0.5276110172271729
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 41/64:
  Train Loss: 0.5684148669242859
  Validation Loss: 0.5275778770446777
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 42/64:
  Train Loss: 0.5653528869152069
  Validation Loss: 0.5275375247001648
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 43/64:
  Train Loss: 0.5603002309799194
  Validation Loss: 0.5274936556816101
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 44/64:
  Train Loss: 0.5645914375782013
  Validation Loss: 0.5274553298950195
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 45/64:
  Train Loss: 0.5643165409564972
  Validation Loss: 0.5274278521537781
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 46/64:
  Train Loss: 0.5669785737991333
  Validation Loss: 0.5273987650871277
  Val ROC-AUC: 0.9166666666666666
  Val Accuracy: 0.46153849363327026
Epoch 47/64:
  Train Loss: 0.5721406638622284
  Validation Loss: 0.5273535847663879
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 48/64:
  Train Loss: 0.5567154288291931
  Validation Loss: 0.5273221135139465
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 49/64:
  Train Loss: 0.5700093805789948
  Validation Loss: 0.5272782444953918
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 50/64:
  Train Loss: 0.5641412138938904
  Validation Loss: 0.5272470712661743
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 51/64:
  Train Loss: 0.5573029816150665
  Validation Loss: 0.5272183418273926
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 52/64:
  Train Loss: 0.5694617033004761
  Validation Loss: 0.5271806120872498
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 53/64:
  Train Loss: 0.5605489611625671
  Validation Loss: 0.5271499156951904
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 54/64:
  Train Loss: 0.5612714290618896
  Validation Loss: 0.5271219611167908
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 55/64:
  Train Loss: 0.561296284198761
  Validation Loss: 0.5270755887031555
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 56/64:
  Train Loss: 0.5677924752235413
  Validation Loss: 0.527042806148529
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 57/64:
  Train Loss: 0.5583813488483429
  Validation Loss: 0.5270088315010071
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 58/64:
  Train Loss: 0.5629470646381378
  Validation Loss: 0.5269729495048523
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 59/64:
  Train Loss: 0.5663166642189026
  Validation Loss: 0.5269412398338318
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 60/64:
  Train Loss: 0.5651145875453949
  Validation Loss: 0.526903510093689
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 61/64:
  Train Loss: 0.5642014443874359
  Validation Loss: 0.5268598794937134
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 62/64:
  Train Loss: 0.5565621554851532
  Validation Loss: 0.5268187522888184
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 63/64:
  Train Loss: 0.5654251873493195
  Validation Loss: 0.5267733335494995
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
Epoch 64/64:
  Train Loss: 0.570643812417984
  Validation Loss: 0.5267471671104431
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.46153849363327026
{'train_loss': 0.570643812417984, 'val_roc_auc': 0.8333333333333334, 'val_accuracy': 0.46153849363327026, 'val_loss': 0.5267471671104431}
 ROC_AUC: 0.8333|| Accuracy 0.4615 || Train Loss: 0.5706
 Val Loss: 0.5267 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.575328505701489
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5333333333333333
test_loss: 0.575328505701489
test_roc_auc: 0.7428571428571429
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.1092839436993624
Epoch 1/64:
  Train Loss: 0.5682594776153564
  Validation Loss: 0.5373836159706116
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5643982589244843
  Validation Loss: 0.5373318791389465
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5632553398609161
  Validation Loss: 0.5372867584228516
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5678369998931885
  Validation Loss: 0.5372820496559143
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5660450756549835
  Validation Loss: 0.5372649431228638
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5620386302471161
  Validation Loss: 0.5372374653816223
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5648702085018158
  Validation Loss: 0.5372076034545898
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5689793825149536
  Validation Loss: 0.5371719598770142
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5681122839450836
  Validation Loss: 0.5371474027633667
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5691864192485809
  Validation Loss: 0.5371260643005371
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5637710988521576
  Validation Loss: 0.5370879173278809
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5598435699939728
  Validation Loss: 0.5370566248893738
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5709967315196991
  Validation Loss: 0.5370209217071533
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5675208866596222
  Validation Loss: 0.5369965434074402
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5690764486789703
  Validation Loss: 0.536973774433136
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.569224625825882
  Validation Loss: 0.5369491577148438
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5616499781608582
  Validation Loss: 0.536939263343811
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5645765364170074
  Validation Loss: 0.5369318723678589
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5711044371128082
  Validation Loss: 0.5369062423706055
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5660872459411621
  Validation Loss: 0.5368897318840027
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5688967108726501
  Validation Loss: 0.5368744730949402
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5698961019515991
  Validation Loss: 0.5368545651435852
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5764730870723724
  Validation Loss: 0.5368348956108093
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5632303655147552
  Validation Loss: 0.5368212461471558
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.568197101354599
  Validation Loss: 0.5368052124977112
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5623654723167419
  Validation Loss: 0.5368078947067261
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5639665126800537
  Validation Loss: 0.5368058085441589
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.565180093050003
  Validation Loss: 0.5368080735206604
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5705821216106415
  Validation Loss: 0.5368108153343201
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5638706088066101
  Validation Loss: 0.5368188619613647
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5628229975700378
  Validation Loss: 0.536819577217102
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5707667768001556
  Validation Loss: 0.5368149280548096
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5707544684410095
  Validation Loss: 0.5368013381958008
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5642023086547852
  Validation Loss: 0.5367963910102844
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5609695613384247
  Validation Loss: 0.5367854833602905
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5646854937076569
  Validation Loss: 0.5367792844772339
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5663800239562988
  Validation Loss: 0.536778450012207
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5683311820030212
  Validation Loss: 0.5367681980133057
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5654597580432892
  Validation Loss: 0.536761999130249
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5604521334171295
  Validation Loss: 0.5367744565010071
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5753035545349121
  Validation Loss: 0.536774754524231
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5691112875938416
  Validation Loss: 0.536780834197998
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5619543492794037
  Validation Loss: 0.5367844700813293
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.56108158826828
  Validation Loss: 0.5367907285690308
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5581971108913422
  Validation Loss: 0.5368059873580933
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5590276122093201
  Validation Loss: 0.5368143320083618
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5589246451854706
  Validation Loss: 0.5368169546127319
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5575942993164062
  Validation Loss: 0.5368296504020691
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5627763569355011
  Validation Loss: 0.5368229150772095
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5601962506771088
  Validation Loss: 0.536820650100708
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5680877268314362
  Validation Loss: 0.5368109941482544
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.565295398235321
  Validation Loss: 0.5368044376373291
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5617440342903137
  Validation Loss: 0.536806046962738
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:54:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:50:INFO:
[92mINFO [0m:      Received: evaluate message dc41f71b-ce88-47d2-8968-cadee80512ce
02/07/2025 22:54:50:INFO:Received: evaluate message dc41f71b-ce88-47d2-8968-cadee80512ce
[92mINFO [0m:      Sent reply
02/07/2025 22:54:52:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:53:INFO:
[92mINFO [0m:      Received: train message 248ae6aa-55dd-4f36-9776-d843c400fa2e
02/07/2025 22:54:53:INFO:Received: train message 248ae6aa-55dd-4f36-9776-d843c400fa2e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.5651251673698425
  Validation Loss: 0.5368080139160156
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5624566078186035
  Validation Loss: 0.5368106961250305
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5592681765556335
  Validation Loss: 0.5368135571479797
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5559504926204681
  Validation Loss: 0.5368262529373169
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.561820775270462
  Validation Loss: 0.5368356704711914
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5619637668132782
  Validation Loss: 0.5368553400039673
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5630779266357422
  Validation Loss: 0.5368574261665344
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5598165988922119
  Validation Loss: 0.5368797779083252
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5631605088710785
  Validation Loss: 0.5368844270706177
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5653272271156311
  Validation Loss: 0.5369032621383667
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5639660358428955
  Validation Loss: 0.5369089245796204
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5639660358428955, 'val_roc_auc': 0.9090909090909091, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5369089245796204}
 ROC_AUC: 0.9091|| Accuracy 0.5385 || Train Loss: 0.5640
 Val Loss: 0.5369 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5754828413327535
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5333333333333333
test_loss: 0.5754828413327535
test_roc_auc: 0.7428571428571429
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.10560030437773091
Epoch 1/64:
  Train Loss: 0.5644059479236603
  Validation Loss: 0.5543524622917175
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5561436414718628
  Validation Loss: 0.5542925596237183
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5653195679187775
  Validation Loss: 0.5542473793029785
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.5642690360546112
  Validation Loss: 0.5542079210281372
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.561316192150116
  Validation Loss: 0.5541660189628601
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5593336224555969
  Validation Loss: 0.5541249513626099
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5611109137535095
  Validation Loss: 0.5541005730628967
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5634129643440247
  Validation Loss: 0.5540769696235657
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.5661638379096985
  Validation Loss: 0.5540234446525574
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.5622254014015198
  Validation Loss: 0.5539841651916504
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.5594849586486816
  Validation Loss: 0.5539577603340149
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5636448264122009
  Validation Loss: 0.5539103746414185
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5693461894989014
  Validation Loss: 0.553860604763031
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5637627243995667
  Validation Loss: 0.5538246631622314
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 15/64:
  Train Loss: 0.565825343132019
  Validation Loss: 0.553787112236023
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 16/64:
  Train Loss: 0.5588835179805756
  Validation Loss: 0.553759753704071
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 17/64:
  Train Loss: 0.5628686845302582
  Validation Loss: 0.553729772567749
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 18/64:
  Train Loss: 0.5603388845920563
  Validation Loss: 0.5537015795707703
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 19/64:
  Train Loss: 0.5629493892192841
  Validation Loss: 0.553674578666687
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.5590672791004181
  Validation Loss: 0.5536399483680725
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.5591905117034912
  Validation Loss: 0.553593635559082
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 22/64:
  Train Loss: 0.562403529882431
  Validation Loss: 0.5535566806793213
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 23/64:
  Train Loss: 0.5648923814296722
  Validation Loss: 0.5535187721252441
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 24/64:
  Train Loss: 0.568891316652298
  Validation Loss: 0.5534804463386536
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 25/64:
  Train Loss: 0.5662589073181152
  Validation Loss: 0.553443431854248
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 26/64:
  Train Loss: 0.5552829504013062
  Validation Loss: 0.553409993648529
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 27/64:
  Train Loss: 0.5588172972202301
  Validation Loss: 0.5533710718154907
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 28/64:
  Train Loss: 0.5595595240592957
  Validation Loss: 0.5533267855644226
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 29/64:
  Train Loss: 0.5619713962078094
  Validation Loss: 0.5532920956611633
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 30/64:
  Train Loss: 0.5508827269077301
  Validation Loss: 0.5532594919204712
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 31/64:
  Train Loss: 0.5645538866519928
  Validation Loss: 0.5532284379005432
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 32/64:
  Train Loss: 0.5566962957382202
  Validation Loss: 0.5532069206237793
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 33/64:
  Train Loss: 0.5575346350669861
  Validation Loss: 0.5531814694404602
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 34/64:
  Train Loss: 0.5656553208827972
  Validation Loss: 0.5531424880027771
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 35/64:
  Train Loss: 0.5653028190135956
  Validation Loss: 0.5531038641929626
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 36/64:
  Train Loss: 0.5681516528129578
  Validation Loss: 0.5530697703361511
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 37/64:
  Train Loss: 0.5596928000450134
  Validation Loss: 0.553052544593811
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 38/64:
  Train Loss: 0.5623881816864014
  Validation Loss: 0.5530365705490112
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 39/64:
  Train Loss: 0.5632404983043671
  Validation Loss: 0.5530115962028503
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:55:11:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:18:INFO:
[92mINFO [0m:      Received: evaluate message a0af1506-bfbc-4ce3-8529-fc76b71c758d
02/07/2025 22:55:18:INFO:Received: evaluate message a0af1506-bfbc-4ce3-8529-fc76b71c758d
[92mINFO [0m:      Sent reply
02/07/2025 22:55:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:20:INFO:
[92mINFO [0m:      Received: train message bf94a0f8-e71f-46f8-b6ac-a1a81dac7c32
02/07/2025 22:55:20:INFO:Received: train message bf94a0f8-e71f-46f8-b6ac-a1a81dac7c32
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 40/64:
  Train Loss: 0.5556308925151825
  Validation Loss: 0.5529742240905762
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5674273371696472
  Validation Loss: 0.5529307126998901
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.5642551183700562
  Validation Loss: 0.5528990626335144
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.5586339831352234
  Validation Loss: 0.5528564453125
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5549095571041107
  Validation Loss: 0.5528239011764526
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5656624734401703
  Validation Loss: 0.5527822971343994
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5589964389801025
  Validation Loss: 0.5527440905570984
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.567724198102951
  Validation Loss: 0.55269455909729
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5575974881649017
  Validation Loss: 0.5526367425918579
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5639583766460419
  Validation Loss: 0.5525895357131958
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5597631633281708
  Validation Loss: 0.5525373220443726
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5582234263420105
  Validation Loss: 0.5524879693984985
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5633415579795837
  Validation Loss: 0.5524414777755737
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5609648823738098
  Validation Loss: 0.5524089932441711
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5556060671806335
  Validation Loss: 0.5523691177368164
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5605790913105011
  Validation Loss: 0.5523179173469543
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5584443807601929
  Validation Loss: 0.5522671341896057
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5579353868961334
  Validation Loss: 0.5522124171257019
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5560206770896912
  Validation Loss: 0.5521674752235413
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5599946677684784
  Validation Loss: 0.5521182417869568
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5580780208110809
  Validation Loss: 0.552068293094635
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5589783787727356
  Validation Loss: 0.5520222783088684
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5613442361354828
  Validation Loss: 0.5519648194313049
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5624774396419525
  Validation Loss: 0.5519073605537415
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.561818540096283
  Validation Loss: 0.5518540740013123
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.561818540096283, 'val_roc_auc': 0.6818181818181819, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.5518540740013123}
 ROC_AUC: 0.6818|| Accuracy 0.6154 || Train Loss: 0.5618
 Val Loss: 0.5519 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5756673137346904
Test ROC-AUC: 0.74
Test Accuracy: 0.5333333333333333
test_loss: 0.5756673137346904
test_roc_auc: 0.74
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.05922265112167223
Epoch 1/64:
  Train Loss: 0.5851293504238129
  Validation Loss: 0.4565441608428955
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5821784734725952
  Validation Loss: 0.4565514922142029
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5930971205234528
  Validation Loss: 0.4565492868423462
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5852936506271362
  Validation Loss: 0.45656129717826843
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5916687250137329
  Validation Loss: 0.45655694603919983
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5844963490962982
  Validation Loss: 0.45654264092445374
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5774082243442535
  Validation Loss: 0.4565451741218567
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5834100246429443
  Validation Loss: 0.45653465390205383
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5888428390026093
  Validation Loss: 0.4565104842185974
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5816103518009186
  Validation Loss: 0.45648685097694397
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5863593518733978
  Validation Loss: 0.4564659595489502
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5893483459949493
  Validation Loss: 0.4564454257488251
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5864830017089844
  Validation Loss: 0.4564233124256134
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5895112454891205
  Validation Loss: 0.45639920234680176
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5888877213001251
  Validation Loss: 0.4563791751861572
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5910110473632812
  Validation Loss: 0.45635902881622314
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5866556763648987
  Validation Loss: 0.4563538730144501
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5847934186458588
  Validation Loss: 0.45634037256240845
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5801651179790497
  Validation Loss: 0.45632147789001465
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5878870189189911
  Validation Loss: 0.45629173517227173
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5835829973220825
  Validation Loss: 0.4562712609767914
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5865724980831146
  Validation Loss: 0.456246018409729
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5856215953826904
  Validation Loss: 0.45621272921562195
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5914895236492157
  Validation Loss: 0.45618322491645813
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5895106494426727
  Validation Loss: 0.456157922744751
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5911386013031006
  Validation Loss: 0.4561382830142975
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5926130414009094
  Validation Loss: 0.45609113574028015
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 22:55:38:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:45:INFO:
[92mINFO [0m:      Received: evaluate message 51182266-cbc5-424d-91d6-d1073d22b790
02/07/2025 22:55:45:INFO:Received: evaluate message 51182266-cbc5-424d-91d6-d1073d22b790
[92mINFO [0m:      Sent reply
02/07/2025 22:55:45:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:47:INFO:
[92mINFO [0m:      Received: train message 14ac4972-ec2f-4145-95bf-bc6ca7cc6ad0
02/07/2025 22:55:47:INFO:Received: train message 14ac4972-ec2f-4145-95bf-bc6ca7cc6ad0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.58803591132164
  Validation Loss: 0.4560515880584717
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.580347090959549
  Validation Loss: 0.4560128152370453
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5856792032718658
  Validation Loss: 0.45598503947257996
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5864521861076355
  Validation Loss: 0.4559590518474579
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5883314907550812
  Validation Loss: 0.45592883229255676
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5929722189903259
  Validation Loss: 0.455901563167572
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5834566950798035
  Validation Loss: 0.45588546991348267
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5829348564147949
  Validation Loss: 0.4558519721031189
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5892819464206696
  Validation Loss: 0.4558181166648865
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5843844413757324
  Validation Loss: 0.4557974338531494
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5871005058288574
  Validation Loss: 0.4557761251926422
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5890055894851685
  Validation Loss: 0.4557415246963501
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5907960832118988
  Validation Loss: 0.4557117223739624
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5840485095977783
  Validation Loss: 0.4556782841682434
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5867943167686462
  Validation Loss: 0.45564645528793335
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5916026830673218
  Validation Loss: 0.4556150734424591
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5854051411151886
  Validation Loss: 0.4555755853652954
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5859789550304413
  Validation Loss: 0.45553305745124817
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.583925724029541
  Validation Loss: 0.455505907535553
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5804297626018524
  Validation Loss: 0.45545968413352966
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5848554968833923
  Validation Loss: 0.45541489124298096
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5815311968326569
  Validation Loss: 0.4553702175617218
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5844471454620361
  Validation Loss: 0.45533376932144165
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5787578523159027
  Validation Loss: 0.4553050398826599
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5818788409233093
  Validation Loss: 0.45527583360671997
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5911124646663666
  Validation Loss: 0.45523491501808167
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.581995815038681
  Validation Loss: 0.4551924765110016
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5854204595088959
  Validation Loss: 0.45514681935310364
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5868920683860779
  Validation Loss: 0.4550979733467102
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5894673764705658
  Validation Loss: 0.4550669491291046
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5841288566589355
  Validation Loss: 0.45503178238868713
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5836844444274902
  Validation Loss: 0.45498958230018616
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5813978016376495
  Validation Loss: 0.4549591541290283
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5873469114303589
  Validation Loss: 0.45494315028190613
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.584960013628006
  Validation Loss: 0.4549063742160797
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5839216709136963
  Validation Loss: 0.4548753798007965
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5756618976593018
  Validation Loss: 0.4548534154891968
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5756618976593018, 'val_roc_auc': nan, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.4548534154891968}
 ROC_AUC: nan|| Accuracy 0.6154 || Train Loss: 0.5757
 Val Loss: 0.4549 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5758590797583262
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5333333333333333
test_loss: 0.5758590797583262
test_roc_auc: 0.7428571428571429
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.018612800272724897
Epoch 1/64:
  Train Loss: 0.5534294545650482
  Validation Loss: 0.593682587146759
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5508959889411926
  Validation Loss: 0.5936099886894226
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5557182729244232
  Validation Loss: 0.5935830473899841
  Val ROC-AUC: 0.7333333333333334
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5556128025054932
  Validation Loss: 0.5935658812522888
  Val ROC-AUC: 0.7333333333333334
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5507732331752777
  Validation Loss: 0.593553364276886
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5531332194805145
  Validation Loss: 0.5935423374176025
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5535335838794708
  Validation Loss: 0.5935207009315491
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5559880435466766
  Validation Loss: 0.5934972763061523
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5501587092876434
  Validation Loss: 0.5934650301933289
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5557463765144348
  Validation Loss: 0.5934386849403381
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5575651824474335
  Validation Loss: 0.5934171676635742
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5543656349182129
  Validation Loss: 0.5933871269226074
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5568433701992035
  Validation Loss: 0.5933715105056763
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5514326989650726
  Validation Loss: 0.5933607816696167
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5567039847373962
  Validation Loss: 0.5933408141136169
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5524393022060394
  Validation Loss: 0.5933244824409485
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5574568510055542
  Validation Loss: 0.5933119058609009
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:56:05:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:12:INFO:
[92mINFO [0m:      Received: evaluate message b12d6715-43ae-49ba-812a-303a42c64b03
02/07/2025 22:56:12:INFO:Received: evaluate message b12d6715-43ae-49ba-812a-303a42c64b03
[92mINFO [0m:      Sent reply
02/07/2025 22:56:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:15:INFO:
[92mINFO [0m:      Received: train message 9b8adf5b-10fd-4729-9a72-9754a178e2d3
02/07/2025 22:56:15:INFO:Received: train message 9b8adf5b-10fd-4729-9a72-9754a178e2d3
  Train Loss: 0.5595033764839172
  Validation Loss: 0.5932936668395996
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5525521337985992
  Validation Loss: 0.5932848453521729
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5472777187824249
  Validation Loss: 0.5932783484458923
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5484732091426849
  Validation Loss: 0.5932533740997314
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5597940981388092
  Validation Loss: 0.5932391881942749
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5485517680644989
  Validation Loss: 0.5932211875915527
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.547298938035965
  Validation Loss: 0.5931927561759949
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.554627537727356
  Validation Loss: 0.5931804180145264
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5573348999023438
  Validation Loss: 0.5931612849235535
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5537513494491577
  Validation Loss: 0.5931347012519836
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5492385625839233
  Validation Loss: 0.593122124671936
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5488957464694977
  Validation Loss: 0.5930914878845215
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5504941344261169
  Validation Loss: 0.5930739045143127
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5532229840755463
  Validation Loss: 0.5930472016334534
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5567907094955444
  Validation Loss: 0.5930296182632446
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5522498786449432
  Validation Loss: 0.5930171012878418
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5508456528186798
  Validation Loss: 0.592994749546051
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5536592900753021
  Validation Loss: 0.5929672718048096
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5531632006168365
  Validation Loss: 0.5929539203643799
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.550182431936264
  Validation Loss: 0.592939555644989
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5552739500999451
  Validation Loss: 0.5929310917854309
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5507001280784607
  Validation Loss: 0.592908501625061
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5554782748222351
  Validation Loss: 0.5928911566734314
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5530834197998047
  Validation Loss: 0.5928784608840942
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5571106970310211
  Validation Loss: 0.5928630828857422
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5566961467266083
  Validation Loss: 0.5928350687026978
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5556369721889496
  Validation Loss: 0.5928085446357727
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5540348291397095
  Validation Loss: 0.5927867293357849
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5499260723590851
  Validation Loss: 0.5927650928497314
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5462772250175476
  Validation Loss: 0.5927451848983765
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5505169034004211
  Validation Loss: 0.5927257537841797
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5515902936458588
  Validation Loss: 0.5927011966705322
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.552638977766037
  Validation Loss: 0.5926747918128967
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5578102469444275
  Validation Loss: 0.5926607251167297
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5534731149673462
  Validation Loss: 0.5926467776298523
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5478897988796234
  Validation Loss: 0.5926277041435242
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5514120161533356
  Validation Loss: 0.5926100015640259
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5568111836910248
  Validation Loss: 0.5925871729850769
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.546620637178421
  Validation Loss: 0.5925686955451965
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5539183914661407
  Validation Loss: 0.5925518274307251
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5507574081420898
  Validation Loss: 0.5925248265266418
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5449568629264832
  Validation Loss: 0.5924956798553467
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5436026155948639
  Validation Loss: 0.5924662947654724
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5514913201332092
  Validation Loss: 0.5924496650695801
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5430732369422913
  Validation Loss: 0.5924328565597534
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5515330731868744
  Validation Loss: 0.5924040079116821
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5448810160160065
  Validation Loss: 0.5923776030540466
  Val ROC-AUC: 0.7
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5448810160160065, 'val_roc_auc': 0.7, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5923776030540466}
 ROC_AUC: 0.7000|| Accuracy 0.5385 || Train Loss: 0.5449
 Val Loss: 0.5924 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5760464198059506
Test ROC-AUC: 0.7485714285714286
Test Accuracy: 0.5333333333333333
test_loss: 0.5760464198059506
test_roc_auc: 0.7485714285714286
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.80810546875
Dynamic noise multiplier: 0.0
Epoch 1/64:
  Train Loss: 0.5734277963638306
  Validation Loss: 0.5429527163505554
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 2/64:
  Train Loss: 0.569381594657898
  Validation Loss: 0.5431249737739563
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 3/64:
  Train Loss: 0.5679211914539337
  Validation Loss: 0.5432774424552917
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 4/64:
  Train Loss: 0.5680157542228699
  Validation Loss: 0.5434325337409973
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5695814788341522
  Validation Loss: 0.5435624122619629
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5689233839511871
  Validation Loss: 0.5436976552009583
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5641175508499146
  Validation Loss: 0.543834924697876
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.563962310552597
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5439873337745667
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5684155523777008
  Validation Loss: 0.5441139340400696
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5686355233192444
  Validation Loss: 0.5442370772361755
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5646028518676758
  Validation Loss: 0.5443457365036011
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5702788233757019
  Validation Loss: 0.5444756746292114
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.565397173166275
  Validation Loss: 0.5445924997329712
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5686732232570648
  Validation Loss: 0.5447081327438354
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5623379945755005
  Validation Loss: 0.5448325872421265
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5635055005550385
  Validation Loss: 0.5449501872062683
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5595043301582336
  Validation Loss: 0.5450745820999146
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5663392543792725
  Validation Loss: 0.5451822280883789
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5730545222759247
  Validation Loss: 0.5453017950057983
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5685933828353882
  Validation Loss: 0.5454173684120178
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.573253720998764
  Validation Loss: 0.545534610748291
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5742334127426147
  Validation Loss: 0.5456526875495911
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5639471411705017
  Validation Loss: 0.5457744598388672
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5663694143295288
  Validation Loss: 0.545896589756012
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5715449154376984
  Validation Loss: 0.5460072159767151
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5691296458244324
  Validation Loss: 0.546120822429657
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5681109130382538
  Validation Loss: 0.5462352633476257
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.567805677652359
  Validation Loss: 0.5463399887084961
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5584093332290649
  Validation Loss: 0.5464629530906677
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5683127641677856
  Validation Loss: 0.5465750694274902
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5616209805011749
  Validation Loss: 0.5467010140419006
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5635719299316406
  Validation Loss: 0.5468312501907349
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5665604174137115
  Validation Loss: 0.5469437837600708
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5635562837123871
  Validation Loss: 0.5470671653747559
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5637312233448029
  Validation Loss: 0.547177791595459
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5609507262706757
  Validation Loss: 0.547293484210968
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5573528409004211
  Validation Loss: 0.5474169254302979
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5610667169094086
  Validation Loss: 0.5475348830223083
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5684456527233124
  Validation Loss: 0.547648549079895
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5629027485847473
  Validation Loss: 0.5477589964866638
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.571789562702179
  Validation Loss: 0.547864556312561
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5654491186141968
  Validation Loss: 0.5479817390441895
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.562789112329483
  Validation Loss: 0.5480952262878418
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5612732172012329
  Validation Loss: 0.5482057332992554
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5600037574768066
  Validation Loss: 0.548316240310669
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5627587139606476
  Validation Loss: 0.5484383702278137
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5602327585220337
  Validation Loss: 0.548554003238678
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5573540329933167
  Validation Loss: 0.5486688613891602
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5579368472099304
  Validation Loss: 0.5487849116325378
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5536486655473709
  Validation Loss: 0.5489002466201782
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5635922253131866
  Validation Loss: 0.5490193367004395
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5623471736907959
  Validation Loss: 0.5491301417350769
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5605232417583466
  Validation Loss: 0.5492475628852844
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5660278499126434
  Validation Loss: 0.5493541955947876
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5626298785209656
  Validation Loss: 0.5494825839996338
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.558512270450592
  Validation Loss: 0.5495988726615906
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.562520444393158
  Validation Loss: 0.5497029423713684
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5601726472377777
  Validation Loss: 0.5498155951499939
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5599672794342041
  Validation Loss: 0.5499259829521179
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5637697577476501
  Validation Loss: 0.5500403046607971
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5608863234519958
  Validation Loss: 0.5501570701599121
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5597098767757416
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:56:32:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:40:INFO:
[92mINFO [0m:      Received: evaluate message 4d7f55da-9878-4c7a-9cb1-eac0f6f8dbd1
02/07/2025 22:56:40:INFO:Received: evaluate message 4d7f55da-9878-4c7a-9cb1-eac0f6f8dbd1
[92mINFO [0m:      Sent reply
02/07/2025 22:56:40:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:42:INFO:
[92mINFO [0m:      Received: reconnect message 836f2ff9-845a-445e-8e82-edaf93528942
02/07/2025 22:56:42:INFO:Received: reconnect message 836f2ff9-845a-445e-8e82-edaf93528942
02/07/2025 22:56:42:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/07/2025 22:56:42:INFO:Disconnect and shut down
  Validation Loss: 0.5502737164497375
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5581696629524231
  Validation Loss: 0.5503816604614258
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5647576153278351
  Validation Loss: 0.5504859685897827
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5647576153278351, 'val_roc_auc': 0.8666666666666667, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5504859685897827}
 ROC_AUC: 0.8667|| Accuracy 0.6923 || Train Loss: 0.5648
 Val Loss: 0.5505 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.576237295071284
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5333333333333333
test_loss: 0.576237295071284
test_roc_auc: 0.7428571428571429
test_accuracy: 0.5333333333333333
eval_cid: 3
CPU Time: 726.706901 seconds
Elapsed Time: 863.3503701686859 seconds
RAM Usage: 0.3794288635253906 megabytes
Logs saved in current directory
F0000 00:00:1738997802.442825 1781413 thd.h:170] Check failed: state_ == FAILED 
*** Check failure stack trace: ***
