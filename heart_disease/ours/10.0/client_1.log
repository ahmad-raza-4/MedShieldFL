nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:42:21:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:42:21:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 22:42:21:DEBUG:ChannelConnectivity.IDLE
02/07/2025 22:42:21:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738996941.916234 1769754 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/07/2025 22:42:23:INFO:
[92mINFO [0m:      Received: train message 4c30cc5e-d53e-4df3-8ae1-80f297f176f4
02/07/2025 22:42:23:INFO:Received: train message 4c30cc5e-d53e-4df3-8ae1-80f297f176f4
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours/10.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours']
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.5152184804683202
Epoch 1/64:
  Train Loss: 0.7126141935586929
  Validation Loss: 0.7635477185249329
  Val ROC-AUC: 0.7416666666666666
  Val Accuracy: 0.65625
Epoch 2/64:
  Train Loss: 0.711466521024704
  Validation Loss: 0.7623528838157654
  Val ROC-AUC: 0.7458333333333333
  Val Accuracy: 0.65625
Epoch 3/64:
  Train Loss: 0.7103499174118042
  Validation Loss: 0.7611501216888428
  Val ROC-AUC: 0.75
  Val Accuracy: 0.65625
Epoch 4/64:
  Train Loss: 0.7092694789171219
  Validation Loss: 0.7598789930343628
  Val ROC-AUC: 0.7666666666666666
  Val Accuracy: 0.6875
Epoch 5/64:
  Train Loss: 0.7081061601638794
  Validation Loss: 0.7586040496826172
  Val ROC-AUC: 0.7666666666666666
  Val Accuracy: 0.6875
Epoch 6/64:
  Train Loss: 0.7069931030273438
  Validation Loss: 0.7574756741523743
  Val ROC-AUC: 0.7666666666666666
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.7059241384267807
  Validation Loss: 0.7563305497169495
  Val ROC-AUC: 0.7791666666666667
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.7049453556537628
  Validation Loss: 0.7552163600921631
  Val ROC-AUC: 0.7791666666666667
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.7039371728897095
  Validation Loss: 0.7540108561515808
  Val ROC-AUC: 0.7791666666666667
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.7029312402009964
  Validation Loss: 0.7528197765350342
  Val ROC-AUC: 0.7875
  Val Accuracy: 0.75
Epoch 11/64:
  Train Loss: 0.7020032703876495
  Validation Loss: 0.7516042590141296
  Val ROC-AUC: 0.7916666666666666
  Val Accuracy: 0.75
Epoch 12/64:
  Train Loss: 0.7010058909654617
  Validation Loss: 0.7504791021347046
  Val ROC-AUC: 0.7916666666666666
  Val Accuracy: 0.75
Epoch 13/64:
  Train Loss: 0.7001221626996994
  Validation Loss: 0.7493000030517578
  Val ROC-AUC: 0.7958333333333333
  Val Accuracy: 0.75
Epoch 14/64:
  Train Loss: 0.6992271244525909
  Validation Loss: 0.7481264472007751
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 15/64:
  Train Loss: 0.6982869207859039
  Validation Loss: 0.7470473051071167
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 16/64:
  Train Loss: 0.6974570900201797
  Validation Loss: 0.7459925413131714
  Val ROC-AUC: 0.8
  Val Accuracy: 0.78125
Epoch 17/64:
  Train Loss: 0.6965952962636948
  Validation Loss: 0.7449613809585571
  Val ROC-AUC: 0.8083333333333333
  Val Accuracy: 0.78125
Epoch 18/64:
  Train Loss: 0.695767804980278
  Validation Loss: 0.7439671754837036
  Val ROC-AUC: 0.8125
  Val Accuracy: 0.78125
Epoch 19/64:
  Train Loss: 0.6949926614761353
  Validation Loss: 0.7429758310317993
  Val ROC-AUC: 0.8125
  Val Accuracy: 0.78125
Epoch 20/64:
  Train Loss: 0.694132000207901
  Validation Loss: 0.7420637607574463
  Val ROC-AUC: 0.8166666666666667
  Val Accuracy: 0.78125
Epoch 21/64:
  Train Loss: 0.6933334320783615
  Validation Loss: 0.7411366701126099
  Val ROC-AUC: 0.8208333333333333
  Val Accuracy: 0.78125
Epoch 22/64:
  Train Loss: 0.6925233453512192
  Validation Loss: 0.7402000427246094
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.78125
Epoch 23/64:
  Train Loss: 0.6917726844549179
  Validation Loss: 0.7392645478248596
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.78125
Epoch 24/64:
  Train Loss: 0.6910368204116821
  Validation Loss: 0.7384090423583984
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.78125
Epoch 25/64:
  Train Loss: 0.6903852224349976
  Validation Loss: 0.7375544905662537
  Val ROC-AUC: 0.8291666666666667
  Val Accuracy: 0.78125
Epoch 26/64:
  Train Loss: 0.6897026747465134
  Validation Loss: 0.7366955876350403
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.78125
Epoch 27/64:
  Train Loss: 0.688988596200943
  Validation Loss: 0.7358114719390869
  Val ROC-AUC: 0.8375
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6882748007774353
  Validation Loss: 0.7349090576171875
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.687593936920166
  Validation Loss: 0.7340017557144165
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6869026571512222
  Validation Loss: 0.7331745624542236
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6862359493970871
  Validation Loss: 0.7323994040489197
  Val ROC-AUC: 0.8541666666666667
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6856303811073303
  Validation Loss: 0.7316710352897644
  Val ROC-AUC: 0.8541666666666667
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6850242465734482
  Validation Loss: 0.7309184670448303
  Val ROC-AUC: 0.8541666666666667
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6843973696231842
  Validation Loss: 0.7301762104034424
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.78125
Epoch 35/64:
  Train Loss: 0.6837608069181442
  Validation Loss: 0.7294825315475464
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.78125
Epoch 36/64:
  Train Loss: 0.6831613332033157
  Validation Loss: 0.7287507653236389
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.78125
Epoch 37/64:
  Train Loss: 0.6825713217258453
  Validation Loss: 0.7280087471008301
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.78125
Epoch 38/64:
  Train Loss: 0.681980550289154
  Validation Loss: 0.727287232875824
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.78125
Epoch 39/64:
  Train Loss: 0.6813633739948273
  Validation Loss: 0.7266117334365845
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.78125
Epoch 40/64:
  Train Loss: 0.6808480471372604
  Validation Loss: 0.7259737849235535
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6803115010261536
  Validation Loss: 0.7253366112709045
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6798471659421921
  Validation Loss: 0.7246956825256348
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6792924255132675
  Validation Loss: 0.7241195440292358
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.678839921951294
  Validation Loss: 0.7235689163208008
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.78125
Epoch 45/64:
  Train Loss: 0.6783340573310852
  Validation Loss: 0.723025918006897
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.6778796017169952
  Validation Loss: 0.722481906414032
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.6773712188005447
  Validation Loss: 0.7219233512878418
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6768992692232132
  Validation Loss: 0.7213375568389893
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.676431342959404
  Validation Loss: 0.7207411527633667
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6759845465421677
  Validation Loss: 0.7201563119888306
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6755708605051041
  Validation Loss: 0.7195899486541748
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.675147294998169
  Validation Loss: 0.7190581560134888
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6747835874557495
  Validation Loss: 0.7184892892837524
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.6743926405906677
  Validation Loss: 0.7179155945777893
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6739904433488846
  Validation Loss: 0.7173972725868225
  Val ROC-AUC: 0.8791666666666667
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:42:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:42:48:INFO:
[92mINFO [0m:      Received: evaluate message 3348926e-acc9-472d-9db1-95a2d07308fa
02/07/2025 22:42:48:INFO:Received: evaluate message 3348926e-acc9-472d-9db1-95a2d07308fa
[92mINFO [0m:      Sent reply
02/07/2025 22:42:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:42:53:INFO:
[92mINFO [0m:      Received: train message e77a49a5-115e-43db-a0de-4326242c3b3e
02/07/2025 22:42:53:INFO:Received: train message e77a49a5-115e-43db-a0de-4326242c3b3e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.673606812953949
  Validation Loss: 0.7169455289840698
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6732063293457031
  Validation Loss: 0.7164636254310608
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6728348881006241
  Validation Loss: 0.7159351110458374
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6723953187465668
  Validation Loss: 0.7153394222259521
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.671983614563942
  Validation Loss: 0.7147164344787598
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6715746819972992
  Validation Loss: 0.7141179442405701
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6712060272693634
  Validation Loss: 0.7135459780693054
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6707665920257568
  Validation Loss: 0.7130006551742554
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6704220473766327
  Validation Loss: 0.7125141620635986
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.78125
{'train_loss': 0.6704220473766327, 'val_roc_auc': 0.8833333333333333, 'val_accuracy': 0.78125, 'val_loss': 0.7125141620635986}
 ROC_AUC: 0.8833|| Accuracy 0.7812 || Train Loss: 0.6704
 Val Loss: 0.7125 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7233975586982874
Test ROC-AUC: 0.6655505952380953
Test Accuracy: 0.625
test_loss: 0.7233975586982874
test_roc_auc: 0.6655505952380953
test_accuracy: 0.625
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.40822017268510535
Epoch 1/64:
  Train Loss: 0.7113161981105804
  Validation Loss: 0.755617618560791
  Val ROC-AUC: 0.7124999999999999
  Val Accuracy: 0.59375
Epoch 2/64:
  Train Loss: 0.7102004289627075
  Validation Loss: 0.7544376850128174
  Val ROC-AUC: 0.7124999999999999
  Val Accuracy: 0.59375
Epoch 3/64:
  Train Loss: 0.7090744823217392
  Validation Loss: 0.75333172082901
  Val ROC-AUC: 0.725
  Val Accuracy: 0.625
Epoch 4/64:
  Train Loss: 0.7079607248306274
  Validation Loss: 0.7522308826446533
  Val ROC-AUC: 0.7291666666666667
  Val Accuracy: 0.625
Epoch 5/64:
  Train Loss: 0.7068526893854141
  Validation Loss: 0.7511430382728577
  Val ROC-AUC: 0.7333333333333333
  Val Accuracy: 0.625
Epoch 6/64:
  Train Loss: 0.7057500630617142
  Validation Loss: 0.7501577138900757
  Val ROC-AUC: 0.7458333333333333
  Val Accuracy: 0.625
Epoch 7/64:
  Train Loss: 0.7047705799341202
  Validation Loss: 0.7491251826286316
  Val ROC-AUC: 0.7541666666666667
  Val Accuracy: 0.625
Epoch 8/64:
  Train Loss: 0.7037601470947266
  Validation Loss: 0.7481399178504944
  Val ROC-AUC: 0.7666666666666666
  Val Accuracy: 0.625
Epoch 9/64:
  Train Loss: 0.7027585059404373
  Validation Loss: 0.747174084186554
  Val ROC-AUC: 0.7749999999999999
  Val Accuracy: 0.625
Epoch 10/64:
  Train Loss: 0.7017410546541214
  Validation Loss: 0.7462109327316284
  Val ROC-AUC: 0.7833333333333333
  Val Accuracy: 0.625
Epoch 11/64:
  Train Loss: 0.7007103562355042
  Validation Loss: 0.745235025882721
  Val ROC-AUC: 0.7875
  Val Accuracy: 0.625
Epoch 12/64:
  Train Loss: 0.6997354477643967
  Validation Loss: 0.7442750930786133
  Val ROC-AUC: 0.7875
  Val Accuracy: 0.625
Epoch 13/64:
  Train Loss: 0.6987226605415344
  Validation Loss: 0.7433173656463623
  Val ROC-AUC: 0.7875
  Val Accuracy: 0.625
Epoch 14/64:
  Train Loss: 0.6977250128984451
  Validation Loss: 0.7424108982086182
  Val ROC-AUC: 0.8
  Val Accuracy: 0.625
Epoch 15/64:
  Train Loss: 0.6967895925045013
  Validation Loss: 0.741542637348175
  Val ROC-AUC: 0.8083333333333333
  Val Accuracy: 0.625
Epoch 16/64:
  Train Loss: 0.6959690004587173
  Validation Loss: 0.740685224533081
  Val ROC-AUC: 0.8083333333333333
  Val Accuracy: 0.625
Epoch 17/64:
  Train Loss: 0.6950801610946655
  Validation Loss: 0.7398668527603149
  Val ROC-AUC: 0.8166666666666667
  Val Accuracy: 0.65625
Epoch 18/64:
  Train Loss: 0.6942496448755264
  Validation Loss: 0.7390375733375549
  Val ROC-AUC: 0.8208333333333333
  Val Accuracy: 0.65625
Epoch 19/64:
  Train Loss: 0.6934431940317154
  Validation Loss: 0.7381507158279419
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.65625
Epoch 20/64:
  Train Loss: 0.6925148814916611
  Validation Loss: 0.737328052520752
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.65625
Epoch 21/64:
  Train Loss: 0.6916917562484741
  Validation Loss: 0.7365199327468872
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.65625
Epoch 22/64:
  Train Loss: 0.6908407509326935
  Validation Loss: 0.7357049584388733
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 23/64:
  Train Loss: 0.6900105327367783
  Validation Loss: 0.7349594831466675
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 24/64:
  Train Loss: 0.6892506182193756
  Validation Loss: 0.7341983318328857
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 25/64:
  Train Loss: 0.6884459108114243
  Validation Loss: 0.7334541082382202
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 26/64:
  Train Loss: 0.6877021938562393
  Validation Loss: 0.7327110767364502
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 27/64:
  Train Loss: 0.6869511753320694
  Validation Loss: 0.7319799661636353
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 28/64:
  Train Loss: 0.686166301369667
  Validation Loss: 0.731273353099823
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 29/64:
  Train Loss: 0.6854911148548126
  Validation Loss: 0.7305371165275574
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 30/64:
  Train Loss: 0.6847225874662399
  Validation Loss: 0.7297844290733337
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 31/64:
  Train Loss: 0.6839871108531952
  Validation Loss: 0.7290765047073364
  Val ROC-AUC: 0.8374999999999999
  Val Accuracy: 0.65625
Epoch 32/64:
  Train Loss: 0.6832926273345947
  Validation Loss: 0.7283843755722046
  Val ROC-AUC: 0.8374999999999999
  Val Accuracy: 0.65625
Epoch 33/64:
  Train Loss: 0.682626873254776
  Validation Loss: 0.7277118563652039
  Val ROC-AUC: 0.8374999999999999
  Val Accuracy: 0.65625
Epoch 34/64:
  Train Loss: 0.6819786578416824
  Validation Loss: 0.7269942760467529
  Val ROC-AUC: 0.8374999999999999
  Val Accuracy: 0.6875
Epoch 35/64:
  Train Loss: 0.6813071668148041
  Validation Loss: 0.7263117432594299
  Val ROC-AUC: 0.8374999999999999
  Val Accuracy: 0.6875
Epoch 36/64:
  Train Loss: 0.6807080954313278
  Validation Loss: 0.7257204651832581
  Val ROC-AUC: 0.8416666666666667
  Val Accuracy: 0.6875
Epoch 37/64:
  Train Loss: 0.6801744848489761
  Validation Loss: 0.7251865863800049
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.6875
Epoch 38/64:
  Train Loss: 0.6796761304140091
  Validation Loss: 0.7246187329292297
  Val ROC-AUC: 0.85
  Val Accuracy: 0.6875
Epoch 39/64:
  Train Loss: 0.6791075468063354
  Validation Loss: 0.7240555882453918
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.6875
Epoch 40/64:
  Train Loss: 0.6785676926374435
  Validation Loss: 0.7234913110733032
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.6875
Epoch 41/64:
  Train Loss: 0.6779870390892029
  Validation Loss: 0.7229577302932739
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.6875
Epoch 42/64:
  Train Loss: 0.677460327744484
  Validation Loss: 0.7223513722419739
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.6875
Epoch 43/64:
  Train Loss: 0.6769274771213531
  Validation Loss: 0.7217462062835693
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6764030605554581
  Validation Loss: 0.7211641073226929
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6758257299661636
  Validation Loss: 0.7206296920776367
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.675340473651886
  Validation Loss: 0.7200875282287598
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:43:18:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:19:INFO:
[92mINFO [0m:      Received: evaluate message c96ebe03-d7dc-4528-a400-2974d8c9bdd8
02/07/2025 22:43:19:INFO:Received: evaluate message c96ebe03-d7dc-4528-a400-2974d8c9bdd8
[92mINFO [0m:      Sent reply
02/07/2025 22:43:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:23:INFO:
[92mINFO [0m:      Received: train message 56459cde-a601-4430-86a6-09b1d6a76b16
02/07/2025 22:43:23:INFO:Received: train message 56459cde-a601-4430-86a6-09b1d6a76b16
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.85
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6748197674751282
  Validation Loss: 0.7195539474487305
  Val ROC-AUC: 0.85
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6743487566709518
  Validation Loss: 0.718986988067627
  Val ROC-AUC: 0.8541666666666666
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6738905161619186
  Validation Loss: 0.718451976776123
  Val ROC-AUC: 0.8583333333333333
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6733900904655457
  Validation Loss: 0.7179092764854431
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6728839725255966
  Validation Loss: 0.7173563838005066
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6724201291799545
  Validation Loss: 0.716805636882782
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6719256788492203
  Validation Loss: 0.7162811756134033
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6714776903390884
  Validation Loss: 0.7158094644546509
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.671047568321228
  Validation Loss: 0.715340256690979
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.6706461906433105
  Validation Loss: 0.7148817181587219
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6702193021774292
  Validation Loss: 0.714455246925354
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.669821247458458
  Validation Loss: 0.7140152454376221
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.669392928481102
  Validation Loss: 0.7136081457138062
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.6689880043268204
  Validation Loss: 0.7132076025009155
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6686221957206726
  Validation Loss: 0.7127944231033325
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6682695746421814
  Validation Loss: 0.7123889327049255
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6678869277238846
  Validation Loss: 0.7120705842971802
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6675621420145035
  Validation Loss: 0.711696207523346
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.71875
{'train_loss': 0.6675621420145035, 'val_roc_auc': 0.8791666666666667, 'val_accuracy': 0.71875, 'val_loss': 0.711696207523346}
 ROC_AUC: 0.8792|| Accuracy 0.7188 || Train Loss: 0.6676
 Val Loss: 0.7117 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7192071747894471
Test ROC-AUC: 0.6960565476190476
Test Accuracy: 0.6442307692307693
test_loss: 0.7192071747894471
test_roc_auc: 0.6960565476190476
test_accuracy: 0.6442307692307693
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.3776589959670673
Epoch 1/64:
  Train Loss: 0.7178003340959549
  Validation Loss: 0.7100158333778381
  Val ROC-AUC: 0.63671875
  Val Accuracy: 0.5625
Epoch 2/64:
  Train Loss: 0.7164218723773956
  Validation Loss: 0.7091943025588989
  Val ROC-AUC: 0.63671875
  Val Accuracy: 0.5625
Epoch 3/64:
  Train Loss: 0.7151164412498474
  Validation Loss: 0.708288311958313
  Val ROC-AUC: 0.6484375
  Val Accuracy: 0.5625
Epoch 4/64:
  Train Loss: 0.7138786613941193
  Validation Loss: 0.7073605060577393
  Val ROC-AUC: 0.66015625
  Val Accuracy: 0.5625
Epoch 5/64:
  Train Loss: 0.7126670926809311
  Validation Loss: 0.7064738869667053
  Val ROC-AUC: 0.66796875
  Val Accuracy: 0.5625
Epoch 6/64:
  Train Loss: 0.7114657014608383
  Validation Loss: 0.7056172490119934
  Val ROC-AUC: 0.66796875
  Val Accuracy: 0.5625
Epoch 7/64:
  Train Loss: 0.7103200554847717
  Validation Loss: 0.7047904133796692
  Val ROC-AUC: 0.671875
  Val Accuracy: 0.5625
Epoch 8/64:
  Train Loss: 0.7092543393373489
  Validation Loss: 0.7039826512336731
  Val ROC-AUC: 0.67578125
  Val Accuracy: 0.5625
Epoch 9/64:
  Train Loss: 0.7081294357776642
  Validation Loss: 0.7031899094581604
  Val ROC-AUC: 0.6875
  Val Accuracy: 0.59375
Epoch 10/64:
  Train Loss: 0.7071123421192169
  Validation Loss: 0.7023746967315674
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.59375
Epoch 11/64:
  Train Loss: 0.7061382234096527
  Validation Loss: 0.7015618085861206
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.59375
Epoch 12/64:
  Train Loss: 0.7051073759794235
  Validation Loss: 0.7007960081100464
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.625
Epoch 13/64:
  Train Loss: 0.7040471881628036
  Validation Loss: 0.7000537514686584
  Val ROC-AUC: 0.69921875
  Val Accuracy: 0.65625
Epoch 14/64:
  Train Loss: 0.703001081943512
  Validation Loss: 0.6993224620819092
  Val ROC-AUC: 0.703125
  Val Accuracy: 0.65625
Epoch 15/64:
  Train Loss: 0.7020057290792465
  Validation Loss: 0.698570728302002
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.65625
Epoch 16/64:
  Train Loss: 0.7009651958942413
  Validation Loss: 0.6978626847267151
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.65625
Epoch 17/64:
  Train Loss: 0.7000640630722046
  Validation Loss: 0.6971661448478699
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.65625
Epoch 18/64:
  Train Loss: 0.699181392788887
  Validation Loss: 0.6964439153671265
  Val ROC-AUC: 0.70703125
  Val Accuracy: 0.65625
Epoch 19/64:
  Train Loss: 0.6982216686010361
  Validation Loss: 0.6957968473434448
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.65625
Epoch 20/64:
  Train Loss: 0.6973658949136734
  Validation Loss: 0.6951367855072021
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.65625
Epoch 21/64:
  Train Loss: 0.696538582444191
  Validation Loss: 0.694469690322876
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.65625
Epoch 22/64:
  Train Loss: 0.695714920759201
  Validation Loss: 0.6938356757164001
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.65625
Epoch 23/64:
  Train Loss: 0.6949115246534348
  Validation Loss: 0.6932268142700195
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.65625
Epoch 24/64:
  Train Loss: 0.6941435188055038
  Validation Loss: 0.6926229596138
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.65625
Epoch 25/64:
  Train Loss: 0.6933336704969406
  Validation Loss: 0.6920474767684937
  Val ROC-AUC: 0.71875
  Val Accuracy: 0.625
Epoch 26/64:
  Train Loss: 0.6926509141921997
  Validation Loss: 0.6915068626403809
  Val ROC-AUC: 0.7265625
  Val Accuracy: 0.65625
Epoch 27/64:
  Train Loss: 0.6919752061367035
  Validation Loss: 0.6909313797950745
  Val ROC-AUC: 0.7265625
  Val Accuracy: 0.625
Epoch 28/64:
  Train Loss: 0.6912441700696945
  Validation Loss: 0.6903538703918457
  Val ROC-AUC: 0.73046875
  Val Accuracy: 0.625
Epoch 29/64:
  Train Loss: 0.6905181556940079
  Validation Loss: 0.6898298263549805
  Val ROC-AUC: 0.73046875
  Val Accuracy: 0.625
Epoch 30/64:
  Train Loss: 0.6898375898599625
  Validation Loss: 0.6892969608306885
  Val ROC-AUC: 0.73046875
  Val Accuracy: 0.625
Epoch 31/64:
  Train Loss: 0.6892078369855881
  Validation Loss: 0.6887329816818237
  Val ROC-AUC: 0.734375
  Val Accuracy: 0.625
Epoch 32/64:
  Train Loss: 0.6885956674814224
  Validation Loss: 0.6881477236747742
  Val ROC-AUC: 0.73828125
  Val Accuracy: 0.625
Epoch 33/64:
  Train Loss: 0.6878611892461777
  Validation Loss: 0.6876094937324524
  Val ROC-AUC: 0.73828125
  Val Accuracy: 0.625
Epoch 34/64:
  Train Loss: 0.6872336268424988
  Validation Loss: 0.6870766878128052
  Val ROC-AUC: 0.73828125
  Val Accuracy: 0.625
Epoch 35/64:
  Train Loss: 0.6866140216588974
  Validation Loss: 0.6865772008895874
  Val ROC-AUC: 0.73828125
  Val Accuracy: 0.625
Epoch 36/64:
  Train Loss: 0.6860252320766449
  Validation Loss: 0.6860843896865845
  Val ROC-AUC: 0.734375
  Val Accuracy: 0.625
Epoch 37/64:
  Train Loss: 0.6854012757539749
  Validation Loss: 0.6855753064155579
  Val ROC-AUC: 0.734375
  Val Accuracy: 0.65625
Epoch 38/64:
  Train Loss: 0.6847699880599976
  Validation Loss: 0.6850804090499878
  Val ROC-AUC: 0.73828125
  Val Accuracy: 0.65625
Epoch 39/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:43:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:49:INFO:
[92mINFO [0m:      Received: evaluate message c8146165-0b8e-4029-9e95-efe89562ff39
02/07/2025 22:43:49:INFO:Received: evaluate message c8146165-0b8e-4029-9e95-efe89562ff39
[92mINFO [0m:      Sent reply
02/07/2025 22:43:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:53:INFO:
[92mINFO [0m:      Received: train message 77fbe085-9650-47e8-9cf0-cba1c305927f
02/07/2025 22:43:53:INFO:Received: train message 77fbe085-9650-47e8-9cf0-cba1c305927f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6841384172439575
  Validation Loss: 0.6845951080322266
  Val ROC-AUC: 0.73828125
  Val Accuracy: 0.65625
Epoch 40/64:
  Train Loss: 0.6835885047912598
  Validation Loss: 0.6841492056846619
  Val ROC-AUC: 0.74609375
  Val Accuracy: 0.65625
Epoch 41/64:
  Train Loss: 0.683075875043869
  Validation Loss: 0.6837432384490967
  Val ROC-AUC: 0.74609375
  Val Accuracy: 0.65625
Epoch 42/64:
  Train Loss: 0.6825853288173676
  Validation Loss: 0.6833322048187256
  Val ROC-AUC: 0.74609375
  Val Accuracy: 0.65625
Epoch 43/64:
  Train Loss: 0.6820785999298096
  Validation Loss: 0.6828883290290833
  Val ROC-AUC: 0.75390625
  Val Accuracy: 0.65625
Epoch 44/64:
  Train Loss: 0.6815927922725677
  Validation Loss: 0.682424783706665
  Val ROC-AUC: 0.7578125
  Val Accuracy: 0.65625
Epoch 45/64:
  Train Loss: 0.6810728013515472
  Validation Loss: 0.6819649934768677
  Val ROC-AUC: 0.75390625
  Val Accuracy: 0.65625
Epoch 46/64:
  Train Loss: 0.6804978102445602
  Validation Loss: 0.681520938873291
  Val ROC-AUC: 0.75390625
  Val Accuracy: 0.65625
Epoch 47/64:
  Train Loss: 0.6799917966127396
  Validation Loss: 0.6810685992240906
  Val ROC-AUC: 0.7578125
  Val Accuracy: 0.65625
Epoch 48/64:
  Train Loss: 0.6794188320636749
  Validation Loss: 0.6806454658508301
  Val ROC-AUC: 0.7578125
  Val Accuracy: 0.65625
Epoch 49/64:
  Train Loss: 0.6789074093103409
  Validation Loss: 0.6802412271499634
  Val ROC-AUC: 0.7578125
  Val Accuracy: 0.6875
Epoch 50/64:
  Train Loss: 0.6784613132476807
  Validation Loss: 0.6798297166824341
  Val ROC-AUC: 0.7578125
  Val Accuracy: 0.6875
Epoch 51/64:
  Train Loss: 0.6780026257038116
  Validation Loss: 0.6794491410255432
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 52/64:
  Train Loss: 0.6775841861963272
  Validation Loss: 0.6790789365768433
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 53/64:
  Train Loss: 0.6771864593029022
  Validation Loss: 0.6786907911300659
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 54/64:
  Train Loss: 0.676781639456749
  Validation Loss: 0.6783140897750854
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 55/64:
  Train Loss: 0.676389753818512
  Validation Loss: 0.6779377460479736
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 56/64:
  Train Loss: 0.676000565290451
  Validation Loss: 0.6775662899017334
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 57/64:
  Train Loss: 0.675612598657608
  Validation Loss: 0.6771891117095947
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 58/64:
  Train Loss: 0.6752335131168365
  Validation Loss: 0.6768742799758911
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 59/64:
  Train Loss: 0.6749226599931717
  Validation Loss: 0.6765459775924683
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 60/64:
  Train Loss: 0.674578994512558
  Validation Loss: 0.6762092113494873
  Val ROC-AUC: 0.765625
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.674235537648201
  Validation Loss: 0.6758537292480469
  Val ROC-AUC: 0.7734375
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6738797575235367
  Validation Loss: 0.6755399107933044
  Val ROC-AUC: 0.7734375
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6736358106136322
  Validation Loss: 0.6751995086669922
  Val ROC-AUC: 0.7734375
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6732905358076096
  Validation Loss: 0.6748647093772888
  Val ROC-AUC: 0.7734375
  Val Accuracy: 0.71875
{'train_loss': 0.6732905358076096, 'val_roc_auc': 0.7734375, 'val_accuracy': 0.71875, 'val_loss': 0.6748647093772888}
 ROC_AUC: 0.7734|| Accuracy 0.7188 || Train Loss: 0.6733
 Val Loss: 0.6749 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.714460845463551
Test ROC-AUC: 0.7220982142857143
Test Accuracy: 0.6346153846153846
test_loss: 0.714460845463551
test_roc_auc: 0.7220982142857143
test_accuracy: 0.6346153846153846
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.4620851877552923
Epoch 1/64:
  Train Loss: 0.7163933962583542
  Validation Loss: 0.6938775777816772
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.7151412814855576
  Validation Loss: 0.6932470798492432
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 3/64:
  Train Loss: 0.7138597518205643
  Validation Loss: 0.692615270614624
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 4/64:
  Train Loss: 0.7127412408590317
  Validation Loss: 0.6920524835586548
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 5/64:
  Train Loss: 0.7116397023200989
  Validation Loss: 0.6915138363838196
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 6/64:
  Train Loss: 0.7105941921472549
  Validation Loss: 0.6909427046775818
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 7/64:
  Train Loss: 0.7095373421907425
  Validation Loss: 0.6904401779174805
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.7084669470787048
  Validation Loss: 0.6899679899215698
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.7074687331914902
  Validation Loss: 0.6894646883010864
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.7064506113529205
  Validation Loss: 0.6889160871505737
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.7054225951433182
  Validation Loss: 0.6884475946426392
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.704474076628685
  Validation Loss: 0.6880066394805908
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.7035333961248398
  Validation Loss: 0.6875835657119751
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.7025588154792786
  Validation Loss: 0.6871432065963745
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.7016397416591644
  Validation Loss: 0.6866981983184814
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.70069719851017
  Validation Loss: 0.6863020658493042
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6997886747121811
  Validation Loss: 0.6859310865402222
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6988753825426102
  Validation Loss: 0.6855497360229492
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6980209499597549
  Validation Loss: 0.6851745247840881
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6971113979816437
  Validation Loss: 0.6848648190498352
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.696384385228157
  Validation Loss: 0.6845700740814209
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.695570781826973
  Validation Loss: 0.6841837167739868
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6947966814041138
  Validation Loss: 0.6837902069091797
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 24/64:
  Train Loss: 0.6939858347177505
  Validation Loss: 0.6834350824356079
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 25/64:
  Train Loss: 0.6933078169822693
  Validation Loss: 0.6831308007240295
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 26/64:
  Train Loss: 0.6925473064184189
  Validation Loss: 0.6828064918518066
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 27/64:
  Train Loss: 0.6918249577283859
  Validation Loss: 0.6824511289596558
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6910572350025177
  Validation Loss: 0.682108461856842
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6903577893972397
  Validation Loss: 0.6817524433135986
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6895433068275452
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:44:17:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:18:INFO:
[92mINFO [0m:      Received: evaluate message afe091e5-740d-430f-92ef-64c844159481
02/07/2025 22:44:18:INFO:Received: evaluate message afe091e5-740d-430f-92ef-64c844159481
[92mINFO [0m:      Sent reply
02/07/2025 22:44:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:22:INFO:
[92mINFO [0m:      Received: train message 5249c448-2b82-48e1-a7f8-97bfec082eb4
02/07/2025 22:44:22:INFO:Received: train message 5249c448-2b82-48e1-a7f8-97bfec082eb4
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6814234256744385
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6888762712478638
  Validation Loss: 0.6811215877532959
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6881994605064392
  Validation Loss: 0.6808162331581116
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6874762624502182
  Validation Loss: 0.6805135607719421
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6867994964122772
  Validation Loss: 0.6801854372024536
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.686171293258667
  Validation Loss: 0.6798786520957947
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.6855752021074295
  Validation Loss: 0.6795973777770996
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.684933215379715
  Validation Loss: 0.6792517900466919
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.684270590543747
  Validation Loss: 0.6789370775222778
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6837051510810852
  Validation Loss: 0.6786576509475708
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6831042319536209
  Validation Loss: 0.6783934831619263
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6825253516435623
  Validation Loss: 0.678147554397583
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6819484233856201
  Validation Loss: 0.6779271960258484
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6813933104276657
  Validation Loss: 0.6777284145355225
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6809145957231522
  Validation Loss: 0.6775563955307007
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6804375350475311
  Validation Loss: 0.6773626804351807
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6799557656049728
  Validation Loss: 0.6771815419197083
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6794270277023315
  Validation Loss: 0.6770249605178833
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6789614409208298
  Validation Loss: 0.6768791675567627
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6784931570291519
  Validation Loss: 0.676743745803833
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6779730319976807
  Validation Loss: 0.6765493154525757
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6774786710739136
  Validation Loss: 0.676354169845581
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6770927011966705
  Validation Loss: 0.6761939525604248
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6766708046197891
  Validation Loss: 0.6760290861129761
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6762570738792419
  Validation Loss: 0.6758196949958801
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6758323162794113
  Validation Loss: 0.6756241917610168
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6754317432641983
  Validation Loss: 0.6754768490791321
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6750413328409195
  Validation Loss: 0.6753063797950745
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6746647357940674
  Validation Loss: 0.6750811338424683
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6742910295724869
  Validation Loss: 0.6749210953712463
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6739344298839569
  Validation Loss: 0.6747454404830933
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.67354916036129
  Validation Loss: 0.6745620369911194
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.673226997256279
  Validation Loss: 0.6743959188461304
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6728861033916473
  Validation Loss: 0.6742795705795288
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6725475788116455
  Validation Loss: 0.6741777658462524
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.78125
{'train_loss': 0.6725475788116455, 'val_roc_auc': 0.8431372549019608, 'val_accuracy': 0.78125, 'val_loss': 0.6741777658462524}
 ROC_AUC: 0.8431|| Accuracy 0.7812 || Train Loss: 0.6725
 Val Loss: 0.6742 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7094457946144618
Test ROC-AUC: 0.7514880952380952
Test Accuracy: 0.6538461538461539
test_loss: 0.7094457946144618
test_roc_auc: 0.7514880952380952
test_accuracy: 0.6538461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.5801341394180781
Epoch 1/64:
  Train Loss: 0.711188942193985
  Validation Loss: 0.6921340823173523
  Val ROC-AUC: 0.8196078431372549
  Val Accuracy: 0.6875
Epoch 2/64:
  Train Loss: 0.7101815938949585
  Validation Loss: 0.6914517879486084
  Val ROC-AUC: 0.8196078431372549
  Val Accuracy: 0.6875
Epoch 3/64:
  Train Loss: 0.7091863006353378
  Validation Loss: 0.6907063722610474
  Val ROC-AUC: 0.8235294117647058
  Val Accuracy: 0.6875
Epoch 4/64:
  Train Loss: 0.7081087827682495
  Validation Loss: 0.6899603605270386
  Val ROC-AUC: 0.8235294117647058
  Val Accuracy: 0.6875
Epoch 5/64:
  Train Loss: 0.7071437835693359
  Validation Loss: 0.6892577409744263
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.6875
Epoch 6/64:
  Train Loss: 0.7061683833599091
  Validation Loss: 0.6886686682701111
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.7052008211612701
  Validation Loss: 0.6880521774291992
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.6875
Epoch 8/64:
  Train Loss: 0.7043051868677139
  Validation Loss: 0.6874181032180786
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.6875
Epoch 9/64:
  Train Loss: 0.7033925950527191
  Validation Loss: 0.6867966055870056
  Val ROC-AUC: 0.8392156862745099
  Val Accuracy: 0.6875
Epoch 10/64:
  Train Loss: 0.702551543712616
  Validation Loss: 0.6861797571182251
  Val ROC-AUC: 0.8392156862745099
  Val Accuracy: 0.6875
Epoch 11/64:
  Train Loss: 0.7016976773738861
  Validation Loss: 0.6855669617652893
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.6875
Epoch 12/64:
  Train Loss: 0.7008528560400009
  Validation Loss: 0.6850013732910156
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.6875
Epoch 13/64:
  Train Loss: 0.7000540643930435
  Validation Loss: 0.6844496130943298
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.6875
Epoch 14/64:
  Train Loss: 0.6992597877979279
  Validation Loss: 0.6838721036911011
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.6875
Epoch 15/64:
  Train Loss: 0.698425829410553
  Validation Loss: 0.6832877397537231
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 16/64:
  Train Loss: 0.6976418644189835
  Validation Loss: 0.6827309131622314
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 17/64:
  Train Loss: 0.6969335228204727
  Validation Loss: 0.682163417339325
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 18/64:
  Train Loss: 0.696151539683342
  Validation Loss: 0.681611955165863
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 19/64:
  Train Loss: 0.6954379230737686
  Validation Loss: 0.6810849905014038
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 20/64:
  Train Loss: 0.69466832280159
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:44:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:50:INFO:
[92mINFO [0m:      Received: evaluate message b001511e-6bb8-4345-876c-1249643f9cf8
02/07/2025 22:44:50:INFO:Received: evaluate message b001511e-6bb8-4345-876c-1249643f9cf8
[92mINFO [0m:      Sent reply
02/07/2025 22:44:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:53:INFO:
[92mINFO [0m:      Received: train message e1fd9dd2-147d-4faa-a751-132ff798ae2e
02/07/2025 22:44:53:INFO:Received: train message e1fd9dd2-147d-4faa-a751-132ff798ae2e
  Validation Loss: 0.6805849671363831
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 21/64:
  Train Loss: 0.6939632445573807
  Validation Loss: 0.6800583004951477
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.6875
Epoch 22/64:
  Train Loss: 0.6932638138532639
  Validation Loss: 0.6795088052749634
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.6875
Epoch 23/64:
  Train Loss: 0.6925203949213028
  Validation Loss: 0.6789312362670898
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.6875
Epoch 24/64:
  Train Loss: 0.6917701363563538
  Validation Loss: 0.6783908605575562
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.6875
Epoch 25/64:
  Train Loss: 0.6911063492298126
  Validation Loss: 0.6778839230537415
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6904387027025223
  Validation Loss: 0.6773672103881836
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6897841691970825
  Validation Loss: 0.676925003528595
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6891657263040543
  Validation Loss: 0.676461398601532
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6884946674108505
  Validation Loss: 0.6760212182998657
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.6878575384616852
  Validation Loss: 0.6756361126899719
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6873352825641632
  Validation Loss: 0.6752274036407471
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6867115795612335
  Validation Loss: 0.6748541593551636
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6861913353204727
  Validation Loss: 0.6745234727859497
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6856338977813721
  Validation Loss: 0.674179196357727
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6851092725992203
  Validation Loss: 0.6737842559814453
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6845702528953552
  Validation Loss: 0.6734288334846497
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6840441673994064
  Validation Loss: 0.6731050610542297
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6835412383079529
  Validation Loss: 0.6727877855300903
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6830582320690155
  Validation Loss: 0.6724657416343689
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6825787574052811
  Validation Loss: 0.6721717119216919
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6821683645248413
  Validation Loss: 0.6718654036521912
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6817080080509186
  Validation Loss: 0.6715101599693298
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6812073141336441
  Validation Loss: 0.6711478233337402
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6807937175035477
  Validation Loss: 0.6708078980445862
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6803474128246307
  Validation Loss: 0.6704673767089844
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6798809170722961
  Validation Loss: 0.670106828212738
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6794615536928177
  Validation Loss: 0.6697747707366943
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6790360659360886
  Validation Loss: 0.6694638729095459
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6786452084779739
  Validation Loss: 0.6691445112228394
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6782397478818893
  Validation Loss: 0.6688218116760254
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6778287440538406
  Validation Loss: 0.668488621711731
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6774248033761978
  Validation Loss: 0.6681751012802124
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6770168989896774
  Validation Loss: 0.6678428649902344
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.6766132414340973
  Validation Loss: 0.6675419807434082
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6761856377124786
  Validation Loss: 0.6672124862670898
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6757360547780991
  Validation Loss: 0.6669082641601562
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.675347164273262
  Validation Loss: 0.6666268110275269
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6749687790870667
  Validation Loss: 0.6663443446159363
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6745836138725281
  Validation Loss: 0.666091799736023
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6742385923862457
  Validation Loss: 0.6658536195755005
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6739005446434021
  Validation Loss: 0.6656581163406372
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6736050546169281
  Validation Loss: 0.6654655337333679
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6733089685440063
  Validation Loss: 0.6653225421905518
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.673052191734314
  Validation Loss: 0.6651847958564758
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.78125
{'train_loss': 0.673052191734314, 'val_roc_auc': 0.8509803921568628, 'val_accuracy': 0.78125, 'val_loss': 0.6651847958564758}
 ROC_AUC: 0.8510|| Accuracy 0.7812 || Train Loss: 0.6731
 Val Loss: 0.6652 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7042591508764487
Test ROC-AUC: 0.7730654761904762
Test Accuracy: 0.6730769230769231
test_loss: 0.7042591508764487
test_roc_auc: 0.7730654761904762
test_accuracy: 0.6730769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.56421767862048
Epoch 1/64:
  Train Loss: 0.6917519122362137
  Validation Loss: 0.7484923601150513
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.625
Epoch 2/64:
  Train Loss: 0.6907596588134766
  Validation Loss: 0.7479104995727539
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.625
Epoch 3/64:
  Train Loss: 0.6897729188203812
  Validation Loss: 0.7473949193954468
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.625
Epoch 4/64:
  Train Loss: 0.6887118965387344
  Validation Loss: 0.7468963861465454
  Val ROC-AUC: 0.7530364372469637
  Val Accuracy: 0.625
Epoch 5/64:
  Train Loss: 0.6877435594797134
  Validation Loss: 0.7464323043823242
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.625
Epoch 6/64:
  Train Loss: 0.6866710931062698
  Validation Loss: 0.7460318207740784
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.625
Epoch 7/64:
  Train Loss: 0.6857565492391586
  Validation Loss: 0.745580792427063
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.625
Epoch 8/64:
  Train Loss: 0.6847818493843079
  Validation Loss: 0.7451459765434265
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.625
Epoch 9/64:
  Train Loss: 0.6838448941707611
  Validation Loss: 0.7447272539138794
  Val ROC-AUC: 0.757085020242915
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:20:INFO:
[92mINFO [0m:      Received: evaluate message 77b7c3b0-1326-42c6-abaa-b83292eae1ab
02/07/2025 22:45:20:INFO:Received: evaluate message 77b7c3b0-1326-42c6-abaa-b83292eae1ab
[92mINFO [0m:      Sent reply
02/07/2025 22:45:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:22:INFO:
[92mINFO [0m:      Received: train message e99f7d6a-b180-45a5-be27-a6bbd49304f1
02/07/2025 22:45:22:INFO:Received: train message e99f7d6a-b180-45a5-be27-a6bbd49304f1
  Val Accuracy: 0.625
Epoch 10/64:
  Train Loss: 0.6829464137554169
  Validation Loss: 0.7442848086357117
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.625
Epoch 11/64:
  Train Loss: 0.682095929980278
  Validation Loss: 0.7438795566558838
  Val ROC-AUC: 0.7489878542510121
  Val Accuracy: 0.625
Epoch 12/64:
  Train Loss: 0.6811578571796417
  Validation Loss: 0.7435226440429688
  Val ROC-AUC: 0.7489878542510121
  Val Accuracy: 0.625
Epoch 13/64:
  Train Loss: 0.6803447008132935
  Validation Loss: 0.7431434392929077
  Val ROC-AUC: 0.7489878542510121
  Val Accuracy: 0.625
Epoch 14/64:
  Train Loss: 0.6794547736644745
  Validation Loss: 0.74272620677948
  Val ROC-AUC: 0.7489878542510121
  Val Accuracy: 0.625
Epoch 15/64:
  Train Loss: 0.6786690354347229
  Validation Loss: 0.7422963380813599
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.625
Epoch 16/64:
  Train Loss: 0.6778667271137238
  Validation Loss: 0.7418954968452454
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.625
Epoch 17/64:
  Train Loss: 0.6770384460687637
  Validation Loss: 0.7415141463279724
  Val ROC-AUC: 0.7611336032388664
  Val Accuracy: 0.625
Epoch 18/64:
  Train Loss: 0.6761424243450165
  Validation Loss: 0.7411623001098633
  Val ROC-AUC: 0.7611336032388664
  Val Accuracy: 0.625
Epoch 19/64:
  Train Loss: 0.6754257380962372
  Validation Loss: 0.7407630681991577
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.625
Epoch 20/64:
  Train Loss: 0.674593523144722
  Validation Loss: 0.7403701543807983
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.625
Epoch 21/64:
  Train Loss: 0.6738489121198654
  Validation Loss: 0.739998996257782
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.625
Epoch 22/64:
  Train Loss: 0.6731018573045731
  Validation Loss: 0.7395926713943481
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.625
Epoch 23/64:
  Train Loss: 0.6723947674036026
  Validation Loss: 0.7391786575317383
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.65625
Epoch 24/64:
  Train Loss: 0.6717221885919571
  Validation Loss: 0.7388147711753845
  Val ROC-AUC: 0.7570850202429149
  Val Accuracy: 0.65625
Epoch 25/64:
  Train Loss: 0.6710491925477982
  Validation Loss: 0.7384587526321411
  Val ROC-AUC: 0.7570850202429149
  Val Accuracy: 0.65625
Epoch 26/64:
  Train Loss: 0.6703491359949112
  Validation Loss: 0.7381551861763
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 27/64:
  Train Loss: 0.6696741729974747
  Validation Loss: 0.7378614544868469
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 28/64:
  Train Loss: 0.6690565347671509
  Validation Loss: 0.7375633716583252
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 29/64:
  Train Loss: 0.668374240398407
  Validation Loss: 0.7372499108314514
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 30/64:
  Train Loss: 0.6678005307912827
  Validation Loss: 0.7369237542152405
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.65625
Epoch 31/64:
  Train Loss: 0.6671797335147858
  Validation Loss: 0.7365866303443909
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 32/64:
  Train Loss: 0.666667714715004
  Validation Loss: 0.7362302541732788
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 33/64:
  Train Loss: 0.6660856902599335
  Validation Loss: 0.7359039783477783
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 34/64:
  Train Loss: 0.6655220687389374
  Validation Loss: 0.7356418371200562
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 35/64:
  Train Loss: 0.6650654673576355
  Validation Loss: 0.7354060411453247
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.6875
Epoch 36/64:
  Train Loss: 0.6646183729171753
  Validation Loss: 0.7351208329200745
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.6875
Epoch 37/64:
  Train Loss: 0.6641133278608322
  Validation Loss: 0.7348343133926392
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.6875
Epoch 38/64:
  Train Loss: 0.6636374443769455
  Validation Loss: 0.7345337867736816
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.6875
Epoch 39/64:
  Train Loss: 0.663215309381485
  Validation Loss: 0.7342734336853027
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.6875
Epoch 40/64:
  Train Loss: 0.6627545803785324
  Validation Loss: 0.7340457439422607
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.6875
Epoch 41/64:
  Train Loss: 0.6623625010251999
  Validation Loss: 0.733859121799469
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.6875
Epoch 42/64:
  Train Loss: 0.6619808673858643
  Validation Loss: 0.7336543798446655
  Val ROC-AUC: 0.7732793522267206
  Val Accuracy: 0.6875
Epoch 43/64:
  Train Loss: 0.6616456806659698
  Validation Loss: 0.7334498167037964
  Val ROC-AUC: 0.7732793522267206
  Val Accuracy: 0.6875
Epoch 44/64:
  Train Loss: 0.6612772941589355
  Validation Loss: 0.7332437634468079
  Val ROC-AUC: 0.7732793522267206
  Val Accuracy: 0.6875
Epoch 45/64:
  Train Loss: 0.6608957797288895
  Validation Loss: 0.7330501079559326
  Val ROC-AUC: 0.7732793522267206
  Val Accuracy: 0.6875
Epoch 46/64:
  Train Loss: 0.66054567694664
  Validation Loss: 0.7328652143478394
  Val ROC-AUC: 0.7732793522267206
  Val Accuracy: 0.6875
Epoch 47/64:
  Train Loss: 0.6601113528013229
  Validation Loss: 0.7327377796173096
  Val ROC-AUC: 0.777327935222672
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6597186475992203
  Validation Loss: 0.7325899004936218
  Val ROC-AUC: 0.7732793522267207
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6593352854251862
  Validation Loss: 0.732394278049469
  Val ROC-AUC: 0.7732793522267207
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6589263528585434
  Validation Loss: 0.7322084903717041
  Val ROC-AUC: 0.7732793522267207
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6585670560598373
  Validation Loss: 0.7320495843887329
  Val ROC-AUC: 0.7732793522267207
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.658217191696167
  Validation Loss: 0.731928825378418
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6578381508588791
  Validation Loss: 0.7318223714828491
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6574427932500839
  Validation Loss: 0.7316769957542419
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6571460217237473
  Validation Loss: 0.7315553426742554
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6568345427513123
  Validation Loss: 0.731397271156311
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6565099954605103
  Validation Loss: 0.7312049865722656
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6562043279409409
  Validation Loss: 0.73103266954422
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6559197157621384
  Validation Loss: 0.7308427691459656
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6556381434202194
  Validation Loss: 0.7306630611419678
  Val ROC-AUC: 0.7611336032388664
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6553744673728943
  Validation Loss: 0.7304871082305908
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6551161259412766
  Validation Loss: 0.7302627563476562
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6548510193824768
  Validation Loss: 0.7300746440887451
  Val ROC-AUC: 0.7611336032388664
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6545514315366745
  Validation Loss: 0.7299089431762695
  Val ROC-AUC: 0.7611336032388664
  Val Accuracy: 0.75
{'train_loss': 0.6545514315366745, 'val_roc_auc': 0.7611336032388664, 'val_accuracy': 0.75, 'val_loss': 0.7299089431762695}
 ROC_AUC: 0.7611|| Accuracy 0.7500 || Train Loss: 0.6546
 Val Loss: 0.7299 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.699017964876615
Test ROC-AUC: 0.7972470238095238
Test Accuracy: 0.7115384615384616
test_loss: 0.699017964876615
test_roc_auc: 0.7972470238095238
test_accuracy: 0.7115384615384616
eval_cid: 0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.5320688241772586
Epoch 1/64:
  Train Loss: 0.6997008472681046
  Validation Loss: 0.6946090459823608
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 2/64:
  Train Loss: 0.6988089680671692
  Validation Loss: 0.6940096616744995
  Val ROC-AUC: 0.8392156862745097
  Val Accuracy: 0.6875
Epoch 3/64:
  Train Loss: 0.6979713886976242
  Validation Loss: 0.6934163570404053
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.6875
Epoch 4/64:
  Train Loss: 0.6971213072538376
  Validation Loss: 0.6928126215934753
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.6875
Epoch 5/64:
  Train Loss: 0.6962962299585342
  Validation Loss: 0.6921885013580322
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.6875
Epoch 6/64:
  Train Loss: 0.6954566687345505
  Validation Loss: 0.6916442513465881
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.6947043389081955
  Validation Loss: 0.6911380887031555
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.6875
Epoch 8/64:
  Train Loss: 0.6939078718423843
  Validation Loss: 0.6906310319900513
  Val ROC-AUC: 0.8549019607843137
  Val Accuracy: 0.6875
Epoch 9/64:
  Train Loss: 0.693105936050415
  Validation Loss: 0.6901363730430603
  Val ROC-AUC: 0.8549019607843137
  Val Accuracy: 0.6875
Epoch 10/64:
  Train Loss: 0.692323848605156
  Validation Loss: 0.6896332502365112
  Val ROC-AUC: 0.8549019607843137
  Val Accuracy: 0.6875
Epoch 11/64:
  Train Loss: 0.6915345638990402
  Validation Loss: 0.6891380548477173
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.6875
Epoch 12/64:
  Train Loss: 0.6907237321138382
  Validation Loss: 0.6886162757873535
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.6875
Epoch 13/64:
  Train Loss: 0.6899802088737488
  Validation Loss: 0.6880776286125183
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.6875
Epoch 14/64:
  Train Loss: 0.6892483979463577
  Validation Loss: 0.687586784362793
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.6875
Epoch 15/64:
  Train Loss: 0.6886180639266968
  Validation Loss: 0.687078595161438
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.6875
Epoch 16/64:
  Train Loss: 0.687968447804451
  Validation Loss: 0.6865979433059692
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.6875
Epoch 17/64:
  Train Loss: 0.6872934103012085
  Validation Loss: 0.6860960721969604
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.6875
Epoch 18/64:
  Train Loss: 0.6866112053394318
  Validation Loss: 0.6856238842010498
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.6875
Epoch 19/64:
  Train Loss: 0.6859263926744461
  Validation Loss: 0.6852047443389893
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.6875
Epoch 20/64:
  Train Loss: 0.6853109002113342
  Validation Loss: 0.6848307847976685
  Val ROC-AUC: 0.8431372549019607
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6847772896289825
  Validation Loss: 0.6844525337219238
  Val ROC-AUC: 0.8431372549019607
  Val Accuracy: 0.6875
Epoch 22/64:
  Train Loss: 0.6842216104269028
  Validation Loss: 0.6840832233428955
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6836594492197037
  Validation Loss: 0.6837329268455505
  Val ROC-AUC: 0.8549019607843137
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.683129221200943
  Validation Loss: 0.6833761930465698
  Val ROC-AUC: 0.8549019607843137
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.682551920413971
  Validation Loss: 0.6829842329025269
  Val ROC-AUC: 0.8549019607843137
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6820321679115295
  Validation Loss: 0.6826144456863403
  Val ROC-AUC: 0.8549019607843137
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6814921647310257
  Validation Loss: 0.6821963787078857
  Val ROC-AUC: 0.8549019607843137
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.680970773100853
  Validation Loss: 0.6817549467086792
  Val ROC-AUC: 0.8549019607843137
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6804255992174149
  Validation Loss: 0.6813399195671082
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6798956990242004
  Validation Loss: 0.6809607148170471
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6793962866067886
  Validation Loss: 0.6805827021598816
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6789378970861435
  Validation Loss: 0.6802570819854736
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6784795820713043
  Validation Loss: 0.6799123883247375
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6780059337615967
  Validation Loss: 0.6795544624328613
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.677587553858757
  Validation Loss: 0.6791796684265137
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.6771882921457291
  Validation Loss: 0.6788355708122253
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.6767498254776001
  Validation Loss: 0.6784972548484802
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6763087958097458
  Validation Loss: 0.6781098246574402
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6758744269609451
  Validation Loss: 0.6777428388595581
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6754289120435715
  Validation Loss: 0.677434504032135
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6750592440366745
  Validation Loss: 0.6771398782730103
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6746594309806824
  Validation Loss: 0.6768890023231506
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6742711663246155
  Validation Loss: 0.6766155362129211
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6739088892936707
  Validation Loss: 0.6762989163398743
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.78125
Epoch 45/64:
  Train Loss: 0.6735358834266663
  Validation Loss: 0.675994336605072
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.6731423437595367
  Validation Loss: 0.6757070422172546
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.672699049115181
  Validation Loss: 0.675365686416626
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6722913384437561
  Validation Loss: 0.6750541925430298
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.6719139069318771
  Validation Loss: 0.6747905015945435
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6715311408042908
  Validation Loss: 0.6745664477348328
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6712475419044495
  Validation Loss: 0.6743350028991699
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6709249466657639
  Validation Loss: 0.6740779280662537
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.670590877532959
  Validation Loss: 0.6738842725753784
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.6703076809644699
  Validation Loss: 0.6736347675323486
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6699746549129486
  Validation Loss: 0.6734124422073364
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6696546971797943
  Validation Loss: 0.6731984615325928
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6693865656852722
  Validation Loss: 0.6729398369789124
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.75
Epoch 58/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:50:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:50:INFO:
[92mINFO [0m:      Received: evaluate message ac70ab53-9802-42f7-a885-1d38559cf061
02/07/2025 22:45:50:INFO:Received: evaluate message ac70ab53-9802-42f7-a885-1d38559cf061
[92mINFO [0m:      Sent reply
02/07/2025 22:45:52:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:52:INFO:
[92mINFO [0m:      Received: train message 31bb888d-898e-464f-9b23-5d6cf09dfb5e
02/07/2025 22:45:52:INFO:Received: train message 31bb888d-898e-464f-9b23-5d6cf09dfb5e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6690928488969803
  Validation Loss: 0.6727216243743896
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6688366383314133
  Validation Loss: 0.6725251078605652
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.668588399887085
  Validation Loss: 0.6723791360855103
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6683625280857086
  Validation Loss: 0.6722198724746704
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.668136939406395
  Validation Loss: 0.6720623970031738
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6678607016801834
  Validation Loss: 0.6719155311584473
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6675839871168137
  Validation Loss: 0.6717771291732788
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
{'train_loss': 0.6675839871168137, 'val_roc_auc': 0.8784313725490196, 'val_accuracy': 0.75, 'val_loss': 0.6717771291732788}
 ROC_AUC: 0.8784|| Accuracy 0.7500 || Train Loss: 0.6676
 Val Loss: 0.6718 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6938484199345112
Test ROC-AUC: 0.8169642857142857
Test Accuracy: 0.75
test_loss: 0.6938484199345112
test_roc_auc: 0.8169642857142857
test_accuracy: 0.75
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.5800424881817889
Epoch 1/64:
  Train Loss: 0.7006610929965973
  Validation Loss: 0.6696484088897705
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.75
Epoch 2/64:
  Train Loss: 0.6997149884700775
  Validation Loss: 0.6690100431442261
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.75
Epoch 3/64:
  Train Loss: 0.6988086104393005
  Validation Loss: 0.6684145927429199
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.75
Epoch 4/64:
  Train Loss: 0.6980014592409134
  Validation Loss: 0.6678760051727295
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 5/64:
  Train Loss: 0.6971748620271683
  Validation Loss: 0.6673930287361145
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.75
Epoch 6/64:
  Train Loss: 0.6964198797941208
  Validation Loss: 0.6668816208839417
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.75
Epoch 7/64:
  Train Loss: 0.6956416666507721
  Validation Loss: 0.666329026222229
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 8/64:
  Train Loss: 0.6948233544826508
  Validation Loss: 0.6658414006233215
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 9/64:
  Train Loss: 0.694177433848381
  Validation Loss: 0.6653069853782654
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.75
Epoch 10/64:
  Train Loss: 0.6934355050325394
  Validation Loss: 0.6648304462432861
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6928209364414215
  Validation Loss: 0.664389431476593
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.692167729139328
  Validation Loss: 0.663986325263977
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6915525645017624
  Validation Loss: 0.6635875105857849
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6909597814083099
  Validation Loss: 0.6632278561592102
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6904124170541763
  Validation Loss: 0.6628730297088623
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6898461729288101
  Validation Loss: 0.6625150442123413
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6892611086368561
  Validation Loss: 0.6621112823486328
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.688742995262146
  Validation Loss: 0.6616876125335693
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6881762146949768
  Validation Loss: 0.6613132953643799
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6876631677150726
  Validation Loss: 0.6609843373298645
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6872056573629379
  Validation Loss: 0.6606888771057129
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 22/64:
  Train Loss: 0.6866938471794128
  Validation Loss: 0.6603782176971436
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 23/64:
  Train Loss: 0.6861495971679688
  Validation Loss: 0.6600026488304138
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 24/64:
  Train Loss: 0.6855937242507935
  Validation Loss: 0.6595736742019653
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 25/64:
  Train Loss: 0.6850479543209076
  Validation Loss: 0.6591799259185791
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 26/64:
  Train Loss: 0.6845435202121735
  Validation Loss: 0.6587659120559692
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 27/64:
  Train Loss: 0.6839669644832611
  Validation Loss: 0.6584070920944214
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6834668070077896
  Validation Loss: 0.6580654978752136
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6830043196678162
  Validation Loss: 0.6577966213226318
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6825819909572601
  Validation Loss: 0.6575226187705994
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6821041107177734
  Validation Loss: 0.6572272777557373
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6816663593053818
  Validation Loss: 0.6569498777389526
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6811786144971848
  Validation Loss: 0.656613826751709
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6806718558073044
  Validation Loss: 0.6562909483909607
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.6802385747432709
  Validation Loss: 0.6559312343597412
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.6797624826431274
  Validation Loss: 0.6555728316307068
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.6793866008520126
  Validation Loss: 0.6552623510360718
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6789774596691132
  Validation Loss: 0.6550454497337341
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6786298751831055
  Validation Loss: 0.654823362827301
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6782989501953125
  Validation Loss: 0.6545736789703369
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6779467314481735
  Validation Loss: 0.6543107032775879
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6776242256164551
  Validation Loss: 0.6540500521659851
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6772983372211456
  Validation Loss: 0.6538451313972473
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6770381778478622
  Validation Loss: 0.6535834074020386
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6767067760229111
  Validation Loss: 0.6532696485519409
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6762933433055878
  Validation Loss: 0.6529101133346558
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6759025305509567
  Validation Loss: 0.6525542736053467
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6755025833845139
  Validation Loss: 0.6522994637489319
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6751428693532944
  Validation Loss: 0.652051568031311
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6747927069664001
  Validation Loss: 0.651795506477356
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6744954437017441
  Validation Loss: 0.6515213251113892
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 52/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:16:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:19:INFO:
[92mINFO [0m:      Received: evaluate message 3bd010d3-d396-4478-a5c8-bb6523e8df2c
02/07/2025 22:46:19:INFO:Received: evaluate message 3bd010d3-d396-4478-a5c8-bb6523e8df2c
[92mINFO [0m:      Sent reply
02/07/2025 22:46:20:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:20:INFO:
[92mINFO [0m:      Received: train message 331c6533-e54d-43d6-b982-7408e0486659
02/07/2025 22:46:20:INFO:Received: train message 331c6533-e54d-43d6-b982-7408e0486659
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6742674112319946
  Validation Loss: 0.6512807607650757
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6740399897098541
  Validation Loss: 0.6510907411575317
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6737810969352722
  Validation Loss: 0.6509153246879578
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6735594570636749
  Validation Loss: 0.6507031917572021
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6732587516307831
  Validation Loss: 0.6505379676818848
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6730295866727829
  Validation Loss: 0.650346040725708
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6727846562862396
  Validation Loss: 0.650165319442749
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6725705713033676
  Validation Loss: 0.6499933004379272
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6723391115665436
  Validation Loss: 0.6498126983642578
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6720754355192184
  Validation Loss: 0.6496793031692505
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6718226224184036
  Validation Loss: 0.6495859622955322
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6715861558914185
  Validation Loss: 0.6495267152786255
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6713655740022659
  Validation Loss: 0.6494722366333008
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.75
{'train_loss': 0.6713655740022659, 'val_roc_auc': 0.86328125, 'val_accuracy': 0.75, 'val_loss': 0.6494722366333008}
 ROC_AUC: 0.8633|| Accuracy 0.7500 || Train Loss: 0.6714
 Val Loss: 0.6495 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6888551906897471
Test ROC-AUC: 0.8314732142857142
Test Accuracy: 0.7788461538461539
test_loss: 0.6888551906897471
test_roc_auc: 0.8314732142857142
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.5007946392288432
Epoch 1/64:
  Train Loss: 0.6923757493495941
  Validation Loss: 0.6836049556732178
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.6917314827442169
  Validation Loss: 0.6828774809837341
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6910461783409119
  Validation Loss: 0.6822640895843506
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.6904030591249466
  Validation Loss: 0.68163001537323
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.689700111746788
  Validation Loss: 0.680981457233429
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.689068004488945
  Validation Loss: 0.6803615093231201
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.688414990901947
  Validation Loss: 0.679741382598877
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6877953112125397
  Validation Loss: 0.6791986227035522
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6872448474168777
  Validation Loss: 0.6786562204360962
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6866449266672134
  Validation Loss: 0.6780609488487244
  Val ROC-AUC: 0.9325396825396826
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.68610480427742
  Validation Loss: 0.6774564385414124
  Val ROC-AUC: 0.9325396825396826
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6855443120002747
  Validation Loss: 0.6768258810043335
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 13/64:
  Train Loss: 0.6849202811717987
  Validation Loss: 0.6762068271636963
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6844270974397659
  Validation Loss: 0.6756548881530762
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6839149743318558
  Validation Loss: 0.6751717925071716
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 16/64:
  Train Loss: 0.6834084391593933
  Validation Loss: 0.6747099161148071
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 17/64:
  Train Loss: 0.6829438656568527
  Validation Loss: 0.6742168664932251
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 18/64:
  Train Loss: 0.6824347078800201
  Validation Loss: 0.6737658381462097
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 19/64:
  Train Loss: 0.681904599070549
  Validation Loss: 0.6733459234237671
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 20/64:
  Train Loss: 0.6814297437667847
  Validation Loss: 0.6729621291160583
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 21/64:
  Train Loss: 0.6809447556734085
  Validation Loss: 0.6725283861160278
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 22/64:
  Train Loss: 0.6805220246315002
  Validation Loss: 0.6721199154853821
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 23/64:
  Train Loss: 0.6800988614559174
  Validation Loss: 0.6717262864112854
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 24/64:
  Train Loss: 0.679704338312149
  Validation Loss: 0.6714224815368652
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 25/64:
  Train Loss: 0.6793341040611267
  Validation Loss: 0.6711175441741943
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 26/64:
  Train Loss: 0.6789931952953339
  Validation Loss: 0.6708676815032959
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 27/64:
  Train Loss: 0.6787387579679489
  Validation Loss: 0.6706545352935791
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 28/64:
  Train Loss: 0.6784359514713287
  Validation Loss: 0.670434832572937
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 29/64:
  Train Loss: 0.678126871585846
  Validation Loss: 0.6702440977096558
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 30/64:
  Train Loss: 0.6777893155813217
  Validation Loss: 0.6698900461196899
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 31/64:
  Train Loss: 0.677417442202568
  Validation Loss: 0.669511616230011
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 32/64:
  Train Loss: 0.6770051121711731
  Validation Loss: 0.6690861582756042
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 33/64:
  Train Loss: 0.6766252517700195
  Validation Loss: 0.6686996221542358
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 34/64:
  Train Loss: 0.6762580573558807
  Validation Loss: 0.6683648824691772
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6759173423051834
  Validation Loss: 0.6680197715759277
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.675652489066124
  Validation Loss: 0.6677554845809937
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6753449887037277
  Validation Loss: 0.6675113439559937
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6750278919935226
  Validation Loss: 0.6672024726867676
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6747083067893982
  Validation Loss: 0.6668875217437744
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6744067519903183
  Validation Loss: 0.666541337966919
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6741054356098175
  Validation Loss: 0.6662112474441528
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6738109886646271
  Validation Loss: 0.6659097671508789
  Val ROC-AUC: 0.9404761904761905
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:46:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:49:INFO:
[92mINFO [0m:      Received: evaluate message c37939b4-0b7f-4816-b121-617c1105a52b
02/07/2025 22:46:49:INFO:Received: evaluate message c37939b4-0b7f-4816-b121-617c1105a52b
[92mINFO [0m:      Sent reply
02/07/2025 22:46:49:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:49:INFO:
[92mINFO [0m:      Received: train message 86170347-8932-42a3-ac14-c67b3ee4215b
02/07/2025 22:46:49:INFO:Received: train message 86170347-8932-42a3-ac14-c67b3ee4215b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6734959930181503
  Validation Loss: 0.6656298637390137
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6731699705123901
  Validation Loss: 0.6652973890304565
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.672802746295929
  Validation Loss: 0.6649765968322754
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6724919825792313
  Validation Loss: 0.6647135019302368
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6722141951322556
  Validation Loss: 0.664440393447876
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6719533801078796
  Validation Loss: 0.6642237305641174
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6716938763856888
  Validation Loss: 0.6639372110366821
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6714356988668442
  Validation Loss: 0.6635398864746094
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6711493283510208
  Validation Loss: 0.6632367968559265
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6709105670452118
  Validation Loss: 0.6629370450973511
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6706290990114212
  Validation Loss: 0.6626538634300232
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6703640520572662
  Validation Loss: 0.6623934507369995
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6701120734214783
  Validation Loss: 0.662146806716919
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.6698285937309265
  Validation Loss: 0.6618918180465698
  Val ROC-AUC: 0.9325396825396826
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.6696103662252426
  Validation Loss: 0.6616335511207581
  Val ROC-AUC: 0.9325396825396826
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6693434417247772
  Validation Loss: 0.66135174036026
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6690858751535416
  Validation Loss: 0.6610896587371826
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6688511669635773
  Validation Loss: 0.6608457565307617
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 61/64:
  Train Loss: 0.6686136722564697
  Validation Loss: 0.6605964303016663
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6683853417634964
  Validation Loss: 0.6604233384132385
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 63/64:
  Train Loss: 0.6681468188762665
  Validation Loss: 0.6601047515869141
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6679098308086395
  Validation Loss: 0.6598374843597412
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
{'train_loss': 0.6679098308086395, 'val_roc_auc': 0.9365079365079365, 'val_accuracy': 0.8125, 'val_loss': 0.6598374843597412}
 ROC_AUC: 0.9365|| Accuracy 0.8125 || Train Loss: 0.6679
 Val Loss: 0.6598 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6840781354560301
Test ROC-AUC: 0.8418898809523809
Test Accuracy: 0.7884615384615384
test_loss: 0.6840781354560301
test_roc_auc: 0.8418898809523809
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.5119176923835767
Epoch 1/64:
  Train Loss: 0.6948993355035782
  Validation Loss: 0.6548644304275513
  Val ROC-AUC: 0.9568627450980391
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6940697133541107
  Validation Loss: 0.6542032957077026
  Val ROC-AUC: 0.9568627450980391
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.6933396309614182
  Validation Loss: 0.6536427140235901
  Val ROC-AUC: 0.9568627450980391
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6927071362733841
  Validation Loss: 0.6531102657318115
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.6920466721057892
  Validation Loss: 0.6525678634643555
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6914231479167938
  Validation Loss: 0.6520933508872986
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.6908247172832489
  Validation Loss: 0.6516804695129395
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.6902436316013336
  Validation Loss: 0.6513020992279053
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6897437870502472
  Validation Loss: 0.6509682536125183
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6892560422420502
  Validation Loss: 0.6505805253982544
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 11/64:
  Train Loss: 0.688748225569725
  Validation Loss: 0.650270938873291
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.688297763466835
  Validation Loss: 0.6499712467193604
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6878094226121902
  Validation Loss: 0.6496457457542419
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.687359943985939
  Validation Loss: 0.6492770910263062
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.6868549287319183
  Validation Loss: 0.6488488912582397
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6862976253032684
  Validation Loss: 0.6484472751617432
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.6857495456933975
  Validation Loss: 0.648058295249939
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.6852097362279892
  Validation Loss: 0.6477104425430298
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6847756206989288
  Validation Loss: 0.647376298904419
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6842279881238937
  Validation Loss: 0.6470454335212708
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6837053298950195
  Validation Loss: 0.6467074155807495
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.6831830143928528
  Validation Loss: 0.646403968334198
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.682771846652031
  Validation Loss: 0.6461811065673828
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 24/64:
  Train Loss: 0.6823221445083618
  Validation Loss: 0.6459403038024902
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 25/64:
  Train Loss: 0.6819219142198563
  Validation Loss: 0.6457639932632446
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 26/64:
  Train Loss: 0.6815717071294785
  Validation Loss: 0.6455703377723694
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 27/64:
  Train Loss: 0.6812085956335068
  Validation Loss: 0.6453964114189148
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 28/64:
  Train Loss: 0.6808615773916245
  Validation Loss: 0.6451311111450195
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 29/64:
  Train Loss: 0.6804105639457703
  Validation Loss: 0.6448259353637695
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 30/64:
  Train Loss: 0.6800026148557663
  Validation Loss: 0.6445506811141968
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 31/64:
  Train Loss: 0.6796026974916458
  Validation Loss: 0.6442629098892212
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 32/64:
  Train Loss: 0.6791921854019165
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:17:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:18:INFO:
[92mINFO [0m:      Received: evaluate message b14048f9-8481-44e7-b698-adfce8fcb483
02/07/2025 22:47:18:INFO:Received: evaluate message b14048f9-8481-44e7-b698-adfce8fcb483
[92mINFO [0m:      Sent reply
02/07/2025 22:47:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:19:INFO:
[92mINFO [0m:      Received: train message a9e7c396-c560-424d-b81a-c72b030d71eb
02/07/2025 22:47:19:INFO:Received: train message a9e7c396-c560-424d-b81a-c72b030d71eb
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.643975019454956
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 33/64:
  Train Loss: 0.6788138747215271
  Validation Loss: 0.6437175869941711
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 34/64:
  Train Loss: 0.67841437458992
  Validation Loss: 0.6434410214424133
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 35/64:
  Train Loss: 0.6780534982681274
  Validation Loss: 0.6431636810302734
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 36/64:
  Train Loss: 0.6776909232139587
  Validation Loss: 0.6429858207702637
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 37/64:
  Train Loss: 0.6773795038461685
  Validation Loss: 0.6428723335266113
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6770653277635574
  Validation Loss: 0.6427695751190186
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.676713615655899
  Validation Loss: 0.6426544189453125
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.676416888833046
  Validation Loss: 0.6424819231033325
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6761144399642944
  Validation Loss: 0.6423776149749756
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6758114099502563
  Validation Loss: 0.6422427892684937
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6755451261997223
  Validation Loss: 0.6421347260475159
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.6752722561359406
  Validation Loss: 0.6420329213142395
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6750152856111526
  Validation Loss: 0.6419485807418823
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6747739762067795
  Validation Loss: 0.6418633460998535
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6745032221078873
  Validation Loss: 0.641747236251831
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6742287278175354
  Validation Loss: 0.6416538953781128
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6739449799060822
  Validation Loss: 0.6415088176727295
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.673688143491745
  Validation Loss: 0.6413936614990234
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.6734413504600525
  Validation Loss: 0.6412661075592041
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6731879115104675
  Validation Loss: 0.6411335468292236
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6729543507099152
  Validation Loss: 0.6409764289855957
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6727102845907211
  Validation Loss: 0.6408413648605347
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6724546849727631
  Validation Loss: 0.6406921148300171
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.6722308844327927
  Validation Loss: 0.6406370997428894
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6720239669084549
  Validation Loss: 0.6405511498451233
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6718334853649139
  Validation Loss: 0.640445351600647
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6716405302286148
  Validation Loss: 0.6403669118881226
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6714432537555695
  Validation Loss: 0.6403090357780457
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6712828725576401
  Validation Loss: 0.6402130722999573
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.671048566699028
  Validation Loss: 0.6401088237762451
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6708140671253204
  Validation Loss: 0.6400713920593262
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.670637845993042
  Validation Loss: 0.639972984790802
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
{'train_loss': 0.670637845993042, 'val_roc_auc': 0.9372549019607843, 'val_accuracy': 0.78125, 'val_loss': 0.639972984790802}
 ROC_AUC: 0.9373|| Accuracy 0.7812 || Train Loss: 0.6706
 Val Loss: 0.6400 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6795854333501595
Test ROC-AUC: 0.8552827380952381
Test Accuracy: 0.7788461538461539
test_loss: 0.6795854333501595
test_roc_auc: 0.8552827380952381
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.5727158115769271
Epoch 1/64:
  Train Loss: 0.695686399936676
  Validation Loss: 0.635506808757782
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6950045377016068
  Validation Loss: 0.6350654363632202
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.6944146901369095
  Validation Loss: 0.63456791639328
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6938128024339676
  Validation Loss: 0.6340464949607849
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.693189412355423
  Validation Loss: 0.6335883736610413
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6925851553678513
  Validation Loss: 0.6331554055213928
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.6920520216226578
  Validation Loss: 0.6327745914459229
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.691514864563942
  Validation Loss: 0.6323992013931274
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6909980177879333
  Validation Loss: 0.632063627243042
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 10/64:
  Train Loss: 0.6904955059289932
  Validation Loss: 0.6317545771598816
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 11/64:
  Train Loss: 0.6900028884410858
  Validation Loss: 0.6314316987991333
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 12/64:
  Train Loss: 0.6894467771053314
  Validation Loss: 0.6310913562774658
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 13/64:
  Train Loss: 0.6889213174581528
  Validation Loss: 0.630733072757721
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 14/64:
  Train Loss: 0.6884199231863022
  Validation Loss: 0.6304342746734619
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 15/64:
  Train Loss: 0.6879644840955734
  Validation Loss: 0.6301848888397217
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.78125
Epoch 16/64:
  Train Loss: 0.6875732392072678
  Validation Loss: 0.6299458742141724
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 17/64:
  Train Loss: 0.6871932446956635
  Validation Loss: 0.6296893954277039
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 18/64:
  Train Loss: 0.6867561936378479
  Validation Loss: 0.6294321417808533
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 19/64:
  Train Loss: 0.6863852739334106
  Validation Loss: 0.6291944980621338
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 20/64:
  Train Loss: 0.6860356330871582
  Validation Loss: 0.6290072202682495
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 21/64:
  Train Loss: 0.6857185363769531
  Validation Loss: 0.6288059949874878
  Val ROC-AUC: 0.9137254901960785
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:45:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:45:INFO:
[92mINFO [0m:      Received: evaluate message 8d9c34ca-82d9-4031-a2d5-21f70d02f1fb
02/07/2025 22:47:45:INFO:Received: evaluate message 8d9c34ca-82d9-4031-a2d5-21f70d02f1fb
[92mINFO [0m:      Sent reply
02/07/2025 22:47:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:47:INFO:
[92mINFO [0m:      Received: train message 808f40ee-d186-4276-a20c-395808b527f3
02/07/2025 22:47:47:INFO:Received: train message 808f40ee-d186-4276-a20c-395808b527f3
  Val Accuracy: 0.78125
Epoch 22/64:
  Train Loss: 0.6853830963373184
  Validation Loss: 0.6285699605941772
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 23/64:
  Train Loss: 0.6850739568471909
  Validation Loss: 0.6284029483795166
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 24/64:
  Train Loss: 0.6847676932811737
  Validation Loss: 0.6282708048820496
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 25/64:
  Train Loss: 0.6844915151596069
  Validation Loss: 0.6281403303146362
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 26/64:
  Train Loss: 0.6842342168092728
  Validation Loss: 0.6279590725898743
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 27/64:
  Train Loss: 0.6839306801557541
  Validation Loss: 0.6277695298194885
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 28/64:
  Train Loss: 0.6835795938968658
  Validation Loss: 0.6276159286499023
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 29/64:
  Train Loss: 0.6833105832338333
  Validation Loss: 0.6274084448814392
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 30/64:
  Train Loss: 0.6828968524932861
  Validation Loss: 0.627180814743042
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 31/64:
  Train Loss: 0.6825365573167801
  Validation Loss: 0.6269471049308777
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 32/64:
  Train Loss: 0.6821606904268265
  Validation Loss: 0.6267331838607788
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 33/64:
  Train Loss: 0.6818872690200806
  Validation Loss: 0.626554548740387
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 34/64:
  Train Loss: 0.6815452873706818
  Validation Loss: 0.6263923048973083
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 35/64:
  Train Loss: 0.6811888217926025
  Validation Loss: 0.6262408494949341
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 36/64:
  Train Loss: 0.6808973848819733
  Validation Loss: 0.6260796785354614
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 37/64:
  Train Loss: 0.6805451810359955
  Validation Loss: 0.6259149312973022
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 38/64:
  Train Loss: 0.6802240610122681
  Validation Loss: 0.6257767677307129
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 39/64:
  Train Loss: 0.6799431145191193
  Validation Loss: 0.6256415843963623
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 40/64:
  Train Loss: 0.6796910613775253
  Validation Loss: 0.625517725944519
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 41/64:
  Train Loss: 0.6793979108333588
  Validation Loss: 0.6253923177719116
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 42/64:
  Train Loss: 0.679164856672287
  Validation Loss: 0.6252924203872681
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 43/64:
  Train Loss: 0.6789292991161346
  Validation Loss: 0.6251293420791626
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 44/64:
  Train Loss: 0.6787211149930954
  Validation Loss: 0.6249634027481079
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 45/64:
  Train Loss: 0.678461104631424
  Validation Loss: 0.6248035430908203
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.6782265305519104
  Validation Loss: 0.624705970287323
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.6779809892177582
  Validation Loss: 0.6246023178100586
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6777452826499939
  Validation Loss: 0.624468207359314
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.6775274723768234
  Validation Loss: 0.6243675351142883
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6772766560316086
  Validation Loss: 0.6243019104003906
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6770563870668411
  Validation Loss: 0.624211311340332
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6768134385347366
  Validation Loss: 0.6241304874420166
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6765755712985992
  Validation Loss: 0.6240158677101135
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.6763015240430832
  Validation Loss: 0.6239469051361084
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6761057823896408
  Validation Loss: 0.6239135265350342
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.67588672041893
  Validation Loss: 0.6238836050033569
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6756426692008972
  Validation Loss: 0.6238418221473694
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6754150241613388
  Validation Loss: 0.6237592697143555
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6752046644687653
  Validation Loss: 0.6237142086029053
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.674963116645813
  Validation Loss: 0.6236322522163391
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6747454255819321
  Validation Loss: 0.6234927177429199
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6745006144046783
  Validation Loss: 0.6233559846878052
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6742894053459167
  Validation Loss: 0.6231714487075806
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6740970760583878
  Validation Loss: 0.6230446696281433
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
{'train_loss': 0.6740970760583878, 'val_roc_auc': 0.9058823529411766, 'val_accuracy': 0.78125, 'val_loss': 0.6230446696281433}
 ROC_AUC: 0.9059|| Accuracy 0.7812 || Train Loss: 0.6741
 Val Loss: 0.6230 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6753912966411847
Test ROC-AUC: 0.8612351190476191
Test Accuracy: 0.7788461538461539
test_loss: 0.6753912966411847
test_roc_auc: 0.8612351190476191
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.3931800608552294
Epoch 1/64:
  Train Loss: 0.6876667737960815
  Validation Loss: 0.6524572372436523
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6869318634271622
  Validation Loss: 0.6519845724105835
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.6863516718149185
  Validation Loss: 0.6515166759490967
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6857042163610458
  Validation Loss: 0.6510763764381409
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.6850903183221817
  Validation Loss: 0.6506552696228027
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6845080852508545
  Validation Loss: 0.650240421295166
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.683960422873497
  Validation Loss: 0.6498091220855713
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.683360144495964
  Validation Loss: 0.6494237184524536
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6828610152006149
  Validation Loss: 0.6490610241889954
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6823824197053909
  Validation Loss: 0.6487041711807251
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 11/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:14:INFO:
[92mINFO [0m:      Received: evaluate message 0b976b6b-d268-48fc-ad20-03dd42d408eb
02/07/2025 22:48:14:INFO:Received: evaluate message 0b976b6b-d268-48fc-ad20-03dd42d408eb
[92mINFO [0m:      Sent reply
02/07/2025 22:48:16:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:17:INFO:
[92mINFO [0m:      Received: train message a48f2dec-f2c9-41a9-88e6-59d6c453ae67
02/07/2025 22:48:17:INFO:Received: train message a48f2dec-f2c9-41a9-88e6-59d6c453ae67
  Train Loss: 0.6818075776100159
  Validation Loss: 0.6483664512634277
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.6812785267829895
  Validation Loss: 0.6480811834335327
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6808665692806244
  Validation Loss: 0.6477516889572144
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.6803915053606033
  Validation Loss: 0.6474158763885498
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.6798966377973557
  Validation Loss: 0.6470708847045898
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6794264316558838
  Validation Loss: 0.6468036770820618
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.679021492600441
  Validation Loss: 0.6465455293655396
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.6786192059516907
  Validation Loss: 0.6462950706481934
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6782062500715256
  Validation Loss: 0.6460530161857605
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6777965128421783
  Validation Loss: 0.6458573341369629
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6774167865514755
  Validation Loss: 0.6456589698791504
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.677078127861023
  Validation Loss: 0.6454396843910217
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.6767595559358597
  Validation Loss: 0.6452039480209351
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 24/64:
  Train Loss: 0.6764182597398758
  Validation Loss: 0.6449824571609497
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 25/64:
  Train Loss: 0.676098644733429
  Validation Loss: 0.6447701454162598
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 26/64:
  Train Loss: 0.6757664382457733
  Validation Loss: 0.6445654630661011
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 27/64:
  Train Loss: 0.6754666864871979
  Validation Loss: 0.6443837881088257
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 28/64:
  Train Loss: 0.6752164214849472
  Validation Loss: 0.6442182064056396
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 29/64:
  Train Loss: 0.6749536693096161
  Validation Loss: 0.6440293788909912
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 30/64:
  Train Loss: 0.6747069954872131
  Validation Loss: 0.643817663192749
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 31/64:
  Train Loss: 0.6743964999914169
  Validation Loss: 0.6436330676078796
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.8125
Epoch 32/64:
  Train Loss: 0.6741043329238892
  Validation Loss: 0.6434333920478821
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 33/64:
  Train Loss: 0.6738046407699585
  Validation Loss: 0.6432230472564697
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6735041439533234
  Validation Loss: 0.642990231513977
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6732091456651688
  Validation Loss: 0.6427780389785767
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6729307919740677
  Validation Loss: 0.6426025629043579
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6726810336112976
  Validation Loss: 0.6424299478530884
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6723921597003937
  Validation Loss: 0.6422924399375916
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6721855252981186
  Validation Loss: 0.642124354839325
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.6718859672546387
  Validation Loss: 0.6419620513916016
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6716306507587433
  Validation Loss: 0.6417912244796753
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6713707745075226
  Validation Loss: 0.6416155099868774
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.671089693903923
  Validation Loss: 0.6414045095443726
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.6708652973175049
  Validation Loss: 0.6412321329116821
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6706034243106842
  Validation Loss: 0.6411079168319702
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6703722476959229
  Validation Loss: 0.6409525275230408
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6701221168041229
  Validation Loss: 0.6407798528671265
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6698755621910095
  Validation Loss: 0.6406540870666504
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6696814894676208
  Validation Loss: 0.6405379772186279
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.669482484459877
  Validation Loss: 0.6404024958610535
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.6692253351211548
  Validation Loss: 0.640305757522583
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6690440773963928
  Validation Loss: 0.64019775390625
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6688308417797089
  Validation Loss: 0.6400848627090454
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6686130911111832
  Validation Loss: 0.6399403214454651
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6683861762285233
  Validation Loss: 0.6398070454597473
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6681962162256241
  Validation Loss: 0.6396852731704712
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6680095195770264
  Validation Loss: 0.6395772695541382
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.6678357124328613
  Validation Loss: 0.6394580602645874
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6676644533872604
  Validation Loss: 0.6393606662750244
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6675786077976227
  Validation Loss: 0.6392447352409363
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 61/64:
  Train Loss: 0.6674647331237793
  Validation Loss: 0.6391189694404602
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6673214137554169
  Validation Loss: 0.6389864683151245
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 63/64:
  Train Loss: 0.6671552956104279
  Validation Loss: 0.6388609409332275
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6670211851596832
  Validation Loss: 0.6387443542480469
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
{'train_loss': 0.6670211851596832, 'val_roc_auc': 0.9098039215686274, 'val_accuracy': 0.8125, 'val_loss': 0.6387443542480469}
 ROC_AUC: 0.9098|| Accuracy 0.8125 || Train Loss: 0.6670
 Val Loss: 0.6387 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6714335138408037
Test ROC-AUC: 0.866815476190476
Test Accuracy: 0.7980769230769231
test_loss: 0.6714335138408037
test_roc_auc: 0.866815476190476
test_accuracy: 0.7980769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Dynamic noise multiplier: 0.6225612241541967
Epoch 1/64:
  Train Loss: 0.6637668311595917
  Validation Loss: 0.7352667450904846
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6630587130784988
  Validation Loss: 0.7348573207855225
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6624186635017395
  Validation Loss: 0.7344925403594971
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.661844328045845
  Validation Loss: 0.7341299653053284
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6613625884056091
  Validation Loss: 0.7339032292366028
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.6608758121728897
  Validation Loss: 0.7336829304695129
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 7/64:
  Train Loss: 0.6604952663183212
  Validation Loss: 0.733434796333313
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 8/64:
  Train Loss: 0.6600676774978638
  Validation Loss: 0.733182966709137
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 9/64:
  Train Loss: 0.6596929430961609
  Validation Loss: 0.7329262495040894
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 10/64:
  Train Loss: 0.6592312306165695
  Validation Loss: 0.7326488494873047
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 11/64:
  Train Loss: 0.6588402390480042
  Validation Loss: 0.7324260473251343
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 12/64:
  Train Loss: 0.6585077047348022
  Validation Loss: 0.7322211265563965
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 13/64:
  Train Loss: 0.6581474840641022
  Validation Loss: 0.7320616245269775
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 14/64:
  Train Loss: 0.6578068733215332
  Validation Loss: 0.7318297028541565
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.75
Epoch 15/64:
  Train Loss: 0.6574608236551285
  Validation Loss: 0.7315725684165955
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 16/64:
  Train Loss: 0.6571273952722549
  Validation Loss: 0.7312935590744019
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 17/64:
  Train Loss: 0.6568056046962738
  Validation Loss: 0.7309929132461548
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 18/64:
  Train Loss: 0.6564559787511826
  Validation Loss: 0.7307324409484863
  Val ROC-AUC: 0.8787878787878789
  Val Accuracy: 0.75
Epoch 19/64:
  Train Loss: 0.6561318933963776
  Validation Loss: 0.7304256558418274
  Val ROC-AUC: 0.8787878787878789
  Val Accuracy: 0.75
Epoch 20/64:
  Train Loss: 0.6557864397764206
  Validation Loss: 0.730256199836731
  Val ROC-AUC: 0.8744588744588745
  Val Accuracy: 0.75
Epoch 21/64:
  Train Loss: 0.6554747074842453
  Validation Loss: 0.730126142501831
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 22/64:
  Train Loss: 0.6551977097988129
  Validation Loss: 0.730034351348877
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 23/64:
  Train Loss: 0.6549373120069504
  Validation Loss: 0.7299702167510986
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 24/64:
  Train Loss: 0.6546546220779419
  Validation Loss: 0.7299061417579651
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 25/64:
  Train Loss: 0.6543760150671005
  Validation Loss: 0.7297585010528564
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 26/64:
  Train Loss: 0.6540822982788086
  Validation Loss: 0.7296340465545654
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 27/64:
  Train Loss: 0.6537823528051376
  Validation Loss: 0.729539155960083
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6535241901874542
  Validation Loss: 0.7293707132339478
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6532324552536011
  Validation Loss: 0.7291364669799805
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6529188603162766
  Validation Loss: 0.7289022207260132
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6526205837726593
  Validation Loss: 0.7286902070045471
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6523691862821579
  Validation Loss: 0.7285087704658508
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.78125
Epoch 33/64:
  Train Loss: 0.6521267145872116
  Validation Loss: 0.7283572554588318
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.78125
Epoch 34/64:
  Train Loss: 0.651899054646492
  Validation Loss: 0.7281617522239685
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.78125
Epoch 35/64:
  Train Loss: 0.6516539454460144
  Validation Loss: 0.727971076965332
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.78125
Epoch 36/64:
  Train Loss: 0.6514319479465485
  Validation Loss: 0.7278019189834595
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.651177242398262
  Validation Loss: 0.7276767492294312
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6509362608194351
  Validation Loss: 0.7275700569152832
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6507526487112045
  Validation Loss: 0.7275221347808838
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.78125
Epoch 40/64:
  Train Loss: 0.6505476832389832
  Validation Loss: 0.7275037169456482
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.78125
Epoch 41/64:
  Train Loss: 0.6503559201955795
  Validation Loss: 0.727508008480072
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6501364707946777
  Validation Loss: 0.7274274826049805
  Val ROC-AUC: 0.8701298701298701
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6499209553003311
  Validation Loss: 0.7273367643356323
  Val ROC-AUC: 0.8701298701298701
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6497560292482376
  Validation Loss: 0.7272403240203857
  Val ROC-AUC: 0.8701298701298701
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6496013253927231
  Validation Loss: 0.7271029949188232
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6494189351797104
  Validation Loss: 0.7270063757896423
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6492809057235718
  Validation Loss: 0.7269482016563416
  Val ROC-AUC: 0.8701298701298701
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6491649597883224
  Validation Loss: 0.7269260883331299
  Val ROC-AUC: 0.8701298701298701
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.6490623950958252
  Validation Loss: 0.7268671989440918
  Val ROC-AUC: 0.8701298701298701
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.648855060338974
  Validation Loss: 0.7267836332321167
  Val ROC-AUC: 0.8701298701298701
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6487206071615219
  Validation Loss: 0.7267012596130371
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6485817283391953
  Validation Loss: 0.7266435623168945
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6484964787960052
  Validation Loss: 0.7265588045120239
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6484533250331879
  Validation Loss: 0.7264671325683594
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6483735889196396
  Validation Loss: 0.7264055013656616
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6482819616794586
  Validation Loss: 0.7263226509094238
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6481446325778961
  Validation Loss: 0.7262603044509888
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6479828506708145
  Validation Loss: 0.726207971572876
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 59/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:41:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:41:INFO:
[92mINFO [0m:      Received: evaluate message 00b36098-1be6-4a6b-b64d-5b647574256c
02/07/2025 22:48:41:INFO:Received: evaluate message 00b36098-1be6-4a6b-b64d-5b647574256c
[92mINFO [0m:      Sent reply
02/07/2025 22:48:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:44:INFO:
[92mINFO [0m:      Received: train message e15080ae-c45d-4de9-9451-6eee265ee3a9
02/07/2025 22:48:44:INFO:Received: train message e15080ae-c45d-4de9-9451-6eee265ee3a9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6478134393692017
  Validation Loss: 0.726151704788208
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6476668268442154
  Validation Loss: 0.7261286377906799
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6474916338920593
  Validation Loss: 0.725983202457428
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6473249793052673
  Validation Loss: 0.7258763313293457
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6471811681985855
  Validation Loss: 0.7257399559020996
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6470220535993576
  Validation Loss: 0.7256011962890625
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.78125
{'train_loss': 0.6470220535993576, 'val_roc_auc': 0.8614718614718615, 'val_accuracy': 0.78125, 'val_loss': 0.7256011962890625}
 ROC_AUC: 0.8615|| Accuracy 0.7812 || Train Loss: 0.6470
 Val Loss: 0.7256 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.66791647959214
Test ROC-AUC: 0.8738839285714286
Test Accuracy: 0.8076923076923077
test_loss: 0.66791647959214
test_roc_auc: 0.8738839285714286
test_accuracy: 0.8076923076923077
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.600505522088497
Epoch 1/64:
  Train Loss: 0.6783251315355301
  Validation Loss: 0.664986789226532
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.6779311299324036
  Validation Loss: 0.6646226644515991
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.71875
Epoch 3/64:
  Train Loss: 0.6775292754173279
  Validation Loss: 0.6642424464225769
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.71875
Epoch 4/64:
  Train Loss: 0.6770894527435303
  Validation Loss: 0.6639351844787598
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.71875
Epoch 5/64:
  Train Loss: 0.6766633689403534
  Validation Loss: 0.6636357307434082
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 6/64:
  Train Loss: 0.676234781742096
  Validation Loss: 0.6632909774780273
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 7/64:
  Train Loss: 0.6758093684911728
  Validation Loss: 0.663011372089386
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.6755169034004211
  Validation Loss: 0.662778377532959
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.6751687526702881
  Validation Loss: 0.6625784039497375
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.6748386770486832
  Validation Loss: 0.6623504161834717
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.674470916390419
  Validation Loss: 0.662117600440979
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.674145057797432
  Validation Loss: 0.6618675589561462
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6737376302480698
  Validation Loss: 0.6616618037223816
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6734344512224197
  Validation Loss: 0.6614048480987549
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6730946600437164
  Validation Loss: 0.6611964702606201
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6727660894393921
  Validation Loss: 0.6610116362571716
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6724639981985092
  Validation Loss: 0.660834789276123
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6721378713846207
  Validation Loss: 0.6606789827346802
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6717926263809204
  Validation Loss: 0.6605245471000671
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.671448215842247
  Validation Loss: 0.6603805422782898
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6711484789848328
  Validation Loss: 0.6602108478546143
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6708571463823318
  Validation Loss: 0.6600499153137207
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6705669164657593
  Validation Loss: 0.659837007522583
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.670266330242157
  Validation Loss: 0.659582793712616
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6698821783065796
  Validation Loss: 0.6593515872955322
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6695540845394135
  Validation Loss: 0.6591911315917969
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6692108660936356
  Validation Loss: 0.6590474843978882
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6689037084579468
  Validation Loss: 0.65888512134552
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6685534417629242
  Validation Loss: 0.6587207317352295
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.668252632021904
  Validation Loss: 0.6585508584976196
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6679453700780869
  Validation Loss: 0.6584446430206299
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6677149832248688
  Validation Loss: 0.6583465933799744
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6674809753894806
  Validation Loss: 0.6582274436950684
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6672400087118149
  Validation Loss: 0.6580601930618286
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6670016348361969
  Validation Loss: 0.6578495502471924
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.6667325645685196
  Validation Loss: 0.6576377153396606
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.6664821207523346
  Validation Loss: 0.6574432253837585
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6662084013223648
  Validation Loss: 0.6572716236114502
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6659553647041321
  Validation Loss: 0.6570950746536255
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6657134592533112
  Validation Loss: 0.6569219827651978
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6654287278652191
  Validation Loss: 0.6568001508712769
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6652177274227142
  Validation Loss: 0.6567049026489258
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.66503044962883
  Validation Loss: 0.6565703749656677
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6648171544075012
  Validation Loss: 0.6563986539840698
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6645887941122055
  Validation Loss: 0.6562403440475464
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6643386781215668
  Validation Loss: 0.6560819149017334
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6640751361846924
  Validation Loss: 0.6559807062149048
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6638600677251816
  Validation Loss: 0.6558518409729004
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:11:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:11:INFO:
[92mINFO [0m:      Received: evaluate message 57fa21f7-5021-434d-8776-83bf1e9b438e
02/07/2025 22:49:11:INFO:Received: evaluate message 57fa21f7-5021-434d-8776-83bf1e9b438e
[92mINFO [0m:      Sent reply
02/07/2025 22:49:12:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:12:INFO:
[92mINFO [0m:      Received: train message 7dc4ddf2-0016-48d5-823e-f1e6e1d06d81
02/07/2025 22:49:12:INFO:Received: train message 7dc4ddf2-0016-48d5-823e-f1e6e1d06d81
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6636517941951752
  Validation Loss: 0.6556484699249268
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6634382903575897
  Validation Loss: 0.655488133430481
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6632362306118011
  Validation Loss: 0.6553125381469727
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6629966497421265
  Validation Loss: 0.655174732208252
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6628173440694809
  Validation Loss: 0.6550721526145935
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6626158952713013
  Validation Loss: 0.6549374461174011
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6624085754156113
  Validation Loss: 0.6547571420669556
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6622190177440643
  Validation Loss: 0.6546480655670166
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6620383113622665
  Validation Loss: 0.6545230150222778
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.661903440952301
  Validation Loss: 0.6544885635375977
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6618077456951141
  Validation Loss: 0.6544402241706848
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6617114692926407
  Validation Loss: 0.6543587446212769
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6615691632032394
  Validation Loss: 0.6542479991912842
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6614218354225159
  Validation Loss: 0.6541266441345215
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6612924635410309
  Validation Loss: 0.6540486812591553
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6611896306276321
  Validation Loss: 0.6539422273635864
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
{'train_loss': 0.6611896306276321, 'val_roc_auc': 0.8823529411764706, 'val_accuracy': 0.75, 'val_loss': 0.6539422273635864}
 ROC_AUC: 0.8824|| Accuracy 0.7500 || Train Loss: 0.6612
 Val Loss: 0.6539 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6646431601391389
Test ROC-AUC: 0.8768601190476191
Test Accuracy: 0.7884615384615384
test_loss: 0.6646431601391389
test_roc_auc: 0.8768601190476191
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.5286320947561762
Epoch 1/64:
  Train Loss: 0.6774331033229828
  Validation Loss: 0.6573702692985535
  Val ROC-AUC: 0.7764705882352941
  Val Accuracy: 0.65625
Epoch 2/64:
  Train Loss: 0.6768792271614075
  Validation Loss: 0.6571356654167175
  Val ROC-AUC: 0.7764705882352941
  Val Accuracy: 0.65625
Epoch 3/64:
  Train Loss: 0.6764607727527618
  Validation Loss: 0.6568512916564941
  Val ROC-AUC: 0.7764705882352941
  Val Accuracy: 0.65625
Epoch 4/64:
  Train Loss: 0.6760359704494476
  Validation Loss: 0.6565738320350647
  Val ROC-AUC: 0.7803921568627451
  Val Accuracy: 0.65625
Epoch 5/64:
  Train Loss: 0.6756458431482315
  Validation Loss: 0.6562269926071167
  Val ROC-AUC: 0.7803921568627451
  Val Accuracy: 0.65625
Epoch 6/64:
  Train Loss: 0.675251379609108
  Validation Loss: 0.6558963656425476
  Val ROC-AUC: 0.7803921568627451
  Val Accuracy: 0.65625
Epoch 7/64:
  Train Loss: 0.674847275018692
  Validation Loss: 0.6555429697036743
  Val ROC-AUC: 0.7803921568627451
  Val Accuracy: 0.65625
Epoch 8/64:
  Train Loss: 0.6744131147861481
  Validation Loss: 0.655229389667511
  Val ROC-AUC: 0.788235294117647
  Val Accuracy: 0.65625
Epoch 9/64:
  Train Loss: 0.674015000462532
  Validation Loss: 0.6548881530761719
  Val ROC-AUC: 0.788235294117647
  Val Accuracy: 0.65625
Epoch 10/64:
  Train Loss: 0.6735201776027679
  Validation Loss: 0.6545112133026123
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 11/64:
  Train Loss: 0.6730862408876419
  Validation Loss: 0.6541915535926819
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 12/64:
  Train Loss: 0.6726936846971512
  Validation Loss: 0.6539470553398132
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 13/64:
  Train Loss: 0.6723722666501999
  Validation Loss: 0.6537050008773804
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 14/64:
  Train Loss: 0.6720100045204163
  Validation Loss: 0.6534937620162964
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 15/64:
  Train Loss: 0.6717317700386047
  Validation Loss: 0.6532883644104004
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 16/64:
  Train Loss: 0.6714223772287369
  Validation Loss: 0.6530150175094604
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 17/64:
  Train Loss: 0.6710701286792755
  Validation Loss: 0.6527101993560791
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 18/64:
  Train Loss: 0.6707461178302765
  Validation Loss: 0.6524153351783752
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 19/64:
  Train Loss: 0.6704585701227188
  Validation Loss: 0.6521079540252686
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 20/64:
  Train Loss: 0.6701948791742325
  Validation Loss: 0.6518161296844482
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 21/64:
  Train Loss: 0.669866144657135
  Validation Loss: 0.6515128016471863
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 22/64:
  Train Loss: 0.6695721447467804
  Validation Loss: 0.651237964630127
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 23/64:
  Train Loss: 0.6692894250154495
  Validation Loss: 0.6509971618652344
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 24/64:
  Train Loss: 0.6690026372671127
  Validation Loss: 0.65077805519104
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 25/64:
  Train Loss: 0.6687322407960892
  Validation Loss: 0.6505399942398071
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 26/64:
  Train Loss: 0.668445274233818
  Validation Loss: 0.6502914428710938
  Val ROC-AUC: 0.8
  Val Accuracy: 0.6875
Epoch 27/64:
  Train Loss: 0.6682132184505463
  Validation Loss: 0.6500451564788818
  Val ROC-AUC: 0.8
  Val Accuracy: 0.6875
Epoch 28/64:
  Train Loss: 0.6679986268281937
  Validation Loss: 0.6497941613197327
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 29/64:
  Train Loss: 0.667746365070343
  Validation Loss: 0.6495416164398193
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 30/64:
  Train Loss: 0.6674488484859467
  Validation Loss: 0.6493343114852905
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 31/64:
  Train Loss: 0.667165994644165
  Validation Loss: 0.6491894721984863
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 32/64:
  Train Loss: 0.6669116318225861
  Validation Loss: 0.6490538120269775
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 33/64:
  Train Loss: 0.6666730046272278
  Validation Loss: 0.648906409740448
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 34/64:
  Train Loss: 0.6664525121450424
  Validation Loss: 0.6487011313438416
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 35/64:
  Train Loss: 0.6661783158779144
  Validation Loss: 0.648466944694519
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 36/64:
  Train Loss: 0.665896937251091
  Validation Loss: 0.6482733488082886
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 37/64:
  Train Loss: 0.6656468212604523
  Validation Loss: 0.6480135917663574
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6653889119625092
  Validation Loss: 0.6477739214897156
  Val ROC-AUC: 0.8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:38:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:38:INFO:
[92mINFO [0m:      Received: evaluate message 062464fd-edec-4973-b0eb-5019f0e92c8e
02/07/2025 22:49:38:INFO:Received: evaluate message 062464fd-edec-4973-b0eb-5019f0e92c8e
[92mINFO [0m:      Sent reply
02/07/2025 22:49:38:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:38:INFO:
[92mINFO [0m:      Received: train message ac5473f3-bdd6-40f1-abe4-159970f6713e
02/07/2025 22:49:38:INFO:Received: train message ac5473f3-bdd6-40f1-abe4-159970f6713e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6651946902275085
  Validation Loss: 0.6475445032119751
  Val ROC-AUC: 0.8
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6649668514728546
  Validation Loss: 0.6473785042762756
  Val ROC-AUC: 0.8
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6647861003875732
  Validation Loss: 0.6472381353378296
  Val ROC-AUC: 0.803921568627451
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6645794957876205
  Validation Loss: 0.6470708250999451
  Val ROC-AUC: 0.803921568627451
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6644479930400848
  Validation Loss: 0.6468706130981445
  Val ROC-AUC: 0.8
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6642579734325409
  Validation Loss: 0.6467093229293823
  Val ROC-AUC: 0.8
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6640934348106384
  Validation Loss: 0.6465351581573486
  Val ROC-AUC: 0.8
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6639225482940674
  Validation Loss: 0.6463881134986877
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6638124734163284
  Validation Loss: 0.6462516784667969
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6636790037155151
  Validation Loss: 0.6461942195892334
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6636032909154892
  Validation Loss: 0.6461711525917053
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.663483276963234
  Validation Loss: 0.6461620926856995
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6634139716625214
  Validation Loss: 0.6461634039878845
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6633415371179581
  Validation Loss: 0.6461474895477295
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6632543653249741
  Validation Loss: 0.6461148262023926
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6631588786840439
  Validation Loss: 0.646075963973999
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6630671620368958
  Validation Loss: 0.6460443735122681
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6629528850317001
  Validation Loss: 0.6459590196609497
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6627997905015945
  Validation Loss: 0.6458399295806885
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6627044528722763
  Validation Loss: 0.6456907987594604
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6625848263502121
  Validation Loss: 0.6455986499786377
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6624498218297958
  Validation Loss: 0.6454535126686096
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6623103469610214
  Validation Loss: 0.6453428268432617
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6621275097131729
  Validation Loss: 0.6453217267990112
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6619895100593567
  Validation Loss: 0.6453088521957397
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6618736386299133
  Validation Loss: 0.6452794075012207
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.75
{'train_loss': 0.6618736386299133, 'val_roc_auc': 0.7960784313725491, 'val_accuracy': 0.75, 'val_loss': 0.6452794075012207}
 ROC_AUC: 0.7961|| Accuracy 0.7500 || Train Loss: 0.6619
 Val Loss: 0.6453 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6617052185420806
Test ROC-AUC: 0.8798363095238095
Test Accuracy: 0.7980769230769231
test_loss: 0.6617052185420806
test_roc_auc: 0.8798363095238095
test_accuracy: 0.7980769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.524018793788855
Epoch 1/64:
  Train Loss: 0.6842376589775085
  Validation Loss: 0.6199121475219727
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.6837692260742188
  Validation Loss: 0.6198856830596924
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6834291070699692
  Validation Loss: 0.6198660731315613
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.6830533146858215
  Validation Loss: 0.6197864413261414
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.682640016078949
  Validation Loss: 0.6196860074996948
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.6823065876960754
  Validation Loss: 0.6196068525314331
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6819169670343399
  Validation Loss: 0.6194808483123779
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6815460324287415
  Validation Loss: 0.6194150447845459
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6812146604061127
  Validation Loss: 0.6193200349807739
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6808777153491974
  Validation Loss: 0.6192049980163574
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6805355250835419
  Validation Loss: 0.6190837621688843
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6802259385585785
  Validation Loss: 0.6189677119255066
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6798871159553528
  Validation Loss: 0.6188544034957886
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6795894950628281
  Validation Loss: 0.6187324523925781
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6792974174022675
  Validation Loss: 0.6186261177062988
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.678990051150322
  Validation Loss: 0.6185227632522583
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6787312924861908
  Validation Loss: 0.6184473633766174
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6784912496805191
  Validation Loss: 0.6183162927627563
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6781943887472153
  Validation Loss: 0.6181919574737549
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6778622716665268
  Validation Loss: 0.6180250644683838
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6775100529193878
  Validation Loss: 0.617856502532959
  Val ROC-AUC: 0.8980392156862746
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6771419644355774
  Validation Loss: 0.6177178621292114
  Val ROC-AUC: 0.8980392156862746
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6768105179071426
  Validation Loss: 0.6175858974456787
  Val ROC-AUC: 0.8980392156862746
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6765056699514389
  Validation Loss: 0.6174793243408203
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6761825829744339
  Validation Loss: 0.617351770401001
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6758331060409546
  Validation Loss: 0.617190957069397
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6755538880825043
  Validation Loss: 0.6170282363891602
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6752632558345795
  Validation Loss: 0.6168956756591797
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6749799847602844
  Validation Loss: 0.6167871952056885
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6747078895568848
  Validation Loss: 0.6167148947715759
  Val ROC-AUC: 0.9019607843137256
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:05:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:05:INFO:
[92mINFO [0m:      Received: evaluate message bc5cf8cd-ba84-4824-aaa5-cd421ed5b68c
02/07/2025 22:50:05:INFO:Received: evaluate message bc5cf8cd-ba84-4824-aaa5-cd421ed5b68c
[92mINFO [0m:      Sent reply
02/07/2025 22:50:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:08:INFO:
[92mINFO [0m:      Received: train message 75954296-157f-4067-bd4e-d32990374302
02/07/2025 22:50:08:INFO:Received: train message 75954296-157f-4067-bd4e-d32990374302
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6744480580091476
  Validation Loss: 0.6166581511497498
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6741569936275482
  Validation Loss: 0.6165844202041626
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6738719046115875
  Validation Loss: 0.6165174245834351
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6736040264368057
  Validation Loss: 0.6164585947990417
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6734083592891693
  Validation Loss: 0.6163609623908997
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.673174574971199
  Validation Loss: 0.6162504553794861
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6729630827903748
  Validation Loss: 0.6161247491836548
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6727219074964523
  Validation Loss: 0.6159726977348328
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6724790036678314
  Validation Loss: 0.6158267259597778
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6722614765167236
  Validation Loss: 0.6157093048095703
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6720663160085678
  Validation Loss: 0.6156511902809143
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6719289273023605
  Validation Loss: 0.6156030893325806
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6717495173215866
  Validation Loss: 0.6155447363853455
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6716044992208481
  Validation Loss: 0.6154929399490356
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.6714400798082352
  Validation Loss: 0.6154840588569641
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6712273210287094
  Validation Loss: 0.6154252290725708
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.671060636639595
  Validation Loss: 0.6153443455696106
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6708698868751526
  Validation Loss: 0.6152716279029846
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6707222610712051
  Validation Loss: 0.6152194142341614
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6705862432718277
  Validation Loss: 0.6151493787765503
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6704757511615753
  Validation Loss: 0.615082859992981
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.67036272585392
  Validation Loss: 0.6149770021438599
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6701956689357758
  Validation Loss: 0.6149048805236816
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6700998395681381
  Validation Loss: 0.6148766279220581
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6700052171945572
  Validation Loss: 0.6148337125778198
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.6698372513055801
  Validation Loss: 0.614766001701355
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.6696485728025436
  Validation Loss: 0.614711582660675
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6695297807455063
  Validation Loss: 0.6147280931472778
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6694862991571426
  Validation Loss: 0.6147803068161011
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.6694772839546204
  Validation Loss: 0.6148521304130554
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6694347560405731
  Validation Loss: 0.6149061918258667
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6693798005580902
  Validation Loss: 0.6149102449417114
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6693322062492371
  Validation Loss: 0.6149394512176514
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6692646145820618
  Validation Loss: 0.6150051355361938
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
{'train_loss': 0.6692646145820618, 'val_roc_auc': 0.8941176470588236, 'val_accuracy': 0.84375, 'val_loss': 0.6150051355361938}
 ROC_AUC: 0.8941|| Accuracy 0.8438 || Train Loss: 0.6693
 Val Loss: 0.6150 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6590619150262612
Test ROC-AUC: 0.8805803571428571
Test Accuracy: 0.8076923076923077
test_loss: 0.6590619150262612
test_roc_auc: 0.8805803571428571
test_accuracy: 0.8076923076923077
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.42199752881667035
Epoch 1/64:
  Train Loss: 0.6857158690690994
  Validation Loss: 0.6050673723220825
  Val ROC-AUC: 0.9803921568627452
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6853727102279663
  Validation Loss: 0.6049808859825134
  Val ROC-AUC: 0.9803921568627452
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.684967115521431
  Validation Loss: 0.6048991680145264
  Val ROC-AUC: 0.9764705882352942
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6845919191837311
  Validation Loss: 0.6048578023910522
  Val ROC-AUC: 0.9764705882352942
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.6842335611581802
  Validation Loss: 0.6048581600189209
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6839148253202438
  Validation Loss: 0.604820728302002
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6836028099060059
  Validation Loss: 0.6048156023025513
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6832365989685059
  Validation Loss: 0.60475754737854
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6828691959381104
  Validation Loss: 0.6046965718269348
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6825103461742401
  Validation Loss: 0.6046431064605713
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.682167261838913
  Validation Loss: 0.6045987606048584
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6818453222513199
  Validation Loss: 0.6045796871185303
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.681542158126831
  Validation Loss: 0.6045513153076172
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6812323778867722
  Validation Loss: 0.6044970750808716
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6808914095163345
  Validation Loss: 0.6044637560844421
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6805741041898727
  Validation Loss: 0.6044368743896484
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6802713423967361
  Validation Loss: 0.604423463344574
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6799624860286713
  Validation Loss: 0.6044080853462219
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.679651290178299
  Validation Loss: 0.6043702363967896
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 20/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:35:INFO:
[92mINFO [0m:      Received: evaluate message ef39e59d-ceb9-479d-9cc7-cac418f8aa3e
02/07/2025 22:50:35:INFO:Received: evaluate message ef39e59d-ceb9-479d-9cc7-cac418f8aa3e
[92mINFO [0m:      Sent reply
02/07/2025 22:50:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:35:INFO:
[92mINFO [0m:      Received: train message 3d1d6d7c-f7e9-4429-b34a-101e8e822cb9
02/07/2025 22:50:35:INFO:Received: train message 3d1d6d7c-f7e9-4429-b34a-101e8e822cb9
  Train Loss: 0.6793947219848633
  Validation Loss: 0.6043694615364075
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.679142951965332
  Validation Loss: 0.6043515205383301
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6788977682590485
  Validation Loss: 0.6043239235877991
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6786555647850037
  Validation Loss: 0.6042261719703674
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6783402264118195
  Validation Loss: 0.6041432619094849
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6780788600444794
  Validation Loss: 0.604106068611145
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6778451055288315
  Validation Loss: 0.6040933132171631
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6775768101215363
  Validation Loss: 0.6040915250778198
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.677308589220047
  Validation Loss: 0.6040787696838379
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6770618557929993
  Validation Loss: 0.6041374206542969
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6768689453601837
  Validation Loss: 0.6041707992553711
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6766241043806076
  Validation Loss: 0.604187548160553
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6764040142297745
  Validation Loss: 0.6041812300682068
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6761705726385117
  Validation Loss: 0.6041373014450073
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.675876572728157
  Validation Loss: 0.6041568517684937
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6756481826305389
  Validation Loss: 0.6041659116744995
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6753605008125305
  Validation Loss: 0.6041486859321594
  Val ROC-AUC: 0.9568627450980393
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6751453429460526
  Validation Loss: 0.6041274070739746
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6749434173107147
  Validation Loss: 0.6040414571762085
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6747119277715683
  Validation Loss: 0.6040019392967224
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6745378524065018
  Validation Loss: 0.6040081977844238
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6743713319301605
  Validation Loss: 0.6039885878562927
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6741892397403717
  Validation Loss: 0.6040281057357788
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6740205734968185
  Validation Loss: 0.6040161848068237
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6738417744636536
  Validation Loss: 0.603960394859314
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.6736619025468826
  Validation Loss: 0.6039314270019531
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6734765917062759
  Validation Loss: 0.6038732528686523
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.673265278339386
  Validation Loss: 0.6038358807563782
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6731010675430298
  Validation Loss: 0.6038439273834229
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6729154586791992
  Validation Loss: 0.6038534641265869
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.672793984413147
  Validation Loss: 0.603901743888855
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6726461201906204
  Validation Loss: 0.6038905382156372
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6725197583436966
  Validation Loss: 0.6039174795150757
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6723879128694534
  Validation Loss: 0.6039215326309204
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6722258776426315
  Validation Loss: 0.6039332747459412
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6720521748065948
  Validation Loss: 0.6039260029792786
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.671836331486702
  Validation Loss: 0.6038926839828491
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.671679675579071
  Validation Loss: 0.603864312171936
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6714942306280136
  Validation Loss: 0.6038292646408081
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6713077425956726
  Validation Loss: 0.603812575340271
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.671175941824913
  Validation Loss: 0.6037788391113281
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6710072159767151
  Validation Loss: 0.6037660837173462
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6708610504865646
  Validation Loss: 0.6037637591362
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6707367300987244
  Validation Loss: 0.6037859916687012
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6706101298332214
  Validation Loss: 0.6038744449615479
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.84375
{'train_loss': 0.6706101298332214, 'val_roc_auc': 0.9294117647058824, 'val_accuracy': 0.84375, 'val_loss': 0.6038744449615479}
 ROC_AUC: 0.9294|| Accuracy 0.8438 || Train Loss: 0.6706
 Val Loss: 0.6039 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6566236666761912
Test ROC-AUC: 0.8813244047619048
Test Accuracy: 0.8076923076923077
test_loss: 0.6566236666761912
test_roc_auc: 0.8813244047619048
test_accuracy: 0.8076923076923077
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.48051831472548656
Epoch 1/64:
  Train Loss: 0.6729372441768646
  Validation Loss: 0.647030234336853
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6725313812494278
  Validation Loss: 0.6465468406677246
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.6722136437892914
  Validation Loss: 0.6461706757545471
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6719279438257217
  Validation Loss: 0.645811140537262
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.6716836243867874
  Validation Loss: 0.6454519033432007
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6713902950286865
  Validation Loss: 0.6450873613357544
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.6711199432611465
  Validation Loss: 0.6447601318359375
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.670888140797615
  Validation Loss: 0.644458532333374
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6706473678350449
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:51:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:04:INFO:
[92mINFO [0m:      Received: evaluate message 1ac74044-1a04-4caa-9469-f868ef77c31f
02/07/2025 22:51:04:INFO:Received: evaluate message 1ac74044-1a04-4caa-9469-f868ef77c31f
  Validation Loss: 0.6441267728805542
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6704467535018921
  Validation Loss: 0.6437551975250244
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 11/64:
  Train Loss: 0.6701944768428802
  Validation Loss: 0.6434175372123718
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.6699716746807098
  Validation Loss: 0.6431386470794678
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6697605848312378
  Validation Loss: 0.6428670287132263
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.6695856750011444
  Validation Loss: 0.6426354646682739
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.669386625289917
  Validation Loss: 0.642377495765686
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6692215502262115
  Validation Loss: 0.6421914100646973
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.6690467894077301
  Validation Loss: 0.642038106918335
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.6689048409461975
  Validation Loss: 0.6419225931167603
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6687774211168289
  Validation Loss: 0.6417692303657532
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6686095893383026
  Validation Loss: 0.6415371894836426
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6684283763170242
  Validation Loss: 0.6413300633430481
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.6682142615318298
  Validation Loss: 0.6410621404647827
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.6680205166339874
  Validation Loss: 0.6408470273017883
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8125
Epoch 24/64:
  Train Loss: 0.6678398847579956
  Validation Loss: 0.6405928730964661
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8125
Epoch 25/64:
  Train Loss: 0.6676564514636993
  Validation Loss: 0.6403826475143433
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.8125
Epoch 26/64:
  Train Loss: 0.6675010621547699
  Validation Loss: 0.6402230262756348
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6673345863819122
  Validation Loss: 0.6400582194328308
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6671880185604095
  Validation Loss: 0.639919638633728
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6670668423175812
  Validation Loss: 0.6398221850395203
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6669315993785858
  Validation Loss: 0.6397006511688232
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6668436974287033
  Validation Loss: 0.6395456790924072
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6667557209730148
  Validation Loss: 0.6393709182739258
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6666470021009445
  Validation Loss: 0.6391850709915161
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6665403842926025
  Validation Loss: 0.6389963030815125
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6663817316293716
  Validation Loss: 0.6388043165206909
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6662587076425552
  Validation Loss: 0.638606071472168
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6661215722560883
  Validation Loss: 0.6384471654891968
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6660174131393433
  Validation Loss: 0.6382541060447693
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6658718287944794
  Validation Loss: 0.6380388736724854
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6657241731882095
  Validation Loss: 0.6378111243247986
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6655555665493011
  Validation Loss: 0.6376470327377319
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6654346883296967
  Validation Loss: 0.6374815702438354
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.665308266878128
  Validation Loss: 0.6373088359832764
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6652118861675262
  Validation Loss: 0.6372017860412598
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.6651713103055954
  Validation Loss: 0.6370550394058228
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6650795042514801
  Validation Loss: 0.6368774175643921
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 47/64:
  Train Loss: 0.6649608761072159
  Validation Loss: 0.6367204189300537
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 48/64:
  Train Loss: 0.6648530662059784
  Validation Loss: 0.6366281509399414
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 49/64:
  Train Loss: 0.6647461503744125
  Validation Loss: 0.6364946365356445
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 50/64:
  Train Loss: 0.6646239310503006
  Validation Loss: 0.636318564414978
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 51/64:
  Train Loss: 0.6644478440284729
  Validation Loss: 0.6361160278320312
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 52/64:
  Train Loss: 0.6642916351556778
  Validation Loss: 0.6359452605247498
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 53/64:
  Train Loss: 0.6641581058502197
  Validation Loss: 0.6358422040939331
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 54/64:
  Train Loss: 0.664083257317543
  Validation Loss: 0.6357402205467224
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 55/64:
  Train Loss: 0.6639731377363205
  Validation Loss: 0.6356656551361084
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 56/64:
  Train Loss: 0.6638629883527756
  Validation Loss: 0.6355218887329102
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 57/64:
  Train Loss: 0.663722351193428
  Validation Loss: 0.6353309154510498
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 58/64:
  Train Loss: 0.6635673344135284
  Validation Loss: 0.6351284980773926
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 59/64:
  Train Loss: 0.6634570211172104
  Validation Loss: 0.6349383592605591
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 60/64:
  Train Loss: 0.6633141487836838
  Validation Loss: 0.6347894668579102
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 61/64:
  Train Loss: 0.6632068753242493
  Validation Loss: 0.6346427202224731
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 62/64:
  Train Loss: 0.6631274819374084
  Validation Loss: 0.634539008140564
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 63/64:
  Train Loss: 0.6630506813526154
  Validation Loss: 0.6344629526138306
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 64/64:
  Train Loss: 0.6629568189382553
  Validation Loss: 0.6343387365341187
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
{'train_loss': 0.6629568189382553, 'val_roc_auc': 0.9246031746031746, 'val_accuracy': 0.875, 'val_loss': 0.6343387365341187}
 ROC_AUC: 0.9246|| Accuracy 0.8750 || Train Loss: 0.6630
 Val Loss: 0.6343 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6544646543379014
Test ROC-AUC: 0.8813244047619048
Test Accuracy: 0.8076923076923077
[92mINFO [0m:      Sent reply
02/07/2025 22:51:06:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:06:INFO:
[92mINFO [0m:      Received: train message 453de51e-9dea-42bf-99f3-3e99b86b161e
02/07/2025 22:51:06:INFO:Received: train message 453de51e-9dea-42bf-99f3-3e99b86b161e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
test_loss: 0.6544646543379014
test_roc_auc: 0.8813244047619048
test_accuracy: 0.8076923076923077
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.46030807508213917
Epoch 1/64:
  Train Loss: 0.6798431873321533
  Validation Loss: 0.6113001704216003
  Val ROC-AUC: 0.9047619047619047
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6794420182704926
  Validation Loss: 0.610925555229187
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.679138258099556
  Validation Loss: 0.6106595993041992
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6787843853235245
  Validation Loss: 0.6103672981262207
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6784961372613907
  Validation Loss: 0.6101124286651611
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.6782566010951996
  Validation Loss: 0.609950065612793
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6780143082141876
  Validation Loss: 0.6097846031188965
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6778701692819595
  Validation Loss: 0.60956871509552
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6776729077100754
  Validation Loss: 0.6092261075973511
  Val ROC-AUC: 0.9126984126984128
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6774568557739258
  Validation Loss: 0.6089506149291992
  Val ROC-AUC: 0.9126984126984128
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6772732734680176
  Validation Loss: 0.608641505241394
  Val ROC-AUC: 0.9126984126984128
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6770659983158112
  Validation Loss: 0.6083691120147705
  Val ROC-AUC: 0.9126984126984128
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6768112629652023
  Validation Loss: 0.6081033945083618
  Val ROC-AUC: 0.9126984126984128
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6765814423561096
  Validation Loss: 0.6079365015029907
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6763679087162018
  Validation Loss: 0.6077849864959717
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6761706471443176
  Validation Loss: 0.6076145172119141
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6759951114654541
  Validation Loss: 0.6075310707092285
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6758308559656143
  Validation Loss: 0.6074127554893494
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6756668537855148
  Validation Loss: 0.60719895362854
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6754534989595413
  Validation Loss: 0.6070172190666199
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6751944273710251
  Validation Loss: 0.6068484783172607
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6749784648418427
  Validation Loss: 0.6067070960998535
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6747741103172302
  Validation Loss: 0.6065695881843567
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6745671331882477
  Validation Loss: 0.6064791083335876
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6743688583374023
  Validation Loss: 0.606446385383606
  Val ROC-AUC: 0.9126984126984126
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.674204409122467
  Validation Loss: 0.6064168214797974
  Val ROC-AUC: 0.9126984126984126
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6740669459104538
  Validation Loss: 0.6063013672828674
  Val ROC-AUC: 0.9126984126984126
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6738846600055695
  Validation Loss: 0.6062194108963013
  Val ROC-AUC: 0.9126984126984126
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6737874150276184
  Validation Loss: 0.6061492562294006
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6736611276865005
  Validation Loss: 0.6060163974761963
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6735074818134308
  Validation Loss: 0.6058391332626343
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6733821332454681
  Validation Loss: 0.6056294441223145
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6731995940208435
  Validation Loss: 0.6054661273956299
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.673046424984932
  Validation Loss: 0.6052743196487427
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6728531718254089
  Validation Loss: 0.6050760746002197
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.672694206237793
  Validation Loss: 0.6049554347991943
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6725478023290634
  Validation Loss: 0.6048654913902283
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6724506914615631
  Validation Loss: 0.6047763824462891
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6723732352256775
  Validation Loss: 0.6046717166900635
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6723114997148514
  Validation Loss: 0.6046246290206909
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6721865087747574
  Validation Loss: 0.6046472191810608
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6720850914716721
  Validation Loss: 0.6046189069747925
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6719738841056824
  Validation Loss: 0.6045461893081665
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6718306392431259
  Validation Loss: 0.6044331789016724
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.6717001497745514
  Validation Loss: 0.6043212413787842
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6715922355651855
  Validation Loss: 0.6042595505714417
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6714974194765091
  Validation Loss: 0.6042975783348083
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6714198291301727
  Validation Loss: 0.6043397188186646
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.671350285410881
  Validation Loss: 0.6043440103530884
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6712688356637955
  Validation Loss: 0.6042661070823669
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6711802929639816
  Validation Loss: 0.6041920781135559
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6711335778236389
  Validation Loss: 0.6041772365570068
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6710799783468246
  Validation Loss: 0.6040623784065247
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.670988917350769
  Validation Loss: 0.6039202809333801
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6709364652633667
  Validation Loss: 0.6037576198577881
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.670867070555687
  Validation Loss: 0.6036017537117004
  Val ROC-AUC: 0.9206349206349207
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:51:37:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:37:INFO:
[92mINFO [0m:      Received: evaluate message 8b17f3d1-7c7b-4d5f-af12-e3033fafc9d4
02/07/2025 22:51:37:INFO:Received: evaluate message 8b17f3d1-7c7b-4d5f-af12-e3033fafc9d4
[92mINFO [0m:      Sent reply
02/07/2025 22:51:37:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:37:INFO:
[92mINFO [0m:      Received: train message 49acc482-80e9-473a-a1a2-4c4a4756c789
02/07/2025 22:51:37:INFO:Received: train message 49acc482-80e9-473a-a1a2-4c4a4756c789
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.6708007454872131
  Validation Loss: 0.6034578084945679
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6707488596439362
  Validation Loss: 0.6033420562744141
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6707219332456589
  Validation Loss: 0.6032774448394775
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.6706545501947403
  Validation Loss: 0.603191614151001
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6706289649009705
  Validation Loss: 0.6031486988067627
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6706050038337708
  Validation Loss: 0.6030997037887573
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6705363988876343
  Validation Loss: 0.6030510663986206
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6704394519329071
  Validation Loss: 0.6029901504516602
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
{'train_loss': 0.6704394519329071, 'val_roc_auc': 0.9206349206349207, 'val_accuracy': 0.84375, 'val_loss': 0.6029901504516602}
 ROC_AUC: 0.9206|| Accuracy 0.8438 || Train Loss: 0.6704
 Val Loss: 0.6030 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6527670469994729
Test ROC-AUC: 0.8790922619047619
Test Accuracy: 0.7980769230769231
test_loss: 0.6527670469994729
test_roc_auc: 0.8790922619047619
test_accuracy: 0.7980769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.3565104172109083
Epoch 1/64:
  Train Loss: 0.6647559851408005
  Validation Loss: 0.6645677089691162
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 2/64:
  Train Loss: 0.6644212156534195
  Validation Loss: 0.6642074584960938
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 3/64:
  Train Loss: 0.6641397327184677
  Validation Loss: 0.6639591455459595
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 4/64:
  Train Loss: 0.663862481713295
  Validation Loss: 0.6637574434280396
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 5/64:
  Train Loss: 0.6636175960302353
  Validation Loss: 0.6635237336158752
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 6/64:
  Train Loss: 0.6633611917495728
  Validation Loss: 0.663277268409729
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 7/64:
  Train Loss: 0.6631680577993393
  Validation Loss: 0.6630685329437256
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 8/64:
  Train Loss: 0.6629221141338348
  Validation Loss: 0.6628825068473816
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 9/64:
  Train Loss: 0.6626744568347931
  Validation Loss: 0.6627117395401001
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 10/64:
  Train Loss: 0.6624829173088074
  Validation Loss: 0.6625066995620728
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 11/64:
  Train Loss: 0.6622666716575623
  Validation Loss: 0.6623560190200806
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 12/64:
  Train Loss: 0.6621036678552628
  Validation Loss: 0.6622116565704346
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 13/64:
  Train Loss: 0.6618986874818802
  Validation Loss: 0.6620513200759888
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 14/64:
  Train Loss: 0.6617294400930405
  Validation Loss: 0.6618504524230957
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 15/64:
  Train Loss: 0.6615297198295593
  Validation Loss: 0.6616390347480774
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 16/64:
  Train Loss: 0.6613161712884903
  Validation Loss: 0.6614416837692261
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 17/64:
  Train Loss: 0.6611087024211884
  Validation Loss: 0.661292552947998
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 18/64:
  Train Loss: 0.6609623581171036
  Validation Loss: 0.6611707806587219
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 19/64:
  Train Loss: 0.6607972681522369
  Validation Loss: 0.6610259413719177
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 20/64:
  Train Loss: 0.6606293618679047
  Validation Loss: 0.6608774065971375
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 21/64:
  Train Loss: 0.6604817062616348
  Validation Loss: 0.660667896270752
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 22/64:
  Train Loss: 0.6602927297353745
  Validation Loss: 0.6604620218276978
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 23/64:
  Train Loss: 0.660130187869072
  Validation Loss: 0.6603384017944336
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 24/64:
  Train Loss: 0.6600337475538254
  Validation Loss: 0.6602301597595215
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 25/64:
  Train Loss: 0.6599098742008209
  Validation Loss: 0.6601231098175049
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 26/64:
  Train Loss: 0.6598100066184998
  Validation Loss: 0.6600307822227478
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 27/64:
  Train Loss: 0.6596988141536713
  Validation Loss: 0.6599684953689575
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 28/64:
  Train Loss: 0.6595848649740219
  Validation Loss: 0.6598904132843018
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 29/64:
  Train Loss: 0.6594857722520828
  Validation Loss: 0.6598277688026428
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 30/64:
  Train Loss: 0.6594083160161972
  Validation Loss: 0.6597542762756348
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 31/64:
  Train Loss: 0.6592674255371094
  Validation Loss: 0.6596806049346924
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 32/64:
  Train Loss: 0.6591770499944687
  Validation Loss: 0.6596598625183105
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 33/64:
  Train Loss: 0.6590766757726669
  Validation Loss: 0.6596184968948364
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 34/64:
  Train Loss: 0.6590119004249573
  Validation Loss: 0.6595940589904785
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 35/64:
  Train Loss: 0.6589180678129196
  Validation Loss: 0.659548282623291
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 36/64:
  Train Loss: 0.658810555934906
  Validation Loss: 0.6594603061676025
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 37/64:
  Train Loss: 0.6586867868900299
  Validation Loss: 0.6593639850616455
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 38/64:
  Train Loss: 0.6585694402456284
  Validation Loss: 0.6592258214950562
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 39/64:
  Train Loss: 0.6584533005952835
  Validation Loss: 0.6591136455535889
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 40/64:
  Train Loss: 0.6583904474973679
  Validation Loss: 0.658998966217041
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 41/64:
  Train Loss: 0.6582652777433395
  Validation Loss: 0.6589266061782837
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 42/64:
  Train Loss: 0.6581459790468216
  Validation Loss: 0.6588341593742371
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 43/64:
  Train Loss: 0.6580201983451843
  Validation Loss: 0.658742368221283
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 44/64:
  Train Loss: 0.6579606980085373
  Validation Loss: 0.6586908102035522
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 45/64:
  Train Loss: 0.6578578948974609
  Validation Loss: 0.6586306095123291
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 46/64:
  Train Loss: 0.6577782034873962
  Validation Loss: 0.658570408821106
  Val ROC-AUC: 0.9595141700404859/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:06:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:06:INFO:
[92mINFO [0m:      Received: evaluate message ce8a48df-4ffb-4233-8da6-2402fb5a0383
02/07/2025 22:52:06:INFO:Received: evaluate message ce8a48df-4ffb-4233-8da6-2402fb5a0383
[92mINFO [0m:      Sent reply
02/07/2025 22:52:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:08:INFO:
[92mINFO [0m:      Received: train message 58ba3bd8-e0fb-473d-be5a-7141ac2dc2f3
02/07/2025 22:52:08:INFO:Received: train message 58ba3bd8-e0fb-473d-be5a-7141ac2dc2f3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

  Val Accuracy: 0.875
Epoch 47/64:
  Train Loss: 0.6576622873544693
  Validation Loss: 0.6585273742675781
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 48/64:
  Train Loss: 0.6575682908296585
  Validation Loss: 0.6584759950637817
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 49/64:
  Train Loss: 0.6574903577566147
  Validation Loss: 0.6584098935127258
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 50/64:
  Train Loss: 0.6573965847492218
  Validation Loss: 0.6583105325698853
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 51/64:
  Train Loss: 0.6572981625795364
  Validation Loss: 0.6582627296447754
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 52/64:
  Train Loss: 0.6572163254022598
  Validation Loss: 0.6582616567611694
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 53/64:
  Train Loss: 0.6571469008922577
  Validation Loss: 0.6582784652709961
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 54/64:
  Train Loss: 0.657078742980957
  Validation Loss: 0.6582411527633667
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 55/64:
  Train Loss: 0.6570131033658981
  Validation Loss: 0.6582303643226624
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 56/64:
  Train Loss: 0.656952977180481
  Validation Loss: 0.6581965088844299
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 57/64:
  Train Loss: 0.6569117903709412
  Validation Loss: 0.6581786870956421
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 58/64:
  Train Loss: 0.6568603962659836
  Validation Loss: 0.6581660509109497
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 59/64:
  Train Loss: 0.6568013727664948
  Validation Loss: 0.6581017374992371
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 60/64:
  Train Loss: 0.6567304283380508
  Validation Loss: 0.6580137014389038
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 61/64:
  Train Loss: 0.6566617488861084
  Validation Loss: 0.6579511761665344
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 62/64:
  Train Loss: 0.6565947234630585
  Validation Loss: 0.6579298377037048
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 63/64:
  Train Loss: 0.6565683335065842
  Validation Loss: 0.657904326915741
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 64/64:
  Train Loss: 0.656516432762146
  Validation Loss: 0.6578640937805176
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
{'train_loss': 0.656516432762146, 'val_roc_auc': 0.9595141700404859, 'val_accuracy': 0.875, 'val_loss': 0.6578640937805176}
 ROC_AUC: 0.9595|| Accuracy 0.8750 || Train Loss: 0.6565
 Val Loss: 0.6579 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6513968711862197
Test ROC-AUC: 0.8783482142857142
Test Accuracy: 0.7884615384615384
test_loss: 0.6513968711862197
test_roc_auc: 0.8783482142857142
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.3053224179893732
Epoch 1/64:
  Train Loss: 0.6640798300504684
  Validation Loss: 0.6602981090545654
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 2/64:
  Train Loss: 0.663748100399971
  Validation Loss: 0.6602555513381958
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 3/64:
  Train Loss: 0.6634921431541443
  Validation Loss: 0.6602046489715576
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 4/64:
  Train Loss: 0.6631822437047958
  Validation Loss: 0.6601216197013855
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 5/64:
  Train Loss: 0.6629290878772736
  Validation Loss: 0.6600651741027832
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 6/64:
  Train Loss: 0.6626762449741364
  Validation Loss: 0.6599950790405273
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 7/64:
  Train Loss: 0.6623996496200562
  Validation Loss: 0.6599805355072021
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 8/64:
  Train Loss: 0.6621670573949814
  Validation Loss: 0.6599599719047546
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 9/64:
  Train Loss: 0.6619134396314621
  Validation Loss: 0.6599016189575195
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6616532206535339
  Validation Loss: 0.659846305847168
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6614181995391846
  Validation Loss: 0.6598312854766846
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6611814945936203
  Validation Loss: 0.659831166267395
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6609865427017212
  Validation Loss: 0.6598425507545471
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6608269959688187
  Validation Loss: 0.6598867177963257
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6606316268444061
  Validation Loss: 0.6598694920539856
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6604238301515579
  Validation Loss: 0.6598460078239441
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6602675169706345
  Validation Loss: 0.659828782081604
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.660067155957222
  Validation Loss: 0.6597937345504761
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6598258167505264
  Validation Loss: 0.6597413420677185
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6596540808677673
  Validation Loss: 0.6597039103507996
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6594619303941727
  Validation Loss: 0.6597110033035278
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6592805832624435
  Validation Loss: 0.6597740650177002
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6591336876153946
  Validation Loss: 0.6598217487335205
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6589809656143188
  Validation Loss: 0.6598600149154663
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6587997823953629
  Validation Loss: 0.6598544120788574
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6586290895938873
  Validation Loss: 0.6598308086395264
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6584571748971939
  Validation Loss: 0.6598598957061768
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6583331376314163
  Validation Loss: 0.6598871946334839
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.658181220293045
  Validation Loss: 0.6599500179290771
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6580721139907837
  Validation Loss: 0.6600303649902344
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6579623818397522
  Validation Loss: 0.6600836515426636
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6578409522771835
  Validation Loss: 0.6601284742355347
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6577455848455429
  Validation Loss: 0.6601521968841553
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6575897932052612
  Validation Loss: 0.6601865887641907
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6574612110853195
  Validation Loss: 0.6601823568344116
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6573002934455872
  Validation Loss: 0.6601812839508057
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:35:INFO:
[92mINFO [0m:      Received: evaluate message 715c14d8-3d1f-45c5-92ab-530e898c4b4a
02/07/2025 22:52:35:INFO:Received: evaluate message 715c14d8-3d1f-45c5-92ab-530e898c4b4a
[92mINFO [0m:      Sent reply
02/07/2025 22:52:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:35:INFO:
[92mINFO [0m:      Received: train message b57fe88b-b78c-4f08-9711-9e5124562313
02/07/2025 22:52:35:INFO:Received: train message b57fe88b-b78c-4f08-9711-9e5124562313
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.657199040055275
  Validation Loss: 0.6601923704147339
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6570452004671097
  Validation Loss: 0.6602165699005127
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6569248139858246
  Validation Loss: 0.6602370738983154
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.656764030456543
  Validation Loss: 0.6602627038955688
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6566181480884552
  Validation Loss: 0.6603000164031982
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6564934998750687
  Validation Loss: 0.6602836847305298
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6563125401735306
  Validation Loss: 0.6603310108184814
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.656194657087326
  Validation Loss: 0.6604211926460266
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6561013609170914
  Validation Loss: 0.6604982614517212
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6560038477182388
  Validation Loss: 0.6605796813964844
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6559097170829773
  Validation Loss: 0.6606844663619995
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6558830738067627
  Validation Loss: 0.6608327031135559
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6558106243610382
  Validation Loss: 0.6609287261962891
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.6557376086711884
  Validation Loss: 0.6610283851623535
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.6556430459022522
  Validation Loss: 0.661104679107666
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6555562168359756
  Validation Loss: 0.6611883640289307
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6554843038320541
  Validation Loss: 0.6612638235092163
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6553959399461746
  Validation Loss: 0.6613160371780396
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6552940756082535
  Validation Loss: 0.6613425016403198
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6551978290081024
  Validation Loss: 0.6613537073135376
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6551146507263184
  Validation Loss: 0.6613454818725586
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.655023530125618
  Validation Loss: 0.6613780856132507
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6549438238143921
  Validation Loss: 0.661415696144104
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6548625528812408
  Validation Loss: 0.6614558696746826
  Val ROC-AUC: 0.9433198380566802
  Val Accuracy: 0.8125
Epoch 61/64:
  Train Loss: 0.6547944843769073
  Validation Loss: 0.661505937576294
  Val ROC-AUC: 0.9433198380566802
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6547204703092575
  Validation Loss: 0.6615912914276123
  Val ROC-AUC: 0.9392712550607288
  Val Accuracy: 0.8125
Epoch 63/64:
  Train Loss: 0.6546719670295715
  Validation Loss: 0.6616353988647461
  Val ROC-AUC: 0.9352226720647774
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6546139866113663
  Validation Loss: 0.6616495847702026
  Val ROC-AUC: 0.9352226720647774
  Val Accuracy: 0.8125
{'train_loss': 0.6546139866113663, 'val_roc_auc': 0.9352226720647774, 'val_accuracy': 0.8125, 'val_loss': 0.6616495847702026}
 ROC_AUC: 0.9352|| Accuracy 0.8125 || Train Loss: 0.6546
 Val Loss: 0.6616 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6503002892893094
Test ROC-AUC: 0.878720238095238
Test Accuracy: 0.7884615384615384
test_loss: 0.6503002892893094
test_roc_auc: 0.878720238095238
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.31260033869572607
Epoch 1/64:
  Train Loss: 0.6658353954553604
  Validation Loss: 0.6476773619651794
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.6655307114124298
  Validation Loss: 0.6474823355674744
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 3/64:
  Train Loss: 0.6653003841638565
  Validation Loss: 0.6472282409667969
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 4/64:
  Train Loss: 0.6650131195783615
  Validation Loss: 0.6469871401786804
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 5/64:
  Train Loss: 0.6647832244634628
  Validation Loss: 0.6467938423156738
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 6/64:
  Train Loss: 0.6646057814359665
  Validation Loss: 0.64659583568573
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.6644070744514465
  Validation Loss: 0.6463775634765625
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 8/64:
  Train Loss: 0.6641725152730942
  Validation Loss: 0.6461848616600037
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 9/64:
  Train Loss: 0.6639610826969147
  Validation Loss: 0.6460309028625488
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 10/64:
  Train Loss: 0.6637560129165649
  Validation Loss: 0.6458741426467896
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 11/64:
  Train Loss: 0.6635565608739853
  Validation Loss: 0.6457189321517944
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 12/64:
  Train Loss: 0.6633489578962326
  Validation Loss: 0.6455838680267334
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 13/64:
  Train Loss: 0.6631629168987274
  Validation Loss: 0.6454334259033203
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.6875
Epoch 14/64:
  Train Loss: 0.6629690527915955
  Validation Loss: 0.6452758312225342
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6628154218196869
  Validation Loss: 0.6450978517532349
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6626728922128677
  Validation Loss: 0.6449402570724487
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6625193059444427
  Validation Loss: 0.6447762250900269
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6623217314481735
  Validation Loss: 0.6446197032928467
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6621768772602081
  Validation Loss: 0.6444991827011108
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6619671434164047
  Validation Loss: 0.644334077835083
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6617866307497025
  Validation Loss: 0.6441634893417358
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6615937352180481
  Validation Loss: 0.6440011858940125
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6614010483026505
  Validation Loss: 0.6438365578651428
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6612213104963303
  Validation Loss: 0.6436506509780884
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6610194444656372
  Validation Loss: 0.6434978246688843
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6608763933181763
  Validation Loss: 0.6433352828025818
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6606784164905548
  Validation Loss: 0.6431994438171387
  Val ROC-AUC: 0.85546875
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:01:INFO:
[92mINFO [0m:      Received: evaluate message f6dba95b-4bc0-4018-9925-9e6fa7f9069d
02/07/2025 22:53:01:INFO:Received: evaluate message f6dba95b-4bc0-4018-9925-9e6fa7f9069d
[92mINFO [0m:      Sent reply
02/07/2025 22:53:03:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: train message e8c89b99-ea7f-430c-a222-47a0473e2032
02/07/2025 22:53:04:INFO:Received: train message e8c89b99-ea7f-430c-a222-47a0473e2032
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6605158001184464
  Validation Loss: 0.6430732607841492
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6604129374027252
  Validation Loss: 0.6429368257522583
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.660318985581398
  Validation Loss: 0.6428383588790894
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6602008193731308
  Validation Loss: 0.6427056789398193
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6600701063871384
  Validation Loss: 0.6426008343696594
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6599631309509277
  Validation Loss: 0.6424927711486816
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6598564982414246
  Validation Loss: 0.6423993110656738
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6597439050674438
  Validation Loss: 0.6422834396362305
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6596303433179855
  Validation Loss: 0.642203688621521
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6595446169376373
  Validation Loss: 0.6421592831611633
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6594685912132263
  Validation Loss: 0.6421055793762207
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6593678593635559
  Validation Loss: 0.642048716545105
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6592728644609451
  Validation Loss: 0.6419893503189087
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6592002063989639
  Validation Loss: 0.6419066190719604
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6591086685657501
  Validation Loss: 0.6418428421020508
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6590439230203629
  Validation Loss: 0.64176344871521
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6589599400758743
  Validation Loss: 0.6416971683502197
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6588852256536484
  Validation Loss: 0.6416223049163818
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6587766855955124
  Validation Loss: 0.6415720582008362
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6586852222681046
  Validation Loss: 0.6414988040924072
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6586143523454666
  Validation Loss: 0.6414357423782349
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.658560574054718
  Validation Loss: 0.6413359642028809
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6584825217723846
  Validation Loss: 0.6412420272827148
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6584257930517197
  Validation Loss: 0.6411235332489014
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6583351492881775
  Validation Loss: 0.6410301327705383
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6582584530115128
  Validation Loss: 0.6409316062927246
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6581983715295792
  Validation Loss: 0.6408203840255737
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.6581079512834549
  Validation Loss: 0.6406927108764648
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.658027857542038
  Validation Loss: 0.640608012676239
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6579941809177399
  Validation Loss: 0.6405582427978516
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.6579724848270416
  Validation Loss: 0.640505850315094
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.6579559892416
  Validation Loss: 0.6404165029525757
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.6579008847475052
  Validation Loss: 0.6403818130493164
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.657851830124855
  Validation Loss: 0.6403434872627258
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6578059047460556
  Validation Loss: 0.6402801275253296
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6577579230070114
  Validation Loss: 0.6402484178543091
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6577053666114807
  Validation Loss: 0.6402022838592529
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
{'train_loss': 0.6577053666114807, 'val_roc_auc': 0.859375, 'val_accuracy': 0.71875, 'val_loss': 0.6402022838592529}
 ROC_AUC: 0.8594|| Accuracy 0.7188 || Train Loss: 0.6577
 Val Loss: 0.6402 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6493906378746033
Test ROC-AUC: 0.8761160714285715
Test Accuracy: 0.7884615384615384
test_loss: 0.6493906378746033
test_roc_auc: 0.8761160714285715
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8050537109375
Dynamic noise multiplier: 0.2152548190933885
Epoch 1/64:
  Train Loss: 0.6636551022529602
  Validation Loss: 0.6510776281356812
  Val ROC-AUC: 0.9087301587301588
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6633174419403076
  Validation Loss: 0.6509539484977722
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.6630309820175171
  Validation Loss: 0.6508135795593262
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6627627164125443
  Validation Loss: 0.6507371664047241
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6624639630317688
  Validation Loss: 0.650680422782898
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.662201002240181
  Validation Loss: 0.6506210565567017
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.75
Epoch 7/64:
  Train Loss: 0.6619521379470825
  Validation Loss: 0.6505271196365356
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.6616743505001068
  Validation Loss: 0.6504392027854919
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.6614327430725098
  Validation Loss: 0.6504154205322266
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.661217451095581
  Validation Loss: 0.6503377556800842
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6609574109315872
  Validation Loss: 0.6502798795700073
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.6607252061367035
  Validation Loss: 0.650232195854187
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6604796946048737
  Validation Loss: 0.6502329707145691
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6603034287691116
  Validation Loss: 0.6502428650856018
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6600949913263321
  Validation Loss: 0.6502320766448975
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6599044352769852
  Validation Loss: 0.6502336263656616
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6597129553556442
  Validation Loss: 0.6502538919448853
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6595510393381119
  Validation Loss: 0.6502754092216492
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.659390315413475
  Validation Loss: 0.6503135561943054
  Val ROC-AUC: 0.9007936507936508
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:29:INFO:
[92mINFO [0m:      Received: evaluate message a241077e-ba08-473e-8e07-082c97a3b9b4
02/07/2025 22:53:29:INFO:Received: evaluate message a241077e-ba08-473e-8e07-082c97a3b9b4
[92mINFO [0m:      Sent reply
02/07/2025 22:53:32:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:32:INFO:
[92mINFO [0m:      Received: train message 5a329975-b274-4e20-8e0e-07f1a91f42c9
02/07/2025 22:53:32:INFO:Received: train message 5a329975-b274-4e20-8e0e-07f1a91f42c9
