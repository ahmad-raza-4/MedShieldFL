nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:42:22:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:42:22:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 22:42:22:DEBUG:ChannelConnectivity.IDLE
02/07/2025 22:42:22:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738996942.477277 1769888 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/07/2025 22:42:23:INFO:
[92mINFO [0m:      Received: train message 8eaf7c43-f5f2-4339-b64e-6546780b2b85
02/07/2025 22:42:23:INFO:Received: train message 8eaf7c43-f5f2-4339-b64e-6546780b2b85
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours/10.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours']
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.28213382942340104
Epoch 1/64:
  Train Loss: 0.7611484676599503
  Validation Loss: 0.7939300537109375
  Val ROC-AUC: 0.5617283950617284
  Val Accuracy: 0.5185185074806213
Epoch 2/64:
  Train Loss: 0.7590935528278351
  Validation Loss: 0.7927199602127075
  Val ROC-AUC: 0.5679012345679013
  Val Accuracy: 0.5185185074806213
Epoch 3/64:
  Train Loss: 0.7641650289297104
  Validation Loss: 0.7914997339248657
  Val ROC-AUC: 0.5740740740740741
  Val Accuracy: 0.5185185074806213
Epoch 4/64:
  Train Loss: 0.7704028636217117
  Validation Loss: 0.7902900576591492
  Val ROC-AUC: 0.5802469135802468
  Val Accuracy: 0.5185185074806213
Epoch 5/64:
  Train Loss: 0.7599961161613464
  Validation Loss: 0.7890529036521912
  Val ROC-AUC: 0.5987654320987654
  Val Accuracy: 0.5555555820465088
Epoch 6/64:
  Train Loss: 0.7622105181217194
  Validation Loss: 0.7878609895706177
  Val ROC-AUC: 0.6049382716049383
  Val Accuracy: 0.5555555820465088
Epoch 7/64:
  Train Loss: 0.7598835825920105
  Validation Loss: 0.786628246307373
  Val ROC-AUC: 0.6172839506172839
  Val Accuracy: 0.5925925970077515
Epoch 8/64:
  Train Loss: 0.7609063982963562
  Validation Loss: 0.7854627966880798
  Val ROC-AUC: 0.6234567901234568
  Val Accuracy: 0.5925925970077515
Epoch 9/64:
  Train Loss: 0.7474794983863831
  Validation Loss: 0.7842362523078918
  Val ROC-AUC: 0.6234567901234568
  Val Accuracy: 0.5925925970077515
Epoch 10/64:
  Train Loss: 0.7478011697530746
  Validation Loss: 0.7830108404159546
  Val ROC-AUC: 0.6358024691358024
  Val Accuracy: 0.5925925970077515
Epoch 11/64:
  Train Loss: 0.7500254362821579
  Validation Loss: 0.7818032503128052
  Val ROC-AUC: 0.6481481481481481
  Val Accuracy: 0.5925925970077515
Epoch 12/64:
  Train Loss: 0.7632164508104324
  Validation Loss: 0.7806019186973572
  Val ROC-AUC: 0.654320987654321
  Val Accuracy: 0.5925925970077515
Epoch 13/64:
  Train Loss: 0.7490033358335495
  Validation Loss: 0.7793887257575989
  Val ROC-AUC: 0.6790123456790124
  Val Accuracy: 0.5925925970077515
Epoch 14/64:
  Train Loss: 0.7439388185739517
  Validation Loss: 0.7781505584716797
  Val ROC-AUC: 0.6851851851851851
  Val Accuracy: 0.6296296119689941
Epoch 15/64:
  Train Loss: 0.7429716289043427
  Validation Loss: 0.7769832015037537
  Val ROC-AUC: 0.6851851851851851
  Val Accuracy: 0.6296296119689941
Epoch 16/64:
  Train Loss: 0.7441629618406296
  Validation Loss: 0.7758674621582031
  Val ROC-AUC: 0.691358024691358
  Val Accuracy: 0.6296296119689941
Epoch 17/64:
  Train Loss: 0.7431896030902863
  Validation Loss: 0.7747623324394226
  Val ROC-AUC: 0.7037037037037037
  Val Accuracy: 0.6296296119689941
Epoch 18/64:
  Train Loss: 0.7340362221002579
  Validation Loss: 0.7736355662345886
  Val ROC-AUC: 0.7160493827160495
  Val Accuracy: 0.6296296119689941
Epoch 19/64:
  Train Loss: 0.7403507977724075
  Validation Loss: 0.772521436214447
  Val ROC-AUC: 0.7160493827160495
  Val Accuracy: 0.6296296119689941
Epoch 20/64:
  Train Loss: 0.7257931232452393
  Validation Loss: 0.7714865207672119
  Val ROC-AUC: 0.7283950617283951
  Val Accuracy: 0.6296296119689941
Epoch 21/64:
  Train Loss: 0.7344133108854294
  Validation Loss: 0.7704613208770752
  Val ROC-AUC: 0.7407407407407407
  Val Accuracy: 0.6296296119689941
Epoch 22/64:
  Train Loss: 0.7255495637655258
  Validation Loss: 0.7694562077522278
  Val ROC-AUC: 0.7407407407407407
  Val Accuracy: 0.6296296119689941
Epoch 23/64:
  Train Loss: 0.7324662357568741
  Validation Loss: 0.7684578895568848
  Val ROC-AUC: 0.7469135802469136
  Val Accuracy: 0.6666666865348816
Epoch 24/64:
  Train Loss: 0.7299719154834747
  Validation Loss: 0.7674875855445862
  Val ROC-AUC: 0.7469135802469136
  Val Accuracy: 0.6666666865348816
Epoch 25/64:
  Train Loss: 0.7166933119297028
  Validation Loss: 0.7665097117424011
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.6666666865348816
Epoch 26/64:
  Train Loss: 0.7156050950288773
  Validation Loss: 0.7655066847801208
  Val ROC-AUC: 0.7592592592592593
  Val Accuracy: 0.6666666865348816
Epoch 27/64:
  Train Loss: 0.7176637500524521
  Validation Loss: 0.7645054459571838
  Val ROC-AUC: 0.7592592592592593
  Val Accuracy: 0.7037037014961243
Epoch 28/64:
  Train Loss: 0.7193502932786942
  Validation Loss: 0.7635146379470825
  Val ROC-AUC: 0.7592592592592593
  Val Accuracy: 0.7037037014961243
Epoch 29/64:
  Train Loss: 0.7193419635295868
  Validation Loss: 0.7625937461853027
  Val ROC-AUC: 0.7592592592592593
  Val Accuracy: 0.7037037014961243
Epoch 30/64:
  Train Loss: 0.7265561074018478
  Validation Loss: 0.761711835861206
  Val ROC-AUC: 0.7592592592592593
  Val Accuracy: 0.7037037014961243
Epoch 31/64:
  Train Loss: 0.7133304476737976
  Validation Loss: 0.7608213424682617
  Val ROC-AUC: 0.7654320987654321
  Val Accuracy: 0.7037037014961243
Epoch 32/64:
  Train Loss: 0.7255480736494064
  Validation Loss: 0.7599551677703857
  Val ROC-AUC: 0.7716049382716049
  Val Accuracy: 0.7037037014961243
Epoch 33/64:
  Train Loss: 0.7236096560955048
  Validation Loss: 0.759102463722229
  Val ROC-AUC: 0.7716049382716049
  Val Accuracy: 0.7037037014961243
Epoch 34/64:
  Train Loss: 0.7114432603120804
  Validation Loss: 0.7582341432571411
  Val ROC-AUC: 0.7839506172839505
  Val Accuracy: 0.7037037014961243
Epoch 35/64:
  Train Loss: 0.717511385679245
  Validation Loss: 0.7573712468147278
  Val ROC-AUC: 0.7839506172839505
  Val Accuracy: 0.7037037014961243
Epoch 36/64:
  Train Loss: 0.7198435366153717
  Validation Loss: 0.7564625144004822
  Val ROC-AUC: 0.7839506172839505
  Val Accuracy: 0.7037037014961243
Epoch 37/64:
  Train Loss: 0.7139823883771896
  Validation Loss: 0.7556045055389404
  Val ROC-AUC: 0.7901234567901234
  Val Accuracy: 0.7037037014961243
Epoch 38/64:
  Train Loss: 0.7175176292657852
  Validation Loss: 0.7547629475593567
  Val ROC-AUC: 0.8024691358024691
  Val Accuracy: 0.7037037014961243
Epoch 39/64:
  Train Loss: 0.7007946968078613
  Validation Loss: 0.7539404630661011
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 40/64:
  Train Loss: 0.7164406180381775
  Validation Loss: 0.7531801462173462
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 41/64:
  Train Loss: 0.7072829008102417
  Validation Loss: 0.7523744702339172
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7407407760620117
Epoch 42/64:
  Train Loss: 0.7143682539463043
  Validation Loss: 0.7515851259231567
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7407407760620117
Epoch 43/64:
  Train Loss: 0.7133743464946747
  Validation Loss: 0.7508469820022583
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 44/64:
  Train Loss: 0.718873605132103
  Validation Loss: 0.7501480579376221
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.7037037014961243
Epoch 45/64:
  Train Loss: 0.6987413913011551
  Validation Loss: 0.749459445476532
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 46/64:
  Train Loss: 0.6998462677001953
  Validation Loss: 0.7487704753875732
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 47/64:
  Train Loss: 0.7096326798200607
  Validation Loss: 0.7480621337890625
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 48/64:
  Train Loss: 0.7013048827648163
  Validation Loss: 0.7473128437995911
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 49/64:
  Train Loss: 0.7086958885192871
  Validation Loss: 0.7465847134590149
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7407407760620117
Epoch 50/64:
  Train Loss: 0.6896705031394958
  Validation Loss: 0.7458395957946777
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:42:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:42:48:INFO:
[92mINFO [0m:      Received: evaluate message 6ddae7bf-dc8f-4313-bb2e-dde37dae1b62
02/07/2025 22:42:48:INFO:Received: evaluate message 6ddae7bf-dc8f-4313-bb2e-dde37dae1b62
[92mINFO [0m:      Sent reply
02/07/2025 22:42:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:42:53:INFO:
[92mINFO [0m:      Received: train message 0547751f-b52c-4661-86f0-7bed579c1555
02/07/2025 22:42:53:INFO:Received: train message 0547751f-b52c-4661-86f0-7bed579c1555
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7407407760620117
Epoch 51/64:
  Train Loss: 0.6893380433320999
  Validation Loss: 0.7451096177101135
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7407407760620117
Epoch 52/64:
  Train Loss: 0.6998158097267151
  Validation Loss: 0.7444024085998535
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7407407760620117
Epoch 53/64:
  Train Loss: 0.6928882747888565
  Validation Loss: 0.7436764240264893
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.7407407760620117
Epoch 54/64:
  Train Loss: 0.6985461860895157
  Validation Loss: 0.742986261844635
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.7407407760620117
Epoch 55/64:
  Train Loss: 0.703090026974678
  Validation Loss: 0.7423208951950073
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7407407760620117
Epoch 56/64:
  Train Loss: 0.6970844566822052
  Validation Loss: 0.7416869401931763
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7407407760620117
Epoch 57/64:
  Train Loss: 0.6873914152383804
  Validation Loss: 0.7410063147544861
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7407407760620117
Epoch 58/64:
  Train Loss: 0.696914941072464
  Validation Loss: 0.7403639554977417
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7407407760620117
Epoch 59/64:
  Train Loss: 0.6970855742692947
  Validation Loss: 0.7396888732910156
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7407407760620117
Epoch 60/64:
  Train Loss: 0.6810689717531204
  Validation Loss: 0.7390244007110596
  Val ROC-AUC: 0.8641975308641975
  Val Accuracy: 0.7407407760620117
Epoch 61/64:
  Train Loss: 0.6858277171850204
  Validation Loss: 0.738359272480011
  Val ROC-AUC: 0.8641975308641975
  Val Accuracy: 0.7407407760620117
Epoch 62/64:
  Train Loss: 0.6988440752029419
  Validation Loss: 0.7376956343650818
  Val ROC-AUC: 0.8641975308641975
  Val Accuracy: 0.7777777910232544
Epoch 63/64:
  Train Loss: 0.6896634250879288
  Validation Loss: 0.7370572090148926
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.7777777910232544
Epoch 64/64:
  Train Loss: 0.6860385686159134
  Validation Loss: 0.7364526987075806
  Val ROC-AUC: 0.8765432098765432
  Val Accuracy: 0.7777777910232544
{'train_loss': 0.6860385686159134, 'val_roc_auc': 0.8765432098765432, 'val_accuracy': 0.7777777910232544, 'val_loss': 0.7364526987075806}
 ROC_AUC: 0.8765|| Accuracy 0.7778 || Train Loss: 0.6860
 Val Loss: 0.7365 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.778533210245411
Test ROC-AUC: 0.6915584415584415
Test Accuracy: 0.5617977528089888
test_loss: 0.778533210245411
test_roc_auc: 0.6915584415584415
test_accuracy: 0.5617977528089888
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.483306918067683
Epoch 1/64:
  Train Loss: 0.7563659399747849
  Validation Loss: 0.8255507349967957
  Val ROC-AUC: 0.611842105263158
  Val Accuracy: 0.5555555820465088
Epoch 2/64:
  Train Loss: 0.7546556293964386
  Validation Loss: 0.8237269520759583
  Val ROC-AUC: 0.631578947368421
  Val Accuracy: 0.5555555820465088
Epoch 3/64:
  Train Loss: 0.7507183998823166
  Validation Loss: 0.8220126032829285
  Val ROC-AUC: 0.6513157894736843
  Val Accuracy: 0.5555555820465088
Epoch 4/64:
  Train Loss: 0.747036874294281
  Validation Loss: 0.8202992081642151
  Val ROC-AUC: 0.6578947368421053
  Val Accuracy: 0.5555555820465088
Epoch 5/64:
  Train Loss: 0.7430208921432495
  Validation Loss: 0.8186236023902893
  Val ROC-AUC: 0.6644736842105263
  Val Accuracy: 0.5925925970077515
Epoch 6/64:
  Train Loss: 0.7371000349521637
  Validation Loss: 0.8169686198234558
  Val ROC-AUC: 0.6776315789473685
  Val Accuracy: 0.5925925970077515
Epoch 7/64:
  Train Loss: 0.7362280189990997
  Validation Loss: 0.8153425455093384
  Val ROC-AUC: 0.6776315789473685
  Val Accuracy: 0.6296296119689941
Epoch 8/64:
  Train Loss: 0.7332436442375183
  Validation Loss: 0.8137179017066956
  Val ROC-AUC: 0.7105263157894737
  Val Accuracy: 0.6296296119689941
Epoch 9/64:
  Train Loss: 0.7423969954252243
  Validation Loss: 0.8121769428253174
  Val ROC-AUC: 0.736842105263158
  Val Accuracy: 0.6296296119689941
Epoch 10/64:
  Train Loss: 0.7490339428186417
  Validation Loss: 0.8106211423873901
  Val ROC-AUC: 0.7500000000000001
  Val Accuracy: 0.6296296119689941
Epoch 11/64:
  Train Loss: 0.7330448180437088
  Validation Loss: 0.8090313076972961
  Val ROC-AUC: 0.7697368421052633
  Val Accuracy: 0.6296296119689941
Epoch 12/64:
  Train Loss: 0.734254002571106
  Validation Loss: 0.8074694275856018
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.6666666865348816
Epoch 13/64:
  Train Loss: 0.723051980137825
  Validation Loss: 0.8059303760528564
  Val ROC-AUC: 0.8223684210526316
  Val Accuracy: 0.6666666865348816
Epoch 14/64:
  Train Loss: 0.7396379709243774
  Validation Loss: 0.8044317960739136
  Val ROC-AUC: 0.8289473684210527
  Val Accuracy: 0.7037037014961243
Epoch 15/64:
  Train Loss: 0.7448025345802307
  Validation Loss: 0.8029094338417053
  Val ROC-AUC: 0.8552631578947368
  Val Accuracy: 0.7037037014961243
Epoch 16/64:
  Train Loss: 0.7460940033197403
  Validation Loss: 0.8015037775039673
  Val ROC-AUC: 0.861842105263158
  Val Accuracy: 0.7037037014961243
Epoch 17/64:
  Train Loss: 0.7343577444553375
  Validation Loss: 0.8000808358192444
  Val ROC-AUC: 0.875
  Val Accuracy: 0.7407407760620117
Epoch 18/64:
  Train Loss: 0.7227119654417038
  Validation Loss: 0.79863440990448
  Val ROC-AUC: 0.8881578947368421
  Val Accuracy: 0.7407407760620117
Epoch 19/64:
  Train Loss: 0.7179052829742432
  Validation Loss: 0.7971494793891907
  Val ROC-AUC: 0.8881578947368421
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.7447309643030167
  Validation Loss: 0.7957029342651367
  Val ROC-AUC: 0.8881578947368421
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.7278323024511337
  Validation Loss: 0.794287919998169
  Val ROC-AUC: 0.8947368421052632
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.7138687968254089
  Validation Loss: 0.7928501963615417
  Val ROC-AUC: 0.8947368421052632
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.7177911251783371
  Validation Loss: 0.7914461493492126
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.7292554974555969
  Validation Loss: 0.7900062799453735
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.7198724150657654
  Validation Loss: 0.788628876209259
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.7260771989822388
  Validation Loss: 0.7872874736785889
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.7198191285133362
  Validation Loss: 0.7859939336776733
  Val ROC-AUC: 0.9144736842105263
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.7261042445898056
  Validation Loss: 0.7846859693527222
  Val ROC-AUC: 0.9210526315789475
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.7080650329589844
  Validation Loss: 0.783440351486206
  Val ROC-AUC: 0.9276315789473684
  Val Accuracy: 0.7777777910232544
Epoch 30/64:
  Train Loss: 0.7119209170341492
  Validation Loss: 0.7821642756462097
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 31/64:
  Train Loss: 0.7165696024894714
  Validation Loss: 0.7809551954269409
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 32/64:
  Train Loss: 0.711815670132637
  Validation Loss: 0.7797631025314331
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.7777777910232544
Epoch 33/64:
  Train Loss: 0.7063539922237396
  Validation Loss: 0.7785831689834595
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.7777777910232544
Epoch 34/64:
  Train Loss: 0.7126581966876984
  Validation Loss: 0.7772964239120483
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.7777777910232544
Epoch 35/64:
  Train Loss: 0.7097857594490051
  Validation Loss: 0.7760360240936279
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.7777777910232544
Epoch 36/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:43:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:19:INFO:
[92mINFO [0m:      Received: evaluate message d127395b-63dd-4bd2-bc5b-6882db4c1c3a
02/07/2025 22:43:19:INFO:Received: evaluate message d127395b-63dd-4bd2-bc5b-6882db4c1c3a
[92mINFO [0m:      Sent reply
02/07/2025 22:43:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:23:INFO:
[92mINFO [0m:      Received: train message a9c5b021-758f-4745-9bd8-53cd7062b4b8
02/07/2025 22:43:23:INFO:Received: train message a9c5b021-758f-4745-9bd8-53cd7062b4b8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.7067318111658096
  Validation Loss: 0.774889349937439
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.7777777910232544
Epoch 37/64:
  Train Loss: 0.6980828046798706
  Validation Loss: 0.7737933993339539
  Val ROC-AUC: 0.9539473684210525
  Val Accuracy: 0.7777777910232544
Epoch 38/64:
  Train Loss: 0.6947652399539948
  Validation Loss: 0.7726633548736572
  Val ROC-AUC: 0.9539473684210525
  Val Accuracy: 0.7777777910232544
Epoch 39/64:
  Train Loss: 0.7012293487787247
  Validation Loss: 0.7715409398078918
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6992193013429642
  Validation Loss: 0.7704799175262451
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6874108910560608
  Validation Loss: 0.769404411315918
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.7145679891109467
  Validation Loss: 0.7682955861091614
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6979541331529617
  Validation Loss: 0.7671785354614258
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6998343020677567
  Validation Loss: 0.7660584449768066
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.7067220956087112
  Validation Loss: 0.7649553418159485
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6972119063138962
  Validation Loss: 0.7638931274414062
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.7011144012212753
  Validation Loss: 0.7628121376037598
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.6741515100002289
  Validation Loss: 0.7616904377937317
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.6858339309692383
  Validation Loss: 0.7606704831123352
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.6859310120344162
  Validation Loss: 0.759674072265625
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6884694397449493
  Validation Loss: 0.7586929202079773
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.6964167803525925
  Validation Loss: 0.7577165961265564
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.7052081525325775
  Validation Loss: 0.7567554712295532
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6828360259532928
  Validation Loss: 0.7558165192604065
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.6959605664014816
  Validation Loss: 0.7548770308494568
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6894381195306778
  Validation Loss: 0.7539781928062439
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6825412660837173
  Validation Loss: 0.7531226873397827
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.7006200551986694
  Validation Loss: 0.7522801160812378
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.6801738739013672
  Validation Loss: 0.7514584064483643
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.6846282929182053
  Validation Loss: 0.7506457567214966
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6822628229856491
  Validation Loss: 0.7498247623443604
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.6813545674085617
  Validation Loss: 0.7490015029907227
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6854709535837173
  Validation Loss: 0.7482367157936096
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6761836260557175
  Validation Loss: 0.7474355697631836
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6761836260557175, 'val_roc_auc': 0.9736842105263158, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.7474355697631836}
 ROC_AUC: 0.9737|| Accuracy 0.8889 || Train Loss: 0.6762
 Val Loss: 0.7474 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7742662007889051
Test ROC-AUC: 0.7164502164502164
Test Accuracy: 0.5842696629213483
test_loss: 0.7742662007889051
test_roc_auc: 0.7164502164502164
test_accuracy: 0.5842696629213483
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.2772066656689276
Epoch 1/64:
  Train Loss: 0.7594539672136307
  Validation Loss: 0.782874345779419
  Val ROC-AUC: 0.7962962962962963
  Val Accuracy: 0.6666666865348816
Epoch 2/64:
  Train Loss: 0.7474896758794785
  Validation Loss: 0.7811298966407776
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.6666666865348816
Epoch 3/64:
  Train Loss: 0.7467735409736633
  Validation Loss: 0.7793740034103394
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.6296296119689941
Epoch 4/64:
  Train Loss: 0.7569516152143478
  Validation Loss: 0.7776069641113281
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.6666666865348816
Epoch 5/64:
  Train Loss: 0.7506922781467438
  Validation Loss: 0.7758497595787048
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.6666666865348816
Epoch 6/64:
  Train Loss: 0.7611415237188339
  Validation Loss: 0.774137556552887
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.6666666865348816
Epoch 7/64:
  Train Loss: 0.7379451096057892
  Validation Loss: 0.7724435925483704
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.6666666865348816
Epoch 8/64:
  Train Loss: 0.7454819530248642
  Validation Loss: 0.7707540988922119
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.6666666865348816
Epoch 9/64:
  Train Loss: 0.7298397272825241
  Validation Loss: 0.7690650224685669
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7037037014961243
Epoch 10/64:
  Train Loss: 0.7521139979362488
  Validation Loss: 0.7674229741096497
  Val ROC-AUC: 0.8703703703703705
  Val Accuracy: 0.7407407760620117
Epoch 11/64:
  Train Loss: 0.7439665496349335
  Validation Loss: 0.7657650113105774
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 12/64:
  Train Loss: 0.7252333164215088
  Validation Loss: 0.7641252875328064
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 13/64:
  Train Loss: 0.7427433133125305
  Validation Loss: 0.76246178150177
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 14/64:
  Train Loss: 0.7400945574045181
  Validation Loss: 0.7607887387275696
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 15/64:
  Train Loss: 0.7391092330217361
  Validation Loss: 0.7591646909713745
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 16/64:
  Train Loss: 0.7333246022462845
  Validation Loss: 0.7575802206993103
  Val ROC-AUC: 0.882716049382716
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7386598736047745
  Validation Loss: 0.7560080885887146
  Val ROC-AUC: 0.882716049382716
  Val Accuracy: 0.7777777910232544
Epoch 18/64:
  Train Loss: 0.7311934679746628
  Validation Loss: 0.7544689774513245
  Val ROC-AUC: 0.882716049382716
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.7180897295475006
  Validation Loss: 0.7529926896095276
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.7257327288389206
  Validation Loss: 0.7515236139297485
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.7375805228948593
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:43:49:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:50:INFO:
[92mINFO [0m:      Received: evaluate message 88f10bb8-5000-40ad-b448-91c9dcb92ead
02/07/2025 22:43:50:INFO:Received: evaluate message 88f10bb8-5000-40ad-b448-91c9dcb92ead
[92mINFO [0m:      Sent reply
02/07/2025 22:43:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:43:53:INFO:
[92mINFO [0m:      Received: train message 57c22659-105b-429b-a07a-52cf71277c2c
02/07/2025 22:43:53:INFO:Received: train message 57c22659-105b-429b-a07a-52cf71277c2c
  Validation Loss: 0.7500914931297302
  Val ROC-AUC: 0.8950617283950617
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.7366603761911392
  Validation Loss: 0.7486823201179504
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.7135064452886581
  Validation Loss: 0.7472164034843445
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.7250642627477646
  Validation Loss: 0.745826005935669
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.7127115726470947
  Validation Loss: 0.7444891929626465
  Val ROC-AUC: 0.9197530864197532
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.7087831646203995
  Validation Loss: 0.7431574463844299
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.7226174920797348
  Validation Loss: 0.7418529987335205
  Val ROC-AUC: 0.9382716049382717
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.7199552953243256
  Validation Loss: 0.74056077003479
  Val ROC-AUC: 0.9444444444444445
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.7168002277612686
  Validation Loss: 0.7392284870147705
  Val ROC-AUC: 0.9444444444444445
  Val Accuracy: 0.7777777910232544
Epoch 30/64:
  Train Loss: 0.7231107205152512
  Validation Loss: 0.737943172454834
  Val ROC-AUC: 0.9444444444444445
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.7083427459001541
  Validation Loss: 0.7366303205490112
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.712970644235611
  Validation Loss: 0.7353052496910095
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 33/64:
  Train Loss: 0.704317256808281
  Validation Loss: 0.7340322732925415
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 34/64:
  Train Loss: 0.7103947699069977
  Validation Loss: 0.7327880859375
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 35/64:
  Train Loss: 0.7237313240766525
  Validation Loss: 0.731597900390625
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 36/64:
  Train Loss: 0.7085965871810913
  Validation Loss: 0.7304275035858154
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 37/64:
  Train Loss: 0.7152738571166992
  Validation Loss: 0.7292294502258301
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8518518805503845
Epoch 38/64:
  Train Loss: 0.7147610932588577
  Validation Loss: 0.7280539870262146
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8518518805503845
Epoch 39/64:
  Train Loss: 0.7043987810611725
  Validation Loss: 0.7268998026847839
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7126031517982483
  Validation Loss: 0.7257804274559021
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7184203714132309
  Validation Loss: 0.7246934175491333
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.7098591774702072
  Validation Loss: 0.7236210703849792
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6967679560184479
  Validation Loss: 0.7225742340087891
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.7122215330600739
  Validation Loss: 0.7215269804000854
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.7023136466741562
  Validation Loss: 0.7205017805099487
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6977090835571289
  Validation Loss: 0.7194574475288391
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6965128630399704
  Validation Loss: 0.7184302806854248
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6904662549495697
  Validation Loss: 0.7174578309059143
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6980742961168289
  Validation Loss: 0.7165108323097229
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.7130695134401321
  Validation Loss: 0.7155715227127075
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6938585340976715
  Validation Loss: 0.7146551609039307
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6902864426374435
  Validation Loss: 0.7137256860733032
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6913316994905472
  Validation Loss: 0.7128201127052307
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6870490163564682
  Validation Loss: 0.7119632363319397
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.699345201253891
  Validation Loss: 0.7110835909843445
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6969645917415619
  Validation Loss: 0.7102174162864685
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6842533946037292
  Validation Loss: 0.709356427192688
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6824418902397156
  Validation Loss: 0.7085261344909668
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6850074380636215
  Validation Loss: 0.7076895236968994
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6941346824169159
  Validation Loss: 0.7068833112716675
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6889620125293732
  Validation Loss: 0.7060978412628174
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6961025893688202
  Validation Loss: 0.7053300142288208
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6808138787746429
  Validation Loss: 0.7045408487319946
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6827251315116882
  Validation Loss: 0.703787088394165
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6827251315116882, 'val_roc_auc': 0.9506172839506174, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.703787088394165}
 ROC_AUC: 0.9506|| Accuracy 0.9259 || Train Loss: 0.6827
 Val Loss: 0.7038 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7694009264533439
Test ROC-AUC: 0.7462121212121212
Test Accuracy: 0.5955056179775281
test_loss: 0.7694009264533439
test_roc_auc: 0.7462121212121212
test_accuracy: 0.5955056179775281
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.4281645999435568
Epoch 1/64:
  Train Loss: 0.7609018832445145
  Validation Loss: 0.7214779853820801
  Val ROC-AUC: 0.9375
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7667343020439148
  Validation Loss: 0.7196981906890869
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7611475139856339
  Validation Loss: 0.717983067035675
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7478549033403397
  Validation Loss: 0.7163770794868469
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.7565320730209351
  Validation Loss: 0.7148231267929077
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.7613436281681061
  Validation Loss: 0.7133198380470276
  Val ROC-AUC: 0.9659090909090908
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.75249944627285
  Validation Loss: 0.7118101716041565
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7521511018276215
  Validation Loss: 0.7103191614151001
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7607164233922958
  Validation Loss: 0.7088659405708313
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.7528516501188278
  Validation Loss: 0.7074217200279236
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.764130249619484
  Validation Loss: 0.7059518098831177
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.7495300769805908
  Validation Loss: 0.7044900059700012
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.763283908367157
  Validation Loss: 0.7030171751976013
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.7491133958101273
  Validation Loss: 0.701503574848175
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.7273289412260056
  Validation Loss: 0.700094997882843
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.7558392584323883
  Validation Loss: 0.6987975835800171
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.7335989326238632
  Validation Loss: 0.6974639892578125
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.7304124683141708
  Validation Loss: 0.6961286664009094
  Val ROC-AUC: 0.9943181818181818
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.7455678880214691
  Validation Loss: 0.6948721408843994
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.7334319651126862
  Validation Loss: 0.6937015056610107
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.7256810963153839
  Validation Loss: 0.6925449967384338
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.7464300096035004
  Validation Loss: 0.6914976835250854
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.7413852512836456
  Validation Loss: 0.6904648542404175
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.7490409314632416
  Validation Loss: 0.6894358992576599
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.7406399250030518
  Validation Loss: 0.6884194612503052
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.7365208566188812
  Validation Loss: 0.6874179840087891
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.7363836914300919
  Validation Loss: 0.6863059997558594
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.7499826550483704
  Validation Loss: 0.6852063536643982
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.7161044776439667
  Validation Loss: 0.6841464638710022
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.7280819416046143
  Validation Loss: 0.6831244230270386
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.7198531776666641
  Validation Loss: 0.6820831298828125
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.7198626399040222
  Validation Loss: 0.6810485124588013
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.7225663363933563
  Validation Loss: 0.6800533533096313
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.7206674814224243
  Validation Loss: 0.6791163682937622
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.715981051325798
  Validation Loss: 0.6781908869743347
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.7200240343809128
  Validation Loss: 0.6772751808166504
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.7163870632648468
  Validation Loss: 0.6762812733650208
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.7291394919157028
  Validation Loss: 0.6752962470054626
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.7225765734910965
  Validation Loss: 0.6743987798690796
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.7220308929681778
  Validation Loss: 0.673481285572052
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.7222229987382889
  Validation Loss: 0.6726366877555847
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.707178458571434
  Validation Loss: 0.6718506217002869
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.710008978843689
  Validation Loss: 0.6710419654846191
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.7202653884887695
  Validation Loss: 0.6702060103416443
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.7174910753965378
  Validation Loss: 0.6693845987319946
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.7151706516742706
  Validation Loss: 0.6686038374900818
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.7122440934181213
  Validation Loss: 0.667790949344635
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.7114355266094208
  Validation Loss: 0.6670538783073425
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.7117973566055298
  Validation Loss: 0.6662764549255371
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.7111462205648422
  Validation Loss: 0.665497899055481
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6983831077814102
  Validation Loss: 0.6647738814353943
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.706440344452858
  Validation Loss: 0.6641104221343994
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.7067615985870361
  Validation Loss: 0.6634827256202698
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6995350569486618
  Validation Loss: 0.662835419178009
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6972814649343491
  Validation Loss: 0.6621280908584595
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.7088890224695206
  Validation Loss: 0.6614580750465393
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.7055089473724365
  Validation Loss: 0.660916268825531
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.708826333284378
  Validation Loss: 0.660323441028595
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.7071786522865295
  Validation Loss: 0.6597376465797424
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.7080224901437759
  Validation Loss: 0.6591974496841431
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.7044879347085953
  Validation Loss: 0.6586260199546814
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.7036633044481277
  Validation Loss: 0.6580733060836792
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.7009105086326599
  Validation Loss: 0.6574866771697998
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6897406727075577
  Validation Loss: 0.6569424271583557
  Val ROC-AUC: 1.0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:44:18:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:18:INFO:
[92mINFO [0m:      Received: evaluate message 5af46d48-c0be-40cb-9a0d-c655f9f2f217
02/07/2025 22:44:18:INFO:Received: evaluate message 5af46d48-c0be-40cb-9a0d-c655f9f2f217
[92mINFO [0m:      Sent reply
02/07/2025 22:44:21:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:22:INFO:
[92mINFO [0m:      Received: train message 41a6fc06-1768-4bfd-b738-057a511d16cc
02/07/2025 22:44:22:INFO:Received: train message 41a6fc06-1768-4bfd-b738-057a511d16cc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6897406727075577, 'val_roc_auc': 1.0, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6569424271583557}
 ROC_AUC: 1.0000|| Accuracy 0.9630 || Train Loss: 0.6897
 Val Loss: 0.6569 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7642477265234744
Test ROC-AUC: 0.7754329004329005
Test Accuracy: 0.651685393258427
test_loss: 0.7642477265234744
test_roc_auc: 0.7754329004329005
test_accuracy: 0.651685393258427
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.17978169325942872
Epoch 1/64:
  Train Loss: 0.752851665019989
  Validation Loss: 0.7358008623123169
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7386291176080704
  Validation Loss: 0.7338660955429077
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7512378841638565
  Validation Loss: 0.7320530414581299
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7360821962356567
  Validation Loss: 0.7302678227424622
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7476093471050262
  Validation Loss: 0.7285832762718201
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7442906945943832
  Validation Loss: 0.7270245552062988
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7525852024555206
  Validation Loss: 0.7255203723907471
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7405567169189453
  Validation Loss: 0.7239700555801392
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7433877885341644
  Validation Loss: 0.7225177884101868
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.7320957034826279
  Validation Loss: 0.7211158275604248
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7312229871749878
  Validation Loss: 0.7197120189666748
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7487088441848755
  Validation Loss: 0.7183822989463806
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.7240858972072601
  Validation Loss: 0.7170379757881165
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.735501155257225
  Validation Loss: 0.7156452536582947
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7272334545850754
  Validation Loss: 0.7142627239227295
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7169132232666016
  Validation Loss: 0.7129074335098267
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7336477488279343
  Validation Loss: 0.711598813533783
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7297783493995667
  Validation Loss: 0.7103531360626221
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.7288937121629715
  Validation Loss: 0.7091670632362366
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.7401273995637894
  Validation Loss: 0.7079618573188782
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.719806432723999
  Validation Loss: 0.7067740559577942
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.7257228642702103
  Validation Loss: 0.7055836319923401
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.7199068665504456
  Validation Loss: 0.7044548392295837
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.7329338192939758
  Validation Loss: 0.7033500671386719
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.7125759124755859
  Validation Loss: 0.7022387385368347
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.73263318836689
  Validation Loss: 0.7011900544166565
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7165271192789078
  Validation Loss: 0.7001270651817322
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.7154476642608643
  Validation Loss: 0.6990901231765747
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.7019243091344833
  Validation Loss: 0.6980425119400024
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.7005199790000916
  Validation Loss: 0.6969760060310364
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7306209057569504
  Validation Loss: 0.6959656476974487
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.7076622545719147
  Validation Loss: 0.6949289441108704
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.7232852876186371
  Validation Loss: 0.6939440369606018
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.725290834903717
  Validation Loss: 0.6930098533630371
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.7160697728395462
  Validation Loss: 0.6920974254608154
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7112315595149994
  Validation Loss: 0.6911603212356567
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7041588425636292
  Validation Loss: 0.6902607679367065
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7017119824886322
  Validation Loss: 0.6893451809883118
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7066785544157028
  Validation Loss: 0.6884949207305908
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7051442712545395
  Validation Loss: 0.6876725554466248
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7097090780735016
  Validation Loss: 0.6868261694908142
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.7040037214756012
  Validation Loss: 0.6859835982322693
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.7039111405611038
  Validation Loss: 0.6851841807365417
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6951508224010468
  Validation Loss: 0.6844256520271301
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.7003302723169327
  Validation Loss: 0.6836662292480469
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.7062907069921494
  Validation Loss: 0.6829196810722351
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6977956295013428
  Validation Loss: 0.6822066307067871
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.7010743618011475
  Validation Loss: 0.681509256362915
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.7010162025690079
  Validation Loss: 0.6808298826217651
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6979936361312866
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:44:50:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:50:INFO:
[92mINFO [0m:      Received: evaluate message 58fd26c8-5cc2-4910-8073-94d50eb779e6
02/07/2025 22:44:50:INFO:Received: evaluate message 58fd26c8-5cc2-4910-8073-94d50eb779e6
[92mINFO [0m:      Sent reply
02/07/2025 22:44:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:44:53:INFO:
[92mINFO [0m:      Received: train message 66ed5b17-006e-4c50-9972-cb3249e5dbbe
02/07/2025 22:44:53:INFO:Received: train message 66ed5b17-006e-4c50-9972-cb3249e5dbbe
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6801890730857849
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.7122045606374741
  Validation Loss: 0.6795558929443359
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.7005333602428436
  Validation Loss: 0.6789293885231018
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6972316652536392
  Validation Loss: 0.678287923336029
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6946704536676407
  Validation Loss: 0.6776631474494934
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6922931224107742
  Validation Loss: 0.6770268678665161
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.7038321495056152
  Validation Loss: 0.6764171123504639
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.7046565860509872
  Validation Loss: 0.6758148670196533
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6960978209972382
  Validation Loss: 0.6752457618713379
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6891726553440094
  Validation Loss: 0.6746614575386047
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6883823275566101
  Validation Loss: 0.674107015132904
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.694276973605156
  Validation Loss: 0.673549234867096
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6906013339757919
  Validation Loss: 0.673018753528595
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.7015184909105301
  Validation Loss: 0.6724810600280762
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.687916561961174
  Validation Loss: 0.6719379425048828
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.687916561961174, 'val_roc_auc': 0.9705882352941176, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6719379425048828}
 ROC_AUC: 0.9706|| Accuracy 0.9259 || Train Loss: 0.6879
 Val Loss: 0.6719 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7589298721109883
Test ROC-AUC: 0.7905844155844155
Test Accuracy: 0.6741573033707865
test_loss: 0.7589298721109883
test_roc_auc: 0.7905844155844155
test_accuracy: 0.6741573033707865
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.33798617603679304
Epoch 1/64:
  Train Loss: 0.7342102974653244
  Validation Loss: 0.7781227231025696
  Val ROC-AUC: 0.9210526315789473
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7462745308876038
  Validation Loss: 0.7764217257499695
  Val ROC-AUC: 0.9276315789473684
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7177602648735046
  Validation Loss: 0.774695634841919
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7324783802032471
  Validation Loss: 0.7730149030685425
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7170419692993164
  Validation Loss: 0.7713186740875244
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7237224280834198
  Validation Loss: 0.7696410417556763
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7323873192071915
  Validation Loss: 0.767973780632019
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7261018007993698
  Validation Loss: 0.7662886381149292
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7253833413124084
  Validation Loss: 0.764650285243988
  Val ROC-AUC: 0.9473684210526316
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.7254532873630524
  Validation Loss: 0.7630859613418579
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7242348939180374
  Validation Loss: 0.7614873051643372
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7254028171300888
  Validation Loss: 0.7598552107810974
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.722353145480156
  Validation Loss: 0.7582104802131653
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.7076822370290756
  Validation Loss: 0.7565928101539612
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7112127095460892
  Validation Loss: 0.7549524903297424
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7192855477333069
  Validation Loss: 0.7533982396125793
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7037862986326218
  Validation Loss: 0.7518154382705688
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7227150946855545
  Validation Loss: 0.7502593994140625
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.7093406170606613
  Validation Loss: 0.748747706413269
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.7163447439670563
  Validation Loss: 0.747255265712738
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.7164076268672943
  Validation Loss: 0.7457617521286011
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.7062214761972427
  Validation Loss: 0.7442820072174072
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7110473960638046
  Validation Loss: 0.7428966164588928
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.7099893689155579
  Validation Loss: 0.7415159344673157
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6972278207540512
  Validation Loss: 0.7401652932167053
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7050432562828064
  Validation Loss: 0.7388423085212708
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7139275670051575
  Validation Loss: 0.7375332713127136
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.7099155932664871
  Validation Loss: 0.7362242341041565
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.7066700458526611
  Validation Loss: 0.7349014282226562
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.7080793678760529
  Validation Loss: 0.7336010336875916
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6976004242897034
  Validation Loss: 0.7323379516601562
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6954669803380966
  Validation Loss: 0.7311351299285889
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.687629759311676
  Validation Loss: 0.7299635410308838
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6947660893201828
  Validation Loss: 0.7287757396697998
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6912752538919449
  Validation Loss: 0.7276196479797363
  Val ROC-AUC: 0.993421052631579
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:20:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:20:INFO:
[92mINFO [0m:      Received: evaluate message 4a0b6479-1ee0-4cd4-b689-fd1b2acd8b15
02/07/2025 22:45:20:INFO:Received: evaluate message 4a0b6479-1ee0-4cd4-b689-fd1b2acd8b15
[92mINFO [0m:      Sent reply
02/07/2025 22:45:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:22:INFO:
[92mINFO [0m:      Received: train message 00b7ad0c-b15e-48b0-9bed-12da6a7fcc75
02/07/2025 22:45:22:INFO:Received: train message 00b7ad0c-b15e-48b0-9bed-12da6a7fcc75
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6962358802556992
  Validation Loss: 0.7264222502708435
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.702333927154541
  Validation Loss: 0.7252541780471802
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6991832107305527
  Validation Loss: 0.7241476774215698
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6722659021615982
  Validation Loss: 0.7230527997016907
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6928589791059494
  Validation Loss: 0.7219880223274231
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6949958950281143
  Validation Loss: 0.7210387587547302
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6922464221715927
  Validation Loss: 0.7200713157653809
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.7079147100448608
  Validation Loss: 0.7190805673599243
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6843107044696808
  Validation Loss: 0.7180642485618591
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6945290863513947
  Validation Loss: 0.7170687317848206
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6851706504821777
  Validation Loss: 0.7161511778831482
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6805516630411148
  Validation Loss: 0.7152233123779297
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6989586502313614
  Validation Loss: 0.7143163084983826
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6938735693693161
  Validation Loss: 0.7133796811103821
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6839421987533569
  Validation Loss: 0.7125061750411987
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6958522945642471
  Validation Loss: 0.711656391620636
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6784845292568207
  Validation Loss: 0.7108255624771118
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6787352710962296
  Validation Loss: 0.7099839448928833
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6895846575498581
  Validation Loss: 0.7092203497886658
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6857580542564392
  Validation Loss: 0.7084122896194458
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6755003929138184
  Validation Loss: 0.7075924277305603
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6825750917196274
  Validation Loss: 0.7067314386367798
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6789442449808121
  Validation Loss: 0.7058692574501038
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6921077817678452
  Validation Loss: 0.7050350308418274
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6761392056941986
  Validation Loss: 0.7042140364646912
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6874329149723053
  Validation Loss: 0.7033988237380981
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6810318380594254
  Validation Loss: 0.7025484442710876
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6760954409837723
  Validation Loss: 0.7016986608505249
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.693601205945015
  Validation Loss: 0.7007986307144165
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.693601205945015, 'val_roc_auc': 1.0, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.7007986307144165}
 ROC_AUC: 1.0000|| Accuracy 0.9630 || Train Loss: 0.6936
 Val Loss: 0.7008 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7535127126768734
Test ROC-AUC: 0.8062770562770564
Test Accuracy: 0.7078651685393258
test_loss: 0.7535127126768734
test_roc_auc: 0.8062770562770564
test_accuracy: 0.7078651685393258
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.5071116750332294
Epoch 1/64:
  Train Loss: 0.713016152381897
  Validation Loss: 0.7424901127815247
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7300342619419098
  Validation Loss: 0.741142988204956
  Val ROC-AUC: 0.8882352941176471
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7349279671907425
  Validation Loss: 0.7397744059562683
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7259872257709503
  Validation Loss: 0.738396942615509
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.720501646399498
  Validation Loss: 0.7370527982711792
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.7180517762899399
  Validation Loss: 0.7357525825500488
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.7373766601085663
  Validation Loss: 0.7344427704811096
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 8/64:
  Train Loss: 0.7200896888971329
  Validation Loss: 0.7331393957138062
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 9/64:
  Train Loss: 0.7300359457731247
  Validation Loss: 0.7318083047866821
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.731699988245964
  Validation Loss: 0.7304785251617432
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7256215363740921
  Validation Loss: 0.7291877269744873
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7005292028188705
  Validation Loss: 0.7278911471366882
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.7216285318136215
  Validation Loss: 0.726709246635437
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.7178623229265213
  Validation Loss: 0.7256324291229248
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.7218958884477615
  Validation Loss: 0.7245983481407166
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.7145390063524246
  Validation Loss: 0.7235199809074402
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.7089244872331619
  Validation Loss: 0.7223480343818665
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.719311311841011
  Validation Loss: 0.7211446166038513
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.7162006795406342
  Validation Loss: 0.7199902534484863
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.7183156162500381
  Validation Loss: 0.7189103364944458
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.7345480173826218
  Validation Loss: 0.7178911566734314
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.7074668258428574
  Validation Loss: 0.7167907953262329
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7218372374773026
  Validation Loss: 0.7157013416290283
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:50:INFO:
[92mINFO [0m:      Received: evaluate message 2dd42d60-e160-44eb-b5f8-16bda3b04d7e
02/07/2025 22:45:50:INFO:Received: evaluate message 2dd42d60-e160-44eb-b5f8-16bda3b04d7e
[92mINFO [0m:      Sent reply
02/07/2025 22:45:52:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:52:INFO:
[92mINFO [0m:      Received: train message 3b5cd3c8-5fce-40cb-abb9-5b4727baaec5
02/07/2025 22:45:52:INFO:Received: train message 3b5cd3c8-5fce-40cb-abb9-5b4727baaec5
  Train Loss: 0.7001823037862778
  Validation Loss: 0.7146056890487671
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.7058841288089752
  Validation Loss: 0.7135244607925415
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.7083871066570282
  Validation Loss: 0.7124956846237183
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.7149264812469482
  Validation Loss: 0.7115287184715271
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6893675625324249
  Validation Loss: 0.7105478644371033
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6937329918146133
  Validation Loss: 0.7095974087715149
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6954985409975052
  Validation Loss: 0.7086849212646484
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7028535008430481
  Validation Loss: 0.7078251242637634
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.7092660814523697
  Validation Loss: 0.7069206237792969
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.7053074985742569
  Validation Loss: 0.7060237526893616
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6940861195325851
  Validation Loss: 0.705099880695343
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.7003650516271591
  Validation Loss: 0.7042256593704224
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7027162909507751
  Validation Loss: 0.703353762626648
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.699801430106163
  Validation Loss: 0.7024806141853333
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.703389048576355
  Validation Loss: 0.7016218900680542
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7083044499158859
  Validation Loss: 0.7008174657821655
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6834319978952408
  Validation Loss: 0.7000899314880371
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6920541673898697
  Validation Loss: 0.6992908716201782
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6787788569927216
  Validation Loss: 0.6984766125679016
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.7042866498231888
  Validation Loss: 0.6977246403694153
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.7055519968271255
  Validation Loss: 0.6969528794288635
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6848859339952469
  Validation Loss: 0.6962078213691711
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6785372346639633
  Validation Loss: 0.6954528093338013
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6934960335493088
  Validation Loss: 0.6946566104888916
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6923505067825317
  Validation Loss: 0.6938675045967102
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6845477670431137
  Validation Loss: 0.6931418776512146
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6963787525892258
  Validation Loss: 0.6924790143966675
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6754511743783951
  Validation Loss: 0.691826343536377
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6861612349748611
  Validation Loss: 0.6911407709121704
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6971109956502914
  Validation Loss: 0.6904752850532532
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6933987736701965
  Validation Loss: 0.6898020505905151
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6943895220756531
  Validation Loss: 0.6891680359840393
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6867723017930984
  Validation Loss: 0.6885676980018616
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6865680664777756
  Validation Loss: 0.6879554986953735
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6882501542568207
  Validation Loss: 0.6873616576194763
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6892978698015213
  Validation Loss: 0.6867960095405579
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6795389205217361
  Validation Loss: 0.6861695647239685
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6777589023113251
  Validation Loss: 0.6856138706207275
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6898392885923386
  Validation Loss: 0.6850262880325317
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6859813630580902
  Validation Loss: 0.6844351291656494
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6767036616802216
  Validation Loss: 0.68382728099823
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6767036616802216, 'val_roc_auc': 0.9647058823529411, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.68382728099823}
 ROC_AUC: 0.9647|| Accuracy 0.9259 || Train Loss: 0.6767
 Val Loss: 0.6838 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7481207546223415
Test ROC-AUC: 0.8203463203463204
Test Accuracy: 0.7191011235955056
test_loss: 0.7481207546223415
test_roc_auc: 0.8203463203463204
test_accuracy: 0.7191011235955056
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.11133685959066497
Epoch 1/64:
  Train Loss: 0.7290784567594528
  Validation Loss: 0.7395066022872925
  Val ROC-AUC: 0.888235294117647
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.709015965461731
  Validation Loss: 0.7383192777633667
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.7124743312597275
  Validation Loss: 0.7371174693107605
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7116604894399643
  Validation Loss: 0.735988199710846
  Val ROC-AUC: 0.9117647058823528
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7124700248241425
  Validation Loss: 0.734856128692627
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7171123921871185
  Validation Loss: 0.7337508201599121
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.7174626588821411
  Validation Loss: 0.7326575517654419
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7155387848615646
  Validation Loss: 0.7315971851348877
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7197475135326385
  Validation Loss: 0.7305557727813721/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6984773129224777
  Validation Loss: 0.7295212149620056
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7045757174491882
  Validation Loss: 0.7284990549087524
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.706647053360939
  Validation Loss: 0.7275031805038452
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.7089079767465591
  Validation Loss: 0.7265240550041199
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.716326043009758
  Validation Loss: 0.7255500555038452
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7008446156978607
  Validation Loss: 0.7245785593986511
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7067505121231079
  Validation Loss: 0.7236576676368713
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7003808170557022
  Validation Loss: 0.7227191925048828
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.706841915845871
  Validation Loss: 0.7217883467674255
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.7007873952388763
  Validation Loss: 0.7208895087242126
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.6973502039909363
  Validation Loss: 0.719983696937561
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.6867686808109283
  Validation Loss: 0.7191082835197449
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.7051582783460617
  Validation Loss: 0.7182634472846985
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.6853811293840408
  Validation Loss: 0.7174028754234314
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6906531453132629
  Validation Loss: 0.7165591716766357
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.7036650776863098
  Validation Loss: 0.7157344818115234
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6906493306159973
  Validation Loss: 0.7149022221565247
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6970871835947037
  Validation Loss: 0.7140620350837708
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.695091649889946
  Validation Loss: 0.7132643461227417
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6929162889719009
  Validation Loss: 0.7125089764595032
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6744939982891083
  Validation Loss: 0.7117549180984497
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6919147968292236
  Validation Loss: 0.7110273838043213
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6852626502513885
  Validation Loss: 0.7102950811386108
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.682200163602829
  Validation Loss: 0.7095583081245422
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6954337507486343
  Validation Loss: 0.7088304758071899
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6824934631586075
  Validation Loss: 0.708106279373169
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6909140795469284
  Validation Loss: 0.7074169516563416
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6748587340116501
  Validation Loss: 0.7067379355430603
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6943202763795853
  Validation Loss: 0.7060734629631042
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6792223155498505
  Validation Loss: 0.7053985595703125
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6901412308216095
  Validation Loss: 0.7047542929649353
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 41/64:
  Train Loss: 0.6857513636350632
  Validation Loss: 0.704116940498352
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 42/64:
  Train Loss: 0.6879548281431198
  Validation Loss: 0.7034710645675659
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 43/64:
  Train Loss: 0.6961109638214111
  Validation Loss: 0.7028342485427856
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 44/64:
  Train Loss: 0.6727479994297028
  Validation Loss: 0.7022337317466736
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 45/64:
  Train Loss: 0.6805694252252579
  Validation Loss: 0.7016146779060364
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 46/64:
  Train Loss: 0.6910766959190369
  Validation Loss: 0.7009913325309753
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 47/64:
  Train Loss: 0.6806894391775131
  Validation Loss: 0.7003726363182068
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.677820235490799
  Validation Loss: 0.699796736240387
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.6720815747976303
  Validation Loss: 0.6992095708847046
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.6803612858057022
  Validation Loss: 0.6986089944839478
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6817219108343124
  Validation Loss: 0.6980475783348083
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.6626704037189484
  Validation Loss: 0.6974730491638184
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.6781721413135529
  Validation Loss: 0.6969412565231323
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6751708388328552
  Validation Loss: 0.6964020133018494
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.6682692915201187
  Validation Loss: 0.695889949798584
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6791533082723618
  Validation Loss: 0.6953777074813843
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6740266531705856
  Validation Loss: 0.694865882396698
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6809668689966202
  Validation Loss: 0.6943557262420654
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.6769899278879166
  Validation Loss: 0.6938487887382507
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.670353963971138
  Validation Loss: 0.6933477520942688
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6703508496284485
  Validation Loss: 0.6928298473358154
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.683711439371109
  Validation Loss: 0.692327618598938
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:19:INFO:
[92mINFO [0m:      Received: evaluate message 0978d85c-add1-40c8-bb52-b09fd563c771
02/07/2025 22:46:19:INFO:Received: evaluate message 0978d85c-add1-40c8-bb52-b09fd563c771
[92mINFO [0m:      Sent reply
02/07/2025 22:46:20:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:20:INFO:
[92mINFO [0m:      Received: train message 5f810f09-bd43-45f6-ad73-2ba0c5952d5e
02/07/2025 22:46:20:INFO:Received: train message 5f810f09-bd43-45f6-ad73-2ba0c5952d5e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.672330692410469
  Validation Loss: 0.6918575763702393
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.6660866141319275
  Validation Loss: 0.6913921236991882
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
{'train_loss': 0.6660866141319275, 'val_roc_auc': 0.9352941176470588, 'val_accuracy': 0.8518518805503845, 'val_loss': 0.6913921236991882}
 ROC_AUC: 0.9353|| Accuracy 0.8519 || Train Loss: 0.6661
 Val Loss: 0.6914 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7428451280915336
Test ROC-AUC: 0.8327922077922079
Test Accuracy: 0.7303370786516854
test_loss: 0.7428451280915336
test_roc_auc: 0.8327922077922079
test_accuracy: 0.7303370786516854
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.48677533839509124
Epoch 1/64:
  Train Loss: 0.7372107207775116
  Validation Loss: 0.6362556219100952
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7338651865720749
  Validation Loss: 0.6351158618927002
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.7368411272764206
  Validation Loss: 0.6340022683143616
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7322932332754135
  Validation Loss: 0.6329070329666138
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7337038666009903
  Validation Loss: 0.6317715048789978
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7349908500909805
  Validation Loss: 0.6306583285331726
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.7451047748327255
  Validation Loss: 0.6295034885406494
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.7368631064891815
  Validation Loss: 0.6284343600273132
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.730663850903511
  Validation Loss: 0.6274294257164001
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.7188863903284073
  Validation Loss: 0.6264007091522217
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.7276729047298431
  Validation Loss: 0.6253058910369873
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.7357809692621231
  Validation Loss: 0.6242560744285583
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7340171933174133
  Validation Loss: 0.6232780814170837
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.7257769852876663
  Validation Loss: 0.622326135635376
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.7156835198402405
  Validation Loss: 0.6213845014572144
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.7292561233043671
  Validation Loss: 0.6204522252082825
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.7174659967422485
  Validation Loss: 0.6195711493492126
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7173026204109192
  Validation Loss: 0.6187000274658203
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7140236794948578
  Validation Loss: 0.61786949634552
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.709293931722641
  Validation Loss: 0.6170844435691833
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.7257054597139359
  Validation Loss: 0.6163281798362732
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.7112766951322556
  Validation Loss: 0.6155766844749451
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.7213080823421478
  Validation Loss: 0.6148635745048523
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.7158995717763901
  Validation Loss: 0.6141665577888489
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.712785005569458
  Validation Loss: 0.613505482673645
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7197264432907104
  Validation Loss: 0.6129072904586792
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7078843712806702
  Validation Loss: 0.6122756600379944
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.7297040224075317
  Validation Loss: 0.6116458773612976
  Val ROC-AUC: 0.9615384615384616
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6989904493093491
  Validation Loss: 0.6110633015632629
  Val ROC-AUC: 0.9615384615384616
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.7105522453784943
  Validation Loss: 0.6104145050048828
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7068595141172409
  Validation Loss: 0.6097148060798645
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.703553169965744
  Validation Loss: 0.6089515686035156
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.7148961126804352
  Validation Loss: 0.608248233795166
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.7133170962333679
  Validation Loss: 0.6075951457023621
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.7157345563173294
  Validation Loss: 0.6069697737693787
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7053441405296326
  Validation Loss: 0.6063756346702576
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7021060436964035
  Validation Loss: 0.6057880520820618
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7172505855560303
  Validation Loss: 0.6052407622337341
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7071841210126877
  Validation Loss: 0.6046513915061951
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7049870640039444
  Validation Loss: 0.6040202975273132
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7251285016536713
  Validation Loss: 0.6034090518951416
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6980220675468445
  Validation Loss: 0.6027730107307434
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.7056958824396133
  Validation Loss: 0.6021079421043396
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.7092344760894775
  Validation Loss: 0.6014549732208252
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.7046300619840622
  Validation Loss: 0.6008084416389465
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.7125484198331833
  Validation Loss: 0.6002476811408997
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.701132595539093
  Validation Loss: 0.5997105240821838
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6997012495994568
  Validation Loss: 0.5991566181182861
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:49:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:49:INFO:
[92mINFO [0m:      Received: evaluate message 1597bcd7-e9f3-4988-8b28-699f6eb8d08c
02/07/2025 22:46:49:INFO:Received: evaluate message 1597bcd7-e9f3-4988-8b28-699f6eb8d08c
[92mINFO [0m:      Sent reply
02/07/2025 22:46:49:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:49:INFO:
[92mINFO [0m:      Received: train message 9a1eb857-28b4-401f-9e71-da90c0565441
02/07/2025 22:46:49:INFO:Received: train message 9a1eb857-28b4-401f-9e71-da90c0565441
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6981960833072662
  Validation Loss: 0.5985822081565857
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.7101574093103409
  Validation Loss: 0.5980110764503479
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.7108418792486191
  Validation Loss: 0.5974825620651245
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6893831491470337
  Validation Loss: 0.5969254374504089
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6995831578969955
  Validation Loss: 0.5963833928108215
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.7047617584466934
  Validation Loss: 0.5958712100982666
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.7079900354146957
  Validation Loss: 0.5953975915908813
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.7108192294836044
  Validation Loss: 0.5948856472969055
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6897214502096176
  Validation Loss: 0.5943759083747864
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.7052231132984161
  Validation Loss: 0.5938596129417419
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6971669644117355
  Validation Loss: 0.5933452248573303
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6972800344228745
  Validation Loss: 0.5928393602371216
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.7123864591121674
  Validation Loss: 0.5923515558242798
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6884718537330627
  Validation Loss: 0.5919271111488342
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.697101429104805
  Validation Loss: 0.591462254524231
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6976900845766068
  Validation Loss: 0.5910289883613586
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6976900845766068, 'val_roc_auc': 0.989010989010989, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.5910289883613586}
 ROC_AUC: 0.9890|| Accuracy 0.9630 || Train Loss: 0.6977
 Val Loss: 0.5910 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7377840163332693
Test ROC-AUC: 0.8457792207792207
Test Accuracy: 0.7415730337078652
test_loss: 0.7377840163332693
test_roc_auc: 0.8457792207792207
test_accuracy: 0.7415730337078652
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.12033948451062315
Epoch 1/64:
  Train Loss: 0.7102286219596863
  Validation Loss: 0.7269008159637451
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 2/64:
  Train Loss: 0.7096993029117584
  Validation Loss: 0.7257824540138245
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 3/64:
  Train Loss: 0.7169294059276581
  Validation Loss: 0.7246025800704956
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 4/64:
  Train Loss: 0.7073624581098557
  Validation Loss: 0.7234175205230713
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.7071601003408432
  Validation Loss: 0.7222606539726257
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.6897970288991928
  Validation Loss: 0.7210502624511719
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.716115802526474
  Validation Loss: 0.7198631763458252
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.715205192565918
  Validation Loss: 0.7187855839729309
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6867573410272598
  Validation Loss: 0.7176615595817566
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.7134387344121933
  Validation Loss: 0.7166679501533508
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.703700989484787
  Validation Loss: 0.7156832814216614
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6894905120134354
  Validation Loss: 0.7146982550621033
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6899397820234299
  Validation Loss: 0.7136712074279785
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6956708282232285
  Validation Loss: 0.7126911282539368
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6919075548648834
  Validation Loss: 0.7116521000862122
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6879106014966965
  Validation Loss: 0.7106705904006958
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6941816657781601
  Validation Loss: 0.7097271084785461
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6920181810855865
  Validation Loss: 0.7088201642036438
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.7004368752241135
  Validation Loss: 0.7079439759254456
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6878158152103424
  Validation Loss: 0.7070404291152954
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.7028492093086243
  Validation Loss: 0.7061482071876526
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6910189390182495
  Validation Loss: 0.7052872180938721
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6916236579418182
  Validation Loss: 0.7044443488121033
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6971306204795837
  Validation Loss: 0.7036750316619873
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6813058406114578
  Validation Loss: 0.7029188275337219
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.686060905456543
  Validation Loss: 0.7021546363830566
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.688517764210701
  Validation Loss: 0.7014141082763672
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6844269186258316
  Validation Loss: 0.7006222605705261
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6880919635295868
  Validation Loss: 0.6998945474624634
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6818007379770279
  Validation Loss: 0.6991342902183533
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6771257370710373
  Validation Loss: 0.6983924508094788
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6890355795621872
  Validation Loss: 0.6976778507232666
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6709709465503693
  Validation Loss: 0.6970299482345581
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6820023357868195
  Validation Loss: 0.6963470578193665
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6979564726352692
  Validation Loss: 0.6956546306610107
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.691563680768013
  Validation Loss: 0.6949820518493652
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:18:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:18:INFO:
[92mINFO [0m:      Received: evaluate message fe21084a-44f9-46c7-b0b7-60ce5dc6362d
02/07/2025 22:47:18:INFO:Received: evaluate message fe21084a-44f9-46c7-b0b7-60ce5dc6362d
[92mINFO [0m:      Sent reply
02/07/2025 22:47:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:19:INFO:
[92mINFO [0m:      Received: train message 2989a1d8-9c78-49a2-9485-b6d49214fcc0
02/07/2025 22:47:19:INFO:Received: train message 2989a1d8-9c78-49a2-9485-b6d49214fcc0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 37/64:
  Train Loss: 0.6835157424211502
  Validation Loss: 0.6943603754043579
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6687429845333099
  Validation Loss: 0.6937193870544434
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6778336316347122
  Validation Loss: 0.6930842995643616
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6773519814014435
  Validation Loss: 0.6925379633903503
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6802130937576294
  Validation Loss: 0.6919800043106079
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6651175022125244
  Validation Loss: 0.6914185285568237
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6817679554224014
  Validation Loss: 0.6908900141716003
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6907274276018143
  Validation Loss: 0.6903641223907471
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 45/64:
  Train Loss: 0.6746991276741028
  Validation Loss: 0.6898543834686279
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 46/64:
  Train Loss: 0.6707727760076523
  Validation Loss: 0.6893142461776733
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 47/64:
  Train Loss: 0.6854733377695084
  Validation Loss: 0.6887660622596741
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 48/64:
  Train Loss: 0.6747478693723679
  Validation Loss: 0.688228189945221
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 49/64:
  Train Loss: 0.6694052070379257
  Validation Loss: 0.6877003312110901
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 50/64:
  Train Loss: 0.6821635961532593
  Validation Loss: 0.6871861815452576
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 51/64:
  Train Loss: 0.6685017794370651
  Validation Loss: 0.686707615852356
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 52/64:
  Train Loss: 0.6625820696353912
  Validation Loss: 0.6862177848815918
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 53/64:
  Train Loss: 0.6742124557495117
  Validation Loss: 0.6857773065567017
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 54/64:
  Train Loss: 0.6631612777709961
  Validation Loss: 0.6853004693984985
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 55/64:
  Train Loss: 0.673721581697464
  Validation Loss: 0.6848458051681519
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 56/64:
  Train Loss: 0.6660650670528412
  Validation Loss: 0.684402585029602
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 57/64:
  Train Loss: 0.6689971685409546
  Validation Loss: 0.6839993596076965
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 58/64:
  Train Loss: 0.6691457629203796
  Validation Loss: 0.683584988117218
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 59/64:
  Train Loss: 0.6615894734859467
  Validation Loss: 0.6831825375556946
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 60/64:
  Train Loss: 0.6624534875154495
  Validation Loss: 0.6828251481056213
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 61/64:
  Train Loss: 0.6720256954431534
  Validation Loss: 0.6824420690536499
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 62/64:
  Train Loss: 0.6813559234142303
  Validation Loss: 0.6820515394210815
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 63/64:
  Train Loss: 0.6666007339954376
  Validation Loss: 0.6816418170928955
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 64/64:
  Train Loss: 0.6696745902299881
  Validation Loss: 0.6812542676925659
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
{'train_loss': 0.6696745902299881, 'val_roc_auc': 1.0, 'val_accuracy': 1.0, 'val_loss': 0.6812542676925659}
 ROC_AUC: 1.0000|| Accuracy 1.0000 || Train Loss: 0.6697
 Val Loss: 0.6813 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7330010305629687
Test ROC-AUC: 0.8593073593073594
Test Accuracy: 0.7415730337078652
test_loss: 0.7330010305629687
test_roc_auc: 0.8593073593073594
test_accuracy: 0.7415730337078652
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.15745139458886115
Epoch 1/64:
  Train Loss: 0.71221062541008
  Validation Loss: 0.6978515982627869
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.7021110951900482
  Validation Loss: 0.6969282627105713
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.7135989964008331
  Validation Loss: 0.6960558891296387
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.7069366723299026
  Validation Loss: 0.6951292753219604
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.695460706949234
  Validation Loss: 0.6942248940467834
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.7010497599840164
  Validation Loss: 0.6933214664459229
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.7015271931886673
  Validation Loss: 0.6924484968185425
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6897923648357391
  Validation Loss: 0.6915850043296814
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7065066993236542
  Validation Loss: 0.6907336115837097
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.7071738392114639
  Validation Loss: 0.6898853778839111
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6964803338050842
  Validation Loss: 0.6890624761581421
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.69205741584301
  Validation Loss: 0.6882542371749878
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7046704888343811
  Validation Loss: 0.6874545812606812
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6874592304229736
  Validation Loss: 0.6866965889930725
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.696903869509697
  Validation Loss: 0.6859511733055115
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6974129378795624
  Validation Loss: 0.6852380037307739
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6942534744739532
  Validation Loss: 0.6845206618309021
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7001063376665115
  Validation Loss: 0.6838135719299316
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6907490640878677
  Validation Loss: 0.6831358671188354
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.696821540594101
  Validation Loss: 0.6824705600738525
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6904575973749161
  Validation Loss: 0.681825578212738
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6985770463943481
  Validation Loss: 0.6811789274215698
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6931591928005219
  Validation Loss: 0.6805399656295776
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6771213263273239
  Validation Loss: 0.6799307465553284
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6886709630489349
  Validation Loss: 0.679351270198822
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6907681971788406
  Validation Loss: 0.6787317991256714
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6854951977729797
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:45:INFO:
[92mINFO [0m:      Received: evaluate message dcfc75c3-de0c-445a-b4a8-0a6660a02fe9
02/07/2025 22:47:45:INFO:Received: evaluate message dcfc75c3-de0c-445a-b4a8-0a6660a02fe9
[92mINFO [0m:      Sent reply
02/07/2025 22:47:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:47:INFO:
[92mINFO [0m:      Received: train message a5345834-03c2-4638-baf7-dfe6396af42b
02/07/2025 22:47:47:INFO:Received: train message a5345834-03c2-4638-baf7-dfe6396af42b
  Validation Loss: 0.678138792514801
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6806372255086899
  Validation Loss: 0.6775745153427124
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6904297918081284
  Validation Loss: 0.6770269870758057
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6909013092517853
  Validation Loss: 0.6764839887619019
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6738265603780746
  Validation Loss: 0.6759608387947083
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.690863236784935
  Validation Loss: 0.675452470779419
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6825554072856903
  Validation Loss: 0.6749573945999146
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6816839873790741
  Validation Loss: 0.6744600534439087
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6780360639095306
  Validation Loss: 0.6739851236343384
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6903508305549622
  Validation Loss: 0.6735101938247681
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6910721957683563
  Validation Loss: 0.673008382320404
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6858580261468887
  Validation Loss: 0.6725059151649475
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6758795082569122
  Validation Loss: 0.6720324158668518
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6596901416778564
  Validation Loss: 0.6715602278709412
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6712749004364014
  Validation Loss: 0.6710682511329651
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6785878539085388
  Validation Loss: 0.6705963611602783
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6786971986293793
  Validation Loss: 0.6701284646987915
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6717584133148193
  Validation Loss: 0.6696941256523132
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6756633669137955
  Validation Loss: 0.6692431569099426
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6788416802883148
  Validation Loss: 0.6688178777694702
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6823158115148544
  Validation Loss: 0.6684260368347168
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.681344673037529
  Validation Loss: 0.6680490970611572
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6683645397424698
  Validation Loss: 0.6676787734031677
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6766394227743149
  Validation Loss: 0.667317271232605
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6688307523727417
  Validation Loss: 0.6669460535049438
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6723751723766327
  Validation Loss: 0.666581392288208
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6742377281188965
  Validation Loss: 0.6662209033966064
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6685438901185989
  Validation Loss: 0.6658799052238464
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6800519227981567
  Validation Loss: 0.6655493974685669
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6740469485521317
  Validation Loss: 0.6651974320411682
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6753141433000565
  Validation Loss: 0.6648659706115723
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6675487458705902
  Validation Loss: 0.6645315885543823
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6622894257307053
  Validation Loss: 0.664225697517395
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6658077389001846
  Validation Loss: 0.6639187932014465
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6714664250612259
  Validation Loss: 0.6635971069335938
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6754156649112701
  Validation Loss: 0.6632825136184692
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6673453450202942
  Validation Loss: 0.6629421710968018
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6709420084953308
  Validation Loss: 0.6626177430152893
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6709420084953308, 'val_roc_auc': 0.9529411764705882, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6626177430152893}
 ROC_AUC: 0.9529|| Accuracy 0.9259 || Train Loss: 0.6709
 Val Loss: 0.6626 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7284157436885191
Test ROC-AUC: 0.8630952380952381
Test Accuracy: 0.7528089887640449
test_loss: 0.7284157436885191
test_roc_auc: 0.8630952380952381
test_accuracy: 0.7528089887640449
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.14921859395144565
Epoch 1/64:
  Train Loss: 0.6909562945365906
  Validation Loss: 0.7194815278053284
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.7077227383852005
  Validation Loss: 0.7183672189712524
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.707776203751564
  Validation Loss: 0.717241644859314
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6954803615808487
  Validation Loss: 0.716180145740509
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.698752760887146
  Validation Loss: 0.7151421308517456
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6801741868257523
  Validation Loss: 0.7140398621559143
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6934020221233368
  Validation Loss: 0.7130224704742432
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6916237473487854
  Validation Loss: 0.7120286226272583
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6842816472053528
  Validation Loss: 0.7110797762870789
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6765095293521881
  Validation Loss: 0.7101343274116516
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6946101039648056
  Validation Loss: 0.7091604471206665
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6946431249380112
  Validation Loss: 0.7082074284553528
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6812556982040405
  Validation Loss: 0.7073033452033997
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.694092184305191
  Validation Loss: 0.7064138650894165
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6853319704532623
  Validation Loss: 0.7054994702339172
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6875271052122116
  Validation Loss: 0.7046520113945007
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6817574799060822
  Validation Loss: 0.7038046717643738
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6846850216388702
  Validation Loss: 0.7029697895050049
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6820769309997559
  Validation Loss: 0.7021597027778625
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6816959381103516
  Validation Loss: 0.7013794183731079
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6826262772083282
  Validation Loss: 0.7005900144577026
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6744206696748734
  Validation Loss: 0.6998283863067627
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6853567063808441
  Validation Loss: 0.6990657448768616
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6760365068912506
  Validation Loss: 0.6983433961868286
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6756812781095505
  Validation Loss: 0.6976215243339539
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6826813668012619
  Validation Loss: 0.6968848705291748
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6720687747001648
  Validation Loss: 0.6962203979492188
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6723974943161011
  Validation Loss: 0.6955651044845581
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6774585098028183
  Validation Loss: 0.6949446201324463
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6872470080852509
  Validation Loss: 0.6942811012268066
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6764218509197235
  Validation Loss: 0.693658173084259
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6651709079742432
  Validation Loss: 0.6930106282234192
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.683491125702858
  Validation Loss: 0.6923741698265076
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6802934557199478
  Validation Loss: 0.6917032599449158
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6760128885507584
  Validation Loss: 0.6910404562950134
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.684184655547142
  Validation Loss: 0.6904312372207642
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6705250442028046
  Validation Loss: 0.6898320317268372
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6635107100009918
  Validation Loss: 0.6892561912536621
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6687473654747009
  Validation Loss: 0.6886903047561646
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6697505712509155
  Validation Loss: 0.6881151795387268
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6598634421825409
  Validation Loss: 0.687548816204071
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6656411290168762
  Validation Loss: 0.6869551539421082
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6561808735132217
  Validation Loss: 0.6864146590232849
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6657944917678833
  Validation Loss: 0.6859034895896912
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.667956069111824
  Validation Loss: 0.6854085326194763
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6675329059362411
  Validation Loss: 0.6849122047424316
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6734444350004196
  Validation Loss: 0.6844066977500916
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6745863407850266
  Validation Loss: 0.6839489340782166
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6587482839822769
  Validation Loss: 0.6834824681282043
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6709589511156082
  Validation Loss: 0.6829957365989685
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6702635735273361
  Validation Loss: 0.6825157403945923
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.672858715057373
  Validation Loss: 0.6820711493492126
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6724355220794678
  Validation Loss: 0.6816295385360718
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6687358617782593
  Validation Loss: 0.6811968088150024
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6617507040500641
  Validation Loss: 0.680722713470459
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6689580231904984
  Validation Loss: 0.6802759766578674
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6575885266065598
  Validation Loss: 0.6798388361930847
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6683782935142517
  Validation Loss: 0.6794440746307373
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6588825732469559
  Validation Loss: 0.6790799498558044
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6663649082183838
  Validation Loss: 0.6787474155426025
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.671165943145752
  Validation Loss: 0.6784102916717529
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6712415665388107
  Validation Loss: 0.678061306476593
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6583768725395203
  Validation Loss: 0.6777114868164062
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6690092384815216
  Validation Loss: 0.6773381233215332
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6690092384815216, 'val_roc_auc': 0.993421052631579, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6773381233215332}
 ROC_AUC: 0.9934|| Accuracy 0.9630 || Train Loss: 0.6690
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:11:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:14:INFO:
[92mINFO [0m:      Received: evaluate message 3ad1015f-daec-41de-bd33-bf92864196b9
02/07/2025 22:48:14:INFO:Received: evaluate message 3ad1015f-daec-41de-bd33-bf92864196b9
[92mINFO [0m:      Sent reply
02/07/2025 22:48:17:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:17:INFO:
[92mINFO [0m:      Received: train message 23647618-f8dc-4f1a-9e35-1b2991a2e2b1
02/07/2025 22:48:17:INFO:Received: train message 23647618-f8dc-4f1a-9e35-1b2991a2e2b1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
 Val Loss: 0.6773 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7240267687299279
Test ROC-AUC: 0.8685064935064936
Test Accuracy: 0.7528089887640449
test_loss: 0.7240267687299279
test_roc_auc: 0.8685064935064936
test_accuracy: 0.7528089887640449
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.26688771631597774
Epoch 1/64:
  Train Loss: 0.6800666004419327
  Validation Loss: 0.7089983820915222
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6711684614419937
  Validation Loss: 0.7081784009933472
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6894033700227737
  Validation Loss: 0.7073380351066589
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.692296713590622
  Validation Loss: 0.7065066695213318
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.688889890909195
  Validation Loss: 0.7057322263717651
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6962815821170807
  Validation Loss: 0.7050029635429382
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6911178827285767
  Validation Loss: 0.7042691111564636
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6813455671072006
  Validation Loss: 0.7035435438156128
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6967378854751587
  Validation Loss: 0.7029179930686951
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6880293488502502
  Validation Loss: 0.7022411227226257
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.696547731757164
  Validation Loss: 0.7015902400016785
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6934346258640289
  Validation Loss: 0.7009338140487671
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7005328983068466
  Validation Loss: 0.7003079056739807
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6902137994766235
  Validation Loss: 0.6996020674705505
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6819833666086197
  Validation Loss: 0.6989488005638123
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6769985258579254
  Validation Loss: 0.6983025074005127
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6845974624156952
  Validation Loss: 0.6976736783981323
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6847675293684006
  Validation Loss: 0.6970236301422119
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6929171532392502
  Validation Loss: 0.6964161992073059
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6868270635604858
  Validation Loss: 0.6958516240119934
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6901133209466934
  Validation Loss: 0.6953109502792358
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.67977574467659
  Validation Loss: 0.6947669982910156
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6837925761938095
  Validation Loss: 0.6942432522773743
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6793326884508133
  Validation Loss: 0.6937403082847595
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6843228191137314
  Validation Loss: 0.693191409111023
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6868630200624466
  Validation Loss: 0.6926504373550415
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6744922548532486
  Validation Loss: 0.6921167969703674
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6800532042980194
  Validation Loss: 0.6915661096572876
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6829417496919632
  Validation Loss: 0.6910271048545837
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6806780993938446
  Validation Loss: 0.6905089020729065
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6784755289554596
  Validation Loss: 0.6899983286857605
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6799929589033127
  Validation Loss: 0.6895069479942322
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6659846007823944
  Validation Loss: 0.6890369057655334
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6788265556097031
  Validation Loss: 0.688526451587677
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6738249212503433
  Validation Loss: 0.6880347728729248
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6755460500717163
  Validation Loss: 0.6875784397125244
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6665690839290619
  Validation Loss: 0.687167763710022
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.681417778134346
  Validation Loss: 0.6867531538009644
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6730284094810486
  Validation Loss: 0.6863524913787842
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6671302765607834
  Validation Loss: 0.6859472990036011
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6789591759443283
  Validation Loss: 0.6855437755584717
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6648666560649872
  Validation Loss: 0.6851603388786316
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.673383504152298
  Validation Loss: 0.6848229765892029
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.661960169672966
  Validation Loss: 0.6844753623008728
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6633120328187943
  Validation Loss: 0.684144139289856
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6607015579938889
  Validation Loss: 0.6837709546089172
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.670764148235321
  Validation Loss: 0.6834332346916199
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6659178882837296
  Validation Loss: 0.6831044554710388
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6579021513462067
  Validation Loss: 0.6827361583709717
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6656492650508881
  Validation Loss: 0.6823891401290894
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.652976006269455
  Validation Loss: 0.6820093989372253
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:41:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:41:INFO:
[92mINFO [0m:      Received: evaluate message 2aa20429-f5ad-4ac7-8f5f-d46f98a022ea
02/07/2025 22:48:41:INFO:Received: evaluate message 2aa20429-f5ad-4ac7-8f5f-d46f98a022ea
[92mINFO [0m:      Sent reply
02/07/2025 22:48:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:44:INFO:
[92mINFO [0m:      Received: train message 50be744b-ba1b-4798-86ef-6f763c0bf914
02/07/2025 22:48:44:INFO:Received: train message 50be744b-ba1b-4798-86ef-6f763c0bf914
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6559681296348572
  Validation Loss: 0.681695282459259
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6641468852758408
  Validation Loss: 0.6814137101173401
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6702235192060471
  Validation Loss: 0.6811224818229675
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6632216721773148
  Validation Loss: 0.6808106303215027
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.671295702457428
  Validation Loss: 0.6805053949356079
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6673721969127655
  Validation Loss: 0.6802048683166504
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6586845368146896
  Validation Loss: 0.6799203157424927
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.656059056520462
  Validation Loss: 0.6796221137046814
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6600908041000366
  Validation Loss: 0.6793628334999084
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6738135516643524
  Validation Loss: 0.6790884733200073
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6593790799379349
  Validation Loss: 0.6788267493247986
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6555206477642059
  Validation Loss: 0.6785564422607422
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6544881910085678
  Validation Loss: 0.67830491065979
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6544881910085678, 'val_roc_auc': 0.9938271604938271, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.67830491065979}
 ROC_AUC: 0.9938|| Accuracy 0.9630 || Train Loss: 0.6545
 Val Loss: 0.6783 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.719981370682127
Test ROC-AUC: 0.8733766233766235
Test Accuracy: 0.7752808988764045
test_loss: 0.719981370682127
test_roc_auc: 0.8733766233766235
test_accuracy: 0.7752808988764045
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.30547742469934747
Epoch 1/64:
  Train Loss: 0.711897611618042
  Validation Loss: 0.625713050365448
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.7133131623268127
  Validation Loss: 0.6249395608901978
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.7124778628349304
  Validation Loss: 0.6241033673286438
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.7017275393009186
  Validation Loss: 0.6233582496643066
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6957020610570908
  Validation Loss: 0.6226478219032288
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.7103731781244278
  Validation Loss: 0.621978759765625
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.7114109396934509
  Validation Loss: 0.6213164329528809
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.7092068493366241
  Validation Loss: 0.6207308769226074
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7075282335281372
  Validation Loss: 0.6202113032341003
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.694983720779419
  Validation Loss: 0.6196231245994568
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.7031043171882629
  Validation Loss: 0.6189823150634766
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.7065044939517975
  Validation Loss: 0.6183192133903503
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7116879671812057
  Validation Loss: 0.6176784038543701
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6939500868320465
  Validation Loss: 0.6170992255210876
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6936052888631821
  Validation Loss: 0.6165432333946228
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6928929090499878
  Validation Loss: 0.6159592866897583
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.7064605057239532
  Validation Loss: 0.6153786778450012
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6995514631271362
  Validation Loss: 0.6148707270622253
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7072737216949463
  Validation Loss: 0.614325225353241
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6963777393102646
  Validation Loss: 0.613746166229248
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6935858577489853
  Validation Loss: 0.6131941080093384
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6977666020393372
  Validation Loss: 0.612642765045166
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6994884163141251
  Validation Loss: 0.612141489982605
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6964087635278702
  Validation Loss: 0.611595094203949
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6905701905488968
  Validation Loss: 0.6110895276069641
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6916016489267349
  Validation Loss: 0.6106162071228027
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.7006864845752716
  Validation Loss: 0.6101588606834412
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6908915489912033
  Validation Loss: 0.6097072958946228
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6922814100980759
  Validation Loss: 0.6092888712882996
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.692835807800293
  Validation Loss: 0.60883629322052
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6814775466918945
  Validation Loss: 0.6084224581718445
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6822954267263412
  Validation Loss: 0.6080480813980103
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6910450756549835
  Validation Loss: 0.6077036261558533
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.68829545378685
  Validation Loss: 0.6073427796363831
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6983784288167953
  Validation Loss: 0.6069310307502747
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6962042152881622
  Validation Loss: 0.6065405607223511
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:11:INFO:
[92mINFO [0m:      Received: evaluate message ae835851-3d86-4ce1-a985-af39b54485cf
02/07/2025 22:49:11:INFO:Received: evaluate message ae835851-3d86-4ce1-a985-af39b54485cf
[92mINFO [0m:      Sent reply
02/07/2025 22:49:12:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:12:INFO:
[92mINFO [0m:      Received: train message a3321812-ff0c-408a-98c6-d4f686e13a79
02/07/2025 22:49:12:INFO:Received: train message a3321812-ff0c-408a-98c6-d4f686e13a79
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6962688565254211
  Validation Loss: 0.6061584949493408
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6803946942090988
  Validation Loss: 0.6057892441749573
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6846000403165817
  Validation Loss: 0.6053804755210876
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6946893483400345
  Validation Loss: 0.6049354076385498
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6794447302818298
  Validation Loss: 0.6045066714286804
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6900179386138916
  Validation Loss: 0.6041252613067627
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6756899058818817
  Validation Loss: 0.6037799715995789
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6751058995723724
  Validation Loss: 0.603419840335846
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6769147962331772
  Validation Loss: 0.6030887961387634
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.669622391462326
  Validation Loss: 0.602812647819519
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6793131530284882
  Validation Loss: 0.6025103330612183
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6861734390258789
  Validation Loss: 0.6021995544433594
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6832368522882462
  Validation Loss: 0.6018631458282471
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6752838641405106
  Validation Loss: 0.6015958189964294
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.669529378414154
  Validation Loss: 0.6012900471687317
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6821378618478775
  Validation Loss: 0.6010088324546814
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6763217896223068
  Validation Loss: 0.6007012128829956
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6719990223646164
  Validation Loss: 0.6003773808479309
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6729206740856171
  Validation Loss: 0.6000836491584778
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6773146390914917
  Validation Loss: 0.599831759929657
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6804251968860626
  Validation Loss: 0.5995795726776123
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6792652010917664
  Validation Loss: 0.5993939638137817
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6814415454864502
  Validation Loss: 0.5991848707199097
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6786172091960907
  Validation Loss: 0.5989454984664917
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6712619662284851
  Validation Loss: 0.5986717939376831
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.680878221988678
  Validation Loss: 0.5983715653419495
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6760999709367752
  Validation Loss: 0.5981516242027283
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6708739399909973
  Validation Loss: 0.5979080200195312
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6708739399909973, 'val_roc_auc': 0.978021978021978, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.5979080200195312}
 ROC_AUC: 0.9780|| Accuracy 0.9259 || Train Loss: 0.6709
 Val Loss: 0.5979 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7161931211359045
Test ROC-AUC: 0.8744588744588745
Test Accuracy: 0.7752808988764045
test_loss: 0.7161931211359045
test_roc_auc: 0.8744588744588745
test_accuracy: 0.7752808988764045
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.23639527384148096
Epoch 1/64:
  Train Loss: 0.6977872550487518
  Validation Loss: 0.6762450933456421
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 2/64:
  Train Loss: 0.7000580132007599
  Validation Loss: 0.6756577491760254
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 3/64:
  Train Loss: 0.6855247616767883
  Validation Loss: 0.675105631351471
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 4/64:
  Train Loss: 0.7001869529485703
  Validation Loss: 0.6745415329933167
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.6878899931907654
  Validation Loss: 0.6739692091941833
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.6976971924304962
  Validation Loss: 0.6734245419502258
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.6833876520395279
  Validation Loss: 0.6728622317314148
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.6935761272907257
  Validation Loss: 0.6723071932792664
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.685921385884285
  Validation Loss: 0.6717180609703064
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6699381470680237
  Validation Loss: 0.6711012721061707
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6887566894292831
  Validation Loss: 0.670571506023407
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.6807559877634048
  Validation Loss: 0.6700860261917114
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.6818086206912994
  Validation Loss: 0.6695934534072876
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.6689887195825577
  Validation Loss: 0.6691110730171204
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6858706921339035
  Validation Loss: 0.6686459183692932
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.6801656782627106
  Validation Loss: 0.6681758165359497
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6879183501005173
  Validation Loss: 0.6677079200744629
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.675558865070343
  Validation Loss: 0.6673027276992798
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6726569980382919
  Validation Loss: 0.6668959259986877
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.683054730296135
  Validation Loss: 0.6664498448371887
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.678876131772995
  Validation Loss: 0.6660086512565613
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.6728470325469971
  Validation Loss: 0.665594220161438
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:38:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:38:INFO:
[92mINFO [0m:      Received: evaluate message 6387f812-2055-478e-a0aa-ab3e4259c3f8
02/07/2025 22:49:38:INFO:Received: evaluate message 6387f812-2055-478e-a0aa-ab3e4259c3f8
[92mINFO [0m:      Sent reply
02/07/2025 22:49:38:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:38:INFO:
[92mINFO [0m:      Received: train message b47ec8e1-e5b1-41e3-9a7f-c8149d932763
02/07/2025 22:49:38:INFO:Received: train message b47ec8e1-e5b1-41e3-9a7f-c8149d932763
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6787218153476715
  Validation Loss: 0.665194034576416
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6796030551195145
  Validation Loss: 0.6647796630859375
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6907089948654175
  Validation Loss: 0.6643815040588379
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6827681213617325
  Validation Loss: 0.6640445590019226
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6744020134210587
  Validation Loss: 0.6637024879455566
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.665852278470993
  Validation Loss: 0.6633648872375488
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.664064347743988
  Validation Loss: 0.6630062460899353
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6777201294898987
  Validation Loss: 0.6626337170600891
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6788754463195801
  Validation Loss: 0.6622965931892395
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6743409931659698
  Validation Loss: 0.6619773507118225
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6769947856664658
  Validation Loss: 0.661663830280304
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.674146756529808
  Validation Loss: 0.6613326072692871
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6722022742033005
  Validation Loss: 0.6609719395637512
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6861761957406998
  Validation Loss: 0.6606063842773438
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6743748635053635
  Validation Loss: 0.6602551341056824
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6717259436845779
  Validation Loss: 0.659916341304779
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6686403304338455
  Validation Loss: 0.6596159934997559
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6650655716657639
  Validation Loss: 0.6593054533004761
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6494400799274445
  Validation Loss: 0.6590086817741394
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6774557679891586
  Validation Loss: 0.658750593662262
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6602119654417038
  Validation Loss: 0.658494770526886
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6699442267417908
  Validation Loss: 0.6582491397857666
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6590761840343475
  Validation Loss: 0.6580154299736023
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6576109081506729
  Validation Loss: 0.6577932834625244
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6600609570741653
  Validation Loss: 0.6575893759727478
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6643818914890289
  Validation Loss: 0.6574276685714722
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6737409085035324
  Validation Loss: 0.6572505831718445
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6677857041358948
  Validation Loss: 0.6570888757705688
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6564173549413681
  Validation Loss: 0.6569345593452454
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6650501638650894
  Validation Loss: 0.65678471326828
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6740750670433044
  Validation Loss: 0.6566234230995178
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6548244208097458
  Validation Loss: 0.656470537185669
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6700924932956696
  Validation Loss: 0.6562777161598206
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6613945811986923
  Validation Loss: 0.6561188697814941
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6597447693347931
  Validation Loss: 0.6559584736824036
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6632078886032104
  Validation Loss: 0.6557861566543579
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6584836840629578
  Validation Loss: 0.6556146740913391
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6628019362688065
  Validation Loss: 0.6554519534111023
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.659167155623436
  Validation Loss: 0.6552659273147583
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6496780663728714
  Validation Loss: 0.6551136374473572
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6616282016038895
  Validation Loss: 0.6550130248069763
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6659116148948669
  Validation Loss: 0.6549089550971985
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6659116148948669, 'val_roc_auc': 0.9588235294117647, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6549089550971985}
 ROC_AUC: 0.9588|| Accuracy 0.9630 || Train Loss: 0.6659
 Val Loss: 0.6549 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7127033676324266
Test ROC-AUC: 0.875
Test Accuracy: 0.7865168539325843
test_loss: 0.7127033676324266
test_roc_auc: 0.875
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.34346176625452546
Epoch 1/64:
  Train Loss: 0.6752151995897293
  Validation Loss: 0.6846409440040588
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6942539513111115
  Validation Loss: 0.6839978098869324
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6816118210554123
  Validation Loss: 0.6833474040031433
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6916751265525818
  Validation Loss: 0.6827244162559509
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6823041588068008
  Validation Loss: 0.6821300983428955
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6747090816497803
  Validation Loss: 0.6815119385719299
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6891574412584305
  Validation Loss: 0.6808929443359375
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6913573443889618
  Validation Loss: 0.680304765701294
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.6820194572210312
  Validation Loss: 0.6797683238983154
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6710737645626068
  Validation Loss: 0.6792574524879456
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6821428835391998
  Validation Loss: 0.6787300109863281
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6888918280601501
  Validation Loss: 0.6782229542732239
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.6705337166786194
  Validation Loss: 0.6777122020721436
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6842881590127945
  Validation Loss: 0.6771922707557678
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6677560806274414
  Validation Loss: 0.6766897439956665
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.6736720204353333
  Validation Loss: 0.6761673092842102
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6710474044084549
  Validation Loss: 0.6756848692893982
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6917524337768555
  Validation Loss: 0.6751993298530579
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6796777844429016
  Validation Loss: 0.6746994256973267
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.6630453765392303
  Validation Loss: 0.6741776466369629
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6680213212966919
  Validation Loss: 0.6736327409744263
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6731030642986298
  Validation Loss: 0.6731614470481873
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.6704842150211334
  Validation Loss: 0.6726951599121094
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.668936088681221
  Validation Loss: 0.6722583174705505
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.6699116975069046
  Validation Loss: 0.6718257665634155
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6821316331624985
  Validation Loss: 0.6713616251945496
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.6765075922012329
  Validation Loss: 0.6709312200546265
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6727112382650375
  Validation Loss: 0.6704965829849243
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6632250100374222
  Validation Loss: 0.6700699925422668
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.6766137480735779
  Validation Loss: 0.669680118560791
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6715547293424606
  Validation Loss: 0.669308066368103
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6721968948841095
  Validation Loss: 0.6689589023590088
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6590132117271423
  Validation Loss: 0.6686429381370544
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6609103083610535
  Validation Loss: 0.6683130860328674
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6730277389287949
  Validation Loss: 0.6679873466491699
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6680116206407547
  Validation Loss: 0.6676249504089355
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.672413781285286
  Validation Loss: 0.6672716736793518
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6765347123146057
  Validation Loss: 0.6669026017189026
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.667058989405632
  Validation Loss: 0.6665481328964233
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6496321707963943
  Validation Loss: 0.6661943793296814
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6746820658445358
  Validation Loss: 0.6658980846405029
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6677144914865494
  Validation Loss: 0.6655821800231934
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6721079796552658
  Validation Loss: 0.6652827262878418
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6569454222917557
  Validation Loss: 0.6649790406227112
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6668571531772614
  Validation Loss: 0.6646683812141418
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.657739669084549
  Validation Loss: 0.6643157005310059
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6551342457532883
  Validation Loss: 0.6639530062675476
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6704462170600891
  Validation Loss: 0.6636412739753723
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6618349552154541
  Validation Loss: 0.6633744239807129
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6498517543077469
  Validation Loss: 0.6631161570549011
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.665631040930748
  Validation Loss: 0.6628848910331726
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6558975875377655
  Validation Loss: 0.6626355051994324
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6750386953353882
  Validation Loss: 0.6623767018318176
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6672971993684769
  Validation Loss: 0.6621376276016235
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6738460212945938
  Validation Loss: 0.6618868112564087
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6602200865745544
  Validation Loss: 0.6616213917732239
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6780286431312561
  Validation Loss: 0.6613847017288208
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6694884747266769
  Validation Loss: 0.6611728072166443
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6555324494838715
  Validation Loss: 0.6609638333320618
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6606769561767578
  Validation Loss: 0.6607752442359924
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6586846858263016
  Validation Loss: 0.6605933308601379
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:05:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:05:INFO:
[92mINFO [0m:      Received: evaluate message e78154f1-73e6-4dfd-9c27-697c0a4a52bd
02/07/2025 22:50:05:INFO:Received: evaluate message e78154f1-73e6-4dfd-9c27-697c0a4a52bd
[92mINFO [0m:      Sent reply
02/07/2025 22:50:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:08:INFO:
[92mINFO [0m:      Received: train message d3ccd898-edb1-4977-a90b-aec20f59ea12
02/07/2025 22:50:08:INFO:Received: train message d3ccd898-edb1-4977-a90b-aec20f59ea12
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6548536121845245
  Validation Loss: 0.6604014039039612
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6600216329097748
  Validation Loss: 0.6602249145507812
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6577606499195099
  Validation Loss: 0.6600486040115356
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6577606499195099, 'val_roc_auc': 0.9647058823529411, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6600486040115356}
 ROC_AUC: 0.9647|| Accuracy 0.9259 || Train Loss: 0.6578
 Val Loss: 0.6600 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7094746667347597
Test ROC-AUC: 0.8771645021645021
Test Accuracy: 0.7865168539325843
test_loss: 0.7094746667347597
test_roc_auc: 0.8771645021645021
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.39353196258161915
Epoch 1/64:
  Train Loss: 0.6673550754785538
  Validation Loss: 0.7787685990333557
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 2/64:
  Train Loss: 0.6334616988897324
  Validation Loss: 0.7783865928649902
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 3/64:
  Train Loss: 0.659712091088295
  Validation Loss: 0.7779895663261414
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 4/64:
  Train Loss: 0.6517463773488998
  Validation Loss: 0.7776399850845337
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 5/64:
  Train Loss: 0.6491484642028809
  Validation Loss: 0.777245819568634
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 6/64:
  Train Loss: 0.6511303633451462
  Validation Loss: 0.7767668962478638
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 7/64:
  Train Loss: 0.6395454704761505
  Validation Loss: 0.7761551141738892
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 8/64:
  Train Loss: 0.6605497449636459
  Validation Loss: 0.7756507396697998
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 9/64:
  Train Loss: 0.6546077877283096
  Validation Loss: 0.7751305103302002
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 10/64:
  Train Loss: 0.6377138942480087
  Validation Loss: 0.7747073769569397
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 11/64:
  Train Loss: 0.6517314165830612
  Validation Loss: 0.7743589878082275
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 12/64:
  Train Loss: 0.660552516579628
  Validation Loss: 0.773962676525116
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 13/64:
  Train Loss: 0.6496243178844452
  Validation Loss: 0.773636519908905
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 14/64:
  Train Loss: 0.6383717954158783
  Validation Loss: 0.7732821106910706
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 15/64:
  Train Loss: 0.6597487330436707
  Validation Loss: 0.772828996181488
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 16/64:
  Train Loss: 0.6544704139232635
  Validation Loss: 0.7724425792694092
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 17/64:
  Train Loss: 0.6537835896015167
  Validation Loss: 0.772057294845581
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 18/64:
  Train Loss: 0.6449851244688034
  Validation Loss: 0.7716211676597595
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.6584193855524063
  Validation Loss: 0.771148145198822
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.6459318697452545
  Validation Loss: 0.7707293033599854
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.6510319411754608
  Validation Loss: 0.7703514099121094
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.6457546651363373
  Validation Loss: 0.7699329257011414
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.6472191363573074
  Validation Loss: 0.769478976726532
  Val ROC-AUC: 0.6190476190476191
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.6453990191221237
  Validation Loss: 0.7690860629081726
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.6393545418977737
  Validation Loss: 0.7687954306602478
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.6494342982769012
  Validation Loss: 0.7685184478759766
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.652582585811615
  Validation Loss: 0.7681525349617004
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6409617960453033
  Validation Loss: 0.7677428722381592
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6503391414880753
  Validation Loss: 0.7674887776374817
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6506583392620087
  Validation Loss: 0.7671539783477783
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6384025067090988
  Validation Loss: 0.7668026089668274
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6430516093969345
  Validation Loss: 0.7664242386817932
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6447424292564392
  Validation Loss: 0.7660045027732849
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6489311158657074
  Validation Loss: 0.7656698226928711
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6447888314723969
  Validation Loss: 0.7653629183769226
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6429208517074585
  Validation Loss: 0.7649800181388855
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6366472393274307
  Validation Loss: 0.7645502686500549
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6357823461294174
  Validation Loss: 0.764123797416687
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6373055130243301
  Validation Loss: 0.7637905478477478
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.654156357049942
  Validation Loss: 0.7635711431503296
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6403178125619888
  Validation Loss: 0.7633647322654724
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6405741572380066
  Validation Loss: 0.7630751132965088
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6399575024843216
  Validation Loss: 0.762731671333313
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6399192214012146
  Validation Loss: 0.7623864412307739
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.6388701647520065
  Validation Loss: 0.7621445059776306
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6229084134101868
  Validation Loss: 0.7619102001190186
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:34:INFO:
[92mINFO [0m:      Received: evaluate message 62c6f4c1-58a0-4739-9cd4-c2a7cefd3bb1
02/07/2025 22:50:34:INFO:Received: evaluate message 62c6f4c1-58a0-4739-9cd4-c2a7cefd3bb1
[92mINFO [0m:      Sent reply
02/07/2025 22:50:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:35:INFO:
[92mINFO [0m:      Received: train message fd3844c7-e64a-4aaa-97bf-3967e0f1f576
02/07/2025 22:50:35:INFO:Received: train message fd3844c7-e64a-4aaa-97bf-3967e0f1f576
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 47/64:
  Train Loss: 0.6275728493928909
  Validation Loss: 0.7616704106330872
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.6430548876523972
  Validation Loss: 0.7614313960075378
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6310769319534302
  Validation Loss: 0.7611434459686279
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.645201176404953
  Validation Loss: 0.760884702205658
  Val ROC-AUC: 0.6746031746031746
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.640564575791359
  Validation Loss: 0.7606341242790222
  Val ROC-AUC: 0.6825396825396826
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6246028542518616
  Validation Loss: 0.7603919506072998
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.6410922557115555
  Validation Loss: 0.7601618766784668
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.6364583075046539
  Validation Loss: 0.7599190473556519
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6374358981847763
  Validation Loss: 0.7595844864845276
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6225881725549698
  Validation Loss: 0.7592878341674805
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.6403306722640991
  Validation Loss: 0.7590644359588623
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.634984090924263
  Validation Loss: 0.7588496804237366
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6327944397926331
  Validation Loss: 0.7586166858673096
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6453793793916702
  Validation Loss: 0.7583884000778198
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6297987401485443
  Validation Loss: 0.758124053478241
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.6281142681837082
  Validation Loss: 0.7578176856040955
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.61995530128479
  Validation Loss: 0.7574599981307983
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.6377887576818466
  Validation Loss: 0.7571929097175598
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.6377887576818466, 'val_roc_auc': 0.6904761904761905, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.7571929097175598}
 ROC_AUC: 0.6905|| Accuracy 0.8148 || Train Loss: 0.6378
 Val Loss: 0.7572 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7064598423711369
Test ROC-AUC: 0.8793290043290044
Test Accuracy: 0.797752808988764
test_loss: 0.7064598423711369
test_roc_auc: 0.8793290043290044
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.19905357106472366
Epoch 1/64:
  Train Loss: 0.6768395751714706
  Validation Loss: 0.6891005039215088
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6778933703899384
  Validation Loss: 0.6884708404541016
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6742708384990692
  Validation Loss: 0.6878218650817871
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6781352311372757
  Validation Loss: 0.6872156858444214
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.675316721200943
  Validation Loss: 0.6866534352302551
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6750424802303314
  Validation Loss: 0.6860679388046265
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6717491447925568
  Validation Loss: 0.68547123670578
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6644800454378128
  Validation Loss: 0.6848767399787903
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.678983524441719
  Validation Loss: 0.6842898726463318
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6578206717967987
  Validation Loss: 0.6837380528450012
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6584646701812744
  Validation Loss: 0.6832171678543091
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6680265814065933
  Validation Loss: 0.6827373504638672
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6693550050258636
  Validation Loss: 0.6822676658630371
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6716340929269791
  Validation Loss: 0.6818177103996277
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6658110320568085
  Validation Loss: 0.6813351511955261
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6595176756381989
  Validation Loss: 0.6808916926383972
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6719822734594345
  Validation Loss: 0.6804344654083252
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6624124199151993
  Validation Loss: 0.6799460649490356
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6667822003364563
  Validation Loss: 0.6794663667678833
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6603946685791016
  Validation Loss: 0.6789543032646179
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6640769988298416
  Validation Loss: 0.6784853339195251
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6745325475931168
  Validation Loss: 0.6779860258102417
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6574598252773285
  Validation Loss: 0.6775192618370056
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6651746183633804
  Validation Loss: 0.6770843863487244
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6717300713062286
  Validation Loss: 0.6767081022262573
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6601935476064682
  Validation Loss: 0.6763312816619873
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6683423221111298
  Validation Loss: 0.6759642362594604
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6555692255496979
  Validation Loss: 0.67561274766922
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6627160459756851
  Validation Loss: 0.6752499938011169
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6527571678161621
  Validation Loss: 0.6749120950698853
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6534141898155212
  Validation Loss: 0.6746081113815308
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6713179647922516
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:51:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:04:INFO:
[92mINFO [0m:      Received: evaluate message 12624663-1f37-4090-b7ed-2b3a62e17136
02/07/2025 22:51:04:INFO:Received: evaluate message 12624663-1f37-4090-b7ed-2b3a62e17136
[92mINFO [0m:      Sent reply
02/07/2025 22:51:06:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:06:INFO:
[92mINFO [0m:      Received: train message 78c6fb3d-2d00-4b9d-b843-dc2560b0aa1e
02/07/2025 22:51:06:INFO:Received: train message 78c6fb3d-2d00-4b9d-b843-dc2560b0aa1e
  Validation Loss: 0.6743143796920776
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6618607193231583
  Validation Loss: 0.6739906668663025
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.657159835100174
  Validation Loss: 0.6736631989479065
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6622940003871918
  Validation Loss: 0.6733366250991821
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6629211455583572
  Validation Loss: 0.6730080842971802
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6582928895950317
  Validation Loss: 0.6727256774902344
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6648526787757874
  Validation Loss: 0.6724305152893066
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.653207927942276
  Validation Loss: 0.6721278429031372
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6629789918661118
  Validation Loss: 0.6718031167984009
  Val ROC-AUC: 0.888235294117647
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6584748774766922
  Validation Loss: 0.671506941318512
  Val ROC-AUC: 0.888235294117647
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6656132638454437
  Validation Loss: 0.671223521232605
  Val ROC-AUC: 0.888235294117647
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6564915329217911
  Validation Loss: 0.6709919571876526
  Val ROC-AUC: 0.888235294117647
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6610410064458847
  Validation Loss: 0.6707736849784851
  Val ROC-AUC: 0.888235294117647
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6531331241130829
  Validation Loss: 0.6705731749534607
  Val ROC-AUC: 0.888235294117647
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6511470377445221
  Validation Loss: 0.6703436374664307
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6647268384695053
  Validation Loss: 0.6700937747955322
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6628013551235199
  Validation Loss: 0.6698304414749146
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6611136943101883
  Validation Loss: 0.6695544123649597
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6580635905265808
  Validation Loss: 0.6692425608634949
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6559934169054031
  Validation Loss: 0.6689382791519165
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6648666560649872
  Validation Loss: 0.6686792969703674
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.64250847697258
  Validation Loss: 0.6684233546257019
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6469306349754333
  Validation Loss: 0.6681686639785767
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6556573212146759
  Validation Loss: 0.6679408550262451
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.654724970459938
  Validation Loss: 0.6677066683769226
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6462909281253815
  Validation Loss: 0.6674544811248779
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6682904660701752
  Validation Loss: 0.6672146320343018
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.645738884806633
  Validation Loss: 0.6669677495956421
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6539065390825272
  Validation Loss: 0.6667737364768982
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6474436819553375
  Validation Loss: 0.6666025519371033
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6525637805461884
  Validation Loss: 0.6664177179336548
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.645382359623909
  Validation Loss: 0.6662445068359375
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6518171578645706
  Validation Loss: 0.6660540699958801
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6518171578645706, 'val_roc_auc': 0.8941176470588235, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6660540699958801}
 ROC_AUC: 0.8941|| Accuracy 0.8889 || Train Loss: 0.6518
 Val Loss: 0.6661 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7037516487448403
Test ROC-AUC: 0.8777056277056278
Test Accuracy: 0.797752808988764
test_loss: 0.7037516487448403
test_roc_auc: 0.8777056277056278
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.3642048504504298
Epoch 1/64:
  Train Loss: 0.6581400036811829
  Validation Loss: 0.6914107203483582
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6842451244592667
  Validation Loss: 0.6909061074256897
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6820864379405975
  Validation Loss: 0.6904115080833435
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6684310734272003
  Validation Loss: 0.689858615398407
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6645534783601761
  Validation Loss: 0.6893454790115356
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6778937578201294
  Validation Loss: 0.6888720393180847
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6719750761985779
  Validation Loss: 0.6883784532546997
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6663967221975327
  Validation Loss: 0.6878746151924133
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6696106493473053
  Validation Loss: 0.6873570084571838
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6665865778923035
  Validation Loss: 0.6868298649787903
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6628900766372681
  Validation Loss: 0.6863651275634766
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6620524525642395
  Validation Loss: 0.6859549283981323
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.673132598400116
  Validation Loss: 0.6855398416519165
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6740137040615082
  Validation Loss: 0.685117244720459
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6744059920310974
  Validation Loss: 0.684740424156189
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6643567085266113
  Validation Loss: 0.6843414306640625
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6659704893827438
  Validation Loss: 0.6839564442634583
  Val ROC-AUC: 0.9629629629629629
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:51:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:37:INFO:
[92mINFO [0m:      Received: evaluate message 2900f70c-4a34-4f0f-9ea0-07f22f5dc7e2
02/07/2025 22:51:37:INFO:Received: evaluate message 2900f70c-4a34-4f0f-9ea0-07f22f5dc7e2
[92mINFO [0m:      Sent reply
02/07/2025 22:51:37:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:37:INFO:
[92mINFO [0m:      Received: train message 9b988128-4c02-405a-aee1-d21ed83d0853
02/07/2025 22:51:37:INFO:Received: train message 9b988128-4c02-405a-aee1-d21ed83d0853
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6648264825344086
  Validation Loss: 0.6835728287696838
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6691550761461258
  Validation Loss: 0.6831387281417847
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6607312262058258
  Validation Loss: 0.6826485991477966
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6638479083776474
  Validation Loss: 0.6821269989013672
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6607807725667953
  Validation Loss: 0.6815819144248962
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6617560386657715
  Validation Loss: 0.6810913681983948
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6768836826086044
  Validation Loss: 0.6806483268737793
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6567975431680679
  Validation Loss: 0.68026202917099
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6614540368318558
  Validation Loss: 0.6799227595329285
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6654916703701019
  Validation Loss: 0.6795931458473206
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6591939479112625
  Validation Loss: 0.6792893409729004
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6584208756685257
  Validation Loss: 0.6790162324905396
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6697795987129211
  Validation Loss: 0.6787070035934448
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6620297431945801
  Validation Loss: 0.6784136891365051
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6623243689537048
  Validation Loss: 0.6781618595123291
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6592155396938324
  Validation Loss: 0.6779223680496216
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6571766138076782
  Validation Loss: 0.6776331663131714
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6656402796506882
  Validation Loss: 0.6772999167442322
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.660065084695816
  Validation Loss: 0.6769787669181824
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6602183431386948
  Validation Loss: 0.6766728758811951
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6658771336078644
  Validation Loss: 0.6763704419136047
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6618830859661102
  Validation Loss: 0.6761047840118408
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6614025086164474
  Validation Loss: 0.675892174243927
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6589378863573074
  Validation Loss: 0.675722062587738
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6679856330156326
  Validation Loss: 0.6755080223083496
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6460009217262268
  Validation Loss: 0.6752946972846985
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6542637348175049
  Validation Loss: 0.6749982237815857
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6674316823482513
  Validation Loss: 0.6747870445251465
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6618213951587677
  Validation Loss: 0.6746132969856262
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6671493202447891
  Validation Loss: 0.6744625568389893
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6494350135326385
  Validation Loss: 0.6743336319923401
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.658229410648346
  Validation Loss: 0.6741984486579895
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6548284292221069
  Validation Loss: 0.6739938855171204
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6536135524511337
  Validation Loss: 0.6737754940986633
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6522284299135208
  Validation Loss: 0.6735783219337463
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6630487889051437
  Validation Loss: 0.673389732837677
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6467321664094925
  Validation Loss: 0.6732025146484375
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6574402153491974
  Validation Loss: 0.6730506420135498
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6556386202573776
  Validation Loss: 0.672858715057373
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6465969383716583
  Validation Loss: 0.6726009845733643
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.666221484541893
  Validation Loss: 0.6723453402519226
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6594168543815613
  Validation Loss: 0.6721133589744568
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6479515135288239
  Validation Loss: 0.671875
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6473875790834427
  Validation Loss: 0.6716690063476562
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6578781753778458
  Validation Loss: 0.671467125415802
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.650666356086731
  Validation Loss: 0.6713064908981323
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6542180776596069
  Validation Loss: 0.6710996031761169
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6542180776596069, 'val_roc_auc': 0.95679012345679, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6710996031761169}
 ROC_AUC: 0.9568|| Accuracy 0.9259 || Train Loss: 0.6542
 Val Loss: 0.6711 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7013857173785735
Test ROC-AUC: 0.8782467532467533
Test Accuracy: 0.797752808988764
test_loss: 0.7013857173785735
test_roc_auc: 0.8782467532467533
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.3024636302143336
Epoch 1/64:
  Train Loss: 0.6539914458990097
  Validation Loss: 0.7082644104957581
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6661804020404816
  Validation Loss: 0.7076391577720642
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6611851751804352
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.7071065306663513
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.668084979057312
  Validation Loss: 0.7065935730934143
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6651592552661896
  Validation Loss: 0.7060496211051941
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6603577733039856
  Validation Loss: 0.7055060863494873
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6696276515722275
  Validation Loss: 0.7050025463104248
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6556489318609238
  Validation Loss: 0.7045159339904785
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6542317718267441
  Validation Loss: 0.7040422558784485
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6492036879062653
  Validation Loss: 0.7035518288612366
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6504688858985901
  Validation Loss: 0.703122615814209
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6518657207489014
  Validation Loss: 0.7027491927146912
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6621260046958923
  Validation Loss: 0.7023601531982422
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6601604968309402
  Validation Loss: 0.7019781470298767
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6612126529216766
  Validation Loss: 0.7015851140022278
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6599656492471695
  Validation Loss: 0.7011546492576599
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6518788635730743
  Validation Loss: 0.7007986307144165
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6579672396183014
  Validation Loss: 0.7004730105400085
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6567695736885071
  Validation Loss: 0.7001441121101379
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6539977192878723
  Validation Loss: 0.6998065710067749
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6567736119031906
  Validation Loss: 0.6994138956069946
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.641171470284462
  Validation Loss: 0.6990484595298767
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6506283283233643
  Validation Loss: 0.6987279057502747
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6602652966976166
  Validation Loss: 0.6984034776687622
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6555061638355255
  Validation Loss: 0.6980587840080261
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6505758315324783
  Validation Loss: 0.6977499723434448
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6564958989620209
  Validation Loss: 0.6974675059318542
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6512169539928436
  Validation Loss: 0.6972047090530396
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6514740139245987
  Validation Loss: 0.6969708800315857
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6461286097764969
  Validation Loss: 0.6967335343360901
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6414385586977005
  Validation Loss: 0.696530282497406
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6572428494691849
  Validation Loss: 0.6963180303573608
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6534940153360367
  Validation Loss: 0.6961372494697571
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6438505500555038
  Validation Loss: 0.6959437727928162
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6465210765600204
  Validation Loss: 0.6957275867462158
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6476073265075684
  Validation Loss: 0.6954874396324158
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6569969058036804
  Validation Loss: 0.6952589750289917
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6501877456903458
  Validation Loss: 0.6950516700744629
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6436044871807098
  Validation Loss: 0.6948170065879822
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6548516154289246
  Validation Loss: 0.6945915222167969
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6452752947807312
  Validation Loss: 0.6943577527999878
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6481582969427109
  Validation Loss: 0.6940977573394775
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6369912922382355
  Validation Loss: 0.6938790082931519
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6584272980690002
  Validation Loss: 0.693719208240509
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6502665281295776
  Validation Loss: 0.693559467792511
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6653072535991669
  Validation Loss: 0.6933478116989136
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6525907516479492
  Validation Loss: 0.6931343674659729
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6448523700237274
  Validation Loss: 0.6929071545600891
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6347255855798721
  Validation Loss: 0.6927005648612976
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6578193455934525
  Validation Loss: 0.6924901008605957
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6510616093873978
  Validation Loss: 0.6922973394393921
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6475844979286194
  Validation Loss: 0.6921092867851257
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6528760492801666
  Validation Loss: 0.6919403076171875
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6514838933944702
  Validation Loss: 0.6917780041694641
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6522600203752518
  Validation Loss: 0.6916642189025879
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6493823975324631
  Validation Loss: 0.6915041208267212
  Val ROC-AUC: 0.9802631578947368
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:05:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:06:INFO:
[92mINFO [0m:      Received: evaluate message 35aeba29-41b1-4162-ab55-37ac7cba4004
02/07/2025 22:52:06:INFO:Received: evaluate message 35aeba29-41b1-4162-ab55-37ac7cba4004
[92mINFO [0m:      Sent reply
02/07/2025 22:52:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:08:INFO:
[92mINFO [0m:      Received: train message fb84f1ea-4988-47a8-a11f-c2860c8dacd7
02/07/2025 22:52:08:INFO:Received: train message fb84f1ea-4988-47a8-a11f-c2860c8dacd7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6442647278308868
  Validation Loss: 0.6912975907325745
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6463951617479324
  Validation Loss: 0.6911331415176392
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6412083208560944
  Validation Loss: 0.6909620761871338
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6429765075445175
  Validation Loss: 0.6907563209533691
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6505789309740067
  Validation Loss: 0.6905477643013
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6440114229917526
  Validation Loss: 0.6903526782989502
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6391710489988327
  Validation Loss: 0.6901679039001465
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6424222141504288
  Validation Loss: 0.6900137662887573
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6424222141504288, 'val_roc_auc': 0.9802631578947368, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6900137662887573}
 ROC_AUC: 0.9803|| Accuracy 0.9259 || Train Loss: 0.6424
 Val Loss: 0.6900 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.699354282925638
Test ROC-AUC: 0.8787878787878788
Test Accuracy: 0.8089887640449438
test_loss: 0.699354282925638
test_roc_auc: 0.8787878787878788
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.1535297180635098
Epoch 1/64:
  Train Loss: 0.6731841564178467
  Validation Loss: 0.683057427406311
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6704608350992203
  Validation Loss: 0.6826031804084778
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6714060604572296
  Validation Loss: 0.6822059750556946
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6609611213207245
  Validation Loss: 0.6818010807037354
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6666989773511887
  Validation Loss: 0.681365966796875
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6721446067094803
  Validation Loss: 0.6809329390525818
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.6658835411071777
  Validation Loss: 0.6805180311203003
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.6806394308805466
  Validation Loss: 0.6801016330718994
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.6714250892400742
  Validation Loss: 0.6797168850898743
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6584928035736084
  Validation Loss: 0.6793708801269531
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6522523909807205
  Validation Loss: 0.6790329217910767
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.653940960764885
  Validation Loss: 0.6787355542182922
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.6646425575017929
  Validation Loss: 0.6784335374832153
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.6617441475391388
  Validation Loss: 0.6781504154205322
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6644070446491241
  Validation Loss: 0.6778616309165955
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.6629835963249207
  Validation Loss: 0.6775516271591187
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6539847999811172
  Validation Loss: 0.6772599220275879
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.6550528407096863
  Validation Loss: 0.6769766211509705
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6585231572389603
  Validation Loss: 0.6766952872276306
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6621167063713074
  Validation Loss: 0.6764343976974487
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6595505625009537
  Validation Loss: 0.6761651039123535
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.649520993232727
  Validation Loss: 0.6759021878242493
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.658453643321991
  Validation Loss: 0.6756531000137329
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6529593765735626
  Validation Loss: 0.6754207611083984
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6456725299358368
  Validation Loss: 0.6751129627227783
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6528059542179108
  Validation Loss: 0.6748652458190918
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6568165272474289
  Validation Loss: 0.6746167540550232
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6654770374298096
  Validation Loss: 0.6744266152381897
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6605623364448547
  Validation Loss: 0.6742348074913025
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6501539647579193
  Validation Loss: 0.6740690469741821
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6653235852718353
  Validation Loss: 0.6739032864570618
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6588979363441467
  Validation Loss: 0.6737427711486816
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6442988365888596
  Validation Loss: 0.6735726594924927
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6560065895318985
  Validation Loss: 0.6733890175819397
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6639592051506042
  Validation Loss: 0.6732116937637329
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6597497910261154
  Validation Loss: 0.6729992032051086
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 37/64:
  Train Loss: 0.6422379910945892
  Validation Loss: 0.6728101968765259
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 38/64:
  Train Loss: 0.6389327645301819
  Validation Loss: 0.6726348400115967
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 39/64:
  Train Loss: 0.6647855341434479
  Validation Loss: 0.6724491119384766
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 40/64:
  Train Loss: 0.6617900282144547
  Validation Loss: 0.6722525954246521
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 41/64:
  Train Loss: 0.6424076557159424
  Validation Loss: 0.6720439195632935
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 42/64:
  Train Loss: 0.6422820538282394
  Validation Loss: 0.6718549132347107
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 43/64:
  Train Loss: 0.6587126851081848
  Validation Loss: 0.671690821647644
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 44/64:
  Train Loss: 0.6587214916944504
  Validation Loss: 0.6715736389160156
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 45/64:
  Train Loss: 0.6508728265762329
  Validation Loss: 0.6714664697647095
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 46/64:
  Train Loss: 0.646781861782074
  Validation Loss: 0.6713371872901917
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 47/64:
  Train Loss: 0.6467739194631577
  Validation Loss: 0.6712307929992676
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:35:INFO:
[92mINFO [0m:      Received: evaluate message 41cd9639-1c42-44ac-83a4-e8541bc566c2
02/07/2025 22:52:35:INFO:Received: evaluate message 41cd9639-1c42-44ac-83a4-e8541bc566c2
[92mINFO [0m:      Sent reply
02/07/2025 22:52:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:35:INFO:
[92mINFO [0m:      Received: train message 97ebcc76-d71f-4b6c-a6e6-8ba3dbd5b394
02/07/2025 22:52:35:INFO:Received: train message 97ebcc76-d71f-4b6c-a6e6-8ba3dbd5b394
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 48/64:
  Train Loss: 0.6450283825397491
  Validation Loss: 0.6711472272872925
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 49/64:
  Train Loss: 0.6595292240381241
  Validation Loss: 0.6710450053215027
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 50/64:
  Train Loss: 0.6594906598329544
  Validation Loss: 0.6709516644477844
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 51/64:
  Train Loss: 0.6405522525310516
  Validation Loss: 0.6708300709724426
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 52/64:
  Train Loss: 0.6476466655731201
  Validation Loss: 0.6707170605659485
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 53/64:
  Train Loss: 0.6586966216564178
  Validation Loss: 0.6705814003944397
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 54/64:
  Train Loss: 0.6299595087766647
  Validation Loss: 0.6704254150390625
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 55/64:
  Train Loss: 0.6563742905855179
  Validation Loss: 0.6703190207481384
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 56/64:
  Train Loss: 0.6504160612821579
  Validation Loss: 0.6701812744140625
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 57/64:
  Train Loss: 0.6505810171365738
  Validation Loss: 0.6700662970542908
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 58/64:
  Train Loss: 0.6610387116670609
  Validation Loss: 0.6699755787849426
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 59/64:
  Train Loss: 0.6565981209278107
  Validation Loss: 0.6699026226997375
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 60/64:
  Train Loss: 0.6447493433952332
  Validation Loss: 0.6698300242424011
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 61/64:
  Train Loss: 0.6600606143474579
  Validation Loss: 0.6697372198104858
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 62/64:
  Train Loss: 0.6533569246530533
  Validation Loss: 0.6696652770042419
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 63/64:
  Train Loss: 0.6530106365680695
  Validation Loss: 0.6695959568023682
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 64/64:
  Train Loss: 0.6471177190542221
  Validation Loss: 0.6695212125778198
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
{'train_loss': 0.6471177190542221, 'val_roc_auc': 1.0, 'val_accuracy': 1.0, 'val_loss': 0.6695212125778198}
 ROC_AUC: 1.0000|| Accuracy 1.0000 || Train Loss: 0.6471
 Val Loss: 0.6695 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6976313339860252
Test ROC-AUC: 0.8787878787878788
Test Accuracy: 0.8089887640449438
test_loss: 0.6976313339860252
test_roc_auc: 0.8787878787878788
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.14865678101584004
Epoch 1/64:
  Train Loss: 0.6690168678760529
  Validation Loss: 0.7016222476959229
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.6511162966489792
  Validation Loss: 0.701141357421875
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.6749610155820847
  Validation Loss: 0.7006553411483765
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.6606051474809647
  Validation Loss: 0.7001457214355469
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.6602779179811478
  Validation Loss: 0.699680745601654
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.6556318700313568
  Validation Loss: 0.6992493867874146
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.6649093925952911
  Validation Loss: 0.6987972855567932
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.6567128002643585
  Validation Loss: 0.6983632445335388
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.6651814132928848
  Validation Loss: 0.6979504823684692
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6631043404340744
  Validation Loss: 0.6975191235542297
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.6520763337612152
  Validation Loss: 0.6971088647842407
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.6536641418933868
  Validation Loss: 0.6967008709907532
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.6628858745098114
  Validation Loss: 0.696317195892334
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.6505402028560638
  Validation Loss: 0.6959239840507507
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.6668595522642136
  Validation Loss: 0.6955271363258362
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.650363951921463
  Validation Loss: 0.6951642036437988
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.6526407301425934
  Validation Loss: 0.694799542427063
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.6537382304668427
  Validation Loss: 0.6944511532783508
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.6632217168807983
  Validation Loss: 0.6941198706626892
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.6472653895616531
  Validation Loss: 0.6937887668609619
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.6485357284545898
  Validation Loss: 0.6934635043144226
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.6588686108589172
  Validation Loss: 0.693175196647644
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.643516018986702
  Validation Loss: 0.6928597688674927
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6469900608062744
  Validation Loss: 0.6925512552261353
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.6410682946443558
  Validation Loss: 0.6922541856765747
  Val ROC-AUC: 0.9197530864197532
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6573237180709839
  Validation Loss: 0.691956639289856
  Val ROC-AUC: 0.9197530864197532
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6462373286485672
  Validation Loss: 0.6916618347167969
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6516707837581635
  Validation Loss: 0.691402018070221
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.648761436343193
  Validation Loss: 0.6911593675613403
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6496963053941727
  Validation Loss: 0.6909022927284241
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6569724082946777
  Validation Loss: 0.6906394958496094
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6582909971475601
  Validation Loss: 0.6903846263885498
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6484737694263458
  Validation Loss: 0.6901605725288391
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6410416215658188
  Validation Loss: 0.6899343729019165
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6550407558679581
  Validation Loss: 0.6897175908088684
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6472016721963882
  Validation Loss: 0.6895262002944946
  Val ROC-AUC: 0.9197530864197531
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:01:INFO:
[92mINFO [0m:      Received: evaluate message 86c49b0d-4cc2-47d8-8ff0-81505f5c991c
02/07/2025 22:53:01:INFO:Received: evaluate message 86c49b0d-4cc2-47d8-8ff0-81505f5c991c
[92mINFO [0m:      Sent reply
02/07/2025 22:53:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: train message f8f3b38a-f18e-4cb5-9a6d-9931fb24ae03
02/07/2025 22:53:04:INFO:Received: train message f8f3b38a-f18e-4cb5-9a6d-9931fb24ae03
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6443178355693817
  Validation Loss: 0.6893463134765625
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6498317271471024
  Validation Loss: 0.6891376376152039
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6399739235639572
  Validation Loss: 0.6889286637306213
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.650550052523613
  Validation Loss: 0.6887283325195312
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6533520817756653
  Validation Loss: 0.6885359287261963
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6435460448265076
  Validation Loss: 0.6883498430252075
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6606816947460175
  Validation Loss: 0.6881852149963379
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6552024334669113
  Validation Loss: 0.6880102753639221
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.6357618719339371
  Validation Loss: 0.6878296136856079
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6548328548669815
  Validation Loss: 0.6876298189163208
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.6354879140853882
  Validation Loss: 0.6874530911445618
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.64100481569767
  Validation Loss: 0.6873112320899963
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6414642781019211
  Validation Loss: 0.6871578097343445
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.6485868990421295
  Validation Loss: 0.6870146989822388
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.6500248312950134
  Validation Loss: 0.6868681907653809
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6300044804811478
  Validation Loss: 0.686744213104248
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.6459759920835495
  Validation Loss: 0.6866274476051331
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.6395421326160431
  Validation Loss: 0.6864992380142212
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6418863087892532
  Validation Loss: 0.6863914132118225
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.646088719367981
  Validation Loss: 0.6862740516662598
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.6291583925485611
  Validation Loss: 0.6861682534217834
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.6500720083713531
  Validation Loss: 0.6860554814338684
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6531876772642136
  Validation Loss: 0.6859248280525208
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6416090130805969
  Validation Loss: 0.6858123540878296
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6525356024503708
  Validation Loss: 0.6857014298439026
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.6479827016592026
  Validation Loss: 0.6855968236923218
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.6553177535533905
  Validation Loss: 0.685477077960968
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.6380633264780045
  Validation Loss: 0.6853374242782593
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.6380633264780045, 'val_roc_auc': 0.9074074074074074, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.6853374242782593}
 ROC_AUC: 0.9074|| Accuracy 0.8148 || Train Loss: 0.6381
 Val Loss: 0.6853 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6961033645640599
Test ROC-AUC: 0.880952380952381
Test Accuracy: 0.8089887640449438
test_loss: 0.6961033645640599
test_roc_auc: 0.880952380952381
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.1987473345846714
Epoch 1/64:
  Train Loss: 0.6838269233703613
  Validation Loss: 0.6259469389915466
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6883584707975388
  Validation Loss: 0.6255539655685425
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6732329279184341
  Validation Loss: 0.6251936554908752
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6749957054853439
  Validation Loss: 0.6248138546943665
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6722259074449539
  Validation Loss: 0.6244687438011169
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6639675199985504
  Validation Loss: 0.6241379976272583
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6765743494033813
  Validation Loss: 0.623794436454773
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6671531796455383
  Validation Loss: 0.6234406232833862
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.667706772685051
  Validation Loss: 0.6230921745300293
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6741281300783157
  Validation Loss: 0.622754693031311
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6844636797904968
  Validation Loss: 0.6224184632301331
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6766787767410278
  Validation Loss: 0.6220869421958923
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6660630404949188
  Validation Loss: 0.6217736005783081
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.671381026506424
  Validation Loss: 0.6214702725410461
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6756261587142944
  Validation Loss: 0.6211885809898376
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6778039634227753
  Validation Loss: 0.6209143400192261
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6656275987625122
  Validation Loss: 0.6206509470939636
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6592767089605331
  Validation Loss: 0.6204157471656799
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6807123571634293
  Validation Loss: 0.6201751232147217
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6684813648462296
  Validation Loss: 0.6199307441711426
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6681037396192551
  Validation Loss: 0.6197288036346436
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.673590898513794
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:29:INFO:
[92mINFO [0m:      Received: evaluate message f0a4fd0b-8664-4559-a651-263c0c238ea4
02/07/2025 22:53:29:INFO:Received: evaluate message f0a4fd0b-8664-4559-a651-263c0c238ea4
[92mINFO [0m:      Sent reply
02/07/2025 22:53:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:32:INFO:
[92mINFO [0m:      Received: train message 75b2c766-3512-45bd-b293-d82f40b369f4
02/07/2025 22:53:32:INFO:Received: train message 75b2c766-3512-45bd-b293-d82f40b369f4
  Validation Loss: 0.6195099353790283
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.660932868719101
  Validation Loss: 0.6192724704742432
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6684764325618744
  Validation Loss: 0.619038462638855
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6616876423358917
  Validation Loss: 0.6188315749168396
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6596990823745728
  Validation Loss: 0.6186040043830872
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6772539019584656
  Validation Loss: 0.6184042692184448
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6666007041931152
  Validation Loss: 0.6182293891906738
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6664232462644577
  Validation Loss: 0.6180233359336853
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6687939763069153
  Validation Loss: 0.6178228855133057
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.681485652923584
  Validation Loss: 0.6176342368125916
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6594716161489487
  Validation Loss: 0.6174675226211548
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6562000215053558
  Validation Loss: 0.6172615885734558
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6840074956417084
  Validation Loss: 0.6170920133590698
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6703900694847107
  Validation Loss: 0.6169505715370178
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6731416881084442
  Validation Loss: 0.6168071627616882
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6619718372821808
  Validation Loss: 0.6166735887527466
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6688012480735779
  Validation Loss: 0.6165043711662292
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6590199023485184
  Validation Loss: 0.6163292527198792
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6677605509757996
  Validation Loss: 0.616127073764801
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6711840480566025
  Validation Loss: 0.6159178614616394
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6605382859706879
  Validation Loss: 0.6157500147819519
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6607555001974106
  Validation Loss: 0.6155898571014404
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.67558354139328
  Validation Loss: 0.6154450178146362
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.664388507604599
  Validation Loss: 0.6153260469436646
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6701572239398956
  Validation Loss: 0.6152054667472839
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6674077808856964
  Validation Loss: 0.615068793296814
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.663155198097229
  Validation Loss: 0.6149629950523376
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6635787189006805
  Validation Loss: 0.6148772239685059
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6655910313129425
  Validation Loss: 0.6147729158401489
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6594627946615219
  Validation Loss: 0.6146736145019531
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6771983355283737
  Validation Loss: 0.6145035624504089
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6695235371589661
  Validation Loss: 0.6143860816955566
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6490342020988464
  Validation Loss: 0.6142352223396301
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6587351411581039
  Validation Loss: 0.6141045093536377
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6609100699424744
  Validation Loss: 0.6139788627624512
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6733075082302094
  Validation Loss: 0.6138541102409363
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6608853489160538
  Validation Loss: 0.6137499809265137
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.658540353178978
  Validation Loss: 0.6136288046836853
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6657760441303253
  Validation Loss: 0.6135377287864685
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6621592938899994
  Validation Loss: 0.6134341359138489
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6578995287418365
  Validation Loss: 0.6133683323860168
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6698123663663864
  Validation Loss: 0.6132607460021973
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6712411493062973
  Validation Loss: 0.613139271736145
  Val ROC-AUC: 0.9666666666666668
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6712411493062973, 'val_roc_auc': 0.9666666666666668, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.613139271736145}
 ROC_AUC: 0.9667|| Accuracy 0.9259 || Train Loss: 0.6712
 Val Loss: 0.6131 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6948078582795818
Test ROC-AUC: 0.8798701298701298
Test Accuracy: 0.8089887640449438
test_loss: 0.6948078582795818
test_roc_auc: 0.8798701298701298
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.1592765010864241
Epoch 1/64:
  Train Loss: 0.6776469498872757
  Validation Loss: 0.6288880109786987
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6763830035924911
  Validation Loss: 0.6284125447273254
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6780869215726852
  Validation Loss: 0.627942681312561
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6736379265785217
  Validation Loss: 0.627494752407074
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6759988516569138
  Validation Loss: 0.6270668506622314
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.674618124961853
  Validation Loss: 0.6266616582870483
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6633903235197067
  Validation Loss: 0.6262446641921997
  Val ROC-AUC: 0.9722222222222223/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6749458760023117
  Validation Loss: 0.6258693337440491
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6770858317613602
  Validation Loss: 0.6254753470420837
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6674129962921143
  Validation Loss: 0.6250903606414795
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6674226224422455
  Validation Loss: 0.6247382164001465
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6635189801454544
  Validation Loss: 0.6243702173233032
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6753184199333191
  Validation Loss: 0.6240023970603943
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6645985096693039
  Validation Loss: 0.6236278414726257
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.663345068693161
  Validation Loss: 0.6232691407203674
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6684644520282745
  Validation Loss: 0.6229246854782104
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6728589236736298
  Validation Loss: 0.6225887537002563
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6784318387508392
  Validation Loss: 0.6222519874572754
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6666156947612762
  Validation Loss: 0.6219314932823181
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6737024784088135
  Validation Loss: 0.6216138005256653
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6625836789608002
  Validation Loss: 0.6213012933731079
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6617842465639114
  Validation Loss: 0.6209931373596191
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6682998836040497
  Validation Loss: 0.6206505298614502
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6768795400857925
  Validation Loss: 0.6203408241271973
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6599224209785461
  Validation Loss: 0.6200816035270691
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6644517481327057
  Validation Loss: 0.6198359727859497
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.676679253578186
  Validation Loss: 0.6195701956748962
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6730417460203171
  Validation Loss: 0.6193199753761292
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6499844193458557
  Validation Loss: 0.6190544962882996
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6728717982769012
  Validation Loss: 0.6187959909439087
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6661077290773392
  Validation Loss: 0.6185531616210938
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6624474376440048
  Validation Loss: 0.6183285117149353
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6587488949298859
  Validation Loss: 0.6181261539459229
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6779606640338898
  Validation Loss: 0.6179226040840149
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.657787561416626
  Validation Loss: 0.6177133917808533
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6672892421483994
  Validation Loss: 0.6175217032432556
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6659588813781738
  Validation Loss: 0.6173189282417297
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6707346588373184
  Validation Loss: 0.6171017289161682
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6700957119464874
  Validation Loss: 0.6169167757034302
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6616179347038269
  Validation Loss: 0.6167263984680176
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6696943044662476
  Validation Loss: 0.616562008857727
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6643502712249756
  Validation Loss: 0.6163855791091919
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6668817400932312
  Validation Loss: 0.6162151098251343
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6573817282915115
  Validation Loss: 0.6160668730735779
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6706204414367676
  Validation Loss: 0.6159133911132812
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6659290194511414
  Validation Loss: 0.6157814860343933
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6591445952653885
  Validation Loss: 0.6156425476074219
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6627910137176514
  Validation Loss: 0.615510106086731
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6718599945306778
  Validation Loss: 0.6153889894485474
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6739141941070557
  Validation Loss: 0.6152313351631165
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6721132397651672
  Validation Loss: 0.615067720413208
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6525471061468124
  Validation Loss: 0.6149049997329712
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6535202711820602
  Validation Loss: 0.6147545576095581
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6598693579435349
  Validation Loss: 0.6146251559257507
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6704637706279755
  Validation Loss: 0.6144798994064331
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6714010089635849
  Validation Loss: 0.6142958402633667
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.657353475689888
  Validation Loss: 0.6141226887702942
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6696974486112595
  Validation Loss: 0.6139879822731018
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6617567092180252
  Validation Loss: 0.6138805150985718
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6606821268796921
  Validation Loss: 0.6137496829032898
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6591957062482834
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:59:INFO:
[92mINFO [0m:      Received: evaluate message a5cc669d-7e46-4019-b9e2-1a819444ab2b
02/07/2025 22:53:59:INFO:Received: evaluate message a5cc669d-7e46-4019-b9e2-1a819444ab2b
[92mINFO [0m:      Sent reply
02/07/2025 22:53:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:59:INFO:
[92mINFO [0m:      Received: train message 5babbc1d-1144-4d34-8e73-34faf96c642a
02/07/2025 22:53:59:INFO:Received: train message 5babbc1d-1144-4d34-8e73-34faf96c642a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6136379837989807
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.660864531993866
  Validation Loss: 0.6135011911392212
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6615646332502365
  Validation Loss: 0.6133658289909363
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6652297973632812
  Validation Loss: 0.6132258772850037
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6652297973632812, 'val_roc_auc': 0.9722222222222223, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6132258772850037}
 ROC_AUC: 0.9722|| Accuracy 0.9259 || Train Loss: 0.6652
 Val Loss: 0.6132 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6936653875902797
Test ROC-AUC: 0.8804112554112554
Test Accuracy: 0.8089887640449438
test_loss: 0.6936653875902797
test_roc_auc: 0.8804112554112554
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.1373253584461054
Epoch 1/64:
  Train Loss: 0.6712693870067596
  Validation Loss: 0.6553832292556763
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6683163344860077
  Validation Loss: 0.6547755599021912
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6609028577804565
  Validation Loss: 0.6542102694511414
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6681353747844696
  Validation Loss: 0.653717041015625
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6654681116342545
  Validation Loss: 0.6532338261604309
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6598555594682693
  Validation Loss: 0.652734637260437
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6721289157867432
  Validation Loss: 0.652229905128479
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6613312214612961
  Validation Loss: 0.6517361998558044
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6625220328569412
  Validation Loss: 0.6512920260429382
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6650149822235107
  Validation Loss: 0.6508301496505737
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6692070215940475
  Validation Loss: 0.6504271030426025
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6577975898981094
  Validation Loss: 0.6500454545021057
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6637400984764099
  Validation Loss: 0.6496692299842834
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6680327206850052
  Validation Loss: 0.6492706537246704
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.663517028093338
  Validation Loss: 0.6489243507385254
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6489432007074356
  Validation Loss: 0.6485926508903503
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6578898131847382
  Validation Loss: 0.6482868790626526
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6591162830591202
  Validation Loss: 0.6479706168174744
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6580911725759506
  Validation Loss: 0.6476603150367737
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6705698668956757
  Validation Loss: 0.6473792791366577
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6602931469678879
  Validation Loss: 0.6470579504966736
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6537646502256393
  Validation Loss: 0.6466982960700989
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6507344841957092
  Validation Loss: 0.6463209390640259
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6595906913280487
  Validation Loss: 0.6459895968437195
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6620760858058929
  Validation Loss: 0.6456763744354248
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6741735935211182
  Validation Loss: 0.6453696489334106
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.650265634059906
  Validation Loss: 0.6450430750846863
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.665105938911438
  Validation Loss: 0.6447376608848572
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6523413360118866
  Validation Loss: 0.6444655060768127
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6582383960485458
  Validation Loss: 0.6442089080810547
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6605541408061981
  Validation Loss: 0.6439396142959595
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6519187688827515
  Validation Loss: 0.6436528563499451
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6552071869373322
  Validation Loss: 0.6433913707733154
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6573164612054825
  Validation Loss: 0.6431626081466675
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6651572287082672
  Validation Loss: 0.6429388523101807
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6590724140405655
  Validation Loss: 0.6426948308944702
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6547072976827621
  Validation Loss: 0.6424607038497925
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6554436981678009
  Validation Loss: 0.642235517501831
  Val ROC-AUC: 0.8920454545454546
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6547657698392868
  Validation Loss: 0.6420325040817261
  Val ROC-AUC: 0.8920454545454546
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6512661576271057
  Validation Loss: 0.6418431401252747
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6603813469409943
  Validation Loss: 0.6416681408882141
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6626797616481781
  Validation Loss: 0.6414825320243835
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6571891009807587
  Validation Loss: 0.6412990689277649
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6588215380907059
  Validation Loss: 0.6410666704177856
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6620510220527649
  Validation Loss: 0.6408609747886658
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6661199927330017
  Validation Loss: 0.6406521201133728
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6546752154827118
  Validation Loss: 0.6405030488967896
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:54:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:23:INFO:
[92mINFO [0m:      Received: evaluate message b94909d7-bf76-4e5b-81e1-a7c849eda5ff
02/07/2025 22:54:23:INFO:Received: evaluate message b94909d7-bf76-4e5b-81e1-a7c849eda5ff
[92mINFO [0m:      Sent reply
02/07/2025 22:54:26:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:26:INFO:
[92mINFO [0m:      Received: train message d4f88c8e-a6f3-4b06-9209-4e92090b867c
02/07/2025 22:54:26:INFO:Received: train message d4f88c8e-a6f3-4b06-9209-4e92090b867c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6589456051588058
  Validation Loss: 0.6403639316558838
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6497808247804642
  Validation Loss: 0.6401918530464172
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6565971225500107
  Validation Loss: 0.6400160193443298
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6527544558048248
  Validation Loss: 0.6398162841796875
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6534212082624435
  Validation Loss: 0.6396050453186035
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6493017375469208
  Validation Loss: 0.6394557952880859
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6544313728809357
  Validation Loss: 0.6392970681190491
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6632330268621445
  Validation Loss: 0.6391698122024536
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6471406519412994
  Validation Loss: 0.6390736699104309
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6529936194419861
  Validation Loss: 0.6389972567558289
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6560409516096115
  Validation Loss: 0.6388750672340393
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6636229902505875
  Validation Loss: 0.6388055086135864
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6485194563865662
  Validation Loss: 0.6387283205986023
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6492131948471069
  Validation Loss: 0.6386209726333618
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6510649919509888
  Validation Loss: 0.6385397911071777
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6576288193464279
  Validation Loss: 0.6384537220001221
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6514582931995392
  Validation Loss: 0.6383623480796814
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6514582931995392, 'val_roc_auc': 0.9034090909090909, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6383623480796814}
 ROC_AUC: 0.9034|| Accuracy 0.9259 || Train Loss: 0.6515
 Val Loss: 0.6384 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6926768522584037
Test ROC-AUC: 0.8804112554112554
Test Accuracy: 0.8314606741573034
test_loss: 0.6926768522584037
test_roc_auc: 0.8804112554112554
test_accuracy: 0.8314606741573034
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.12603925108366337
Epoch 1/64:
  Train Loss: 0.6709740161895752
  Validation Loss: 0.6402894258499146
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6695061922073364
  Validation Loss: 0.6398522257804871
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6681950688362122
  Validation Loss: 0.639463484287262
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.663039043545723
  Validation Loss: 0.6390705704689026
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6747611314058304
  Validation Loss: 0.6387004256248474
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6551316231489182
  Validation Loss: 0.6383282542228699
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6697812676429749
  Validation Loss: 0.6379629373550415
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6731811910867691
  Validation Loss: 0.6375832557678223
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.6654805988073349
  Validation Loss: 0.6372280716896057
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6594653874635696
  Validation Loss: 0.636901319026947
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6641873866319656
  Validation Loss: 0.6365441083908081
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6693689823150635
  Validation Loss: 0.6362155079841614
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.667077362537384
  Validation Loss: 0.6358808875083923
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.676479384303093
  Validation Loss: 0.635562539100647
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6645257622003555
  Validation Loss: 0.6352273225784302
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.6559825241565704
  Validation Loss: 0.6348831057548523
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6553442925214767
  Validation Loss: 0.6345458030700684
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6618865877389908
  Validation Loss: 0.6342369914054871
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6585486084222794
  Validation Loss: 0.6339775323867798
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.6687600910663605
  Validation Loss: 0.6336966753005981
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6768745183944702
  Validation Loss: 0.6334030628204346
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6546515226364136
  Validation Loss: 0.6331225037574768
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.6615025848150253
  Validation Loss: 0.6328457593917847
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.6673655807971954
  Validation Loss: 0.6325755715370178
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.6581326723098755
  Validation Loss: 0.6323140263557434
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6714834272861481
  Validation Loss: 0.6320469975471497
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.6649049669504166
  Validation Loss: 0.6318044066429138
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6563094109296799
  Validation Loss: 0.6315786838531494
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6577576249837875
  Validation Loss: 0.6313338279724121
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.6613483875989914
  Validation Loss: 0.6310781836509705
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6549296230077744
  Validation Loss: 0.6308234333992004
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6562438011169434
  Validation Loss: 0.6306071281433105
  Val ROC-AUC: 0.9659090909090909
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:54:50:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:50:INFO:
[92mINFO [0m:      Received: evaluate message 829d7132-2655-4162-b068-7d59608ac226
02/07/2025 22:54:50:INFO:Received: evaluate message 829d7132-2655-4162-b068-7d59608ac226
[92mINFO [0m:      Sent reply
02/07/2025 22:54:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:53:INFO:
[92mINFO [0m:      Received: train message 75c0d6ea-548d-44c5-8d12-5ddd48f42a6d
02/07/2025 22:54:53:INFO:Received: train message 75c0d6ea-548d-44c5-8d12-5ddd48f42a6d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6660303920507431
  Validation Loss: 0.6303969621658325
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6573340743780136
  Validation Loss: 0.6302122473716736
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6677436977624893
  Validation Loss: 0.6300177574157715
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6602213978767395
  Validation Loss: 0.6298311352729797
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6619568020105362
  Validation Loss: 0.6296524405479431
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6634046584367752
  Validation Loss: 0.6294586658477783
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6644138246774673
  Validation Loss: 0.6292704939842224
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.66697096824646
  Validation Loss: 0.6291123628616333
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.661854088306427
  Validation Loss: 0.6289466619491577
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6671143472194672
  Validation Loss: 0.6287798285484314
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6538780182600021
  Validation Loss: 0.6286284923553467
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6604883819818497
  Validation Loss: 0.6284801363945007
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.664665699005127
  Validation Loss: 0.628328263759613
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6538120061159134
  Validation Loss: 0.6281839609146118
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6525259464979172
  Validation Loss: 0.6280263066291809
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6570077836513519
  Validation Loss: 0.6278867125511169
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.653175488114357
  Validation Loss: 0.6277347803115845
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.664620578289032
  Validation Loss: 0.6275862455368042
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6674883514642715
  Validation Loss: 0.6274261474609375
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6584994494915009
  Validation Loss: 0.6272848844528198
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6550646871328354
  Validation Loss: 0.627160370349884
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6712411195039749
  Validation Loss: 0.6270277500152588
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6684534549713135
  Validation Loss: 0.6269347667694092
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.659539058804512
  Validation Loss: 0.6268293857574463
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.651908278465271
  Validation Loss: 0.6267341375350952
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6539078056812286
  Validation Loss: 0.6266049742698669
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6583023816347122
  Validation Loss: 0.6265052556991577
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6571455746889114
  Validation Loss: 0.6263951659202576
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6533688902854919
  Validation Loss: 0.6262907981872559
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6560184508562088
  Validation Loss: 0.626189649105072
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6523784250020981
  Validation Loss: 0.6261094212532043
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6447086334228516
  Validation Loss: 0.6260103583335876
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6447086334228516, 'val_roc_auc': 0.9772727272727273, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6260103583335876}
 ROC_AUC: 0.9773|| Accuracy 0.8889 || Train Loss: 0.6447
 Val Loss: 0.6260 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6918485399042622
Test ROC-AUC: 0.8814935064935064
Test Accuracy: 0.8426966292134831
test_loss: 0.6918485399042622
test_roc_auc: 0.8814935064935064
test_accuracy: 0.8426966292134831
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.051049599438556456
Epoch 1/64:
  Train Loss: 0.6607067883014679
  Validation Loss: 0.7068188786506653
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.662428542971611
  Validation Loss: 0.7063986659049988
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.665665939450264
  Validation Loss: 0.7059898376464844
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6736452132463455
  Validation Loss: 0.7055912613868713
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.654281497001648
  Validation Loss: 0.7052407264709473
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6599913835525513
  Validation Loss: 0.7049217224121094
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6500918120145798
  Validation Loss: 0.7045685052871704
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6477997601032257
  Validation Loss: 0.7042773365974426
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6439483463764191
  Validation Loss: 0.7040004134178162
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6510631144046783
  Validation Loss: 0.7037261128425598
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6447313278913498
  Validation Loss: 0.7034677863121033
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6533079594373703
  Validation Loss: 0.7031948566436768
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6509483903646469
  Validation Loss: 0.7029514312744141
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6522847563028336
  Validation Loss: 0.7026965022087097
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6394742280244827
  Validation Loss: 0.7024136185646057
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6516816318035126
  Validation Loss: 0.7021549344062805
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6559761762619019
  Validation Loss: 0.7019273042678833
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6292950510978699
  Validation Loss: 0.701668381690979
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6526435166597366
  Validation Loss: 0.7014492154121399
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:55:16:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:18:INFO:
[92mINFO [0m:      Received: evaluate message a316f29e-8ce4-46fa-938c-22362aea569d
02/07/2025 22:55:18:INFO:Received: evaluate message a316f29e-8ce4-46fa-938c-22362aea569d
[92mINFO [0m:      Sent reply
02/07/2025 22:55:20:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:20:INFO:
[92mINFO [0m:      Received: train message f352e527-a077-425f-bb7d-ae8b8c29c71f
02/07/2025 22:55:20:INFO:Received: train message f352e527-a077-425f-bb7d-ae8b8c29c71f
  Train Loss: 0.644986018538475
  Validation Loss: 0.7012329697608948
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6397436410188675
  Validation Loss: 0.7010087370872498
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6614279001951218
  Validation Loss: 0.7007800936698914
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6360399574041367
  Validation Loss: 0.7005466222763062
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6451573371887207
  Validation Loss: 0.7003207802772522
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6415599286556244
  Validation Loss: 0.7001567482948303
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6514619588851929
  Validation Loss: 0.6999947428703308
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6503141224384308
  Validation Loss: 0.6998199224472046
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6516110599040985
  Validation Loss: 0.6996521949768066
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6540322005748749
  Validation Loss: 0.6994765996932983
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6453159153461456
  Validation Loss: 0.699292778968811
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6416770219802856
  Validation Loss: 0.6991260647773743
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.641602024435997
  Validation Loss: 0.6989502906799316
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6410591453313828
  Validation Loss: 0.6987571120262146
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6405700594186783
  Validation Loss: 0.6985945701599121
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6387997269630432
  Validation Loss: 0.6984337568283081
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6484834104776382
  Validation Loss: 0.6982876658439636
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6352730095386505
  Validation Loss: 0.6981493234634399
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6593481451272964
  Validation Loss: 0.6980387568473816
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6421768516302109
  Validation Loss: 0.6979045271873474
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6457964181900024
  Validation Loss: 0.6977748274803162
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6512232273817062
  Validation Loss: 0.697651743888855
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6399803459644318
  Validation Loss: 0.6975110173225403
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6419728696346283
  Validation Loss: 0.6973881125450134
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6440018713474274
  Validation Loss: 0.6972885131835938
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6456989198923111
  Validation Loss: 0.6971736550331116
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6414760947227478
  Validation Loss: 0.6970633268356323
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6428592056035995
  Validation Loss: 0.6969469785690308
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6357707977294922
  Validation Loss: 0.6968488097190857
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6445303112268448
  Validation Loss: 0.6967471837997437
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6467407941818237
  Validation Loss: 0.6966474652290344
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.629805251955986
  Validation Loss: 0.6965417265892029
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6330971717834473
  Validation Loss: 0.6964839100837708
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6445212066173553
  Validation Loss: 0.6964194774627686
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6453892439603806
  Validation Loss: 0.6963366270065308
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6413994580507278
  Validation Loss: 0.6962653994560242
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6348299384117126
  Validation Loss: 0.6961873173713684
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.653169110417366
  Validation Loss: 0.6961328983306885
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.631796270608902
  Validation Loss: 0.6960711479187012
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6504868417978287
  Validation Loss: 0.6960147023200989
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6342041343450546
  Validation Loss: 0.6959762573242188
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6309092342853546
  Validation Loss: 0.6958891749382019
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6397723704576492
  Validation Loss: 0.6958047151565552
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6463369131088257
  Validation Loss: 0.6957531571388245
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6430565565824509
  Validation Loss: 0.6957176327705383
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6430565565824509, 'val_roc_auc': 0.9928571428571428, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6957176327705383}
 ROC_AUC: 0.9929|| Accuracy 0.9259 || Train Loss: 0.6431
 Val Loss: 0.6957 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6911940189559808
Test ROC-AUC: 0.8787878787878788
Test Accuracy: 0.8202247191011236
test_loss: 0.6911940189559808
test_roc_auc: 0.8787878787878788
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.0408383698183267
Epoch 1/64:
  Train Loss: 0.6826261729001999
  Validation Loss: 0.6015040278434753
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6775634288787842
  Validation Loss: 0.6012121438980103
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6892089992761612
  Validation Loss: 0.6009326577186584
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.674157977104187
  Validation Loss: 0.6006579995155334
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6868163198232651
  Validation Loss: 0.6004047393798828
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6668315529823303
  Validation Loss: 0.6001604199409485
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6638481914997101
  Validation Loss: 0.5999083518981934
  Val ROC-AUC: 0.9945054945054945
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6816737204790115
  Validation Loss: 0.599677324295044
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6676001697778702
  Validation Loss: 0.5994396805763245
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6686146408319473
  Validation Loss: 0.5992233157157898
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6839011609554291
  Validation Loss: 0.5989733934402466
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6677928566932678
  Validation Loss: 0.5987478494644165
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6805595755577087
  Validation Loss: 0.5985249876976013
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6683612018823624
  Validation Loss: 0.5983147621154785
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6806245148181915
  Validation Loss: 0.5981127619743347
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.6544435322284698
  Validation Loss: 0.5979219675064087
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6782528012990952
  Validation Loss: 0.5977339744567871
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.6693823039531708
  Validation Loss: 0.5975634455680847
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.677052766084671
  Validation Loss: 0.597415030002594
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6676133722066879
  Validation Loss: 0.597255289554596
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6746595650911331
  Validation Loss: 0.5971077680587769
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.672767847776413
  Validation Loss: 0.5969654321670532
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6708533316850662
  Validation Loss: 0.5967951416969299
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6832057535648346
  Validation Loss: 0.5966389179229736
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6692671477794647
  Validation Loss: 0.5965011715888977
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6667950302362442
  Validation Loss: 0.596383273601532
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6816417276859283
  Validation Loss: 0.5962702631950378
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6612094342708588
  Validation Loss: 0.5961670279502869
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.680725947022438
  Validation Loss: 0.5960665345191956
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6681169718503952
  Validation Loss: 0.5959537625312805
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6681599318981171
  Validation Loss: 0.5958430767059326
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6657938659191132
  Validation Loss: 0.5957342386245728
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6640028804540634
  Validation Loss: 0.5956301689147949
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6824967712163925
  Validation Loss: 0.5955030918121338
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6641721278429031
  Validation Loss: 0.5954055786132812
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6765116304159164
  Validation Loss: 0.5953112840652466
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6679717898368835
  Validation Loss: 0.5952030420303345
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6675418168306351
  Validation Loss: 0.5951316952705383
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6704988926649094
  Validation Loss: 0.5950474143028259
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6706994473934174
  Validation Loss: 0.5949826240539551
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6667851656675339
  Validation Loss: 0.5948967933654785
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6586301624774933
  Validation Loss: 0.5948325395584106
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6629282683134079
  Validation Loss: 0.5947582125663757
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6693914234638214
  Validation Loss: 0.5946739315986633
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6566606014966965
  Validation Loss: 0.5946109890937805
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6686527281999588
  Validation Loss: 0.5945543646812439
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.66416434943676
  Validation Loss: 0.5944834351539612
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6561104506254196
  Validation Loss: 0.5944347977638245
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6439814120531082
  Validation Loss: 0.594383955001831
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.667127713561058
  Validation Loss: 0.5943262577056885
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6754046678543091
  Validation Loss: 0.5942803621292114
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.67115518450737
  Validation Loss: 0.5942448377609253
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6765204668045044
  Validation Loss: 0.5941990613937378
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6613982617855072
  Validation Loss: 0.5941553711891174
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6624912917613983
  Validation Loss: 0.5940983891487122
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6739879697561264
  Validation Loss: 0.5940645337104797
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6611523926258087
  Validation Loss: 0.5940151810646057
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6479522883892059
  Validation Loss: 0.5939673781394958
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.655099093914032
  Validation Loss: 0.5939399600028992
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6687924414873123
  Validation Loss: 0.5939164161682129
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6607395708560944
  Validation Loss: 0.5938819646835327
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6604992598295212
  Validation Loss: 0.5938419699668884
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 63/64:
  Train Loss: 0.665531188249588
  Validation Loss: 0.5938214659690857
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 64/64:
  Train Loss: 0.6624121069908142
  Validation Loss: 0.5937836170196533
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:55:42:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:45:INFO:
[92mINFO [0m:      Received: evaluate message 4f127f89-2009-42dc-9c32-8a2b7c8e61e6
02/07/2025 22:55:45:INFO:Received: evaluate message 4f127f89-2009-42dc-9c32-8a2b7c8e61e6
[92mINFO [0m:      Sent reply
02/07/2025 22:55:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:47:INFO:
[92mINFO [0m:      Received: train message 23ff87f1-fe4c-4d96-8e5f-006759235f4f
02/07/2025 22:55:47:INFO:Received: train message 23ff87f1-fe4c-4d96-8e5f-006759235f4f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
{'train_loss': 0.6624121069908142, 'val_roc_auc': 1.0, 'val_accuracy': 1.0, 'val_loss': 0.5937836170196533}
 ROC_AUC: 1.0000|| Accuracy 1.0000 || Train Loss: 0.6624
 Val Loss: 0.5938 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6907256871796725
Test ROC-AUC: 0.8793290043290044
Test Accuracy: 0.8089887640449438
test_loss: 0.6907256871796725
test_roc_auc: 0.8793290043290044
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.029877267069726553
Epoch 1/64:
  Train Loss: 0.6544127017259598
  Validation Loss: 0.6864973902702332
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.663247674703598
  Validation Loss: 0.6862080693244934
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6469995826482773
  Validation Loss: 0.6859433054924011
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6558970510959625
  Validation Loss: 0.6857311129570007
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6571163982152939
  Validation Loss: 0.6855111122131348
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6544243097305298
  Validation Loss: 0.6852996349334717
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6466338485479355
  Validation Loss: 0.6851030588150024
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6536902636289597
  Validation Loss: 0.6849158406257629
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6501878947019577
  Validation Loss: 0.6847279071807861
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6499654650688171
  Validation Loss: 0.6845454573631287
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6525719463825226
  Validation Loss: 0.6843858957290649
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6516891419887543
  Validation Loss: 0.6842318177223206
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6563524305820465
  Validation Loss: 0.6840935945510864
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6613149046897888
  Validation Loss: 0.6839482188224792
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6559938043355942
  Validation Loss: 0.6838134527206421
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6432258784770966
  Validation Loss: 0.6836651563644409
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6465499103069305
  Validation Loss: 0.6835501194000244
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6461320072412491
  Validation Loss: 0.683443546295166
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.651450976729393
  Validation Loss: 0.6833454966545105
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.65434330701828
  Validation Loss: 0.6832695603370667
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6599995344877243
  Validation Loss: 0.6831775307655334
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6317136585712433
  Validation Loss: 0.6830654740333557
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6514132171869278
  Validation Loss: 0.6830020546913147
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.637914627790451
  Validation Loss: 0.6829273104667664
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6575049310922623
  Validation Loss: 0.68285071849823
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6501488089561462
  Validation Loss: 0.6827754378318787
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6542313396930695
  Validation Loss: 0.6827228665351868
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6443724483251572
  Validation Loss: 0.6826667785644531
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6554931849241257
  Validation Loss: 0.6826238036155701
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6427807211875916
  Validation Loss: 0.6825793981552124
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6506166011095047
  Validation Loss: 0.6825363636016846
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6460722237825394
  Validation Loss: 0.6825011372566223
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6477212011814117
  Validation Loss: 0.6824467778205872
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6481812000274658
  Validation Loss: 0.6824179887771606
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6463630795478821
  Validation Loss: 0.6823890805244446
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6424338221549988
  Validation Loss: 0.6823691725730896
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.640385165810585
  Validation Loss: 0.682335615158081
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6489148288965225
  Validation Loss: 0.6823261380195618
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6477861255407333
  Validation Loss: 0.6823334693908691
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6465800553560257
  Validation Loss: 0.682316243648529
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6542187482118607
  Validation Loss: 0.6823118925094604
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6361148506402969
  Validation Loss: 0.6822998523712158
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.642009049654007
  Validation Loss: 0.6823005676269531
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6293599903583527
  Validation Loss: 0.6822782754898071
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6347037702798843
  Validation Loss: 0.6822854280471802
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6384777724742889
  Validation Loss: 0.682294487953186
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6456422507762909
  Validation Loss: 0.682311475276947
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.6524576842784882
  Validation Loss: 0.6823195219039917
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.643173098564148
  Validation Loss: 0.6823151707649231
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.636250227689743
  Validation Loss: 0.6823228001594543
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:56:11:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:12:INFO:
[92mINFO [0m:      Received: evaluate message 31ad2ef5-de99-4ba6-a0d8-84ea59c36057
02/07/2025 22:56:12:INFO:Received: evaluate message 31ad2ef5-de99-4ba6-a0d8-84ea59c36057
[92mINFO [0m:      Sent reply
02/07/2025 22:56:15:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:15:INFO:
[92mINFO [0m:      Received: train message bd89c930-850a-4cb3-bdbf-902ef0cc0970
02/07/2025 22:56:15:INFO:Received: train message bd89c930-850a-4cb3-bdbf-902ef0cc0970
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6428318917751312
  Validation Loss: 0.6823269128799438
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.6445774435997009
  Validation Loss: 0.6823450922966003
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.6447899490594864
  Validation Loss: 0.6823462247848511
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6428415775299072
  Validation Loss: 0.6823685765266418
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.6454679518938065
  Validation Loss: 0.6823878884315491
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6520038694143295
  Validation Loss: 0.6824070811271667
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6411218345165253
  Validation Loss: 0.6824263334274292
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6494522541761398
  Validation Loss: 0.6824439764022827
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.637354701757431
  Validation Loss: 0.6824778914451599
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6491727381944656
  Validation Loss: 0.6824941039085388
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6471696197986603
  Validation Loss: 0.6825254559516907
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.643857017159462
  Validation Loss: 0.6825427412986755
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6459223628044128
  Validation Loss: 0.6825703978538513
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6449959576129913
  Validation Loss: 0.6825965046882629
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6449959576129913, 'val_roc_auc': 0.9802631578947367, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6825965046882629}
 ROC_AUC: 0.9803|| Accuracy 0.8889 || Train Loss: 0.6450
 Val Loss: 0.6826 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6903684986441323
Test ROC-AUC: 0.8771645021645021
Test Accuracy: 0.8089887640449438
test_loss: 0.6903684986441323
test_roc_auc: 0.8771645021645021
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.8062744140625
Dynamic noise multiplier: 0.0
Epoch 1/64:
  Train Loss: 0.6661694943904877
  Validation Loss: 0.6921977400779724
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.6533906012773514
  Validation Loss: 0.6919057965278625
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.661314383149147
  Validation Loss: 0.6916297078132629
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.6614320576190948
  Validation Loss: 0.6913312077522278
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.6683188378810883
  Validation Loss: 0.6910365223884583
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.6386011391878128
  Validation Loss: 0.6907473802566528
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.6459411829710007
  Validation Loss: 0.6904643774032593
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.6562624573707581
  Validation Loss: 0.6902269721031189
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.6558274328708649
  Validation Loss: 0.6899653673171997
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6566409766674042
  Validation Loss: 0.6897317171096802
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.6543470025062561
  Validation Loss: 0.6894779205322266
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.645687609910965
  Validation Loss: 0.6892368197441101
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.6546619534492493
  Validation Loss: 0.6890203952789307
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.6422409266233444
  Validation Loss: 0.6888047456741333
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.6562213003635406
  Validation Loss: 0.6885970234870911
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.6525303721427917
  Validation Loss: 0.6883636713027954
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.6468767374753952
  Validation Loss: 0.6881533861160278
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.6438416540622711
  Validation Loss: 0.687944233417511
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.6502937376499176
  Validation Loss: 0.6877521276473999
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.6475932002067566
  Validation Loss: 0.687554121017456
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.6481380611658096
  Validation Loss: 0.6873588562011719
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.633374810218811
  Validation Loss: 0.6871790289878845
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.6430560946464539
  Validation Loss: 0.687008261680603
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6469432562589645
  Validation Loss: 0.6868401765823364
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.6460952013731003
  Validation Loss: 0.6866673231124878
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6441960334777832
  Validation Loss: 0.6865111589431763
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6490383148193359
  Validation Loss: 0.686366617679596
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6410200595855713
  Validation Loss: 0.6862204074859619
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6527311205863953
  Validation Loss: 0.6860867142677307
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.650755912065506
  Validation Loss: 0.6859564185142517
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6398645490407944
  Validation Loss: 0.6858145594596863
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6533092856407166
  Validation Loss: 0.6856788396835327
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6483079940080643
  Validation Loss: 0.6855398416519165
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.635857030749321
  Validation Loss: 0.6854063272476196
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6430083066225052
  Validation Loss: 0.685291588306427
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:56:37:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:40:INFO:
[92mINFO [0m:      Received: evaluate message 9a068fae-6dfe-4824-8148-76470bc6469c
02/07/2025 22:56:40:INFO:Received: evaluate message 9a068fae-6dfe-4824-8148-76470bc6469c
[92mINFO [0m:      Sent reply
02/07/2025 22:56:41:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:42:INFO:
[92mINFO [0m:      Received: reconnect message 9f2ae3bb-b525-44ae-8669-5fa842730518
02/07/2025 22:56:42:INFO:Received: reconnect message 9f2ae3bb-b525-44ae-8669-5fa842730518
02/07/2025 22:56:42:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/07/2025 22:56:42:INFO:Disconnect and shut down
  Train Loss: 0.6445640474557877
  Validation Loss: 0.6851800084114075
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6346748918294907
  Validation Loss: 0.6850472092628479
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6437062174081802
  Validation Loss: 0.68494713306427
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6391123533248901
  Validation Loss: 0.6848437190055847
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6417325288057327
  Validation Loss: 0.6847463846206665
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6465651392936707
  Validation Loss: 0.6846489906311035
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6412651836872101
  Validation Loss: 0.684547483921051
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6420177519321442
  Validation Loss: 0.6844667792320251
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6548096388578415
  Validation Loss: 0.6843867301940918
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.6515168398618698
  Validation Loss: 0.6842905879020691
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6380123198032379
  Validation Loss: 0.6841995716094971
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.6327082067728043
  Validation Loss: 0.6841174364089966
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.6499875634908676
  Validation Loss: 0.6840429902076721
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6409808546304703
  Validation Loss: 0.6839739680290222
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.6409292668104172
  Validation Loss: 0.6839145421981812
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.6284449100494385
  Validation Loss: 0.6838507056236267
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6387400776147842
  Validation Loss: 0.6837841868400574
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.645872175693512
  Validation Loss: 0.683709442615509
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.6500505059957504
  Validation Loss: 0.6836537718772888
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6327912658452988
  Validation Loss: 0.6835776567459106
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6435079276561737
  Validation Loss: 0.6835121512413025
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.6370112746953964
  Validation Loss: 0.6834505200386047
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.6331717371940613
  Validation Loss: 0.6834040284156799
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6345881223678589
  Validation Loss: 0.6833311319351196
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6415932029485703
  Validation Loss: 0.683283269405365
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6379772126674652
  Validation Loss: 0.6832410097122192
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.6322719752788544
  Validation Loss: 0.6831998229026794
  Val ROC-AUC: 0.8641975308641975
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.639822319149971
  Validation Loss: 0.6831566691398621
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.646746426820755
  Validation Loss: 0.6831240057945251
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.646746426820755, 'val_roc_auc': 0.8703703703703703, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.6831240057945251}
 ROC_AUC: 0.8704|| Accuracy 0.8148 || Train Loss: 0.6467
 Val Loss: 0.6831 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.69010518240125
Test ROC-AUC: 0.8755411255411255
Test Accuracy: 0.8089887640449438
test_loss: 0.69010518240125
test_roc_auc: 0.8755411255411255
test_accuracy: 0.8089887640449438
eval_cid: 1
CPU Time: 916.180377 seconds
Elapsed Time: 862.9060189723969 seconds
RAM Usage: 0.3854331970214844 megabytes
Logs saved in current directory
