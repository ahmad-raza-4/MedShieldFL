nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:44:55:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:44:55:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 22:44:55:DEBUG:ChannelConnectivity.IDLE
02/07/2025 22:44:55:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738997095.952698 1773001 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/07/2025 22:44:59:INFO:
[92mINFO [0m:      Received: train message 28a36efd-56b4-48b9-b6ae-af78b2cf31ac
02/07/2025 22:44:59:INFO:Received: train message 28a36efd-56b4-48b9-b6ae-af78b2cf31ac
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours/30.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours']
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.12603650725850457
Epoch 1/64:
  Train Loss: 0.7611480057239532
  Validation Loss: 0.7939112782478333
  Val ROC-AUC: 0.5617283950617284
  Val Accuracy: 0.5185185074806213
Epoch 2/64:
  Train Loss: 0.7590620815753937
  Validation Loss: 0.7926821708679199
  Val ROC-AUC: 0.5679012345679013
  Val Accuracy: 0.5185185074806213
Epoch 3/64:
  Train Loss: 0.764098659157753
  Validation Loss: 0.7914349436759949
  Val ROC-AUC: 0.5740740740740741
  Val Accuracy: 0.5185185074806213
Epoch 4/64:
  Train Loss: 0.7702983468770981
  Validation Loss: 0.7902129888534546
  Val ROC-AUC: 0.5802469135802468
  Val Accuracy: 0.5185185074806213
Epoch 5/64:
  Train Loss: 0.7598583549261093
  Validation Loss: 0.7889729738235474
  Val ROC-AUC: 0.5987654320987654
  Val Accuracy: 0.5555555820465088
Epoch 6/64:
  Train Loss: 0.7620630115270615
  Validation Loss: 0.7877536416053772
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.5555555820465088
Epoch 7/64:
  Train Loss: 0.7596922218799591
  Validation Loss: 0.7865039706230164
  Val ROC-AUC: 0.6172839506172839
  Val Accuracy: 0.5925925970077515
Epoch 8/64:
  Train Loss: 0.760659784078598
  Validation Loss: 0.7853123545646667
  Val ROC-AUC: 0.6234567901234568
  Val Accuracy: 0.5925925970077515
Epoch 9/64:
  Train Loss: 0.7472141534090042
  Validation Loss: 0.784081757068634
  Val ROC-AUC: 0.6296296296296297
  Val Accuracy: 0.5925925970077515
Epoch 10/64:
  Train Loss: 0.7474689930677414
  Validation Loss: 0.7828555703163147
  Val ROC-AUC: 0.6358024691358024
  Val Accuracy: 0.5925925970077515
Epoch 11/64:
  Train Loss: 0.7497508823871613
  Validation Loss: 0.7816450595855713
  Val ROC-AUC: 0.6481481481481481
  Val Accuracy: 0.5925925970077515
Epoch 12/64:
  Train Loss: 0.7628934383392334
  Validation Loss: 0.7804438471794128
  Val ROC-AUC: 0.654320987654321
  Val Accuracy: 0.5925925970077515
Epoch 13/64:
  Train Loss: 0.7486122697591782
  Validation Loss: 0.7792559862136841
  Val ROC-AUC: 0.6851851851851851
  Val Accuracy: 0.5925925970077515
Epoch 14/64:
  Train Loss: 0.7435182332992554
  Validation Loss: 0.7780531644821167
  Val ROC-AUC: 0.6851851851851851
  Val Accuracy: 0.6296296119689941
Epoch 15/64:
  Train Loss: 0.742502361536026
  Validation Loss: 0.7769021987915039
  Val ROC-AUC: 0.691358024691358
  Val Accuracy: 0.6296296119689941
Epoch 16/64:
  Train Loss: 0.7437002956867218
  Validation Loss: 0.7757828235626221
  Val ROC-AUC: 0.6975308641975309
  Val Accuracy: 0.6296296119689941
Epoch 17/64:
  Train Loss: 0.7426781505346298
  Validation Loss: 0.7746796607971191
  Val ROC-AUC: 0.7037037037037037
  Val Accuracy: 0.6296296119689941
Epoch 18/64:
  Train Loss: 0.7335821837186813
  Validation Loss: 0.7735641002655029
  Val ROC-AUC: 0.7160493827160495
  Val Accuracy: 0.6296296119689941
Epoch 19/64:
  Train Loss: 0.739931732416153
  Validation Loss: 0.772459089756012
  Val ROC-AUC: 0.7222222222222222
  Val Accuracy: 0.6296296119689941
Epoch 20/64:
  Train Loss: 0.7253018021583557
  Validation Loss: 0.7714206576347351
  Val ROC-AUC: 0.7222222222222223
  Val Accuracy: 0.6296296119689941
Epoch 21/64:
  Train Loss: 0.7339726537466049
  Validation Loss: 0.7703857421875
  Val ROC-AUC: 0.7283950617283951
  Val Accuracy: 0.6296296119689941
Epoch 22/64:
  Train Loss: 0.7250351458787918
  Validation Loss: 0.7693518996238708
  Val ROC-AUC: 0.7345679012345678
  Val Accuracy: 0.6296296119689941
Epoch 23/64:
  Train Loss: 0.7320300787687302
  Validation Loss: 0.7683239579200745
  Val ROC-AUC: 0.7407407407407408
  Val Accuracy: 0.6666666865348816
Epoch 24/64:
  Train Loss: 0.7295189201831818
  Validation Loss: 0.7673298716545105
  Val ROC-AUC: 0.7407407407407408
  Val Accuracy: 0.6666666865348816
Epoch 25/64:
  Train Loss: 0.7162128537893295
  Validation Loss: 0.7663471102714539
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.6666666865348816
Epoch 26/64:
  Train Loss: 0.7150728851556778
  Validation Loss: 0.765340268611908
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.6666666865348816
Epoch 27/64:
  Train Loss: 0.717025876045227
  Validation Loss: 0.7643467783927917
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.7037037014961243
Epoch 28/64:
  Train Loss: 0.7187124341726303
  Validation Loss: 0.7633686661720276
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.7037037014961243
Epoch 29/64:
  Train Loss: 0.7187734097242355
  Validation Loss: 0.7624452710151672
  Val ROC-AUC: 0.7469135802469136
  Val Accuracy: 0.7037037014961243
Epoch 30/64:
  Train Loss: 0.7259832173585892
  Validation Loss: 0.7615394592285156
  Val ROC-AUC: 0.7469135802469136
  Val Accuracy: 0.7037037014961243
Epoch 31/64:
  Train Loss: 0.7127563953399658
  Validation Loss: 0.7606257200241089
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.7037037014961243
Epoch 32/64:
  Train Loss: 0.7249380946159363
  Validation Loss: 0.7597357034683228
  Val ROC-AUC: 0.7654320987654321
  Val Accuracy: 0.7037037014961243
Epoch 33/64:
  Train Loss: 0.7229992151260376
  Validation Loss: 0.7588591575622559
  Val ROC-AUC: 0.7716049382716049
  Val Accuracy: 0.7037037014961243
Epoch 34/64:
  Train Loss: 0.7108537554740906
  Validation Loss: 0.7579782605171204
  Val ROC-AUC: 0.7839506172839505
  Val Accuracy: 0.7037037014961243
Epoch 35/64:
  Train Loss: 0.7170127630233765
  Validation Loss: 0.7571073770523071
  Val ROC-AUC: 0.7839506172839505
  Val Accuracy: 0.7037037014961243
Epoch 36/64:
  Train Loss: 0.7192710041999817
  Validation Loss: 0.7562099099159241
  Val ROC-AUC: 0.7962962962962963
  Val Accuracy: 0.7037037014961243
Epoch 37/64:
  Train Loss: 0.713386595249176
  Validation Loss: 0.7553576827049255
  Val ROC-AUC: 0.8024691358024691
  Val Accuracy: 0.7037037014961243
Epoch 38/64:
  Train Loss: 0.7170184999704361
  Validation Loss: 0.7545027732849121
  Val ROC-AUC: 0.8024691358024691
  Val Accuracy: 0.7037037014961243
Epoch 39/64:
  Train Loss: 0.7002899199724197
  Validation Loss: 0.7536652088165283
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.7037037014961243
Epoch 40/64:
  Train Loss: 0.7158654481172562
  Validation Loss: 0.7528789639472961
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.7037037014961243
Epoch 41/64:
  Train Loss: 0.706750825047493
  Validation Loss: 0.7520603537559509
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 42/64:
  Train Loss: 0.7137512266635895
  Validation Loss: 0.7512622475624084
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 43/64:
  Train Loss: 0.7128222733736038
  Validation Loss: 0.7505061030387878
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 44/64:
  Train Loss: 0.7182053625583649
  Validation Loss: 0.7497724890708923
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.7037037014961243
Epoch 45/64:
  Train Loss: 0.6981456726789474
  Validation Loss: 0.7490408420562744
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 46/64:
  Train Loss: 0.699280858039856
  Validation Loss: 0.7483170628547668
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 47/64:
  Train Loss: 0.7090519964694977
  Validation Loss: 0.7475833296775818
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 48/64:
  Train Loss: 0.7006275802850723
  Validation Loss: 0.746829628944397
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7407407760620117
Epoch 49/64:
  Train Loss: 0.7081423252820969
  Validation Loss: 0.7461053133010864
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7407407760620117
Epoch 50/64:
  Train Loss: 0.6891325861215591
  Validation Loss: 0.7453662157058716
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:27:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:27:INFO:
[92mINFO [0m:      Received: evaluate message d9b4f70e-5559-4848-9248-a71c6a6324a5
02/07/2025 22:45:27:INFO:Received: evaluate message d9b4f70e-5559-4848-9248-a71c6a6324a5
[92mINFO [0m:      Sent reply
02/07/2025 22:45:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:33:INFO:
[92mINFO [0m:      Received: train message cad0f848-e526-415f-a02c-46cb9a9720ae
02/07/2025 22:45:33:INFO:Received: train message cad0f848-e526-415f-a02c-46cb9a9720ae
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.7407407760620117
Epoch 51/64:
  Train Loss: 0.6887906789779663
  Validation Loss: 0.7446499466896057
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7407407760620117
Epoch 52/64:
  Train Loss: 0.6992069631814957
  Validation Loss: 0.7439529895782471
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7407407760620117
Epoch 53/64:
  Train Loss: 0.6923009306192398
  Validation Loss: 0.7432341575622559
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7407407760620117
Epoch 54/64:
  Train Loss: 0.6979590654373169
  Validation Loss: 0.7425487637519836
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.7407407760620117
Epoch 55/64:
  Train Loss: 0.7024815678596497
  Validation Loss: 0.7418793439865112
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7407407760620117
Epoch 56/64:
  Train Loss: 0.6965043842792511
  Validation Loss: 0.7412421703338623
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.7407407760620117
Epoch 57/64:
  Train Loss: 0.6868105828762054
  Validation Loss: 0.7405683994293213
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.7407407760620117
Epoch 58/64:
  Train Loss: 0.696342408657074
  Validation Loss: 0.7399349808692932
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.7407407760620117
Epoch 59/64:
  Train Loss: 0.6964626610279083
  Validation Loss: 0.7392802834510803
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7407407760620117
Epoch 60/64:
  Train Loss: 0.6805939674377441
  Validation Loss: 0.7386317849159241
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7407407760620117
Epoch 61/64:
  Train Loss: 0.6853093057870865
  Validation Loss: 0.7379906177520752
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7407407760620117
Epoch 62/64:
  Train Loss: 0.6982651650905609
  Validation Loss: 0.7373533844947815
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7777777910232544
Epoch 63/64:
  Train Loss: 0.689112588763237
  Validation Loss: 0.7367267608642578
  Val ROC-AUC: 0.8641975308641975
  Val Accuracy: 0.7777777910232544
Epoch 64/64:
  Train Loss: 0.6854957789182663
  Validation Loss: 0.7361254096031189
  Val ROC-AUC: 0.8641975308641975
  Val Accuracy: 0.7777777910232544
{'train_loss': 0.6854957789182663, 'val_roc_auc': 0.8641975308641975, 'val_accuracy': 0.7777777910232544, 'val_loss': 0.7361254096031189}
 ROC_AUC: 0.8642|| Accuracy 0.7778 || Train Loss: 0.6855
 Val Loss: 0.7361 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7785191941127348
Test ROC-AUC: 0.6915584415584415
Test Accuracy: 0.5617977528089888
test_loss: 0.7785191941127348
test_roc_auc: 0.6915584415584415
test_accuracy: 0.5617977528089888
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.21596150346340437
Epoch 1/64:
  Train Loss: 0.7564104348421097
  Validation Loss: 0.8255694508552551
  Val ROC-AUC: 0.611842105263158
  Val Accuracy: 0.5555555820465088
Epoch 2/64:
  Train Loss: 0.7546585351228714
  Validation Loss: 0.8237076997756958
  Val ROC-AUC: 0.638157894736842
  Val Accuracy: 0.5555555820465088
Epoch 3/64:
  Train Loss: 0.750661090016365
  Validation Loss: 0.821927547454834
  Val ROC-AUC: 0.6513157894736843
  Val Accuracy: 0.5555555820465088
Epoch 4/64:
  Train Loss: 0.7469203174114227
  Validation Loss: 0.8201568722724915
  Val ROC-AUC: 0.6644736842105263
  Val Accuracy: 0.5555555820465088
Epoch 5/64:
  Train Loss: 0.7428368031978607
  Validation Loss: 0.8184127807617188
  Val ROC-AUC: 0.6644736842105263
  Val Accuracy: 0.5925925970077515
Epoch 6/64:
  Train Loss: 0.7368616610765457
  Validation Loss: 0.8166923522949219
  Val ROC-AUC: 0.6776315789473685
  Val Accuracy: 0.5925925970077515
Epoch 7/64:
  Train Loss: 0.7359291166067123
  Validation Loss: 0.8149807453155518
  Val ROC-AUC: 0.6842105263157895
  Val Accuracy: 0.6296296119689941
Epoch 8/64:
  Train Loss: 0.7328525483608246
  Validation Loss: 0.8132692575454712
  Val ROC-AUC: 0.7171052631578947
  Val Accuracy: 0.6296296119689941
Epoch 9/64:
  Train Loss: 0.7419317662715912
  Validation Loss: 0.8116347789764404
  Val ROC-AUC: 0.736842105263158
  Val Accuracy: 0.6296296119689941
Epoch 10/64:
  Train Loss: 0.7484351694583893
  Validation Loss: 0.8099804520606995
  Val ROC-AUC: 0.7565789473684211
  Val Accuracy: 0.6296296119689941
Epoch 11/64:
  Train Loss: 0.732444167137146
  Validation Loss: 0.8083246350288391
  Val ROC-AUC: 0.7763157894736843
  Val Accuracy: 0.6666666865348816
Epoch 12/64:
  Train Loss: 0.7335939854383469
  Validation Loss: 0.8067024946212769
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.6666666865348816
Epoch 13/64:
  Train Loss: 0.7223166972398758
  Validation Loss: 0.8050881624221802
  Val ROC-AUC: 0.8223684210526316
  Val Accuracy: 0.6666666865348816
Epoch 14/64:
  Train Loss: 0.7388055324554443
  Validation Loss: 0.8035023808479309
  Val ROC-AUC: 0.8421052631578947
  Val Accuracy: 0.6666666865348816
Epoch 15/64:
  Train Loss: 0.7440262585878372
  Validation Loss: 0.8018863797187805
  Val ROC-AUC: 0.8552631578947368
  Val Accuracy: 0.7407407760620117
Epoch 16/64:
  Train Loss: 0.7451715618371964
  Validation Loss: 0.8003647327423096
  Val ROC-AUC: 0.8552631578947368
  Val Accuracy: 0.7407407760620117
Epoch 17/64:
  Train Loss: 0.7333241403102875
  Validation Loss: 0.7988405227661133
  Val ROC-AUC: 0.875
  Val Accuracy: 0.7407407760620117
Epoch 18/64:
  Train Loss: 0.7216075509786606
  Validation Loss: 0.7973126173019409
  Val ROC-AUC: 0.8881578947368421
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.7166749835014343
  Validation Loss: 0.7957722544670105
  Val ROC-AUC: 0.8881578947368421
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.7435391992330551
  Validation Loss: 0.794276773929596
  Val ROC-AUC: 0.8947368421052632
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.7265590578317642
  Validation Loss: 0.792806088924408
  Val ROC-AUC: 0.9013157894736842
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.7126188278198242
  Validation Loss: 0.7913117408752441
  Val ROC-AUC: 0.9013157894736842
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.7164216935634613
  Validation Loss: 0.7898600697517395
  Val ROC-AUC: 0.9013157894736842
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.7280088812112808
  Validation Loss: 0.7883898615837097
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.7185962796211243
  Validation Loss: 0.7869685292243958
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.7246081978082657
  Validation Loss: 0.7855790257453918
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.7184613198041916
  Validation Loss: 0.7842414975166321
  Val ROC-AUC: 0.9210526315789475
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.7246236503124237
  Validation Loss: 0.7828887104988098
  Val ROC-AUC: 0.9210526315789475
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.7066292464733124
  Validation Loss: 0.7815712690353394
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 30/64:
  Train Loss: 0.7106236666440964
  Validation Loss: 0.7802394032478333
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 31/64:
  Train Loss: 0.7149292379617691
  Validation Loss: 0.778972327709198
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 32/64:
  Train Loss: 0.7102395445108414
  Validation Loss: 0.7777144908905029
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.7777777910232544
Epoch 33/64:
  Train Loss: 0.7048020511865616
  Validation Loss: 0.7764803171157837
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.7777777910232544
Epoch 34/64:
  Train Loss: 0.7111542969942093
  Validation Loss: 0.7751984596252441
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.7777777910232544
Epoch 35/64:
  Train Loss: 0.7081658095121384
  Validation Loss: 0.7739407420158386
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.7777777910232544
Epoch 36/64:/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:01:INFO:
[92mINFO [0m:      Received: evaluate message bb059b66-e64d-4bc3-8437-d1fb5cef2518
02/07/2025 22:46:01:INFO:Received: evaluate message bb059b66-e64d-4bc3-8437-d1fb5cef2518
[92mINFO [0m:      Sent reply
02/07/2025 22:46:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:01:INFO:
[92mINFO [0m:      Received: train message 1b6d5484-453f-4e86-ac63-209cdf5647d2
02/07/2025 22:46:01:INFO:Received: train message 1b6d5484-453f-4e86-ac63-209cdf5647d2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

  Train Loss: 0.7050710171461105
  Validation Loss: 0.7727435231208801
  Val ROC-AUC: 0.9539473684210525
  Val Accuracy: 0.7777777910232544
Epoch 37/64:
  Train Loss: 0.6966347247362137
  Validation Loss: 0.771584153175354
  Val ROC-AUC: 0.9539473684210525
  Val Accuracy: 0.7777777910232544
Epoch 38/64:
  Train Loss: 0.6930486410856247
  Validation Loss: 0.7704173922538757
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.699442133307457
  Validation Loss: 0.7692726254463196
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6975273340940475
  Validation Loss: 0.7681552767753601
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6855337619781494
  Validation Loss: 0.7670539021492004
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.7125526368618011
  Validation Loss: 0.7659549713134766
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6960291117429733
  Validation Loss: 0.7648428082466125
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6980821937322617
  Validation Loss: 0.7637400031089783
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.7047820389270782
  Validation Loss: 0.7626540660858154
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6952321231365204
  Validation Loss: 0.7615944147109985
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8518518805503845
Epoch 47/64:
  Train Loss: 0.6991572678089142
  Validation Loss: 0.7605390548706055
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.6723097860813141
  Validation Loss: 0.7594573497772217
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.6840225160121918
  Validation Loss: 0.7584487199783325
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.6840103566646576
  Validation Loss: 0.7574585676193237
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6865938603878021
  Validation Loss: 0.7564895749092102
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.69471675157547
  Validation Loss: 0.7555121183395386
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.7031823247671127
  Validation Loss: 0.7545568943023682
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6810690760612488
  Validation Loss: 0.75362229347229
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.6941066533327103
  Validation Loss: 0.7526940107345581
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6876619160175323
  Validation Loss: 0.7517872452735901
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6807241886854172
  Validation Loss: 0.7509150505065918
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6987394094467163
  Validation Loss: 0.750078022480011
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.6783908158540726
  Validation Loss: 0.7492461204528809
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.682805523276329
  Validation Loss: 0.7484109997749329
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6804459244012833
  Validation Loss: 0.747575581073761
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.6795071661472321
  Validation Loss: 0.746747612953186
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6835525631904602
  Validation Loss: 0.7459605932235718
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.6742091476917267
  Validation Loss: 0.745153546333313
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6742091476917267, 'val_roc_auc': 0.9736842105263158, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.745153546333313}
 ROC_AUC: 0.9737|| Accuracy 0.8889 || Train Loss: 0.6742
 Val Loss: 0.7452 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.774246392290244
Test ROC-AUC: 0.7175324675324676
Test Accuracy: 0.5842696629213483
test_loss: 0.774246392290244
test_roc_auc: 0.7175324675324676
test_accuracy: 0.5842696629213483
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.1231892419423275
Epoch 1/64:
  Train Loss: 0.7595773786306381
  Validation Loss: 0.7829490303993225
  Val ROC-AUC: 0.7962962962962963
  Val Accuracy: 0.6666666865348816
Epoch 2/64:
  Train Loss: 0.7476332485675812
  Validation Loss: 0.7811352610588074
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.6296296119689941
Epoch 3/64:
  Train Loss: 0.7468882352113724
  Validation Loss: 0.7793360948562622
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.6296296119689941
Epoch 4/64:
  Train Loss: 0.7570145130157471
  Validation Loss: 0.77753746509552
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.6666666865348816
Epoch 5/64:
  Train Loss: 0.75074902176857
  Validation Loss: 0.7757393717765808
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.6666666865348816
Epoch 6/64:
  Train Loss: 0.7611669898033142
  Validation Loss: 0.7739691138267517
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.6666666865348816
Epoch 7/64:
  Train Loss: 0.7379012107849121
  Validation Loss: 0.7722288370132446
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.6666666865348816
Epoch 8/64:
  Train Loss: 0.7453792244195938
  Validation Loss: 0.7705038785934448
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.6666666865348816
Epoch 9/64:
  Train Loss: 0.7297089993953705
  Validation Loss: 0.7687734961509705
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7037037014961243
Epoch 10/64:
  Train Loss: 0.7519223392009735
  Validation Loss: 0.7670912742614746
  Val ROC-AUC: 0.8703703703703705
  Val Accuracy: 0.7407407760620117
Epoch 11/64:
  Train Loss: 0.743775799870491
  Validation Loss: 0.7654035687446594
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 12/64:
  Train Loss: 0.724932387471199
  Validation Loss: 0.7637527585029602
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 13/64:
  Train Loss: 0.7424271702766418
  Validation Loss: 0.7620909214019775
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 14/64:
  Train Loss: 0.7398594915866852
  Validation Loss: 0.7604169845581055
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 15/64:
  Train Loss: 0.7388031184673309
  Validation Loss: 0.7588003873825073
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7777777910232544
Epoch 16/64:
  Train Loss: 0.7330206781625748
  Validation Loss: 0.7572001814842224
  Val ROC-AUC: 0.882716049382716
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7383991181850433
  Validation Loss: 0.7556225061416626
  Val ROC-AUC: 0.882716049382716
  Val Accuracy: 0.7777777910232544
Epoch 18/64:
  Train Loss: 0.7308831363916397
  Validation Loss: 0.7540717124938965
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.717750608921051
  Validation Loss: 0.7525658011436462
  Val ROC-AUC: 0.8827160493827161
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.7254040390253067
  Validation Loss: 0.7510726451873779
  Val ROC-AUC: 0.8827160493827161
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.7372206449508667
  Validation Loss: 0.7496121525764465
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:29:INFO:
[92mINFO [0m:      Received: evaluate message 6724a284-ddd7-4f95-93a8-8d0b33158ae2
02/07/2025 22:46:29:INFO:Received: evaluate message 6724a284-ddd7-4f95-93a8-8d0b33158ae2
[92mINFO [0m:      Sent reply
02/07/2025 22:46:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:30:INFO:
[92mINFO [0m:      Received: train message 289b3ed4-373f-4f21-ab4d-2a521bca4edd
02/07/2025 22:46:30:INFO:Received: train message 289b3ed4-373f-4f21-ab4d-2a521bca4edd
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.7362360209226608
  Validation Loss: 0.7481793165206909
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.7131125330924988
  Validation Loss: 0.7467114329338074
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.7246499210596085
  Validation Loss: 0.7453027963638306
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.712307795882225
  Validation Loss: 0.7439337372779846
  Val ROC-AUC: 0.9197530864197532
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.7083185166120529
  Validation Loss: 0.7425709962844849
  Val ROC-AUC: 0.9382716049382717
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.7221459150314331
  Validation Loss: 0.7412407994270325
  Val ROC-AUC: 0.9382716049382717
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.7194092571735382
  Validation Loss: 0.7399352192878723
  Val ROC-AUC: 0.9444444444444445
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.7163462042808533
  Validation Loss: 0.7385947108268738
  Val ROC-AUC: 0.9444444444444445
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.7225714921951294
  Validation Loss: 0.737301230430603
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.7078642547130585
  Validation Loss: 0.7359920740127563
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.7124471813440323
  Validation Loss: 0.7346869111061096
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 33/64:
  Train Loss: 0.7037981599569321
  Validation Loss: 0.7334251403808594
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 34/64:
  Train Loss: 0.7098666131496429
  Validation Loss: 0.732193112373352
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 35/64:
  Train Loss: 0.723163053393364
  Validation Loss: 0.731005847454071
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 36/64:
  Train Loss: 0.7080366611480713
  Validation Loss: 0.7298293709754944
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 37/64:
  Train Loss: 0.7147578448057175
  Validation Loss: 0.728654682636261
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8518518805503845
Epoch 38/64:
  Train Loss: 0.7142022848129272
  Validation Loss: 0.7274945378303528
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8518518805503845
Epoch 39/64:
  Train Loss: 0.7039486318826675
  Validation Loss: 0.7263445258140564
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7120646387338638
  Validation Loss: 0.7252287864685059
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7179279625415802
  Validation Loss: 0.7241364121437073
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.7093675583600998
  Validation Loss: 0.7230575084686279
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6961811929941177
  Validation Loss: 0.7219973802566528
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.7116137892007828
  Validation Loss: 0.7209429144859314
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.7016576677560806
  Validation Loss: 0.7199200391769409
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6971073150634766
  Validation Loss: 0.7188898324966431
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6960140913724899
  Validation Loss: 0.7178688049316406
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.689906969666481
  Validation Loss: 0.7169023752212524
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.697499543428421
  Validation Loss: 0.7159557342529297
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.7124665528535843
  Validation Loss: 0.7150049805641174
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6932362914085388
  Validation Loss: 0.7140855193138123
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6896726340055466
  Validation Loss: 0.713151752948761
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6908693313598633
  Validation Loss: 0.7122328281402588
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6864084303379059
  Validation Loss: 0.7113621234893799
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6988107711076736
  Validation Loss: 0.7104811668395996
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6963526606559753
  Validation Loss: 0.709621012210846
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6835466474294662
  Validation Loss: 0.7087592482566833
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6818537265062332
  Validation Loss: 0.7079174518585205
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6843577176332474
  Validation Loss: 0.7070796489715576
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6934441477060318
  Validation Loss: 0.7062724232673645
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6882924437522888
  Validation Loss: 0.7054794430732727
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6954080760478973
  Validation Loss: 0.7047037482261658
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.680102214217186
  Validation Loss: 0.7039124369621277
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6819924712181091
  Validation Loss: 0.7031694650650024
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6819924712181091, 'val_roc_auc': 0.9506172839506174, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.7031694650650024}
 ROC_AUC: 0.9506|| Accuracy 0.9259 || Train Loss: 0.6820
 Val Loss: 0.7032 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7693897800499134
Test ROC-AUC: 0.7456709956709956
Test Accuracy: 0.5955056179775281
test_loss: 0.7693897800499134
test_roc_auc: 0.7456709956709956
test_accuracy: 0.5955056179775281
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.19137434893309546
Epoch 1/64:
  Train Loss: 0.7610423862934113
  Validation Loss: 0.7217006087303162
  Val ROC-AUC: 0.9318181818181819
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7668316960334778
  Validation Loss: 0.7199252247810364
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7612134218215942
  Validation Loss: 0.7181772589683533
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7478805333375931
  Validation Loss: 0.7164863348007202
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.7564267069101334
  Validation Loss: 0.7148540019989014
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.7611638903617859
  Validation Loss: 0.713272213935852
  Val ROC-AUC: 0.9659090909090908
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.7523619681596756
  Validation Loss: 0.7116890549659729
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.75189009308815
  Validation Loss: 0.7101387977600098
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7603932619094849
  Validation Loss: 0.708635151386261
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.752392590045929
  Validation Loss: 0.7071319818496704
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.763596311211586
  Validation Loss: 0.7055968046188354
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.7490418702363968
  Validation Loss: 0.7041079998016357
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.7626796960830688
  Validation Loss: 0.7026110887527466
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.7484394013881683
  Validation Loss: 0.7011027932167053
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.726700559258461
  Validation Loss: 0.6996636390686035
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.7550851851701736
  Validation Loss: 0.6983047723770142
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.7328220009803772
  Validation Loss: 0.6969438791275024
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.7297366261482239
  Validation Loss: 0.6955806612968445
  Val ROC-AUC: 0.9943181818181818
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.744849756360054
  Validation Loss: 0.6942700147628784
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.7326952069997787
  Validation Loss: 0.6930415034294128
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.7248908281326294
  Validation Loss: 0.6918041110038757
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.745583787560463
  Validation Loss: 0.6906692981719971
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.7404559105634689
  Validation Loss: 0.689538300037384
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.7480100393295288
  Validation Loss: 0.6883972883224487
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.7395966500043869
  Validation Loss: 0.687287449836731
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.735419437289238
  Validation Loss: 0.6862143278121948
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.735355481505394
  Validation Loss: 0.68504798412323
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.7489489763975143
  Validation Loss: 0.6839153170585632
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.7150249481201172
  Validation Loss: 0.6828374266624451
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.7267975062131882
  Validation Loss: 0.6817898750305176
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.7187681496143341
  Validation Loss: 0.6807204484939575
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.7188113480806351
  Validation Loss: 0.6796668171882629
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.7213426381349564
  Validation Loss: 0.6786590814590454
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.7195452749729156
  Validation Loss: 0.6776975989341736
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.7148043811321259
  Validation Loss: 0.6767519116401672
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.7188472896814346
  Validation Loss: 0.6758001446723938
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.7152569144964218
  Validation Loss: 0.6748149991035461
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.7278034836053848
  Validation Loss: 0.6738426685333252
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.7213701903820038
  Validation Loss: 0.672934353351593
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.7206737697124481
  Validation Loss: 0.6720340251922607
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.7208239734172821
  Validation Loss: 0.6711711287498474
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.7058420330286026
  Validation Loss: 0.6703653931617737
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.7086713761091232
  Validation Loss: 0.6695432066917419
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.7188892811536789
  Validation Loss: 0.6687015891075134
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.7160705178976059
  Validation Loss: 0.6678767800331116
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.7138859033584595
  Validation Loss: 0.6670900583267212
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.7108396589756012
  Validation Loss: 0.6662903428077698
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.7099378108978271
  Validation Loss: 0.6655514240264893
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.7103603631258011
  Validation Loss: 0.664788007736206
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.7097487300634384
  Validation Loss: 0.6640240550041199
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6969956010580063
  Validation Loss: 0.6632965207099915
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.7050013989210129
  Validation Loss: 0.662604808807373
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.7053805440664291
  Validation Loss: 0.6619518399238586
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6982383579015732
  Validation Loss: 0.6612824201583862
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6958400011062622
  Validation Loss: 0.6605930924415588
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.707595095038414
  Validation Loss: 0.6599196791648865
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.7039468735456467
  Validation Loss: 0.6593581438064575
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.7073180973529816
  Validation Loss: 0.6587557792663574
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.7055145800113678
  Validation Loss: 0.6581519842147827
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.7063024193048477
  Validation Loss: 0.6575866937637329
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.7029008120298386
  Validation Loss: 0.656997561454773
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.702126681804657
  Validation Loss: 0.6564239263534546
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6993318349123001
  Validation Loss: 0.6558466553688049
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6880812346935272
  Validation Loss: 0.6553043127059937
  Val ROC-AUC: 1.0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:58:INFO:
[92mINFO [0m:      Received: evaluate message ad2a1e01-7823-4cca-ae61-f4580856d290
02/07/2025 22:46:58:INFO:Received: evaluate message ad2a1e01-7823-4cca-ae61-f4580856d290
[92mINFO [0m:      Sent reply
02/07/2025 22:46:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:59:INFO:
[92mINFO [0m:      Received: train message 19eac88b-fd2b-4042-bbbd-395a521e9254
02/07/2025 22:46:59:INFO:Received: train message 19eac88b-fd2b-4042-bbbd-395a521e9254
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6880812346935272, 'val_roc_auc': 1.0, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6553043127059937}
 ROC_AUC: 1.0000|| Accuracy 0.9630 || Train Loss: 0.6881
 Val Loss: 0.6553 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7642489340198174
Test ROC-AUC: 0.7754329004329005
Test Accuracy: 0.651685393258427
test_loss: 0.7642489340198174
test_roc_auc: 0.7754329004329005
test_accuracy: 0.651685393258427
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.08039979243562811
Epoch 1/64:
  Train Loss: 0.7529468387365341
  Validation Loss: 0.7361927628517151
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7386660724878311
  Validation Loss: 0.7342557311058044
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7513322532176971
  Validation Loss: 0.7324584126472473
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7361598461866379
  Validation Loss: 0.7306835055351257
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7476758509874344
  Validation Loss: 0.729005753993988
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7443252950906754
  Validation Loss: 0.727425217628479
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7526157945394516
  Validation Loss: 0.7258830070495605
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7405568212270737
  Validation Loss: 0.7243031859397888
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7433657199144363
  Validation Loss: 0.7228224277496338
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.732101246714592
  Validation Loss: 0.7213692665100098
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7311811447143555
  Validation Loss: 0.7199122309684753
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7487345188856125
  Validation Loss: 0.7185264825820923
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.724015399813652
  Validation Loss: 0.7171386480331421
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.7354102283716202
  Validation Loss: 0.7157379388809204
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7271004915237427
  Validation Loss: 0.7143630981445312
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7168202698230743
  Validation Loss: 0.7130088806152344
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7335290163755417
  Validation Loss: 0.7116945385932922
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7296431958675385
  Validation Loss: 0.710427463054657
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.7287141978740692
  Validation Loss: 0.7092006802558899
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.7400041073560715
  Validation Loss: 0.7079659700393677
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.7196350544691086
  Validation Loss: 0.7067714929580688
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.7255468368530273
  Validation Loss: 0.7055743336677551
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7196995913982391
  Validation Loss: 0.7044300436973572
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.7327649295330048
  Validation Loss: 0.703306257724762
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.712381586432457
  Validation Loss: 0.7021811008453369
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7323947101831436
  Validation Loss: 0.7011260986328125
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7163385897874832
  Validation Loss: 0.7000495791435242
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.7152058631181717
  Validation Loss: 0.6990055441856384
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.7016850262880325
  Validation Loss: 0.697956919670105
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.7003033012151718
  Validation Loss: 0.6968996524810791
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.730336457490921
  Validation Loss: 0.6959197521209717
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.7074139416217804
  Validation Loss: 0.6949073076248169
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.7230314463376999
  Validation Loss: 0.6939280033111572
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.7250029891729355
  Validation Loss: 0.6929916143417358
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.7157986760139465
  Validation Loss: 0.692075788974762
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7109900414943695
  Validation Loss: 0.691160261631012
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7039172947406769
  Validation Loss: 0.6902793645858765
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7014443576335907
  Validation Loss: 0.689385712146759
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7064450830221176
  Validation Loss: 0.6885338425636292
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7048722505569458
  Validation Loss: 0.6877120733261108
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7094638794660568
  Validation Loss: 0.6868934631347656
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.7037633955478668
  Validation Loss: 0.6860785484313965
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.7036708444356918
  Validation Loss: 0.6852871179580688
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6949093788862228
  Validation Loss: 0.6845351457595825
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.7001100182533264
  Validation Loss: 0.6837692856788635
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.7060809582471848
  Validation Loss: 0.6830328106880188
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6976475864648819
  Validation Loss: 0.6823262572288513
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.7008927762508392
  Validation Loss: 0.6816221475601196
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.7008341401815414
  Validation Loss: 0.6809356808662415
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6977556645870209
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:28:INFO:
[92mINFO [0m:      Received: evaluate message 2cbb8ade-9997-4b09-aba2-0a4bd94ac382
02/07/2025 22:47:28:INFO:Received: evaluate message 2cbb8ade-9997-4b09-aba2-0a4bd94ac382
[92mINFO [0m:      Sent reply
02/07/2025 22:47:31:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:31:INFO:
[92mINFO [0m:      Received: train message 6a69e076-2ce1-40f3-86c6-fd9ba0a5518f
02/07/2025 22:47:31:INFO:Received: train message 6a69e076-2ce1-40f3-86c6-fd9ba0a5518f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6802718043327332
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.7119848877191544
  Validation Loss: 0.6796131134033203
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.7003088295459747
  Validation Loss: 0.6789650917053223
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6970349997282028
  Validation Loss: 0.6783087253570557
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6945239752531052
  Validation Loss: 0.6776859164237976
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6921103298664093
  Validation Loss: 0.6770507097244263
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.7036339640617371
  Validation Loss: 0.6764514446258545
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.7045523822307587
  Validation Loss: 0.6758454442024231
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6959227323532104
  Validation Loss: 0.6752749085426331
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6890143901109695
  Validation Loss: 0.6746978759765625
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6882048547267914
  Validation Loss: 0.6741350293159485
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6941182762384415
  Validation Loss: 0.6735893487930298
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.690465435385704
  Validation Loss: 0.6730636358261108
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.7013650089502335
  Validation Loss: 0.6725331544876099
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6877349466085434
  Validation Loss: 0.6720020174980164
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6877349466085434, 'val_roc_auc': 0.9705882352941176, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6720020174980164}
 ROC_AUC: 0.9706|| Accuracy 0.9259 || Train Loss: 0.6877
 Val Loss: 0.6720 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7589251774080684
Test ROC-AUC: 0.7927489177489178
Test Accuracy: 0.6741573033707865
test_loss: 0.7589251774080684
test_roc_auc: 0.7927489177489178
test_accuracy: 0.6741573033707865
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.15102689618970544
Epoch 1/64:
  Train Loss: 0.7344894409179688
  Validation Loss: 0.7782748341560364
  Val ROC-AUC: 0.9210526315789473
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7464447170495987
  Validation Loss: 0.7764530777931213
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7178459763526917
  Validation Loss: 0.7746396064758301
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7325541079044342
  Validation Loss: 0.7728704810142517
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7170658856630325
  Validation Loss: 0.7710777521133423
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7237604111433029
  Validation Loss: 0.7693057656288147
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7322549670934677
  Validation Loss: 0.7675508856773376
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7259764820337296
  Validation Loss: 0.7657940983772278
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7251952886581421
  Validation Loss: 0.7640632390975952
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.7252351939678192
  Validation Loss: 0.762396514415741
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7239566296339035
  Validation Loss: 0.7607142329216003
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7250755280256271
  Validation Loss: 0.7590195536613464
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.721948429942131
  Validation Loss: 0.7573218941688538
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.707281768321991
  Validation Loss: 0.755660891532898
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7108245491981506
  Validation Loss: 0.7540034651756287
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.718792736530304
  Validation Loss: 0.7524071931838989
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7033741027116776
  Validation Loss: 0.7507807612419128
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7222062647342682
  Validation Loss: 0.7492036819458008
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.7088294625282288
  Validation Loss: 0.7476717233657837
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.715837374329567
  Validation Loss: 0.7461487054824829
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.7159182131290436
  Validation Loss: 0.744644284248352
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.7056312412023544
  Validation Loss: 0.7431564927101135
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7104428708553314
  Validation Loss: 0.7417482733726501
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.709442213177681
  Validation Loss: 0.7403168678283691
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6966860294342041
  Validation Loss: 0.7389101982116699
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7044622600078583
  Validation Loss: 0.7375487089157104
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7133359313011169
  Validation Loss: 0.7362178564071655
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.7092316299676895
  Validation Loss: 0.7348925471305847
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.7060376703739166
  Validation Loss: 0.733551025390625
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.7073744386434555
  Validation Loss: 0.7322317361831665
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6970192342996597
  Validation Loss: 0.7309550046920776
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6948213577270508
  Validation Loss: 0.7297254800796509
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6870015859603882
  Validation Loss: 0.7285293936729431
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6940339803695679
  Validation Loss: 0.72732013463974
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6906832307577133
  Validation Loss: 0.726144015789032
  Val ROC-AUC: 0.993421052631579
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:59:INFO:
[92mINFO [0m:      Received: evaluate message fd6a6cea-090e-4d67-8173-50857dfa13c2
02/07/2025 22:47:59:INFO:Received: evaluate message fd6a6cea-090e-4d67-8173-50857dfa13c2
[92mINFO [0m:      Sent reply
02/07/2025 22:48:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:01:INFO:
[92mINFO [0m:      Received: train message 3cedc310-4261-44a1-bbeb-bccfaf3b13b7
02/07/2025 22:48:01:INFO:Received: train message 3cedc310-4261-44a1-bbeb-bccfaf3b13b7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6955378204584122
  Validation Loss: 0.724942684173584
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.7015954107046127
  Validation Loss: 0.7237664461135864
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6984551548957825
  Validation Loss: 0.7226477861404419
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6715889871120453
  Validation Loss: 0.7215425968170166
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6921939104795456
  Validation Loss: 0.7204533815383911
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6943071484565735
  Validation Loss: 0.7194429636001587
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6915367245674133
  Validation Loss: 0.7184203267097473
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.7070829421281815
  Validation Loss: 0.7174007892608643
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6835123151540756
  Validation Loss: 0.7163782715797424
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6937024295330048
  Validation Loss: 0.715369701385498
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6844023764133453
  Validation Loss: 0.7144303321838379
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.679788738489151
  Validation Loss: 0.7134737372398376
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6980233639478683
  Validation Loss: 0.7125445008277893
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6929866671562195
  Validation Loss: 0.7116013169288635
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.683026984333992
  Validation Loss: 0.710695743560791
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6949382871389389
  Validation Loss: 0.709806501865387
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6775745153427124
  Validation Loss: 0.7089428901672363
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6779407858848572
  Validation Loss: 0.7080783247947693
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6886525452136993
  Validation Loss: 0.7072768807411194
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6848135143518448
  Validation Loss: 0.7064365744590759
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6744931489229202
  Validation Loss: 0.7056087851524353
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6814019531011581
  Validation Loss: 0.7047760486602783
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6779707372188568
  Validation Loss: 0.7039274573326111
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.691092848777771
  Validation Loss: 0.7031015753746033
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6750911623239517
  Validation Loss: 0.7023018002510071
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6863581091165543
  Validation Loss: 0.7015208601951599
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6799299120903015
  Validation Loss: 0.7007120847702026
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6751251667737961
  Validation Loss: 0.6999068856239319
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6926641762256622
  Validation Loss: 0.6990717649459839
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6926641762256622, 'val_roc_auc': 1.0, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6990717649459839}
 ROC_AUC: 1.0000|| Accuracy 0.9630 || Train Loss: 0.6927
 Val Loss: 0.6991 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7534909248352051
Test ROC-AUC: 0.808982683982684
Test Accuracy: 0.7078651685393258
test_loss: 0.7534909248352051
test_roc_auc: 0.808982683982684
test_accuracy: 0.7078651685393258
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.22708111204792658
Epoch 1/64:
  Train Loss: 0.7133252769708633
  Validation Loss: 0.7421755790710449
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7303102165460587
  Validation Loss: 0.7406807541847229
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7350583076477051
  Validation Loss: 0.7392039895057678
  Val ROC-AUC: 0.8882352941176471
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7260648906230927
  Validation Loss: 0.7377378940582275
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.7203681766986847
  Validation Loss: 0.736303985118866
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.717886433005333
  Validation Loss: 0.7349117398262024
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7370765954256058
  Validation Loss: 0.7335124611854553
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7196727842092514
  Validation Loss: 0.7321423888206482
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7296426892280579
  Validation Loss: 0.7307484745979309
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.7312362939119339
  Validation Loss: 0.7293819785118103
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7250760644674301
  Validation Loss: 0.728036105632782
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.6999865919351578
  Validation Loss: 0.7266924977302551
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.7209835350513458
  Validation Loss: 0.7254220247268677
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.7171378880739212
  Validation Loss: 0.7242074012756348
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.7210673242807388
  Validation Loss: 0.7230444550514221
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.7135899066925049
  Validation Loss: 0.7218728065490723
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.7079685181379318
  Validation Loss: 0.720644474029541
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.7182563543319702
  Validation Loss: 0.7194185853004456
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.715127632021904
  Validation Loss: 0.7182216048240662
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.7170744836330414
  Validation Loss: 0.7170763611793518
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.7333340495824814
  Validation Loss: 0.7159640789031982
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.7063794136047363
  Validation Loss: 0.7148249745368958
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7204576432704926
  Validation Loss: 0.7137032747268677
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:29:INFO:
[92mINFO [0m:      Received: evaluate message 030838d9-39ce-44cb-9a5f-012baf81ed01
02/07/2025 22:48:29:INFO:Received: evaluate message 030838d9-39ce-44cb-9a5f-012baf81ed01
[92mINFO [0m:      Sent reply
02/07/2025 22:48:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:29:INFO:
[92mINFO [0m:      Received: train message d85e79e8-d747-4155-96c5-db725faac85b
02/07/2025 22:48:29:INFO:Received: train message d85e79e8-d747-4155-96c5-db725faac85b
  Train Loss: 0.698927640914917
  Validation Loss: 0.7125720381736755
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.7044638395309448
  Validation Loss: 0.7114601731300354
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7070244401693344
  Validation Loss: 0.710386335849762
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.713418647646904
  Validation Loss: 0.7093668580055237
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6879375129938126
  Validation Loss: 0.7083539366722107
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6924451887607574
  Validation Loss: 0.7073726654052734
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6939358413219452
  Validation Loss: 0.7064103484153748
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7011535465717316
  Validation Loss: 0.7055012583732605
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.7075373828411102
  Validation Loss: 0.7045612335205078
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.7037141919136047
  Validation Loss: 0.7036315202713013
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6926156878471375
  Validation Loss: 0.7026900053024292
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6986564099788666
  Validation Loss: 0.7017902135848999
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7010258436203003
  Validation Loss: 0.7008976340293884
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6980996876955032
  Validation Loss: 0.7000222206115723
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7016986012458801
  Validation Loss: 0.6991551518440247
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.706580713391304
  Validation Loss: 0.6983112096786499
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6817749589681625
  Validation Loss: 0.6975286602973938
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6903363615274429
  Validation Loss: 0.6966979503631592
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6771209239959717
  Validation Loss: 0.6958751082420349
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.702366054058075
  Validation Loss: 0.6951075792312622
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.7036325186491013
  Validation Loss: 0.6943161487579346
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6831560730934143
  Validation Loss: 0.6935544013977051
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6768301725387573
  Validation Loss: 0.6927986741065979
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6918800622224808
  Validation Loss: 0.6920130252838135
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6904458105564117
  Validation Loss: 0.6912556290626526
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6826675981283188
  Validation Loss: 0.6905367374420166
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6944991648197174
  Validation Loss: 0.6898521184921265
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6736109852790833
  Validation Loss: 0.6891801953315735
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6843300759792328
  Validation Loss: 0.6884880661964417
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6951264441013336
  Validation Loss: 0.6878197193145752
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6915822923183441
  Validation Loss: 0.6871453523635864
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6923449337482452
  Validation Loss: 0.6865032315254211
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6848153322935104
  Validation Loss: 0.6858847141265869
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6846000403165817
  Validation Loss: 0.6852552890777588
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6862953901290894
  Validation Loss: 0.6846468448638916
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6874455660581589
  Validation Loss: 0.6840689182281494
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6774699091911316
  Validation Loss: 0.6834445595741272
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6756778210401535
  Validation Loss: 0.6828644871711731
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6877717524766922
  Validation Loss: 0.6822717785835266
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6839201152324677
  Validation Loss: 0.681692361831665
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6747264862060547
  Validation Loss: 0.6810985207557678
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6747264862060547, 'val_roc_auc': 0.9647058823529411, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6810985207557678}
 ROC_AUC: 0.9647|| Accuracy 0.9259 || Train Loss: 0.6747
 Val Loss: 0.6811 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7480855309561397
Test ROC-AUC: 0.8219696969696969
Test Accuracy: 0.7191011235955056
test_loss: 0.7480855309561397
test_roc_auc: 0.8219696969696969
test_accuracy: 0.7191011235955056
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.049878023668270544
Epoch 1/64:
  Train Loss: 0.7293074578046799
  Validation Loss: 0.7401494383811951
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.7093362957239151
  Validation Loss: 0.7389567494392395
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.712698757648468
  Validation Loss: 0.7377479076385498
  Val ROC-AUC: 0.8999999999999999
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7118752747774124
  Validation Loss: 0.7366112470626831
  Val ROC-AUC: 0.8999999999999999
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7127053737640381
  Validation Loss: 0.7354694604873657
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7172200679779053
  Validation Loss: 0.734353244304657
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7176438271999359
  Validation Loss: 0.7332475781440735
  Val ROC-AUC: 0.9117647058823528
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7157713174819946
  Validation Loss: 0.7321673035621643
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7198442369699478
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.7311011552810669
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6986876279115677
  Validation Loss: 0.7300499677658081
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7047220319509506
  Validation Loss: 0.7290129661560059
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7067292183637619
  Validation Loss: 0.7279985547065735
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.7090597450733185
  Validation Loss: 0.7270011305809021
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.7163566201925278
  Validation Loss: 0.7260072827339172
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7008719742298126
  Validation Loss: 0.7250193357467651
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7068431377410889
  Validation Loss: 0.72408127784729
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7004328519105911
  Validation Loss: 0.7231321930885315
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7069104164838791
  Validation Loss: 0.7221927642822266
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.7008254379034042
  Validation Loss: 0.721287190914154
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.6973463892936707
  Validation Loss: 0.7203719615936279
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6867670267820358
  Validation Loss: 0.7194896340370178
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.7051808089017868
  Validation Loss: 0.7186344265937805
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.6853857338428497
  Validation Loss: 0.7177697420120239
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6907266974449158
  Validation Loss: 0.7169215083122253
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.7036453038454056
  Validation Loss: 0.7160887718200684
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6905755549669266
  Validation Loss: 0.715251624584198
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6970443427562714
  Validation Loss: 0.7144085168838501
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6951227337121964
  Validation Loss: 0.7136141657829285
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6929027587175369
  Validation Loss: 0.7128461003303528
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6745292544364929
  Validation Loss: 0.7120683789253235
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6918832361698151
  Validation Loss: 0.7113216519355774
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6851955503225327
  Validation Loss: 0.7105769515037537
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6821736991405487
  Validation Loss: 0.7098342180252075
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6954537034034729
  Validation Loss: 0.7091012001037598
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.682449996471405
  Validation Loss: 0.7083721160888672
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.690939262509346
  Validation Loss: 0.7076824307441711
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6748871952295303
  Validation Loss: 0.706999659538269
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6943265646696091
  Validation Loss: 0.706325113773346
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6791953891515732
  Validation Loss: 0.7056319713592529
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.690122440457344
  Validation Loss: 0.7049727439880371
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6857289671897888
  Validation Loss: 0.7043254971504211
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 42/64:
  Train Loss: 0.6878887563943863
  Validation Loss: 0.7036741375923157
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 43/64:
  Train Loss: 0.6960592269897461
  Validation Loss: 0.7030296325683594
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 44/64:
  Train Loss: 0.6727510243654251
  Validation Loss: 0.7024269104003906
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 45/64:
  Train Loss: 0.6805496215820312
  Validation Loss: 0.7018080949783325
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 46/64:
  Train Loss: 0.691033273935318
  Validation Loss: 0.7011881470680237
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 47/64:
  Train Loss: 0.6806581169366837
  Validation Loss: 0.7005748152732849
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.6777839362621307
  Validation Loss: 0.699994683265686
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.6720839738845825
  Validation Loss: 0.6994119882583618
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.6803346574306488
  Validation Loss: 0.698821485042572
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6816965341567993
  Validation Loss: 0.6982676982879639
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.6626197099685669
  Validation Loss: 0.6976944208145142
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.6781766712665558
  Validation Loss: 0.6971591114997864
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6751112341880798
  Validation Loss: 0.6966186165809631
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.668238639831543
  Validation Loss: 0.6961014866828918
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6790906935930252
  Validation Loss: 0.695583164691925
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6739738583564758
  Validation Loss: 0.6950646638870239
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6809466332197189
  Validation Loss: 0.6945560574531555
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.6769520193338394
  Validation Loss: 0.6940554976463318
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.6703362017869949
  Validation Loss: 0.6935645341873169
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6702961325645447
  Validation Loss: 0.6930645108222961
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.6835933774709702
  Validation Loss: 0.6925722360610962
  Val ROC-AUC: 0.9352941176470588
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:57:INFO:
[92mINFO [0m:      Received: evaluate message 346db251-a63a-4208-b78f-416430fcaa7e
02/07/2025 22:48:57:INFO:Received: evaluate message 346db251-a63a-4208-b78f-416430fcaa7e
[92mINFO [0m:      Sent reply
02/07/2025 22:48:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:58:INFO:
[92mINFO [0m:      Received: train message 4f4c169a-c9b8-4174-bbb6-bab775865fea
02/07/2025 22:48:58:INFO:Received: train message 4f4c169a-c9b8-4174-bbb6-bab775865fea
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6722838282585144
  Validation Loss: 0.6921077370643616
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.6660239994525909
  Validation Loss: 0.691644549369812
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
{'train_loss': 0.6660239994525909, 'val_roc_auc': 0.9352941176470588, 'val_accuracy': 0.8518518805503845, 'val_loss': 0.691644549369812}
 ROC_AUC: 0.9353|| Accuracy 0.8519 || Train Loss: 0.6660
 Val Loss: 0.6916 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7427804295936328
Test ROC-AUC: 0.83495670995671
Test Accuracy: 0.7303370786516854
test_loss: 0.7427804295936328
test_roc_auc: 0.83495670995671
test_accuracy: 0.7303370786516854
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.21789294954942307
Epoch 1/64:
  Train Loss: 0.7375977486371994
  Validation Loss: 0.6361122131347656
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.734156921505928
  Validation Loss: 0.6348339915275574
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.7369171530008316
  Validation Loss: 0.6335970759391785
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7323179244995117
  Validation Loss: 0.6323694586753845
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.7336389124393463
  Validation Loss: 0.6311388611793518
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.73497174680233
  Validation Loss: 0.6299654841423035
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.744880735874176
  Validation Loss: 0.6287517547607422
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.736590102314949
  Validation Loss: 0.6275959610939026
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.7303178608417511
  Validation Loss: 0.6265000104904175
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.7185681611299515
  Validation Loss: 0.6253998279571533
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.7273764610290527
  Validation Loss: 0.6242586970329285
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.7353077828884125
  Validation Loss: 0.6231822371482849
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7334480732679367
  Validation Loss: 0.6221539378166199
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.7250445336103439
  Validation Loss: 0.6211432218551636
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.7150205969810486
  Validation Loss: 0.6201551556587219
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.7285226732492447
  Validation Loss: 0.6191737651824951
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.716635450720787
  Validation Loss: 0.6182380318641663
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7164154648780823
  Validation Loss: 0.6173079013824463
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7132232189178467
  Validation Loss: 0.6164060831069946
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.7083371877670288
  Validation Loss: 0.6155439615249634
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.7246792912483215
  Validation Loss: 0.6147029995918274
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.7103130370378494
  Validation Loss: 0.61387699842453
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.7201791256666183
  Validation Loss: 0.6130914092063904
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.7146690785884857
  Validation Loss: 0.6123114228248596
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.7114734500646591
  Validation Loss: 0.6115500330924988
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7184891104698181
  Validation Loss: 0.6108415722846985
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7064077407121658
  Validation Loss: 0.6101187467575073
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.7282713502645493
  Validation Loss: 0.6094069480895996
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6973680555820465
  Validation Loss: 0.6087342500686646
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.7088150382041931
  Validation Loss: 0.6080247163772583
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7051298767328262
  Validation Loss: 0.6072989702224731
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.7018483430147171
  Validation Loss: 0.6065444946289062
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.713236927986145
  Validation Loss: 0.6058428287506104
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.7114884108304977
  Validation Loss: 0.6051781177520752
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.7137967795133591
  Validation Loss: 0.6045215129852295
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7036780714988708
  Validation Loss: 0.6038891077041626
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7004513889551163
  Validation Loss: 0.6032536625862122
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7152971178293228
  Validation Loss: 0.6026642322540283
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7053095996379852
  Validation Loss: 0.6020691990852356
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7032295614480972
  Validation Loss: 0.6014376878738403
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7232924848794937
  Validation Loss: 0.6008296608924866
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6961866319179535
  Validation Loss: 0.6002230048179626
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.7037889957427979
  Validation Loss: 0.5995966792106628
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.7075781971216202
  Validation Loss: 0.5989848971366882
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.702909842133522
  Validation Loss: 0.5983835458755493
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.71062932908535
  Validation Loss: 0.5978383421897888
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6993823945522308
  Validation Loss: 0.5973095297813416
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6979535222053528
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:26:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:26:INFO:
[92mINFO [0m:      Received: evaluate message 58e0496d-eaa5-4100-bf98-f564c5a749d5
02/07/2025 22:49:26:INFO:Received: evaluate message 58e0496d-eaa5-4100-bf98-f564c5a749d5
[92mINFO [0m:      Sent reply
02/07/2025 22:49:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:28:INFO:
[92mINFO [0m:      Received: train message 02ded268-9c4c-42e3-ab93-b6af978f20bc
02/07/2025 22:49:28:INFO:Received: train message 02ded268-9c4c-42e3-ab93-b6af978f20bc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5967698097229004
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6964541375637054
  Validation Loss: 0.5962204933166504
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.7083978354930878
  Validation Loss: 0.5956878662109375
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.7090776413679123
  Validation Loss: 0.5951926708221436
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6878255158662796
  Validation Loss: 0.5946751236915588
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6979838162660599
  Validation Loss: 0.5941687226295471
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.703416183590889
  Validation Loss: 0.5936684608459473
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.7060744017362595
  Validation Loss: 0.5932104587554932
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.7092422991991043
  Validation Loss: 0.5927329659461975
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6881304979324341
  Validation Loss: 0.592254638671875
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.7036663293838501
  Validation Loss: 0.5917837619781494
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6954905688762665
  Validation Loss: 0.5913155674934387
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6958363205194473
  Validation Loss: 0.5908533930778503
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.7108411937952042
  Validation Loss: 0.590408205986023
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6869351416826248
  Validation Loss: 0.5900003910064697
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6956439316272736
  Validation Loss: 0.5895757675170898
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6963170021772385
  Validation Loss: 0.5891675353050232
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6963170021772385, 'val_roc_auc': 0.989010989010989, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.5891675353050232}
 ROC_AUC: 0.9890|| Accuracy 0.9630 || Train Loss: 0.6963
 Val Loss: 0.5892 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.737668928805362
Test ROC-AUC: 0.8506493506493507
Test Accuracy: 0.7415730337078652
test_loss: 0.737668928805362
test_roc_auc: 0.8506493506493507
test_accuracy: 0.7415730337078652
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.05315007788226467
Epoch 1/64:
  Train Loss: 0.7103563696146011
  Validation Loss: 0.7278621196746826
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 2/64:
  Train Loss: 0.7098000198602676
  Validation Loss: 0.7267239689826965
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 3/64:
  Train Loss: 0.7170977741479874
  Validation Loss: 0.7255240082740784
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 4/64:
  Train Loss: 0.7075101882219315
  Validation Loss: 0.7243179082870483
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.707396075129509
  Validation Loss: 0.7231627702713013
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.689920112490654
  Validation Loss: 0.7219506502151489
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.716150239109993
  Validation Loss: 0.7207461595535278
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.7153262197971344
  Validation Loss: 0.719636857509613
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.6868319362401962
  Validation Loss: 0.7184818983078003
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.7135358452796936
  Validation Loss: 0.7174601554870605
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.70368492603302
  Validation Loss: 0.716441810131073
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.689513087272644
  Validation Loss: 0.7154271006584167
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6899505406618118
  Validation Loss: 0.7143805623054504
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.695711761713028
  Validation Loss: 0.7134036421775818
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6918554604053497
  Validation Loss: 0.7123817205429077
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6880079656839371
  Validation Loss: 0.7114113569259644
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6941203474998474
  Validation Loss: 0.7104650735855103
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6920139044523239
  Validation Loss: 0.7095406651496887
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.700437530875206
  Validation Loss: 0.7086535692214966
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6878134459257126
  Validation Loss: 0.7077507972717285
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.7028311043977737
  Validation Loss: 0.7068579792976379
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.691000759601593
  Validation Loss: 0.7059890031814575
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6915682554244995
  Validation Loss: 0.7051199078559875
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6971375495195389
  Validation Loss: 0.7043200135231018
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.681230440735817
  Validation Loss: 0.7035222053527832
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6860030144453049
  Validation Loss: 0.7027347683906555
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6883995682001114
  Validation Loss: 0.7019818425178528
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6843106895685196
  Validation Loss: 0.7011909484863281
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6880567371845245
  Validation Loss: 0.7004609107971191
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6817412823438644
  Validation Loss: 0.6996974349021912
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6770443618297577
  Validation Loss: 0.698955237865448
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6890222579240799
  Validation Loss: 0.6982348561286926
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6708892285823822
  Validation Loss: 0.697579026222229
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6819591522216797
  Validation Loss: 0.6968997716903687
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6979303508996964
  Validation Loss: 0.6962022185325623
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6915189772844315
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:57:INFO:
[92mINFO [0m:      Received: evaluate message 15caaf45-2296-43e8-9c99-f61da4a0e423
02/07/2025 22:49:57:INFO:Received: evaluate message 15caaf45-2296-43e8-9c99-f61da4a0e423
[92mINFO [0m:      Sent reply
02/07/2025 22:49:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:58:INFO:
[92mINFO [0m:      Received: train message ef446c9d-3fc9-4cf5-ac54-d7dfa2d23aa7
02/07/2025 22:49:58:INFO:Received: train message ef446c9d-3fc9-4cf5-ac54-d7dfa2d23aa7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6955273151397705
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6834623366594315
  Validation Loss: 0.6948990821838379
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6687453985214233
  Validation Loss: 0.6942626237869263
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6778077334165573
  Validation Loss: 0.6936153769493103
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6773168742656708
  Validation Loss: 0.6930461525917053
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6801810413599014
  Validation Loss: 0.6924543976783752
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 42/64:
  Train Loss: 0.6651010513305664
  Validation Loss: 0.6918619275093079
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 43/64:
  Train Loss: 0.6816823780536652
  Validation Loss: 0.6913033723831177
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 44/64:
  Train Loss: 0.6906378269195557
  Validation Loss: 0.6907463669776917
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 45/64:
  Train Loss: 0.6746042966842651
  Validation Loss: 0.690216064453125
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 46/64:
  Train Loss: 0.6707063615322113
  Validation Loss: 0.6896679997444153
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 47/64:
  Train Loss: 0.6853609085083008
  Validation Loss: 0.6891204118728638
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 48/64:
  Train Loss: 0.6746840626001358
  Validation Loss: 0.6885877847671509
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 49/64:
  Train Loss: 0.669318437576294
  Validation Loss: 0.688066840171814
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 50/64:
  Train Loss: 0.6820072680711746
  Validation Loss: 0.6875442862510681
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 51/64:
  Train Loss: 0.6684008091688156
  Validation Loss: 0.6870530247688293
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 52/64:
  Train Loss: 0.6624777615070343
  Validation Loss: 0.6865543723106384
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 53/64:
  Train Loss: 0.6741936057806015
  Validation Loss: 0.6861128807067871
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 54/64:
  Train Loss: 0.6630567759275436
  Validation Loss: 0.6856262683868408
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 55/64:
  Train Loss: 0.6735971122980118
  Validation Loss: 0.685166597366333
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 56/64:
  Train Loss: 0.6659859418869019
  Validation Loss: 0.684712290763855
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 57/64:
  Train Loss: 0.6689199060201645
  Validation Loss: 0.6842995882034302
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 58/64:
  Train Loss: 0.6690770983695984
  Validation Loss: 0.6838739514350891
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 59/64:
  Train Loss: 0.6615145355463028
  Validation Loss: 0.6834567189216614
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 60/64:
  Train Loss: 0.6623418480157852
  Validation Loss: 0.6830719113349915
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 61/64:
  Train Loss: 0.6719355285167694
  Validation Loss: 0.6826649308204651
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 62/64:
  Train Loss: 0.6812417656183243
  Validation Loss: 0.6822636723518372
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 63/64:
  Train Loss: 0.6665400117635727
  Validation Loss: 0.6818398237228394
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 64/64:
  Train Loss: 0.6695679426193237
  Validation Loss: 0.6814419031143188
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
{'train_loss': 0.6695679426193237, 'val_roc_auc': 1.0, 'val_accuracy': 1.0, 'val_loss': 0.6814419031143188}
 ROC_AUC: 1.0000|| Accuracy 1.0000 || Train Loss: 0.6696
 Val Loss: 0.6814 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7328432028213244
Test ROC-AUC: 0.8603896103896104
Test Accuracy: 0.7415730337078652
test_loss: 0.7328432028213244
test_roc_auc: 0.8603896103896104
test_accuracy: 0.7415730337078652
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.07004282982734367
Epoch 1/64:
  Train Loss: 0.7124720215797424
  Validation Loss: 0.6987078189849854
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.7023186534643173
  Validation Loss: 0.6977310180664062
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.7138252407312393
  Validation Loss: 0.6968163251876831
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.7071212828159332
  Validation Loss: 0.695863664150238
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6955900490283966
  Validation Loss: 0.6949294805526733
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.7011303454637527
  Validation Loss: 0.6939965486526489
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.7015992254018784
  Validation Loss: 0.6930934190750122
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6898782104253769
  Validation Loss: 0.692212700843811
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.70657679438591
  Validation Loss: 0.6913405060768127
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.7072175890207291
  Validation Loss: 0.6904716491699219
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6965287625789642
  Validation Loss: 0.689624011516571
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6921625882387161
  Validation Loss: 0.6887974143028259
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7047237455844879
  Validation Loss: 0.6879744529724121
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6875484734773636
  Validation Loss: 0.6871960163116455
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6969334185123444
  Validation Loss: 0.6864256858825684
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6974825859069824
  Validation Loss: 0.6856868863105774
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6942391395568848
  Validation Loss: 0.6849480867385864
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7001427114009857
  Validation Loss: 0.684223473072052
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6907250881195068
  Validation Loss: 0.6835222840309143
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6967625468969345
  Validation Loss: 0.6828339695930481
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6903593093156815
  Validation Loss: 0.6821652054786682
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6984727680683136
  Validation Loss: 0.6814999580383301
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6930441707372665
  Validation Loss: 0.6808415651321411
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6769993901252747
  Validation Loss: 0.6801995635032654
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6885394155979156
  Validation Loss: 0.6795862913131714
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.690624937415123
  Validation Loss: 0.6789623498916626
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:25:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:25:INFO:
[92mINFO [0m:      Received: evaluate message da171d71-2c78-4dcf-8c0a-289409ad6c60
02/07/2025 22:50:25:INFO:Received: evaluate message da171d71-2c78-4dcf-8c0a-289409ad6c60
[92mINFO [0m:      Sent reply
02/07/2025 22:50:27:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:27:INFO:
[92mINFO [0m:      Received: train message 57e4579e-ad2d-4b86-a6ef-00962a87fd27
02/07/2025 22:50:27:INFO:Received: train message 57e4579e-ad2d-4b86-a6ef-00962a87fd27
  Train Loss: 0.6853347569704056
  Validation Loss: 0.6783638596534729
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6804482936859131
  Validation Loss: 0.6777763366699219
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6901940107345581
  Validation Loss: 0.6772032380104065
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6906461864709854
  Validation Loss: 0.6766451001167297
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6736079007387161
  Validation Loss: 0.6760926246643066
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6906473487615585
  Validation Loss: 0.6755596399307251
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.682316929101944
  Validation Loss: 0.6750388145446777
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6814357936382294
  Validation Loss: 0.674523651599884
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6778068244457245
  Validation Loss: 0.6740239262580872
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6900844722986221
  Validation Loss: 0.6735352277755737
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6907685548067093
  Validation Loss: 0.6730339527130127
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.685660719871521
  Validation Loss: 0.6725336909294128
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6756182014942169
  Validation Loss: 0.6720545887947083
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.659471333026886
  Validation Loss: 0.6715869307518005
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6710210889577866
  Validation Loss: 0.6711052656173706
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6783435493707657
  Validation Loss: 0.6706480979919434
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6784901022911072
  Validation Loss: 0.6701808571815491
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6715592294931412
  Validation Loss: 0.6697513461112976
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6753991395235062
  Validation Loss: 0.6693207621574402
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6785584837198257
  Validation Loss: 0.6688976287841797
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6820695251226425
  Validation Loss: 0.6684971451759338
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.681051954627037
  Validation Loss: 0.6681190729141235
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6680974662303925
  Validation Loss: 0.6677346229553223
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6763463169336319
  Validation Loss: 0.6673596501350403
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6685646176338196
  Validation Loss: 0.666984498500824
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6720812022686005
  Validation Loss: 0.666612982749939
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.673917606472969
  Validation Loss: 0.666247546672821
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6682811081409454
  Validation Loss: 0.6659014821052551
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6797331422567368
  Validation Loss: 0.6655681729316711
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6737466901540756
  Validation Loss: 0.6652141213417053
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6750174462795258
  Validation Loss: 0.6648794412612915
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6672906279563904
  Validation Loss: 0.6645408868789673
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6620346903800964
  Validation Loss: 0.6642283201217651
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6655358821153641
  Validation Loss: 0.6639138460159302
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6712389588356018
  Validation Loss: 0.6635875105857849
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6751688420772552
  Validation Loss: 0.6632771492004395
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6670752167701721
  Validation Loss: 0.6629521250724792
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.670641228556633
  Validation Loss: 0.6626438498497009
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.670641228556633, 'val_roc_auc': 0.9529411764705882, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6626438498497009}
 ROC_AUC: 0.9529|| Accuracy 0.9259 || Train Loss: 0.6706
 Val Loss: 0.6626 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7282238974330131
Test ROC-AUC: 0.863095238095238
Test Accuracy: 0.7640449438202247
test_loss: 0.7282238974330131
test_roc_auc: 0.863095238095238
test_accuracy: 0.7640449438202247
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.06690415479738476
Epoch 1/64:
  Train Loss: 0.6913959830999374
  Validation Loss: 0.7200756669044495
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.7079717367887497
  Validation Loss: 0.7189398407936096
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.7080539017915726
  Validation Loss: 0.7177861332893372
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6957470327615738
  Validation Loss: 0.716701328754425
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6990502327680588
  Validation Loss: 0.7156346440315247
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6804199367761612
  Validation Loss: 0.7145114541053772
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6936659663915634
  Validation Loss: 0.7134683728218079
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6917705982923508
  Validation Loss: 0.7124491333961487
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6844573616981506
  Validation Loss: 0.7114664912223816
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6766367703676224
  Validation Loss: 0.7104925513267517
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6947254091501236
  Validation Loss: 0.7094988226890564
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6946800351142883
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.7085188627243042
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6813670545816422
  Validation Loss: 0.7075760364532471
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6941743642091751
  Validation Loss: 0.7066585421562195
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.685406967997551
  Validation Loss: 0.7057235240936279
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6876078099012375
  Validation Loss: 0.704853355884552
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6817588657140732
  Validation Loss: 0.7039800882339478
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6847627311944962
  Validation Loss: 0.703124463558197
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6821387410163879
  Validation Loss: 0.7022984623908997
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6817031502723694
  Validation Loss: 0.7014937400817871
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6826403141021729
  Validation Loss: 0.7006832361221313
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6744373589754105
  Validation Loss: 0.69990074634552
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6853449493646622
  Validation Loss: 0.6991155743598938
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6759704649448395
  Validation Loss: 0.6983700394630432
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6756222993135452
  Validation Loss: 0.6976238489151001
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6826144605875015
  Validation Loss: 0.6968689560890198
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6719961613416672
  Validation Loss: 0.6961661577224731
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6723028123378754
  Validation Loss: 0.695472240447998
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6772910952568054
  Validation Loss: 0.6948280334472656
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.687139555811882
  Validation Loss: 0.6941493153572083
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6762070208787918
  Validation Loss: 0.6935084462165833
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6650220453739166
  Validation Loss: 0.6928538084030151
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6833140701055527
  Validation Loss: 0.6922159790992737
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6801160126924515
  Validation Loss: 0.6915545463562012
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6758244335651398
  Validation Loss: 0.6908996105194092
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6839864552021027
  Validation Loss: 0.6902828812599182
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.670317530632019
  Validation Loss: 0.6896812319755554
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6633240431547165
  Validation Loss: 0.6891065835952759
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6685568690299988
  Validation Loss: 0.688532292842865
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.669523686170578
  Validation Loss: 0.6879563331604004
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6596732884645462
  Validation Loss: 0.6873968839645386
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6654110699892044
  Validation Loss: 0.6868167519569397
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6559392213821411
  Validation Loss: 0.6862881779670715
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6655919700860977
  Validation Loss: 0.6857749223709106
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6677006781101227
  Validation Loss: 0.6852740049362183
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.667306050658226
  Validation Loss: 0.6847789883613586
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6731716990470886
  Validation Loss: 0.6842823624610901
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6742910891771317
  Validation Loss: 0.6838229894638062
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6585051417350769
  Validation Loss: 0.6833562254905701
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6706604659557343
  Validation Loss: 0.6828746199607849
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6699472516775131
  Validation Loss: 0.6823973059654236
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6725127547979355
  Validation Loss: 0.6819543242454529
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.672152504324913
  Validation Loss: 0.6815288662910461
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6684634536504745
  Validation Loss: 0.6811129450798035
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6614944338798523
  Validation Loss: 0.680663526058197
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6687561869621277
  Validation Loss: 0.6802533268928528
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6573289781808853
  Validation Loss: 0.6798385381698608
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6680656522512436
  Validation Loss: 0.6794498562812805
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6586536318063736
  Validation Loss: 0.6790720820426941
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6660739630460739
  Validation Loss: 0.6787126660346985
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6708176732063293
  Validation Loss: 0.6783623695373535
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6709241420030594
  Validation Loss: 0.6780112385749817
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6581023037433624
  Validation Loss: 0.6776734590530396
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6687088459730148
  Validation Loss: 0.6773172616958618
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6687088459730148, 'val_roc_auc': 0.993421052631579, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6773172616958618}
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:56:INFO:
[92mINFO [0m:      Received: evaluate message b4da4701-cf77-48b2-bef2-993ee527ac2e
02/07/2025 22:50:56:INFO:Received: evaluate message b4da4701-cf77-48b2-bef2-993ee527ac2e
[92mINFO [0m:      Sent reply
02/07/2025 22:50:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:59:INFO:
[92mINFO [0m:      Received: train message 931e7297-700b-43a0-b891-af224368c57d
02/07/2025 22:50:59:INFO:Received: train message 931e7297-700b-43a0-b891-af224368c57d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
 ROC_AUC: 0.9934|| Accuracy 0.9630 || Train Loss: 0.6687
 Val Loss: 0.6773 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7238151176591937
Test ROC-AUC: 0.8701298701298702
Test Accuracy: 0.7528089887640449
test_loss: 0.7238151176591937
test_roc_auc: 0.8701298701298702
test_accuracy: 0.7528089887640449
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.1202199489762279
Epoch 1/64:
  Train Loss: 0.6803814172744751
  Validation Loss: 0.7096865773200989
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.67152139544487
  Validation Loss: 0.7088448405265808
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.689716026186943
  Validation Loss: 0.7079727053642273
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6925899982452393
  Validation Loss: 0.707099199295044
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6891406625509262
  Validation Loss: 0.7062814831733704
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6964382827281952
  Validation Loss: 0.7055011987686157
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6912871450185776
  Validation Loss: 0.704723060131073
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6814858913421631
  Validation Loss: 0.7039479613304138
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6968155950307846
  Validation Loss: 0.7032619118690491
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.688082367181778
  Validation Loss: 0.7025241255760193
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.696506604552269
  Validation Loss: 0.7018057107925415
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6933662444353104
  Validation Loss: 0.7010974287986755
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7003977745771408
  Validation Loss: 0.7004181146621704
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.690077930688858
  Validation Loss: 0.6996871829032898
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6817887425422668
  Validation Loss: 0.6990162134170532
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6767650842666626
  Validation Loss: 0.6983461976051331
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6843720972537994
  Validation Loss: 0.6976918578147888
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6845795065164566
  Validation Loss: 0.6970182657241821
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6926480084657669
  Validation Loss: 0.6963809728622437
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6864560842514038
  Validation Loss: 0.6957663297653198
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.689778283238411
  Validation Loss: 0.6951740384101868
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6794488430023193
  Validation Loss: 0.6945831775665283
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6834925562143326
  Validation Loss: 0.6940137147903442
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6788959950208664
  Validation Loss: 0.6934639811515808
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6838183104991913
  Validation Loss: 0.6928871870040894
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6863972842693329
  Validation Loss: 0.6923274397850037
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6740437000989914
  Validation Loss: 0.6917765736579895
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6795777678489685
  Validation Loss: 0.6912249326705933
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6824827492237091
  Validation Loss: 0.6906935572624207
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6801568418741226
  Validation Loss: 0.690159261226654
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6779780238866806
  Validation Loss: 0.6896464228630066
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6795029193162918
  Validation Loss: 0.68914794921875
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6654504835605621
  Validation Loss: 0.6886630654335022
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6782740652561188
  Validation Loss: 0.6881614923477173
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6733031570911407
  Validation Loss: 0.6876764893531799
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6748950630426407
  Validation Loss: 0.6872209906578064
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6660506725311279
  Validation Loss: 0.6867905855178833
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6808726489543915
  Validation Loss: 0.686363160610199
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6724115312099457
  Validation Loss: 0.6859383583068848
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6665777266025543
  Validation Loss: 0.6855224370956421
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6784008890390396
  Validation Loss: 0.6851046681404114
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6643591374158859
  Validation Loss: 0.6847123503684998
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6727459579706192
  Validation Loss: 0.6843540668487549
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6614681929349899
  Validation Loss: 0.6839774250984192
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6626149415969849
  Validation Loss: 0.683624267578125
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6600896716117859
  Validation Loss: 0.6832339763641357
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6701783835887909
  Validation Loss: 0.6828757524490356
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.66522516310215
  Validation Loss: 0.6825366616249084
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6571617722511292
  Validation Loss: 0.6821727156639099
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6649309396743774
  Validation Loss: 0.6818371415138245
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6523246169090271
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:51:31:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:31:INFO:
[92mINFO [0m:      Received: evaluate message a9a03174-e3ff-4e0d-8c3f-7bf110ab80a2
02/07/2025 22:51:31:INFO:Received: evaluate message a9a03174-e3ff-4e0d-8c3f-7bf110ab80a2
[92mINFO [0m:      Sent reply
02/07/2025 22:51:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:34:INFO:
[92mINFO [0m:      Received: train message 0da08197-91f2-4225-8746-1fe70abf679b
02/07/2025 22:51:34:INFO:Received: train message 0da08197-91f2-4225-8746-1fe70abf679b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.681459903717041
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6553022265434265
  Validation Loss: 0.6811432838439941
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6634130924940109
  Validation Loss: 0.680848240852356
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6694782078266144
  Validation Loss: 0.6805399060249329
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6625592559576035
  Validation Loss: 0.6802214980125427
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6704994738101959
  Validation Loss: 0.6799208521842957
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6665701866149902
  Validation Loss: 0.6796239018440247
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6579196453094482
  Validation Loss: 0.6793364882469177
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6553061008453369
  Validation Loss: 0.6790432333946228
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6592869907617569
  Validation Loss: 0.6787682175636292
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6730179190635681
  Validation Loss: 0.6784951090812683
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6586471945047379
  Validation Loss: 0.67823326587677
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6548565179109573
  Validation Loss: 0.6779667735099792
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6538342088460922
  Validation Loss: 0.677716851234436
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6538342088460922, 'val_roc_auc': 0.9938271604938271, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.677716851234436}
 ROC_AUC: 0.9938|| Accuracy 0.9630 || Train Loss: 0.6538
 Val Loss: 0.6777 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7197347966472755
Test ROC-AUC: 0.8744588744588745
Test Accuracy: 0.7865168539325843
test_loss: 0.7197347966472755
test_roc_auc: 0.8744588744588745
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.13291333639699587
Epoch 1/64:
  Train Loss: 0.7124695181846619
  Validation Loss: 0.6254526376724243
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.7138036638498306
  Validation Loss: 0.6246504187583923
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.7128161042928696
  Validation Loss: 0.6238030195236206
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.7020828276872635
  Validation Loss: 0.6230374574661255
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6960541605949402
  Validation Loss: 0.622300386428833
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.7106561064720154
  Validation Loss: 0.6215977072715759
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.7116845101118088
  Validation Loss: 0.6209034323692322
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.7093582898378372
  Validation Loss: 0.6202636957168579
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7075891047716141
  Validation Loss: 0.6196752786636353
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6950624585151672
  Validation Loss: 0.6190474033355713
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.7031267881393433
  Validation Loss: 0.6183879375457764
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.7064045518636703
  Validation Loss: 0.6177241206169128
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7116090506315231
  Validation Loss: 0.6170879602432251
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6937379539012909
  Validation Loss: 0.6165066957473755
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6934869140386581
  Validation Loss: 0.6159519553184509
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6925665140151978
  Validation Loss: 0.6153773665428162
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.7062366604804993
  Validation Loss: 0.614795982837677
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6992447972297668
  Validation Loss: 0.6142714023590088
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7069078087806702
  Validation Loss: 0.6137292981147766
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6959335505962372
  Validation Loss: 0.6131609678268433
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6931236833333969
  Validation Loss: 0.6126357913017273
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.697296530008316
  Validation Loss: 0.6120947599411011
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6989402174949646
  Validation Loss: 0.6116225719451904
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6959561258554459
  Validation Loss: 0.6111045479774475
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6900565028190613
  Validation Loss: 0.6106296181678772
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6909483820199966
  Validation Loss: 0.6101649403572083
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.7001987248659134
  Validation Loss: 0.6097146272659302
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6902317255735397
  Validation Loss: 0.6092702150344849
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6916122436523438
  Validation Loss: 0.6088567972183228
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6922290772199631
  Validation Loss: 0.6084213256835938
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6809745281934738
  Validation Loss: 0.6080150008201599
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6817503422498703
  Validation Loss: 0.6076318025588989
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6904598474502563
  Validation Loss: 0.6072661876678467
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6877023130655289
  Validation Loss: 0.6069042682647705
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6977391093969345
  Validation Loss: 0.6065182089805603
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6956276446580887
  Validation Loss: 0.6061397194862366
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:04:INFO:
[92mINFO [0m:      Received: evaluate message 26eab27b-a3dc-4953-a1dc-e3bc778df140
02/07/2025 22:52:04:INFO:Received: evaluate message 26eab27b-a3dc-4953-a1dc-e3bc778df140
[92mINFO [0m:      Sent reply
02/07/2025 22:52:06:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:06:INFO:
[92mINFO [0m:      Received: train message 67cf6680-c9c7-4b49-9a5f-23f7eb694db5
02/07/2025 22:52:06:INFO:Received: train message 67cf6680-c9c7-4b49-9a5f-23f7eb694db5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6956759989261627
  Validation Loss: 0.6057780385017395
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.679842159152031
  Validation Loss: 0.6054213047027588
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6840932965278625
  Validation Loss: 0.6050417423248291
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6941644549369812
  Validation Loss: 0.6046451330184937
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6788938790559769
  Validation Loss: 0.6042690873146057
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6895239651203156
  Validation Loss: 0.6039227843284607
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6750642359256744
  Validation Loss: 0.603601336479187
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6746019273996353
  Validation Loss: 0.6032797694206238
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6763894557952881
  Validation Loss: 0.6029601693153381
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6691639870405197
  Validation Loss: 0.6026971936225891
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6788040995597839
  Validation Loss: 0.6024035811424255
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6857099235057831
  Validation Loss: 0.6021085977554321
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6828515231609344
  Validation Loss: 0.6017903685569763
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.674691691994667
  Validation Loss: 0.6015304327011108
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6690484881401062
  Validation Loss: 0.6012260317802429
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6816404312849045
  Validation Loss: 0.600958526134491
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6758672893047333
  Validation Loss: 0.600670576095581
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6715457886457443
  Validation Loss: 0.6003860831260681
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6724789142608643
  Validation Loss: 0.6001223921775818
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6769590973854065
  Validation Loss: 0.599888265132904
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6800307035446167
  Validation Loss: 0.5996325016021729
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6790188550949097
  Validation Loss: 0.5994314551353455
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6810282617807388
  Validation Loss: 0.5992100834846497
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6781818121671677
  Validation Loss: 0.598980188369751
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6709906160831451
  Validation Loss: 0.5987346768379211
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6804863959550858
  Validation Loss: 0.598477303981781
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6756874024868011
  Validation Loss: 0.5982615947723389
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6704680919647217
  Validation Loss: 0.5980252623558044
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6704680919647217, 'val_roc_auc': 0.978021978021978, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.5980252623558044}
 ROC_AUC: 0.9780|| Accuracy 0.9259 || Train Loss: 0.6705
 Val Loss: 0.5980 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7159173769897289
Test ROC-AUC: 0.8744588744588744
Test Accuracy: 0.7865168539325843
test_loss: 0.7159173769897289
test_roc_auc: 0.8744588744588744
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.10473093901055108
Epoch 1/64:
  Train Loss: 0.6982236802577972
  Validation Loss: 0.6762568950653076
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 2/64:
  Train Loss: 0.7005218267440796
  Validation Loss: 0.6756156086921692
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 3/64:
  Train Loss: 0.6858434826135635
  Validation Loss: 0.6750187277793884
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 4/64:
  Train Loss: 0.7005154341459274
  Validation Loss: 0.6744200587272644
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.6881476640701294
  Validation Loss: 0.6738373637199402
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.6978658884763718
  Validation Loss: 0.67326420545578
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.6835823953151703
  Validation Loss: 0.67268306016922
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.6937240213155746
  Validation Loss: 0.6721186637878418
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.6860135942697525
  Validation Loss: 0.6715421080589294
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6699976474046707
  Validation Loss: 0.6709505319595337
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6887843906879425
  Validation Loss: 0.6704316139221191
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.6807376742362976
  Validation Loss: 0.6699344515800476
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.6818304359912872
  Validation Loss: 0.6694281101226807
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.668964684009552
  Validation Loss: 0.6689323782920837
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6857377290725708
  Validation Loss: 0.6684592962265015
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.6799651384353638
  Validation Loss: 0.6679829359054565
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6878440082073212
  Validation Loss: 0.667515218257904
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.6753959357738495
  Validation Loss: 0.6671076416969299
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6724061220884323
  Validation Loss: 0.6666957139968872
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6827577203512192
  Validation Loss: 0.6662524342536926
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6786612421274185
  Validation Loss: 0.6658183336257935
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:34:INFO:
[92mINFO [0m:      Received: evaluate message 82e72ed2-95e6-4f5b-b012-75f2ed4943fd
02/07/2025 22:52:34:INFO:Received: evaluate message 82e72ed2-95e6-4f5b-b012-75f2ed4943fd
[92mINFO [0m:      Sent reply
02/07/2025 22:52:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:35:INFO:
[92mINFO [0m:      Received: train message 30b8e815-fd28-44ff-9949-ba15acb504ad
02/07/2025 22:52:35:INFO:Received: train message 30b8e815-fd28-44ff-9949-ba15acb504ad
Epoch 22/64:
  Train Loss: 0.6725980788469315
  Validation Loss: 0.6654018759727478
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6785231679677963
  Validation Loss: 0.6650005578994751
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6793206483125687
  Validation Loss: 0.6645918488502502
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6904824376106262
  Validation Loss: 0.6641958951950073
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6826001405715942
  Validation Loss: 0.6638514399528503
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6741594970226288
  Validation Loss: 0.6635028719902039
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6656874865293503
  Validation Loss: 0.6631580591201782
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6638568788766861
  Validation Loss: 0.6628136038780212
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6773806065320969
  Validation Loss: 0.6624596118927002
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6785572469234467
  Validation Loss: 0.6621248722076416
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6740519851446152
  Validation Loss: 0.6618111729621887
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6767195612192154
  Validation Loss: 0.6615031361579895
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6738128811120987
  Validation Loss: 0.6611886024475098
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6718410402536392
  Validation Loss: 0.6608670353889465
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6859282106161118
  Validation Loss: 0.6605391502380371
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6741697490215302
  Validation Loss: 0.6602259278297424
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6713370084762573
  Validation Loss: 0.6599160432815552
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6683531403541565
  Validation Loss: 0.6596416234970093
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6647573411464691
  Validation Loss: 0.6593472361564636
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6491891145706177
  Validation Loss: 0.6590688824653625
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6771380305290222
  Validation Loss: 0.6588115096092224
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6598993241786957
  Validation Loss: 0.6585632562637329
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6695558130741119
  Validation Loss: 0.6583316326141357
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6587417274713516
  Validation Loss: 0.6581088900566101
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6572232395410538
  Validation Loss: 0.6578940749168396
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6596979945898056
  Validation Loss: 0.6576896905899048
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6639738529920578
  Validation Loss: 0.6575065851211548
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6733451187610626
  Validation Loss: 0.6573086380958557
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6673651933670044
  Validation Loss: 0.6571221351623535
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.656000092625618
  Validation Loss: 0.6569373607635498
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.664567232131958
  Validation Loss: 0.6567685008049011
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6735742092132568
  Validation Loss: 0.6565979719161987
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6543429791927338
  Validation Loss: 0.6564398407936096
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6695850044488907
  Validation Loss: 0.6562396287918091
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6609313935041428
  Validation Loss: 0.6560900807380676
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6592297703027725
  Validation Loss: 0.6559247374534607
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6626904159784317
  Validation Loss: 0.6557571291923523
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6580263823270798
  Validation Loss: 0.6555927395820618
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6623218655586243
  Validation Loss: 0.6554383635520935
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6587073653936386
  Validation Loss: 0.6552685499191284
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6492016762495041
  Validation Loss: 0.6551130414009094
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6611318588256836
  Validation Loss: 0.6550013422966003
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6653991341590881
  Validation Loss: 0.6548857092857361
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6653991341590881, 'val_roc_auc': 0.9588235294117647, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6548857092857361}
 ROC_AUC: 0.9588|| Accuracy 0.9630 || Train Loss: 0.6654
 Val Loss: 0.6549 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7124059893442004
Test ROC-AUC: 0.8766233766233766
Test Accuracy: 0.7865168539325843
test_loss: 0.7124059893442004
test_roc_auc: 0.8766233766233766
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.1528864488685334
Epoch 1/64:
  Train Loss: 0.6757056266069412
  Validation Loss: 0.6852774620056152
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6945623010396957
  Validation Loss: 0.684592068195343
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6818718314170837
  Validation Loss: 0.6839082837104797
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6918839514255524
  Validation Loss: 0.683255672454834
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6825212687253952
  Validation Loss: 0.6826293468475342
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6748183071613312
  Validation Loss: 0.6819888353347778
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6891943216323853
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6813598275184631
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.691271647810936
  Validation Loss: 0.6807471513748169
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.681934118270874
  Validation Loss: 0.6801639795303345
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6709613353013992
  Validation Loss: 0.6796011924743652
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6820369064807892
  Validation Loss: 0.6790305376052856
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6887782365083694
  Validation Loss: 0.6784745454788208
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.6703339666128159
  Validation Loss: 0.677924394607544
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6840878278017044
  Validation Loss: 0.677369236946106
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6675641238689423
  Validation Loss: 0.6768337488174438
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.6734918802976608
  Validation Loss: 0.6762829422950745
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6707867980003357
  Validation Loss: 0.6757698059082031
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6914316564798355
  Validation Loss: 0.675250232219696
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.679357185959816
  Validation Loss: 0.6747338175773621
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.6627053320407867
  Validation Loss: 0.6742180585861206
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6676319688558578
  Validation Loss: 0.6736857891082764
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6727518439292908
  Validation Loss: 0.673212468624115
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.6701731085777283
  Validation Loss: 0.6727383732795715
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.6685638278722763
  Validation Loss: 0.6722821593284607
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.6694609373807907
  Validation Loss: 0.6718391180038452
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6816487461328506
  Validation Loss: 0.6713786125183105
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.6759865581989288
  Validation Loss: 0.6709491610527039
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6721630692481995
  Validation Loss: 0.6705141663551331
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6628016829490662
  Validation Loss: 0.6700880527496338
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.6761369109153748
  Validation Loss: 0.6696871519088745
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.6710977107286453
  Validation Loss: 0.6693001389503479
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.6717339009046555
  Validation Loss: 0.6689262390136719
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6585101336240768
  Validation Loss: 0.6685738563537598
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6604849100112915
  Validation Loss: 0.6682102084159851
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6725559383630753
  Validation Loss: 0.667869508266449
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6675234287977219
  Validation Loss: 0.667492687702179
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6719216704368591
  Validation Loss: 0.6671393513679504
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6760551780462265
  Validation Loss: 0.6667870879173279
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.666518360376358
  Validation Loss: 0.6664358973503113
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6492851227521896
  Validation Loss: 0.6660798192024231
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.674283042550087
  Validation Loss: 0.6657612919807434
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6672752201557159
  Validation Loss: 0.665435791015625
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6716790348291397
  Validation Loss: 0.6651291251182556
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6564299464225769
  Validation Loss: 0.6648128032684326
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6663804948329926
  Validation Loss: 0.6644967198371887
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6572859585285187
  Validation Loss: 0.6641740202903748
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6546437293291092
  Validation Loss: 0.663837730884552
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6701271384954453
  Validation Loss: 0.6635355353355408
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6613103747367859
  Validation Loss: 0.6632595062255859
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6494294703006744
  Validation Loss: 0.6629835367202759
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.665255069732666
  Validation Loss: 0.6627295017242432
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6554274260997772
  Validation Loss: 0.6624710559844971
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6744735240936279
  Validation Loss: 0.6622046232223511
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6668015420436859
  Validation Loss: 0.6619438529014587
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6733537912368774
  Validation Loss: 0.6616925597190857
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6596833616495132
  Validation Loss: 0.661435604095459
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6775671988725662
  Validation Loss: 0.6611931324005127
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6690165102481842
  Validation Loss: 0.6609669327735901
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6550157219171524
  Validation Loss: 0.6607407927513123
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.660117119550705
  Validation Loss: 0.6605311632156372
  Val ROC-AUC: 0.9647058823529411
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: evaluate message 1f8a5485-b0ed-4be0-8bf8-c0ff13e62562
02/07/2025 22:53:04:INFO:Received: evaluate message 1f8a5485-b0ed-4be0-8bf8-c0ff13e62562
[92mINFO [0m:      Sent reply
02/07/2025 22:53:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: train message e897e235-313b-4f55-ac66-88972a118f29
02/07/2025 22:53:04:INFO:Received: train message e897e235-313b-4f55-ac66-88972a118f29
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6581708788871765
  Validation Loss: 0.6603296399116516
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6543392837047577
  Validation Loss: 0.6601235270500183
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6594116687774658
  Validation Loss: 0.6599157452583313
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6572240591049194
  Validation Loss: 0.6597217917442322
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6572240591049194, 'val_roc_auc': 0.9647058823529411, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6597217917442322}
 ROC_AUC: 0.9647|| Accuracy 0.9259 || Train Loss: 0.6572
 Val Loss: 0.6597 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7091671285334598
Test ROC-AUC: 0.8782467532467532
Test Accuracy: 0.797752808988764
test_loss: 0.7091671285334598
test_roc_auc: 0.8782467532467532
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.17555469355708436
Epoch 1/64:
  Train Loss: 0.6675553172826767
  Validation Loss: 0.7797828912734985
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 2/64:
  Train Loss: 0.6336281076073647
  Validation Loss: 0.7793270945549011
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 3/64:
  Train Loss: 0.6596745550632477
  Validation Loss: 0.7788909673690796
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 4/64:
  Train Loss: 0.6516718715429306
  Validation Loss: 0.7784959077835083
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 5/64:
  Train Loss: 0.6489499062299728
  Validation Loss: 0.778045117855072
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 6/64:
  Train Loss: 0.6508489698171616
  Validation Loss: 0.7775219082832336
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 7/64:
  Train Loss: 0.6392259746789932
  Validation Loss: 0.7769185304641724
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 8/64:
  Train Loss: 0.660036638379097
  Validation Loss: 0.7764080166816711
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 9/64:
  Train Loss: 0.6540417671203613
  Validation Loss: 0.7758793234825134
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 10/64:
  Train Loss: 0.6372144967317581
  Validation Loss: 0.77541184425354
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 11/64:
  Train Loss: 0.6512870490550995
  Validation Loss: 0.7749943137168884
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 12/64:
  Train Loss: 0.6599236875772476
  Validation Loss: 0.7745362520217896
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 13/64:
  Train Loss: 0.6490394920110703
  Validation Loss: 0.7741368412971497
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 14/64:
  Train Loss: 0.6379000246524811
  Validation Loss: 0.7737331986427307
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 15/64:
  Train Loss: 0.6590680181980133
  Validation Loss: 0.7732601761817932
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 16/64:
  Train Loss: 0.6536442637443542
  Validation Loss: 0.7728326916694641
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 17/64:
  Train Loss: 0.6530113965272903
  Validation Loss: 0.7724030017852783
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 18/64:
  Train Loss: 0.6442674696445465
  Validation Loss: 0.7719405293464661
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.6576522141695023
  Validation Loss: 0.7714529037475586
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.6451115757226944
  Validation Loss: 0.7709940671920776
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.6501418352127075
  Validation Loss: 0.7705622315406799
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.6449181586503983
  Validation Loss: 0.7701123356819153
  Val ROC-AUC: 0.6190476190476191
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.6462646722793579
  Validation Loss: 0.7696810960769653
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.644488513469696
  Validation Loss: 0.7692707180976868
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.6385008841753006
  Validation Loss: 0.7689169049263
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.6484528630971909
  Validation Loss: 0.768580436706543
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.651731088757515
  Validation Loss: 0.7681757807731628
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6400408148765564
  Validation Loss: 0.767738938331604
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6494321227073669
  Validation Loss: 0.7674124240875244
  Val ROC-AUC: 0.6349206349206349
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6497327983379364
  Validation Loss: 0.7670460343360901
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6375500857830048
  Validation Loss: 0.7666698098182678
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6421425044536591
  Validation Loss: 0.7662826180458069
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6437547504901886
  Validation Loss: 0.7658699750900269
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6480506956577301
  Validation Loss: 0.765498697757721
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6439013928174973
  Validation Loss: 0.765174150466919
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6419912725687027
  Validation Loss: 0.7647907137870789
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6357365697622299
  Validation Loss: 0.7643566727638245
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6349592953920364
  Validation Loss: 0.7639386057853699
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6365074515342712
  Validation Loss: 0.7635800242424011
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6532277762889862
  Validation Loss: 0.7633110880851746
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6394204646348953
  Validation Loss: 0.7630505561828613
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6397344172000885
  Validation Loss: 0.7627274394035339
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6391233205795288
  Validation Loss: 0.7623874545097351
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6391220986843109
  Validation Loss: 0.762040913105011
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.6380511671304703
  Validation Loss: 0.7617514133453369
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:30:INFO:
[92mINFO [0m:      Received: evaluate message fac2413e-f23d-44a9-8afd-8913c57f77d4
02/07/2025 22:53:30:INFO:Received: evaluate message fac2413e-f23d-44a9-8afd-8913c57f77d4
[92mINFO [0m:      Sent reply
02/07/2025 22:53:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:33:INFO:
[92mINFO [0m:      Received: train message ee217392-86a7-43ea-b6ae-ae6c86c5ba31
02/07/2025 22:53:33:INFO:Received: train message ee217392-86a7-43ea-b6ae-ae6c86c5ba31
