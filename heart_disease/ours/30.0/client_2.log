nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:44:55:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:44:55:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 22:44:55:DEBUG:ChannelConnectivity.IDLE
02/07/2025 22:44:55:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738997095.952698 1773001 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/07/2025 22:44:59:INFO:
[92mINFO [0m:      Received: train message 28a36efd-56b4-48b9-b6ae-af78b2cf31ac
02/07/2025 22:44:59:INFO:Received: train message 28a36efd-56b4-48b9-b6ae-af78b2cf31ac
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours/30.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours']
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.12603650725850457
Epoch 1/64:
  Train Loss: 0.7611480057239532
  Validation Loss: 0.7939112782478333
  Val ROC-AUC: 0.5617283950617284
  Val Accuracy: 0.5185185074806213
Epoch 2/64:
  Train Loss: 0.7590620815753937
  Validation Loss: 0.7926821708679199
  Val ROC-AUC: 0.5679012345679013
  Val Accuracy: 0.5185185074806213
Epoch 3/64:
  Train Loss: 0.764098659157753
  Validation Loss: 0.7914349436759949
  Val ROC-AUC: 0.5740740740740741
  Val Accuracy: 0.5185185074806213
Epoch 4/64:
  Train Loss: 0.7702983468770981
  Validation Loss: 0.7902129888534546
  Val ROC-AUC: 0.5802469135802468
  Val Accuracy: 0.5185185074806213
Epoch 5/64:
  Train Loss: 0.7598583549261093
  Validation Loss: 0.7889729738235474
  Val ROC-AUC: 0.5987654320987654
  Val Accuracy: 0.5555555820465088
Epoch 6/64:
  Train Loss: 0.7620630115270615
  Validation Loss: 0.7877536416053772
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.5555555820465088
Epoch 7/64:
  Train Loss: 0.7596922218799591
  Validation Loss: 0.7865039706230164
  Val ROC-AUC: 0.6172839506172839
  Val Accuracy: 0.5925925970077515
Epoch 8/64:
  Train Loss: 0.760659784078598
  Validation Loss: 0.7853123545646667
  Val ROC-AUC: 0.6234567901234568
  Val Accuracy: 0.5925925970077515
Epoch 9/64:
  Train Loss: 0.7472141534090042
  Validation Loss: 0.784081757068634
  Val ROC-AUC: 0.6296296296296297
  Val Accuracy: 0.5925925970077515
Epoch 10/64:
  Train Loss: 0.7474689930677414
  Validation Loss: 0.7828555703163147
  Val ROC-AUC: 0.6358024691358024
  Val Accuracy: 0.5925925970077515
Epoch 11/64:
  Train Loss: 0.7497508823871613
  Validation Loss: 0.7816450595855713
  Val ROC-AUC: 0.6481481481481481
  Val Accuracy: 0.5925925970077515
Epoch 12/64:
  Train Loss: 0.7628934383392334
  Validation Loss: 0.7804438471794128
  Val ROC-AUC: 0.654320987654321
  Val Accuracy: 0.5925925970077515
Epoch 13/64:
  Train Loss: 0.7486122697591782
  Validation Loss: 0.7792559862136841
  Val ROC-AUC: 0.6851851851851851
  Val Accuracy: 0.5925925970077515
Epoch 14/64:
  Train Loss: 0.7435182332992554
  Validation Loss: 0.7780531644821167
  Val ROC-AUC: 0.6851851851851851
  Val Accuracy: 0.6296296119689941
Epoch 15/64:
  Train Loss: 0.742502361536026
  Validation Loss: 0.7769021987915039
  Val ROC-AUC: 0.691358024691358
  Val Accuracy: 0.6296296119689941
Epoch 16/64:
  Train Loss: 0.7437002956867218
  Validation Loss: 0.7757828235626221
  Val ROC-AUC: 0.6975308641975309
  Val Accuracy: 0.6296296119689941
Epoch 17/64:
  Train Loss: 0.7426781505346298
  Validation Loss: 0.7746796607971191
  Val ROC-AUC: 0.7037037037037037
  Val Accuracy: 0.6296296119689941
Epoch 18/64:
  Train Loss: 0.7335821837186813
  Validation Loss: 0.7735641002655029
  Val ROC-AUC: 0.7160493827160495
  Val Accuracy: 0.6296296119689941
Epoch 19/64:
  Train Loss: 0.739931732416153
  Validation Loss: 0.772459089756012
  Val ROC-AUC: 0.7222222222222222
  Val Accuracy: 0.6296296119689941
Epoch 20/64:
  Train Loss: 0.7253018021583557
  Validation Loss: 0.7714206576347351
  Val ROC-AUC: 0.7222222222222223
  Val Accuracy: 0.6296296119689941
Epoch 21/64:
  Train Loss: 0.7339726537466049
  Validation Loss: 0.7703857421875
  Val ROC-AUC: 0.7283950617283951
  Val Accuracy: 0.6296296119689941
Epoch 22/64:
  Train Loss: 0.7250351458787918
  Validation Loss: 0.7693518996238708
  Val ROC-AUC: 0.7345679012345678
  Val Accuracy: 0.6296296119689941
Epoch 23/64:
  Train Loss: 0.7320300787687302
  Validation Loss: 0.7683239579200745
  Val ROC-AUC: 0.7407407407407408
  Val Accuracy: 0.6666666865348816
Epoch 24/64:
  Train Loss: 0.7295189201831818
  Validation Loss: 0.7673298716545105
  Val ROC-AUC: 0.7407407407407408
  Val Accuracy: 0.6666666865348816
Epoch 25/64:
  Train Loss: 0.7162128537893295
  Validation Loss: 0.7663471102714539
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.6666666865348816
Epoch 26/64:
  Train Loss: 0.7150728851556778
  Validation Loss: 0.765340268611908
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.6666666865348816
Epoch 27/64:
  Train Loss: 0.717025876045227
  Validation Loss: 0.7643467783927917
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.7037037014961243
Epoch 28/64:
  Train Loss: 0.7187124341726303
  Validation Loss: 0.7633686661720276
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.7037037014961243
Epoch 29/64:
  Train Loss: 0.7187734097242355
  Validation Loss: 0.7624452710151672
  Val ROC-AUC: 0.7469135802469136
  Val Accuracy: 0.7037037014961243
Epoch 30/64:
  Train Loss: 0.7259832173585892
  Validation Loss: 0.7615394592285156
  Val ROC-AUC: 0.7469135802469136
  Val Accuracy: 0.7037037014961243
Epoch 31/64:
  Train Loss: 0.7127563953399658
  Validation Loss: 0.7606257200241089
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.7037037014961243
Epoch 32/64:
  Train Loss: 0.7249380946159363
  Validation Loss: 0.7597357034683228
  Val ROC-AUC: 0.7654320987654321
  Val Accuracy: 0.7037037014961243
Epoch 33/64:
  Train Loss: 0.7229992151260376
  Validation Loss: 0.7588591575622559
  Val ROC-AUC: 0.7716049382716049
  Val Accuracy: 0.7037037014961243
Epoch 34/64:
  Train Loss: 0.7108537554740906
  Validation Loss: 0.7579782605171204
  Val ROC-AUC: 0.7839506172839505
  Val Accuracy: 0.7037037014961243
Epoch 35/64:
  Train Loss: 0.7170127630233765
  Validation Loss: 0.7571073770523071
  Val ROC-AUC: 0.7839506172839505
  Val Accuracy: 0.7037037014961243
Epoch 36/64:
  Train Loss: 0.7192710041999817
  Validation Loss: 0.7562099099159241
  Val ROC-AUC: 0.7962962962962963
  Val Accuracy: 0.7037037014961243
Epoch 37/64:
  Train Loss: 0.713386595249176
  Validation Loss: 0.7553576827049255
  Val ROC-AUC: 0.8024691358024691
  Val Accuracy: 0.7037037014961243
Epoch 38/64:
  Train Loss: 0.7170184999704361
  Validation Loss: 0.7545027732849121
  Val ROC-AUC: 0.8024691358024691
  Val Accuracy: 0.7037037014961243
Epoch 39/64:
  Train Loss: 0.7002899199724197
  Validation Loss: 0.7536652088165283
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.7037037014961243
Epoch 40/64:
  Train Loss: 0.7158654481172562
  Validation Loss: 0.7528789639472961
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.7037037014961243
Epoch 41/64:
  Train Loss: 0.706750825047493
  Validation Loss: 0.7520603537559509
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 42/64:
  Train Loss: 0.7137512266635895
  Validation Loss: 0.7512622475624084
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 43/64:
  Train Loss: 0.7128222733736038
  Validation Loss: 0.7505061030387878
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 44/64:
  Train Loss: 0.7182053625583649
  Validation Loss: 0.7497724890708923
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.7037037014961243
Epoch 45/64:
  Train Loss: 0.6981456726789474
  Validation Loss: 0.7490408420562744
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 46/64:
  Train Loss: 0.699280858039856
  Validation Loss: 0.7483170628547668
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 47/64:
  Train Loss: 0.7090519964694977
  Validation Loss: 0.7475833296775818
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7037037014961243
Epoch 48/64:
  Train Loss: 0.7006275802850723
  Validation Loss: 0.746829628944397
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7407407760620117
Epoch 49/64:
  Train Loss: 0.7081423252820969
  Validation Loss: 0.7461053133010864
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.7407407760620117
Epoch 50/64:
  Train Loss: 0.6891325861215591
  Validation Loss: 0.7453662157058716
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:27:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:27:INFO:
[92mINFO [0m:      Received: evaluate message d9b4f70e-5559-4848-9248-a71c6a6324a5
02/07/2025 22:45:27:INFO:Received: evaluate message d9b4f70e-5559-4848-9248-a71c6a6324a5
[92mINFO [0m:      Sent reply
02/07/2025 22:45:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:33:INFO:
[92mINFO [0m:      Received: train message cad0f848-e526-415f-a02c-46cb9a9720ae
02/07/2025 22:45:33:INFO:Received: train message cad0f848-e526-415f-a02c-46cb9a9720ae
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.7407407760620117
Epoch 51/64:
  Train Loss: 0.6887906789779663
  Validation Loss: 0.7446499466896057
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7407407760620117
Epoch 52/64:
  Train Loss: 0.6992069631814957
  Validation Loss: 0.7439529895782471
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7407407760620117
Epoch 53/64:
  Train Loss: 0.6923009306192398
  Validation Loss: 0.7432341575622559
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7407407760620117
Epoch 54/64:
  Train Loss: 0.6979590654373169
  Validation Loss: 0.7425487637519836
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.7407407760620117
Epoch 55/64:
  Train Loss: 0.7024815678596497
  Validation Loss: 0.7418793439865112
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7407407760620117
Epoch 56/64:
  Train Loss: 0.6965043842792511
  Validation Loss: 0.7412421703338623
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.7407407760620117
Epoch 57/64:
  Train Loss: 0.6868105828762054
  Validation Loss: 0.7405683994293213
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.7407407760620117
Epoch 58/64:
  Train Loss: 0.696342408657074
  Validation Loss: 0.7399349808692932
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.7407407760620117
Epoch 59/64:
  Train Loss: 0.6964626610279083
  Validation Loss: 0.7392802834510803
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.7407407760620117
Epoch 60/64:
  Train Loss: 0.6805939674377441
  Validation Loss: 0.7386317849159241
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7407407760620117
Epoch 61/64:
  Train Loss: 0.6853093057870865
  Validation Loss: 0.7379906177520752
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7407407760620117
Epoch 62/64:
  Train Loss: 0.6982651650905609
  Validation Loss: 0.7373533844947815
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7777777910232544
Epoch 63/64:
  Train Loss: 0.689112588763237
  Validation Loss: 0.7367267608642578
  Val ROC-AUC: 0.8641975308641975
  Val Accuracy: 0.7777777910232544
Epoch 64/64:
  Train Loss: 0.6854957789182663
  Validation Loss: 0.7361254096031189
  Val ROC-AUC: 0.8641975308641975
  Val Accuracy: 0.7777777910232544
{'train_loss': 0.6854957789182663, 'val_roc_auc': 0.8641975308641975, 'val_accuracy': 0.7777777910232544, 'val_loss': 0.7361254096031189}
 ROC_AUC: 0.8642|| Accuracy 0.7778 || Train Loss: 0.6855
 Val Loss: 0.7361 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7785191941127348
Test ROC-AUC: 0.6915584415584415
Test Accuracy: 0.5617977528089888
test_loss: 0.7785191941127348
test_roc_auc: 0.6915584415584415
test_accuracy: 0.5617977528089888
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.21596150346340437
Epoch 1/64:
  Train Loss: 0.7564104348421097
  Validation Loss: 0.8255694508552551
  Val ROC-AUC: 0.611842105263158
  Val Accuracy: 0.5555555820465088
Epoch 2/64:
  Train Loss: 0.7546585351228714
  Validation Loss: 0.8237076997756958
  Val ROC-AUC: 0.638157894736842
  Val Accuracy: 0.5555555820465088
Epoch 3/64:
  Train Loss: 0.750661090016365
  Validation Loss: 0.821927547454834
  Val ROC-AUC: 0.6513157894736843
  Val Accuracy: 0.5555555820465088
Epoch 4/64:
  Train Loss: 0.7469203174114227
  Validation Loss: 0.8201568722724915
  Val ROC-AUC: 0.6644736842105263
  Val Accuracy: 0.5555555820465088
Epoch 5/64:
  Train Loss: 0.7428368031978607
  Validation Loss: 0.8184127807617188
  Val ROC-AUC: 0.6644736842105263
  Val Accuracy: 0.5925925970077515
Epoch 6/64:
  Train Loss: 0.7368616610765457
  Validation Loss: 0.8166923522949219
  Val ROC-AUC: 0.6776315789473685
  Val Accuracy: 0.5925925970077515
Epoch 7/64:
  Train Loss: 0.7359291166067123
  Validation Loss: 0.8149807453155518
  Val ROC-AUC: 0.6842105263157895
  Val Accuracy: 0.6296296119689941
Epoch 8/64:
  Train Loss: 0.7328525483608246
  Validation Loss: 0.8132692575454712
  Val ROC-AUC: 0.7171052631578947
  Val Accuracy: 0.6296296119689941
Epoch 9/64:
  Train Loss: 0.7419317662715912
  Validation Loss: 0.8116347789764404
  Val ROC-AUC: 0.736842105263158
  Val Accuracy: 0.6296296119689941
Epoch 10/64:
  Train Loss: 0.7484351694583893
  Validation Loss: 0.8099804520606995
  Val ROC-AUC: 0.7565789473684211
  Val Accuracy: 0.6296296119689941
Epoch 11/64:
  Train Loss: 0.732444167137146
  Validation Loss: 0.8083246350288391
  Val ROC-AUC: 0.7763157894736843
  Val Accuracy: 0.6666666865348816
Epoch 12/64:
  Train Loss: 0.7335939854383469
  Validation Loss: 0.8067024946212769
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.6666666865348816
Epoch 13/64:
  Train Loss: 0.7223166972398758
  Validation Loss: 0.8050881624221802
  Val ROC-AUC: 0.8223684210526316
  Val Accuracy: 0.6666666865348816
Epoch 14/64:
  Train Loss: 0.7388055324554443
  Validation Loss: 0.8035023808479309
  Val ROC-AUC: 0.8421052631578947
  Val Accuracy: 0.6666666865348816
Epoch 15/64:
  Train Loss: 0.7440262585878372
  Validation Loss: 0.8018863797187805
  Val ROC-AUC: 0.8552631578947368
  Val Accuracy: 0.7407407760620117
Epoch 16/64:
  Train Loss: 0.7451715618371964
  Validation Loss: 0.8003647327423096
  Val ROC-AUC: 0.8552631578947368
  Val Accuracy: 0.7407407760620117
Epoch 17/64:
  Train Loss: 0.7333241403102875
  Validation Loss: 0.7988405227661133
  Val ROC-AUC: 0.875
  Val Accuracy: 0.7407407760620117
Epoch 18/64:
  Train Loss: 0.7216075509786606
  Validation Loss: 0.7973126173019409
  Val ROC-AUC: 0.8881578947368421
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.7166749835014343
  Validation Loss: 0.7957722544670105
  Val ROC-AUC: 0.8881578947368421
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.7435391992330551
  Validation Loss: 0.794276773929596
  Val ROC-AUC: 0.8947368421052632
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.7265590578317642
  Validation Loss: 0.792806088924408
  Val ROC-AUC: 0.9013157894736842
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.7126188278198242
  Validation Loss: 0.7913117408752441
  Val ROC-AUC: 0.9013157894736842
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.7164216935634613
  Validation Loss: 0.7898600697517395
  Val ROC-AUC: 0.9013157894736842
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.7280088812112808
  Validation Loss: 0.7883898615837097
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.7185962796211243
  Validation Loss: 0.7869685292243958
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.7246081978082657
  Validation Loss: 0.7855790257453918
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.7184613198041916
  Validation Loss: 0.7842414975166321
  Val ROC-AUC: 0.9210526315789475
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.7246236503124237
  Validation Loss: 0.7828887104988098
  Val ROC-AUC: 0.9210526315789475
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.7066292464733124
  Validation Loss: 0.7815712690353394
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 30/64:
  Train Loss: 0.7106236666440964
  Validation Loss: 0.7802394032478333
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 31/64:
  Train Loss: 0.7149292379617691
  Validation Loss: 0.778972327709198
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 32/64:
  Train Loss: 0.7102395445108414
  Validation Loss: 0.7777144908905029
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.7777777910232544
Epoch 33/64:
  Train Loss: 0.7048020511865616
  Validation Loss: 0.7764803171157837
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.7777777910232544
Epoch 34/64:
  Train Loss: 0.7111542969942093
  Validation Loss: 0.7751984596252441
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.7777777910232544
Epoch 35/64:
  Train Loss: 0.7081658095121384
  Validation Loss: 0.7739407420158386
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.7777777910232544
Epoch 36/64:/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:01:INFO:
[92mINFO [0m:      Received: evaluate message bb059b66-e64d-4bc3-8437-d1fb5cef2518
02/07/2025 22:46:01:INFO:Received: evaluate message bb059b66-e64d-4bc3-8437-d1fb5cef2518
[92mINFO [0m:      Sent reply
02/07/2025 22:46:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:01:INFO:
[92mINFO [0m:      Received: train message 1b6d5484-453f-4e86-ac63-209cdf5647d2
02/07/2025 22:46:01:INFO:Received: train message 1b6d5484-453f-4e86-ac63-209cdf5647d2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

  Train Loss: 0.7050710171461105
  Validation Loss: 0.7727435231208801
  Val ROC-AUC: 0.9539473684210525
  Val Accuracy: 0.7777777910232544
Epoch 37/64:
  Train Loss: 0.6966347247362137
  Validation Loss: 0.771584153175354
  Val ROC-AUC: 0.9539473684210525
  Val Accuracy: 0.7777777910232544
Epoch 38/64:
  Train Loss: 0.6930486410856247
  Validation Loss: 0.7704173922538757
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.699442133307457
  Validation Loss: 0.7692726254463196
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6975273340940475
  Validation Loss: 0.7681552767753601
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6855337619781494
  Validation Loss: 0.7670539021492004
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.7125526368618011
  Validation Loss: 0.7659549713134766
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6960291117429733
  Validation Loss: 0.7648428082466125
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6980821937322617
  Validation Loss: 0.7637400031089783
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.7047820389270782
  Validation Loss: 0.7626540660858154
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6952321231365204
  Validation Loss: 0.7615944147109985
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8518518805503845
Epoch 47/64:
  Train Loss: 0.6991572678089142
  Validation Loss: 0.7605390548706055
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.6723097860813141
  Validation Loss: 0.7594573497772217
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.6840225160121918
  Validation Loss: 0.7584487199783325
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.6840103566646576
  Validation Loss: 0.7574585676193237
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6865938603878021
  Validation Loss: 0.7564895749092102
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.69471675157547
  Validation Loss: 0.7555121183395386
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.7031823247671127
  Validation Loss: 0.7545568943023682
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6810690760612488
  Validation Loss: 0.75362229347229
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.6941066533327103
  Validation Loss: 0.7526940107345581
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6876619160175323
  Validation Loss: 0.7517872452735901
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6807241886854172
  Validation Loss: 0.7509150505065918
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6987394094467163
  Validation Loss: 0.750078022480011
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.6783908158540726
  Validation Loss: 0.7492461204528809
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.682805523276329
  Validation Loss: 0.7484109997749329
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6804459244012833
  Validation Loss: 0.747575581073761
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.6795071661472321
  Validation Loss: 0.746747612953186
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6835525631904602
  Validation Loss: 0.7459605932235718
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.6742091476917267
  Validation Loss: 0.745153546333313
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6742091476917267, 'val_roc_auc': 0.9736842105263158, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.745153546333313}
 ROC_AUC: 0.9737|| Accuracy 0.8889 || Train Loss: 0.6742
 Val Loss: 0.7452 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.774246392290244
Test ROC-AUC: 0.7175324675324676
Test Accuracy: 0.5842696629213483
test_loss: 0.774246392290244
test_roc_auc: 0.7175324675324676
test_accuracy: 0.5842696629213483
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.1231892419423275
Epoch 1/64:
  Train Loss: 0.7595773786306381
  Validation Loss: 0.7829490303993225
  Val ROC-AUC: 0.7962962962962963
  Val Accuracy: 0.6666666865348816
Epoch 2/64:
  Train Loss: 0.7476332485675812
  Validation Loss: 0.7811352610588074
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.6296296119689941
Epoch 3/64:
  Train Loss: 0.7468882352113724
  Validation Loss: 0.7793360948562622
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.6296296119689941
Epoch 4/64:
  Train Loss: 0.7570145130157471
  Validation Loss: 0.77753746509552
  Val ROC-AUC: 0.8148148148148149
  Val Accuracy: 0.6666666865348816
Epoch 5/64:
  Train Loss: 0.75074902176857
  Validation Loss: 0.7757393717765808
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.6666666865348816
Epoch 6/64:
  Train Loss: 0.7611669898033142
  Validation Loss: 0.7739691138267517
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.6666666865348816
Epoch 7/64:
  Train Loss: 0.7379012107849121
  Validation Loss: 0.7722288370132446
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.6666666865348816
Epoch 8/64:
  Train Loss: 0.7453792244195938
  Validation Loss: 0.7705038785934448
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.6666666865348816
Epoch 9/64:
  Train Loss: 0.7297089993953705
  Validation Loss: 0.7687734961509705
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7037037014961243
Epoch 10/64:
  Train Loss: 0.7519223392009735
  Validation Loss: 0.7670912742614746
  Val ROC-AUC: 0.8703703703703705
  Val Accuracy: 0.7407407760620117
Epoch 11/64:
  Train Loss: 0.743775799870491
  Validation Loss: 0.7654035687446594
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 12/64:
  Train Loss: 0.724932387471199
  Validation Loss: 0.7637527585029602
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 13/64:
  Train Loss: 0.7424271702766418
  Validation Loss: 0.7620909214019775
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 14/64:
  Train Loss: 0.7398594915866852
  Validation Loss: 0.7604169845581055
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 15/64:
  Train Loss: 0.7388031184673309
  Validation Loss: 0.7588003873825073
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7777777910232544
Epoch 16/64:
  Train Loss: 0.7330206781625748
  Validation Loss: 0.7572001814842224
  Val ROC-AUC: 0.882716049382716
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7383991181850433
  Validation Loss: 0.7556225061416626
  Val ROC-AUC: 0.882716049382716
  Val Accuracy: 0.7777777910232544
Epoch 18/64:
  Train Loss: 0.7308831363916397
  Validation Loss: 0.7540717124938965
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.717750608921051
  Validation Loss: 0.7525658011436462
  Val ROC-AUC: 0.8827160493827161
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.7254040390253067
  Validation Loss: 0.7510726451873779
  Val ROC-AUC: 0.8827160493827161
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.7372206449508667
  Validation Loss: 0.7496121525764465
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:29:INFO:
[92mINFO [0m:      Received: evaluate message 6724a284-ddd7-4f95-93a8-8d0b33158ae2
02/07/2025 22:46:29:INFO:Received: evaluate message 6724a284-ddd7-4f95-93a8-8d0b33158ae2
[92mINFO [0m:      Sent reply
02/07/2025 22:46:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:30:INFO:
[92mINFO [0m:      Received: train message 289b3ed4-373f-4f21-ab4d-2a521bca4edd
02/07/2025 22:46:30:INFO:Received: train message 289b3ed4-373f-4f21-ab4d-2a521bca4edd
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.7362360209226608
  Validation Loss: 0.7481793165206909
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.7131125330924988
  Validation Loss: 0.7467114329338074
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.7246499210596085
  Validation Loss: 0.7453027963638306
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.712307795882225
  Validation Loss: 0.7439337372779846
  Val ROC-AUC: 0.9197530864197532
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.7083185166120529
  Validation Loss: 0.7425709962844849
  Val ROC-AUC: 0.9382716049382717
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.7221459150314331
  Validation Loss: 0.7412407994270325
  Val ROC-AUC: 0.9382716049382717
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.7194092571735382
  Validation Loss: 0.7399352192878723
  Val ROC-AUC: 0.9444444444444445
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.7163462042808533
  Validation Loss: 0.7385947108268738
  Val ROC-AUC: 0.9444444444444445
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.7225714921951294
  Validation Loss: 0.737301230430603
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.7078642547130585
  Validation Loss: 0.7359920740127563
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.7124471813440323
  Validation Loss: 0.7346869111061096
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 33/64:
  Train Loss: 0.7037981599569321
  Validation Loss: 0.7334251403808594
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 34/64:
  Train Loss: 0.7098666131496429
  Validation Loss: 0.732193112373352
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 35/64:
  Train Loss: 0.723163053393364
  Validation Loss: 0.731005847454071
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 36/64:
  Train Loss: 0.7080366611480713
  Validation Loss: 0.7298293709754944
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 37/64:
  Train Loss: 0.7147578448057175
  Validation Loss: 0.728654682636261
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8518518805503845
Epoch 38/64:
  Train Loss: 0.7142022848129272
  Validation Loss: 0.7274945378303528
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8518518805503845
Epoch 39/64:
  Train Loss: 0.7039486318826675
  Validation Loss: 0.7263445258140564
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7120646387338638
  Validation Loss: 0.7252287864685059
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7179279625415802
  Validation Loss: 0.7241364121437073
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.7093675583600998
  Validation Loss: 0.7230575084686279
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6961811929941177
  Validation Loss: 0.7219973802566528
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.7116137892007828
  Validation Loss: 0.7209429144859314
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.7016576677560806
  Validation Loss: 0.7199200391769409
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6971073150634766
  Validation Loss: 0.7188898324966431
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6960140913724899
  Validation Loss: 0.7178688049316406
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.689906969666481
  Validation Loss: 0.7169023752212524
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.697499543428421
  Validation Loss: 0.7159557342529297
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.7124665528535843
  Validation Loss: 0.7150049805641174
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6932362914085388
  Validation Loss: 0.7140855193138123
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6896726340055466
  Validation Loss: 0.713151752948761
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6908693313598633
  Validation Loss: 0.7122328281402588
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6864084303379059
  Validation Loss: 0.7113621234893799
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6988107711076736
  Validation Loss: 0.7104811668395996
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6963526606559753
  Validation Loss: 0.709621012210846
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6835466474294662
  Validation Loss: 0.7087592482566833
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6818537265062332
  Validation Loss: 0.7079174518585205
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6843577176332474
  Validation Loss: 0.7070796489715576
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6934441477060318
  Validation Loss: 0.7062724232673645
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6882924437522888
  Validation Loss: 0.7054794430732727
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6954080760478973
  Validation Loss: 0.7047037482261658
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.680102214217186
  Validation Loss: 0.7039124369621277
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6819924712181091
  Validation Loss: 0.7031694650650024
  Val ROC-AUC: 0.9506172839506174
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6819924712181091, 'val_roc_auc': 0.9506172839506174, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.7031694650650024}
 ROC_AUC: 0.9506|| Accuracy 0.9259 || Train Loss: 0.6820
 Val Loss: 0.7032 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7693897800499134
Test ROC-AUC: 0.7456709956709956
Test Accuracy: 0.5955056179775281
test_loss: 0.7693897800499134
test_roc_auc: 0.7456709956709956
test_accuracy: 0.5955056179775281
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.19137434893309546
Epoch 1/64:
  Train Loss: 0.7610423862934113
  Validation Loss: 0.7217006087303162
  Val ROC-AUC: 0.9318181818181819
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7668316960334778
  Validation Loss: 0.7199252247810364
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7612134218215942
  Validation Loss: 0.7181772589683533
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7478805333375931
  Validation Loss: 0.7164863348007202
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.7564267069101334
  Validation Loss: 0.7148540019989014
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.7611638903617859
  Validation Loss: 0.713272213935852
  Val ROC-AUC: 0.9659090909090908
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.7523619681596756
  Validation Loss: 0.7116890549659729
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.75189009308815
  Validation Loss: 0.7101387977600098
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7603932619094849
  Validation Loss: 0.708635151386261
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.752392590045929
  Validation Loss: 0.7071319818496704
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.763596311211586
  Validation Loss: 0.7055968046188354
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.7490418702363968
  Validation Loss: 0.7041079998016357
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.7626796960830688
  Validation Loss: 0.7026110887527466
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.7484394013881683
  Validation Loss: 0.7011027932167053
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.726700559258461
  Validation Loss: 0.6996636390686035
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.7550851851701736
  Validation Loss: 0.6983047723770142
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.7328220009803772
  Validation Loss: 0.6969438791275024
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.7297366261482239
  Validation Loss: 0.6955806612968445
  Val ROC-AUC: 0.9943181818181818
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.744849756360054
  Validation Loss: 0.6942700147628784
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.7326952069997787
  Validation Loss: 0.6930415034294128
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.7248908281326294
  Validation Loss: 0.6918041110038757
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.745583787560463
  Validation Loss: 0.6906692981719971
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.7404559105634689
  Validation Loss: 0.689538300037384
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.7480100393295288
  Validation Loss: 0.6883972883224487
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.7395966500043869
  Validation Loss: 0.687287449836731
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.735419437289238
  Validation Loss: 0.6862143278121948
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.735355481505394
  Validation Loss: 0.68504798412323
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.7489489763975143
  Validation Loss: 0.6839153170585632
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.7150249481201172
  Validation Loss: 0.6828374266624451
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.7267975062131882
  Validation Loss: 0.6817898750305176
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.7187681496143341
  Validation Loss: 0.6807204484939575
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.7188113480806351
  Validation Loss: 0.6796668171882629
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.7213426381349564
  Validation Loss: 0.6786590814590454
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.7195452749729156
  Validation Loss: 0.6776975989341736
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.7148043811321259
  Validation Loss: 0.6767519116401672
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.7188472896814346
  Validation Loss: 0.6758001446723938
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.7152569144964218
  Validation Loss: 0.6748149991035461
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.7278034836053848
  Validation Loss: 0.6738426685333252
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.7213701903820038
  Validation Loss: 0.672934353351593
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.7206737697124481
  Validation Loss: 0.6720340251922607
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.7208239734172821
  Validation Loss: 0.6711711287498474
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.7058420330286026
  Validation Loss: 0.6703653931617737
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.7086713761091232
  Validation Loss: 0.6695432066917419
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.7188892811536789
  Validation Loss: 0.6687015891075134
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.7160705178976059
  Validation Loss: 0.6678767800331116
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.7138859033584595
  Validation Loss: 0.6670900583267212
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.7108396589756012
  Validation Loss: 0.6662903428077698
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.7099378108978271
  Validation Loss: 0.6655514240264893
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.7103603631258011
  Validation Loss: 0.664788007736206
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.7097487300634384
  Validation Loss: 0.6640240550041199
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6969956010580063
  Validation Loss: 0.6632965207099915
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.7050013989210129
  Validation Loss: 0.662604808807373
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.7053805440664291
  Validation Loss: 0.6619518399238586
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6982383579015732
  Validation Loss: 0.6612824201583862
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6958400011062622
  Validation Loss: 0.6605930924415588
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.707595095038414
  Validation Loss: 0.6599196791648865
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.7039468735456467
  Validation Loss: 0.6593581438064575
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.7073180973529816
  Validation Loss: 0.6587557792663574
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.7055145800113678
  Validation Loss: 0.6581519842147827
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.7063024193048477
  Validation Loss: 0.6575866937637329
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.7029008120298386
  Validation Loss: 0.656997561454773
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.702126681804657
  Validation Loss: 0.6564239263534546
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6993318349123001
  Validation Loss: 0.6558466553688049
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6880812346935272
  Validation Loss: 0.6553043127059937
  Val ROC-AUC: 1.0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:58:INFO:
[92mINFO [0m:      Received: evaluate message ad2a1e01-7823-4cca-ae61-f4580856d290
02/07/2025 22:46:58:INFO:Received: evaluate message ad2a1e01-7823-4cca-ae61-f4580856d290
[92mINFO [0m:      Sent reply
02/07/2025 22:46:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:59:INFO:
[92mINFO [0m:      Received: train message 19eac88b-fd2b-4042-bbbd-395a521e9254
02/07/2025 22:46:59:INFO:Received: train message 19eac88b-fd2b-4042-bbbd-395a521e9254
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6880812346935272, 'val_roc_auc': 1.0, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6553043127059937}
 ROC_AUC: 1.0000|| Accuracy 0.9630 || Train Loss: 0.6881
 Val Loss: 0.6553 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7642489340198174
Test ROC-AUC: 0.7754329004329005
Test Accuracy: 0.651685393258427
test_loss: 0.7642489340198174
test_roc_auc: 0.7754329004329005
test_accuracy: 0.651685393258427
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.08039979243562811
Epoch 1/64:
  Train Loss: 0.7529468387365341
  Validation Loss: 0.7361927628517151
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7386660724878311
  Validation Loss: 0.7342557311058044
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7513322532176971
  Validation Loss: 0.7324584126472473
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7361598461866379
  Validation Loss: 0.7306835055351257
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7476758509874344
  Validation Loss: 0.729005753993988
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7443252950906754
  Validation Loss: 0.727425217628479
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7526157945394516
  Validation Loss: 0.7258830070495605
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7405568212270737
  Validation Loss: 0.7243031859397888
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7433657199144363
  Validation Loss: 0.7228224277496338
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.732101246714592
  Validation Loss: 0.7213692665100098
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7311811447143555
  Validation Loss: 0.7199122309684753
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7487345188856125
  Validation Loss: 0.7185264825820923
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.724015399813652
  Validation Loss: 0.7171386480331421
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.7354102283716202
  Validation Loss: 0.7157379388809204
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7271004915237427
  Validation Loss: 0.7143630981445312
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7168202698230743
  Validation Loss: 0.7130088806152344
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7335290163755417
  Validation Loss: 0.7116945385932922
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7296431958675385
  Validation Loss: 0.710427463054657
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.7287141978740692
  Validation Loss: 0.7092006802558899
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.7400041073560715
  Validation Loss: 0.7079659700393677
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.7196350544691086
  Validation Loss: 0.7067714929580688
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.7255468368530273
  Validation Loss: 0.7055743336677551
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7196995913982391
  Validation Loss: 0.7044300436973572
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.7327649295330048
  Validation Loss: 0.703306257724762
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.712381586432457
  Validation Loss: 0.7021811008453369
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7323947101831436
  Validation Loss: 0.7011260986328125
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7163385897874832
  Validation Loss: 0.7000495791435242
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.7152058631181717
  Validation Loss: 0.6990055441856384
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.7016850262880325
  Validation Loss: 0.697956919670105
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.7003033012151718
  Validation Loss: 0.6968996524810791
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.730336457490921
  Validation Loss: 0.6959197521209717
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.7074139416217804
  Validation Loss: 0.6949073076248169
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.7230314463376999
  Validation Loss: 0.6939280033111572
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.7250029891729355
  Validation Loss: 0.6929916143417358
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.7157986760139465
  Validation Loss: 0.692075788974762
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7109900414943695
  Validation Loss: 0.691160261631012
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7039172947406769
  Validation Loss: 0.6902793645858765
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7014443576335907
  Validation Loss: 0.689385712146759
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7064450830221176
  Validation Loss: 0.6885338425636292
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7048722505569458
  Validation Loss: 0.6877120733261108
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7094638794660568
  Validation Loss: 0.6868934631347656
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.7037633955478668
  Validation Loss: 0.6860785484313965
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.7036708444356918
  Validation Loss: 0.6852871179580688
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6949093788862228
  Validation Loss: 0.6845351457595825
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.7001100182533264
  Validation Loss: 0.6837692856788635
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.7060809582471848
  Validation Loss: 0.6830328106880188
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6976475864648819
  Validation Loss: 0.6823262572288513
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.7008927762508392
  Validation Loss: 0.6816221475601196
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.7008341401815414
  Validation Loss: 0.6809356808662415
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6977556645870209
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:28:INFO:
[92mINFO [0m:      Received: evaluate message 2cbb8ade-9997-4b09-aba2-0a4bd94ac382
02/07/2025 22:47:28:INFO:Received: evaluate message 2cbb8ade-9997-4b09-aba2-0a4bd94ac382
[92mINFO [0m:      Sent reply
02/07/2025 22:47:31:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:31:INFO:
[92mINFO [0m:      Received: train message 6a69e076-2ce1-40f3-86c6-fd9ba0a5518f
02/07/2025 22:47:31:INFO:Received: train message 6a69e076-2ce1-40f3-86c6-fd9ba0a5518f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6802718043327332
  Val ROC-AUC: 0.9823529411764705
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.7119848877191544
  Validation Loss: 0.6796131134033203
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.7003088295459747
  Validation Loss: 0.6789650917053223
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6970349997282028
  Validation Loss: 0.6783087253570557
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6945239752531052
  Validation Loss: 0.6776859164237976
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6921103298664093
  Validation Loss: 0.6770507097244263
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.7036339640617371
  Validation Loss: 0.6764514446258545
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.7045523822307587
  Validation Loss: 0.6758454442024231
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6959227323532104
  Validation Loss: 0.6752749085426331
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6890143901109695
  Validation Loss: 0.6746978759765625
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6882048547267914
  Validation Loss: 0.6741350293159485
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6941182762384415
  Validation Loss: 0.6735893487930298
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.690465435385704
  Validation Loss: 0.6730636358261108
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.7013650089502335
  Validation Loss: 0.6725331544876099
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6877349466085434
  Validation Loss: 0.6720020174980164
  Val ROC-AUC: 0.9705882352941176
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6877349466085434, 'val_roc_auc': 0.9705882352941176, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6720020174980164}
 ROC_AUC: 0.9706|| Accuracy 0.9259 || Train Loss: 0.6877
 Val Loss: 0.6720 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7589251774080684
Test ROC-AUC: 0.7927489177489178
Test Accuracy: 0.6741573033707865
test_loss: 0.7589251774080684
test_roc_auc: 0.7927489177489178
test_accuracy: 0.6741573033707865
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.15102689618970544
Epoch 1/64:
  Train Loss: 0.7344894409179688
  Validation Loss: 0.7782748341560364
  Val ROC-AUC: 0.9210526315789473
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7464447170495987
  Validation Loss: 0.7764530777931213
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7178459763526917
  Validation Loss: 0.7746396064758301
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7325541079044342
  Validation Loss: 0.7728704810142517
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7170658856630325
  Validation Loss: 0.7710777521133423
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7237604111433029
  Validation Loss: 0.7693057656288147
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7322549670934677
  Validation Loss: 0.7675508856773376
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7259764820337296
  Validation Loss: 0.7657940983772278
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7251952886581421
  Validation Loss: 0.7640632390975952
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.7252351939678192
  Validation Loss: 0.762396514415741
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7239566296339035
  Validation Loss: 0.7607142329216003
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7250755280256271
  Validation Loss: 0.7590195536613464
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.721948429942131
  Validation Loss: 0.7573218941688538
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.707281768321991
  Validation Loss: 0.755660891532898
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7108245491981506
  Validation Loss: 0.7540034651756287
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.718792736530304
  Validation Loss: 0.7524071931838989
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7033741027116776
  Validation Loss: 0.7507807612419128
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7222062647342682
  Validation Loss: 0.7492036819458008
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.7088294625282288
  Validation Loss: 0.7476717233657837
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.715837374329567
  Validation Loss: 0.7461487054824829
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.7159182131290436
  Validation Loss: 0.744644284248352
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.7056312412023544
  Validation Loss: 0.7431564927101135
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7104428708553314
  Validation Loss: 0.7417482733726501
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.709442213177681
  Validation Loss: 0.7403168678283691
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6966860294342041
  Validation Loss: 0.7389101982116699
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7044622600078583
  Validation Loss: 0.7375487089157104
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7133359313011169
  Validation Loss: 0.7362178564071655
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.7092316299676895
  Validation Loss: 0.7348925471305847
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.7060376703739166
  Validation Loss: 0.733551025390625
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.7073744386434555
  Validation Loss: 0.7322317361831665
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6970192342996597
  Validation Loss: 0.7309550046920776
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6948213577270508
  Validation Loss: 0.7297254800796509
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6870015859603882
  Validation Loss: 0.7285293936729431
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6940339803695679
  Validation Loss: 0.72732013463974
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6906832307577133
  Validation Loss: 0.726144015789032
  Val ROC-AUC: 0.993421052631579
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:59:INFO:
[92mINFO [0m:      Received: evaluate message fd6a6cea-090e-4d67-8173-50857dfa13c2
02/07/2025 22:47:59:INFO:Received: evaluate message fd6a6cea-090e-4d67-8173-50857dfa13c2
[92mINFO [0m:      Sent reply
02/07/2025 22:48:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:01:INFO:
[92mINFO [0m:      Received: train message 3cedc310-4261-44a1-bbeb-bccfaf3b13b7
02/07/2025 22:48:01:INFO:Received: train message 3cedc310-4261-44a1-bbeb-bccfaf3b13b7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6955378204584122
  Validation Loss: 0.724942684173584
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.7015954107046127
  Validation Loss: 0.7237664461135864
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6984551548957825
  Validation Loss: 0.7226477861404419
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6715889871120453
  Validation Loss: 0.7215425968170166
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6921939104795456
  Validation Loss: 0.7204533815383911
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6943071484565735
  Validation Loss: 0.7194429636001587
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6915367245674133
  Validation Loss: 0.7184203267097473
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.7070829421281815
  Validation Loss: 0.7174007892608643
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6835123151540756
  Validation Loss: 0.7163782715797424
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6937024295330048
  Validation Loss: 0.715369701385498
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6844023764133453
  Validation Loss: 0.7144303321838379
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.679788738489151
  Validation Loss: 0.7134737372398376
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6980233639478683
  Validation Loss: 0.7125445008277893
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6929866671562195
  Validation Loss: 0.7116013169288635
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.683026984333992
  Validation Loss: 0.710695743560791
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6949382871389389
  Validation Loss: 0.709806501865387
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6775745153427124
  Validation Loss: 0.7089428901672363
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6779407858848572
  Validation Loss: 0.7080783247947693
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6886525452136993
  Validation Loss: 0.7072768807411194
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6848135143518448
  Validation Loss: 0.7064365744590759
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6744931489229202
  Validation Loss: 0.7056087851524353
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6814019531011581
  Validation Loss: 0.7047760486602783
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6779707372188568
  Validation Loss: 0.7039274573326111
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.691092848777771
  Validation Loss: 0.7031015753746033
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6750911623239517
  Validation Loss: 0.7023018002510071
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6863581091165543
  Validation Loss: 0.7015208601951599
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6799299120903015
  Validation Loss: 0.7007120847702026
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6751251667737961
  Validation Loss: 0.6999068856239319
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6926641762256622
  Validation Loss: 0.6990717649459839
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6926641762256622, 'val_roc_auc': 1.0, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6990717649459839}
 ROC_AUC: 1.0000|| Accuracy 0.9630 || Train Loss: 0.6927
 Val Loss: 0.6991 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7534909248352051
Test ROC-AUC: 0.808982683982684
Test Accuracy: 0.7078651685393258
test_loss: 0.7534909248352051
test_roc_auc: 0.808982683982684
test_accuracy: 0.7078651685393258
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.22708111204792658
Epoch 1/64:
  Train Loss: 0.7133252769708633
  Validation Loss: 0.7421755790710449
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7303102165460587
  Validation Loss: 0.7406807541847229
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7350583076477051
  Validation Loss: 0.7392039895057678
  Val ROC-AUC: 0.8882352941176471
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7260648906230927
  Validation Loss: 0.7377378940582275
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.7203681766986847
  Validation Loss: 0.736303985118866
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.717886433005333
  Validation Loss: 0.7349117398262024
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7370765954256058
  Validation Loss: 0.7335124611854553
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7196727842092514
  Validation Loss: 0.7321423888206482
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7296426892280579
  Validation Loss: 0.7307484745979309
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.7312362939119339
  Validation Loss: 0.7293819785118103
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7250760644674301
  Validation Loss: 0.728036105632782
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.6999865919351578
  Validation Loss: 0.7266924977302551
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.7209835350513458
  Validation Loss: 0.7254220247268677
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.7171378880739212
  Validation Loss: 0.7242074012756348
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.7210673242807388
  Validation Loss: 0.7230444550514221
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.7135899066925049
  Validation Loss: 0.7218728065490723
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.7079685181379318
  Validation Loss: 0.720644474029541
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.7182563543319702
  Validation Loss: 0.7194185853004456
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.715127632021904
  Validation Loss: 0.7182216048240662
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.7170744836330414
  Validation Loss: 0.7170763611793518
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.7333340495824814
  Validation Loss: 0.7159640789031982
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.7063794136047363
  Validation Loss: 0.7148249745368958
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7204576432704926
  Validation Loss: 0.7137032747268677
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:29:INFO:
[92mINFO [0m:      Received: evaluate message 030838d9-39ce-44cb-9a5f-012baf81ed01
02/07/2025 22:48:29:INFO:Received: evaluate message 030838d9-39ce-44cb-9a5f-012baf81ed01
[92mINFO [0m:      Sent reply
02/07/2025 22:48:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:29:INFO:
[92mINFO [0m:      Received: train message d85e79e8-d747-4155-96c5-db725faac85b
02/07/2025 22:48:29:INFO:Received: train message d85e79e8-d747-4155-96c5-db725faac85b
  Train Loss: 0.698927640914917
  Validation Loss: 0.7125720381736755
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.7044638395309448
  Validation Loss: 0.7114601731300354
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7070244401693344
  Validation Loss: 0.710386335849762
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.713418647646904
  Validation Loss: 0.7093668580055237
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6879375129938126
  Validation Loss: 0.7083539366722107
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6924451887607574
  Validation Loss: 0.7073726654052734
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6939358413219452
  Validation Loss: 0.7064103484153748
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7011535465717316
  Validation Loss: 0.7055012583732605
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.7075373828411102
  Validation Loss: 0.7045612335205078
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.7037141919136047
  Validation Loss: 0.7036315202713013
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6926156878471375
  Validation Loss: 0.7026900053024292
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6986564099788666
  Validation Loss: 0.7017902135848999
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7010258436203003
  Validation Loss: 0.7008976340293884
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6980996876955032
  Validation Loss: 0.7000222206115723
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7016986012458801
  Validation Loss: 0.6991551518440247
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.706580713391304
  Validation Loss: 0.6983112096786499
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6817749589681625
  Validation Loss: 0.6975286602973938
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6903363615274429
  Validation Loss: 0.6966979503631592
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6771209239959717
  Validation Loss: 0.6958751082420349
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.702366054058075
  Validation Loss: 0.6951075792312622
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.7036325186491013
  Validation Loss: 0.6943161487579346
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6831560730934143
  Validation Loss: 0.6935544013977051
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6768301725387573
  Validation Loss: 0.6927986741065979
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6918800622224808
  Validation Loss: 0.6920130252838135
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6904458105564117
  Validation Loss: 0.6912556290626526
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6826675981283188
  Validation Loss: 0.6905367374420166
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6944991648197174
  Validation Loss: 0.6898521184921265
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6736109852790833
  Validation Loss: 0.6891801953315735
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6843300759792328
  Validation Loss: 0.6884880661964417
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6951264441013336
  Validation Loss: 0.6878197193145752
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6915822923183441
  Validation Loss: 0.6871453523635864
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6923449337482452
  Validation Loss: 0.6865032315254211
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6848153322935104
  Validation Loss: 0.6858847141265869
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6846000403165817
  Validation Loss: 0.6852552890777588
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6862953901290894
  Validation Loss: 0.6846468448638916
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6874455660581589
  Validation Loss: 0.6840689182281494
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6774699091911316
  Validation Loss: 0.6834445595741272
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6756778210401535
  Validation Loss: 0.6828644871711731
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6877717524766922
  Validation Loss: 0.6822717785835266
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6839201152324677
  Validation Loss: 0.681692361831665
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6747264862060547
  Validation Loss: 0.6810985207557678
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6747264862060547, 'val_roc_auc': 0.9647058823529411, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6810985207557678}
 ROC_AUC: 0.9647|| Accuracy 0.9259 || Train Loss: 0.6747
 Val Loss: 0.6811 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7480855309561397
Test ROC-AUC: 0.8219696969696969
Test Accuracy: 0.7191011235955056
test_loss: 0.7480855309561397
test_roc_auc: 0.8219696969696969
test_accuracy: 0.7191011235955056
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.049878023668270544
Epoch 1/64:
  Train Loss: 0.7293074578046799
  Validation Loss: 0.7401494383811951
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.7093362957239151
  Validation Loss: 0.7389567494392395
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.712698757648468
  Validation Loss: 0.7377479076385498
  Val ROC-AUC: 0.8999999999999999
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7118752747774124
  Validation Loss: 0.7366112470626831
  Val ROC-AUC: 0.8999999999999999
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7127053737640381
  Validation Loss: 0.7354694604873657
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7172200679779053
  Validation Loss: 0.734353244304657
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7176438271999359
  Validation Loss: 0.7332475781440735
  Val ROC-AUC: 0.9117647058823528
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7157713174819946
  Validation Loss: 0.7321673035621643
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7198442369699478
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.7311011552810669
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6986876279115677
  Validation Loss: 0.7300499677658081
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7047220319509506
  Validation Loss: 0.7290129661560059
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7067292183637619
  Validation Loss: 0.7279985547065735
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.7090597450733185
  Validation Loss: 0.7270011305809021
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.7163566201925278
  Validation Loss: 0.7260072827339172
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7008719742298126
  Validation Loss: 0.7250193357467651
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7068431377410889
  Validation Loss: 0.72408127784729
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7004328519105911
  Validation Loss: 0.7231321930885315
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7069104164838791
  Validation Loss: 0.7221927642822266
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.7008254379034042
  Validation Loss: 0.721287190914154
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.6973463892936707
  Validation Loss: 0.7203719615936279
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6867670267820358
  Validation Loss: 0.7194896340370178
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.7051808089017868
  Validation Loss: 0.7186344265937805
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.6853857338428497
  Validation Loss: 0.7177697420120239
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6907266974449158
  Validation Loss: 0.7169215083122253
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.7036453038454056
  Validation Loss: 0.7160887718200684
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6905755549669266
  Validation Loss: 0.715251624584198
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6970443427562714
  Validation Loss: 0.7144085168838501
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6951227337121964
  Validation Loss: 0.7136141657829285
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6929027587175369
  Validation Loss: 0.7128461003303528
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6745292544364929
  Validation Loss: 0.7120683789253235
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6918832361698151
  Validation Loss: 0.7113216519355774
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6851955503225327
  Validation Loss: 0.7105769515037537
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6821736991405487
  Validation Loss: 0.7098342180252075
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6954537034034729
  Validation Loss: 0.7091012001037598
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.682449996471405
  Validation Loss: 0.7083721160888672
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.690939262509346
  Validation Loss: 0.7076824307441711
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6748871952295303
  Validation Loss: 0.706999659538269
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6943265646696091
  Validation Loss: 0.706325113773346
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6791953891515732
  Validation Loss: 0.7056319713592529
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.690122440457344
  Validation Loss: 0.7049727439880371
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6857289671897888
  Validation Loss: 0.7043254971504211
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 42/64:
  Train Loss: 0.6878887563943863
  Validation Loss: 0.7036741375923157
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 43/64:
  Train Loss: 0.6960592269897461
  Validation Loss: 0.7030296325683594
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 44/64:
  Train Loss: 0.6727510243654251
  Validation Loss: 0.7024269104003906
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 45/64:
  Train Loss: 0.6805496215820312
  Validation Loss: 0.7018080949783325
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 46/64:
  Train Loss: 0.691033273935318
  Validation Loss: 0.7011881470680237
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 47/64:
  Train Loss: 0.6806581169366837
  Validation Loss: 0.7005748152732849
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.6777839362621307
  Validation Loss: 0.699994683265686
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.6720839738845825
  Validation Loss: 0.6994119882583618
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.6803346574306488
  Validation Loss: 0.698821485042572
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6816965341567993
  Validation Loss: 0.6982676982879639
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.6626197099685669
  Validation Loss: 0.6976944208145142
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.6781766712665558
  Validation Loss: 0.6971591114997864
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6751112341880798
  Validation Loss: 0.6966186165809631
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.668238639831543
  Validation Loss: 0.6961014866828918
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6790906935930252
  Validation Loss: 0.695583164691925
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6739738583564758
  Validation Loss: 0.6950646638870239
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6809466332197189
  Validation Loss: 0.6945560574531555
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.6769520193338394
  Validation Loss: 0.6940554976463318
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.6703362017869949
  Validation Loss: 0.6935645341873169
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6702961325645447
  Validation Loss: 0.6930645108222961
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.6835933774709702
  Validation Loss: 0.6925722360610962
  Val ROC-AUC: 0.9352941176470588
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:57:INFO:
[92mINFO [0m:      Received: evaluate message 346db251-a63a-4208-b78f-416430fcaa7e
02/07/2025 22:48:57:INFO:Received: evaluate message 346db251-a63a-4208-b78f-416430fcaa7e
[92mINFO [0m:      Sent reply
02/07/2025 22:48:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:58:INFO:
[92mINFO [0m:      Received: train message 4f4c169a-c9b8-4174-bbb6-bab775865fea
02/07/2025 22:48:58:INFO:Received: train message 4f4c169a-c9b8-4174-bbb6-bab775865fea
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6722838282585144
  Validation Loss: 0.6921077370643616
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.6660239994525909
  Validation Loss: 0.691644549369812
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
{'train_loss': 0.6660239994525909, 'val_roc_auc': 0.9352941176470588, 'val_accuracy': 0.8518518805503845, 'val_loss': 0.691644549369812}
 ROC_AUC: 0.9353|| Accuracy 0.8519 || Train Loss: 0.6660
 Val Loss: 0.6916 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7427804295936328
Test ROC-AUC: 0.83495670995671
Test Accuracy: 0.7303370786516854
test_loss: 0.7427804295936328
test_roc_auc: 0.83495670995671
test_accuracy: 0.7303370786516854
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.21789294954942307
Epoch 1/64:
  Train Loss: 0.7375977486371994
  Validation Loss: 0.6361122131347656
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.734156921505928
  Validation Loss: 0.6348339915275574
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.7369171530008316
  Validation Loss: 0.6335970759391785
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7323179244995117
  Validation Loss: 0.6323694586753845
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.7336389124393463
  Validation Loss: 0.6311388611793518
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.73497174680233
  Validation Loss: 0.6299654841423035
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.744880735874176
  Validation Loss: 0.6287517547607422
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.736590102314949
  Validation Loss: 0.6275959610939026
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.7303178608417511
  Validation Loss: 0.6265000104904175
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.7185681611299515
  Validation Loss: 0.6253998279571533
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.7273764610290527
  Validation Loss: 0.6242586970329285
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.7353077828884125
  Validation Loss: 0.6231822371482849
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7334480732679367
  Validation Loss: 0.6221539378166199
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.7250445336103439
  Validation Loss: 0.6211432218551636
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.7150205969810486
  Validation Loss: 0.6201551556587219
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.7285226732492447
  Validation Loss: 0.6191737651824951
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.716635450720787
  Validation Loss: 0.6182380318641663
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7164154648780823
  Validation Loss: 0.6173079013824463
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7132232189178467
  Validation Loss: 0.6164060831069946
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.7083371877670288
  Validation Loss: 0.6155439615249634
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.7246792912483215
  Validation Loss: 0.6147029995918274
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.7103130370378494
  Validation Loss: 0.61387699842453
  Val ROC-AUC: 0.9560439560439561
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.7201791256666183
  Validation Loss: 0.6130914092063904
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.7146690785884857
  Validation Loss: 0.6123114228248596
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.7114734500646591
  Validation Loss: 0.6115500330924988
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7184891104698181
  Validation Loss: 0.6108415722846985
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7064077407121658
  Validation Loss: 0.6101187467575073
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.7282713502645493
  Validation Loss: 0.6094069480895996
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6973680555820465
  Validation Loss: 0.6087342500686646
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.7088150382041931
  Validation Loss: 0.6080247163772583
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7051298767328262
  Validation Loss: 0.6072989702224731
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.7018483430147171
  Validation Loss: 0.6065444946289062
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.713236927986145
  Validation Loss: 0.6058428287506104
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.7114884108304977
  Validation Loss: 0.6051781177520752
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.7137967795133591
  Validation Loss: 0.6045215129852295
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7036780714988708
  Validation Loss: 0.6038891077041626
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7004513889551163
  Validation Loss: 0.6032536625862122
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7152971178293228
  Validation Loss: 0.6026642322540283
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7053095996379852
  Validation Loss: 0.6020691990852356
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7032295614480972
  Validation Loss: 0.6014376878738403
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7232924848794937
  Validation Loss: 0.6008296608924866
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6961866319179535
  Validation Loss: 0.6002230048179626
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.7037889957427979
  Validation Loss: 0.5995966792106628
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.7075781971216202
  Validation Loss: 0.5989848971366882
  Val ROC-AUC: 0.9835164835164836
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.702909842133522
  Validation Loss: 0.5983835458755493
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.71062932908535
  Validation Loss: 0.5978383421897888
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6993823945522308
  Validation Loss: 0.5973095297813416
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6979535222053528
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:26:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:26:INFO:
[92mINFO [0m:      Received: evaluate message 58e0496d-eaa5-4100-bf98-f564c5a749d5
02/07/2025 22:49:26:INFO:Received: evaluate message 58e0496d-eaa5-4100-bf98-f564c5a749d5
[92mINFO [0m:      Sent reply
02/07/2025 22:49:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:28:INFO:
[92mINFO [0m:      Received: train message 02ded268-9c4c-42e3-ab93-b6af978f20bc
02/07/2025 22:49:28:INFO:Received: train message 02ded268-9c4c-42e3-ab93-b6af978f20bc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5967698097229004
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6964541375637054
  Validation Loss: 0.5962204933166504
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.7083978354930878
  Validation Loss: 0.5956878662109375
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.7090776413679123
  Validation Loss: 0.5951926708221436
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6878255158662796
  Validation Loss: 0.5946751236915588
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6979838162660599
  Validation Loss: 0.5941687226295471
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.703416183590889
  Validation Loss: 0.5936684608459473
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.7060744017362595
  Validation Loss: 0.5932104587554932
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.7092422991991043
  Validation Loss: 0.5927329659461975
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6881304979324341
  Validation Loss: 0.592254638671875
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.7036663293838501
  Validation Loss: 0.5917837619781494
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6954905688762665
  Validation Loss: 0.5913155674934387
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6958363205194473
  Validation Loss: 0.5908533930778503
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.7108411937952042
  Validation Loss: 0.590408205986023
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6869351416826248
  Validation Loss: 0.5900003910064697
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6956439316272736
  Validation Loss: 0.5895757675170898
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6963170021772385
  Validation Loss: 0.5891675353050232
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6963170021772385, 'val_roc_auc': 0.989010989010989, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.5891675353050232}
 ROC_AUC: 0.9890|| Accuracy 0.9630 || Train Loss: 0.6963
 Val Loss: 0.5892 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.737668928805362
Test ROC-AUC: 0.8506493506493507
Test Accuracy: 0.7415730337078652
test_loss: 0.737668928805362
test_roc_auc: 0.8506493506493507
test_accuracy: 0.7415730337078652
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.05315007788226467
Epoch 1/64:
  Train Loss: 0.7103563696146011
  Validation Loss: 0.7278621196746826
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 2/64:
  Train Loss: 0.7098000198602676
  Validation Loss: 0.7267239689826965
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 3/64:
  Train Loss: 0.7170977741479874
  Validation Loss: 0.7255240082740784
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 4/64:
  Train Loss: 0.7075101882219315
  Validation Loss: 0.7243179082870483
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.707396075129509
  Validation Loss: 0.7231627702713013
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.689920112490654
  Validation Loss: 0.7219506502151489
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.716150239109993
  Validation Loss: 0.7207461595535278
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.7153262197971344
  Validation Loss: 0.719636857509613
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.6868319362401962
  Validation Loss: 0.7184818983078003
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.7135358452796936
  Validation Loss: 0.7174601554870605
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.70368492603302
  Validation Loss: 0.716441810131073
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.689513087272644
  Validation Loss: 0.7154271006584167
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6899505406618118
  Validation Loss: 0.7143805623054504
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.695711761713028
  Validation Loss: 0.7134036421775818
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6918554604053497
  Validation Loss: 0.7123817205429077
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6880079656839371
  Validation Loss: 0.7114113569259644
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6941203474998474
  Validation Loss: 0.7104650735855103
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6920139044523239
  Validation Loss: 0.7095406651496887
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.700437530875206
  Validation Loss: 0.7086535692214966
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6878134459257126
  Validation Loss: 0.7077507972717285
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.7028311043977737
  Validation Loss: 0.7068579792976379
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.691000759601593
  Validation Loss: 0.7059890031814575
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6915682554244995
  Validation Loss: 0.7051199078559875
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6971375495195389
  Validation Loss: 0.7043200135231018
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.681230440735817
  Validation Loss: 0.7035222053527832
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6860030144453049
  Validation Loss: 0.7027347683906555
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6883995682001114
  Validation Loss: 0.7019818425178528
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6843106895685196
  Validation Loss: 0.7011909484863281
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6880567371845245
  Validation Loss: 0.7004609107971191
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6817412823438644
  Validation Loss: 0.6996974349021912
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6770443618297577
  Validation Loss: 0.698955237865448
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6890222579240799
  Validation Loss: 0.6982348561286926
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6708892285823822
  Validation Loss: 0.697579026222229
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6819591522216797
  Validation Loss: 0.6968997716903687
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6979303508996964
  Validation Loss: 0.6962022185325623
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6915189772844315
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:57:INFO:
[92mINFO [0m:      Received: evaluate message 15caaf45-2296-43e8-9c99-f61da4a0e423
02/07/2025 22:49:57:INFO:Received: evaluate message 15caaf45-2296-43e8-9c99-f61da4a0e423
[92mINFO [0m:      Sent reply
02/07/2025 22:49:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:58:INFO:
[92mINFO [0m:      Received: train message ef446c9d-3fc9-4cf5-ac54-d7dfa2d23aa7
02/07/2025 22:49:58:INFO:Received: train message ef446c9d-3fc9-4cf5-ac54-d7dfa2d23aa7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6955273151397705
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6834623366594315
  Validation Loss: 0.6948990821838379
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6687453985214233
  Validation Loss: 0.6942626237869263
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6778077334165573
  Validation Loss: 0.6936153769493103
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6773168742656708
  Validation Loss: 0.6930461525917053
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6801810413599014
  Validation Loss: 0.6924543976783752
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 42/64:
  Train Loss: 0.6651010513305664
  Validation Loss: 0.6918619275093079
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 43/64:
  Train Loss: 0.6816823780536652
  Validation Loss: 0.6913033723831177
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 44/64:
  Train Loss: 0.6906378269195557
  Validation Loss: 0.6907463669776917
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 45/64:
  Train Loss: 0.6746042966842651
  Validation Loss: 0.690216064453125
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 46/64:
  Train Loss: 0.6707063615322113
  Validation Loss: 0.6896679997444153
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 47/64:
  Train Loss: 0.6853609085083008
  Validation Loss: 0.6891204118728638
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 48/64:
  Train Loss: 0.6746840626001358
  Validation Loss: 0.6885877847671509
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 49/64:
  Train Loss: 0.669318437576294
  Validation Loss: 0.688066840171814
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 50/64:
  Train Loss: 0.6820072680711746
  Validation Loss: 0.6875442862510681
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 51/64:
  Train Loss: 0.6684008091688156
  Validation Loss: 0.6870530247688293
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 52/64:
  Train Loss: 0.6624777615070343
  Validation Loss: 0.6865543723106384
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 53/64:
  Train Loss: 0.6741936057806015
  Validation Loss: 0.6861128807067871
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 54/64:
  Train Loss: 0.6630567759275436
  Validation Loss: 0.6856262683868408
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 55/64:
  Train Loss: 0.6735971122980118
  Validation Loss: 0.685166597366333
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 56/64:
  Train Loss: 0.6659859418869019
  Validation Loss: 0.684712290763855
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 57/64:
  Train Loss: 0.6689199060201645
  Validation Loss: 0.6842995882034302
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 58/64:
  Train Loss: 0.6690770983695984
  Validation Loss: 0.6838739514350891
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 59/64:
  Train Loss: 0.6615145355463028
  Validation Loss: 0.6834567189216614
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 60/64:
  Train Loss: 0.6623418480157852
  Validation Loss: 0.6830719113349915
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 61/64:
  Train Loss: 0.6719355285167694
  Validation Loss: 0.6826649308204651
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 62/64:
  Train Loss: 0.6812417656183243
  Validation Loss: 0.6822636723518372
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 63/64:
  Train Loss: 0.6665400117635727
  Validation Loss: 0.6818398237228394
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 64/64:
  Train Loss: 0.6695679426193237
  Validation Loss: 0.6814419031143188
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
{'train_loss': 0.6695679426193237, 'val_roc_auc': 1.0, 'val_accuracy': 1.0, 'val_loss': 0.6814419031143188}
 ROC_AUC: 1.0000|| Accuracy 1.0000 || Train Loss: 0.6696
 Val Loss: 0.6814 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7328432028213244
Test ROC-AUC: 0.8603896103896104
Test Accuracy: 0.7415730337078652
test_loss: 0.7328432028213244
test_roc_auc: 0.8603896103896104
test_accuracy: 0.7415730337078652
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.07004282982734367
Epoch 1/64:
  Train Loss: 0.7124720215797424
  Validation Loss: 0.6987078189849854
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.7023186534643173
  Validation Loss: 0.6977310180664062
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.7138252407312393
  Validation Loss: 0.6968163251876831
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.7071212828159332
  Validation Loss: 0.695863664150238
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6955900490283966
  Validation Loss: 0.6949294805526733
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.7011303454637527
  Validation Loss: 0.6939965486526489
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.7015992254018784
  Validation Loss: 0.6930934190750122
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6898782104253769
  Validation Loss: 0.692212700843811
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.70657679438591
  Validation Loss: 0.6913405060768127
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.7072175890207291
  Validation Loss: 0.6904716491699219
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6965287625789642
  Validation Loss: 0.689624011516571
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6921625882387161
  Validation Loss: 0.6887974143028259
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7047237455844879
  Validation Loss: 0.6879744529724121
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6875484734773636
  Validation Loss: 0.6871960163116455
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6969334185123444
  Validation Loss: 0.6864256858825684
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6974825859069824
  Validation Loss: 0.6856868863105774
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6942391395568848
  Validation Loss: 0.6849480867385864
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7001427114009857
  Validation Loss: 0.684223473072052
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6907250881195068
  Validation Loss: 0.6835222840309143
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6967625468969345
  Validation Loss: 0.6828339695930481
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6903593093156815
  Validation Loss: 0.6821652054786682
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6984727680683136
  Validation Loss: 0.6814999580383301
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6930441707372665
  Validation Loss: 0.6808415651321411
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6769993901252747
  Validation Loss: 0.6801995635032654
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6885394155979156
  Validation Loss: 0.6795862913131714
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.690624937415123
  Validation Loss: 0.6789623498916626
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:25:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:25:INFO:
[92mINFO [0m:      Received: evaluate message da171d71-2c78-4dcf-8c0a-289409ad6c60
02/07/2025 22:50:25:INFO:Received: evaluate message da171d71-2c78-4dcf-8c0a-289409ad6c60
[92mINFO [0m:      Sent reply
02/07/2025 22:50:27:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:27:INFO:
[92mINFO [0m:      Received: train message 57e4579e-ad2d-4b86-a6ef-00962a87fd27
02/07/2025 22:50:27:INFO:Received: train message 57e4579e-ad2d-4b86-a6ef-00962a87fd27
  Train Loss: 0.6853347569704056
  Validation Loss: 0.6783638596534729
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6804482936859131
  Validation Loss: 0.6777763366699219
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6901940107345581
  Validation Loss: 0.6772032380104065
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6906461864709854
  Validation Loss: 0.6766451001167297
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6736079007387161
  Validation Loss: 0.6760926246643066
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6906473487615585
  Validation Loss: 0.6755596399307251
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.682316929101944
  Validation Loss: 0.6750388145446777
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6814357936382294
  Validation Loss: 0.674523651599884
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6778068244457245
  Validation Loss: 0.6740239262580872
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6900844722986221
  Validation Loss: 0.6735352277755737
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6907685548067093
  Validation Loss: 0.6730339527130127
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.685660719871521
  Validation Loss: 0.6725336909294128
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6756182014942169
  Validation Loss: 0.6720545887947083
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.659471333026886
  Validation Loss: 0.6715869307518005
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6710210889577866
  Validation Loss: 0.6711052656173706
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6783435493707657
  Validation Loss: 0.6706480979919434
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6784901022911072
  Validation Loss: 0.6701808571815491
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6715592294931412
  Validation Loss: 0.6697513461112976
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6753991395235062
  Validation Loss: 0.6693207621574402
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6785584837198257
  Validation Loss: 0.6688976287841797
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6820695251226425
  Validation Loss: 0.6684971451759338
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.681051954627037
  Validation Loss: 0.6681190729141235
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6680974662303925
  Validation Loss: 0.6677346229553223
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6763463169336319
  Validation Loss: 0.6673596501350403
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6685646176338196
  Validation Loss: 0.666984498500824
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6720812022686005
  Validation Loss: 0.666612982749939
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.673917606472969
  Validation Loss: 0.666247546672821
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6682811081409454
  Validation Loss: 0.6659014821052551
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6797331422567368
  Validation Loss: 0.6655681729316711
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6737466901540756
  Validation Loss: 0.6652141213417053
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6750174462795258
  Validation Loss: 0.6648794412612915
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6672906279563904
  Validation Loss: 0.6645408868789673
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6620346903800964
  Validation Loss: 0.6642283201217651
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6655358821153641
  Validation Loss: 0.6639138460159302
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6712389588356018
  Validation Loss: 0.6635875105857849
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6751688420772552
  Validation Loss: 0.6632771492004395
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6670752167701721
  Validation Loss: 0.6629521250724792
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.670641228556633
  Validation Loss: 0.6626438498497009
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.670641228556633, 'val_roc_auc': 0.9529411764705882, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6626438498497009}
 ROC_AUC: 0.9529|| Accuracy 0.9259 || Train Loss: 0.6706
 Val Loss: 0.6626 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7282238974330131
Test ROC-AUC: 0.863095238095238
Test Accuracy: 0.7640449438202247
test_loss: 0.7282238974330131
test_roc_auc: 0.863095238095238
test_accuracy: 0.7640449438202247
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.06690415479738476
Epoch 1/64:
  Train Loss: 0.6913959830999374
  Validation Loss: 0.7200756669044495
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.7079717367887497
  Validation Loss: 0.7189398407936096
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.7080539017915726
  Validation Loss: 0.7177861332893372
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6957470327615738
  Validation Loss: 0.716701328754425
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6990502327680588
  Validation Loss: 0.7156346440315247
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6804199367761612
  Validation Loss: 0.7145114541053772
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6936659663915634
  Validation Loss: 0.7134683728218079
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6917705982923508
  Validation Loss: 0.7124491333961487
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6844573616981506
  Validation Loss: 0.7114664912223816
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6766367703676224
  Validation Loss: 0.7104925513267517
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6947254091501236
  Validation Loss: 0.7094988226890564
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6946800351142883
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.7085188627243042
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6813670545816422
  Validation Loss: 0.7075760364532471
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6941743642091751
  Validation Loss: 0.7066585421562195
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.685406967997551
  Validation Loss: 0.7057235240936279
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6876078099012375
  Validation Loss: 0.704853355884552
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6817588657140732
  Validation Loss: 0.7039800882339478
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6847627311944962
  Validation Loss: 0.703124463558197
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6821387410163879
  Validation Loss: 0.7022984623908997
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6817031502723694
  Validation Loss: 0.7014937400817871
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6826403141021729
  Validation Loss: 0.7006832361221313
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6744373589754105
  Validation Loss: 0.69990074634552
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6853449493646622
  Validation Loss: 0.6991155743598938
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6759704649448395
  Validation Loss: 0.6983700394630432
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6756222993135452
  Validation Loss: 0.6976238489151001
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6826144605875015
  Validation Loss: 0.6968689560890198
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6719961613416672
  Validation Loss: 0.6961661577224731
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6723028123378754
  Validation Loss: 0.695472240447998
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6772910952568054
  Validation Loss: 0.6948280334472656
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.687139555811882
  Validation Loss: 0.6941493153572083
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6762070208787918
  Validation Loss: 0.6935084462165833
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6650220453739166
  Validation Loss: 0.6928538084030151
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6833140701055527
  Validation Loss: 0.6922159790992737
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6801160126924515
  Validation Loss: 0.6915545463562012
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6758244335651398
  Validation Loss: 0.6908996105194092
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6839864552021027
  Validation Loss: 0.6902828812599182
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.670317530632019
  Validation Loss: 0.6896812319755554
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6633240431547165
  Validation Loss: 0.6891065835952759
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6685568690299988
  Validation Loss: 0.688532292842865
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.669523686170578
  Validation Loss: 0.6879563331604004
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6596732884645462
  Validation Loss: 0.6873968839645386
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6654110699892044
  Validation Loss: 0.6868167519569397
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6559392213821411
  Validation Loss: 0.6862881779670715
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6655919700860977
  Validation Loss: 0.6857749223709106
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6677006781101227
  Validation Loss: 0.6852740049362183
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.667306050658226
  Validation Loss: 0.6847789883613586
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6731716990470886
  Validation Loss: 0.6842823624610901
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6742910891771317
  Validation Loss: 0.6838229894638062
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6585051417350769
  Validation Loss: 0.6833562254905701
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6706604659557343
  Validation Loss: 0.6828746199607849
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6699472516775131
  Validation Loss: 0.6823973059654236
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6725127547979355
  Validation Loss: 0.6819543242454529
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.672152504324913
  Validation Loss: 0.6815288662910461
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6684634536504745
  Validation Loss: 0.6811129450798035
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6614944338798523
  Validation Loss: 0.680663526058197
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6687561869621277
  Validation Loss: 0.6802533268928528
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6573289781808853
  Validation Loss: 0.6798385381698608
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6680656522512436
  Validation Loss: 0.6794498562812805
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6586536318063736
  Validation Loss: 0.6790720820426941
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6660739630460739
  Validation Loss: 0.6787126660346985
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6708176732063293
  Validation Loss: 0.6783623695373535
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6709241420030594
  Validation Loss: 0.6780112385749817
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6581023037433624
  Validation Loss: 0.6776734590530396
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6687088459730148
  Validation Loss: 0.6773172616958618
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6687088459730148, 'val_roc_auc': 0.993421052631579, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6773172616958618}
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:56:INFO:
[92mINFO [0m:      Received: evaluate message b4da4701-cf77-48b2-bef2-993ee527ac2e
02/07/2025 22:50:56:INFO:Received: evaluate message b4da4701-cf77-48b2-bef2-993ee527ac2e
[92mINFO [0m:      Sent reply
02/07/2025 22:50:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:59:INFO:
[92mINFO [0m:      Received: train message 931e7297-700b-43a0-b891-af224368c57d
02/07/2025 22:50:59:INFO:Received: train message 931e7297-700b-43a0-b891-af224368c57d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
 ROC_AUC: 0.9934|| Accuracy 0.9630 || Train Loss: 0.6687
 Val Loss: 0.6773 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7238151176591937
Test ROC-AUC: 0.8701298701298702
Test Accuracy: 0.7528089887640449
test_loss: 0.7238151176591937
test_roc_auc: 0.8701298701298702
test_accuracy: 0.7528089887640449
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.1202199489762279
Epoch 1/64:
  Train Loss: 0.6803814172744751
  Validation Loss: 0.7096865773200989
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.67152139544487
  Validation Loss: 0.7088448405265808
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.689716026186943
  Validation Loss: 0.7079727053642273
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6925899982452393
  Validation Loss: 0.707099199295044
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6891406625509262
  Validation Loss: 0.7062814831733704
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6964382827281952
  Validation Loss: 0.7055011987686157
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6912871450185776
  Validation Loss: 0.704723060131073
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6814858913421631
  Validation Loss: 0.7039479613304138
  Val ROC-AUC: 0.9691358024691359
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6968155950307846
  Validation Loss: 0.7032619118690491
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.688082367181778
  Validation Loss: 0.7025241255760193
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.696506604552269
  Validation Loss: 0.7018057107925415
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6933662444353104
  Validation Loss: 0.7010974287986755
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7003977745771408
  Validation Loss: 0.7004181146621704
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.690077930688858
  Validation Loss: 0.6996871829032898
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6817887425422668
  Validation Loss: 0.6990162134170532
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6767650842666626
  Validation Loss: 0.6983461976051331
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6843720972537994
  Validation Loss: 0.6976918578147888
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6845795065164566
  Validation Loss: 0.6970182657241821
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6926480084657669
  Validation Loss: 0.6963809728622437
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6864560842514038
  Validation Loss: 0.6957663297653198
  Val ROC-AUC: 0.9753086419753086
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.689778283238411
  Validation Loss: 0.6951740384101868
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6794488430023193
  Validation Loss: 0.6945831775665283
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6834925562143326
  Validation Loss: 0.6940137147903442
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6788959950208664
  Validation Loss: 0.6934639811515808
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6838183104991913
  Validation Loss: 0.6928871870040894
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6863972842693329
  Validation Loss: 0.6923274397850037
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6740437000989914
  Validation Loss: 0.6917765736579895
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6795777678489685
  Validation Loss: 0.6912249326705933
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6824827492237091
  Validation Loss: 0.6906935572624207
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6801568418741226
  Validation Loss: 0.690159261226654
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6779780238866806
  Validation Loss: 0.6896464228630066
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6795029193162918
  Validation Loss: 0.68914794921875
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6654504835605621
  Validation Loss: 0.6886630654335022
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6782740652561188
  Validation Loss: 0.6881614923477173
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6733031570911407
  Validation Loss: 0.6876764893531799
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6748950630426407
  Validation Loss: 0.6872209906578064
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6660506725311279
  Validation Loss: 0.6867905855178833
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6808726489543915
  Validation Loss: 0.686363160610199
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6724115312099457
  Validation Loss: 0.6859383583068848
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6665777266025543
  Validation Loss: 0.6855224370956421
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6784008890390396
  Validation Loss: 0.6851046681404114
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6643591374158859
  Validation Loss: 0.6847123503684998
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6727459579706192
  Validation Loss: 0.6843540668487549
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6614681929349899
  Validation Loss: 0.6839774250984192
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6626149415969849
  Validation Loss: 0.683624267578125
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6600896716117859
  Validation Loss: 0.6832339763641357
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6701783835887909
  Validation Loss: 0.6828757524490356
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.66522516310215
  Validation Loss: 0.6825366616249084
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6571617722511292
  Validation Loss: 0.6821727156639099
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6649309396743774
  Validation Loss: 0.6818371415138245
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6523246169090271
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:51:31:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:31:INFO:
[92mINFO [0m:      Received: evaluate message a9a03174-e3ff-4e0d-8c3f-7bf110ab80a2
02/07/2025 22:51:31:INFO:Received: evaluate message a9a03174-e3ff-4e0d-8c3f-7bf110ab80a2
[92mINFO [0m:      Sent reply
02/07/2025 22:51:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:34:INFO:
[92mINFO [0m:      Received: train message 0da08197-91f2-4225-8746-1fe70abf679b
02/07/2025 22:51:34:INFO:Received: train message 0da08197-91f2-4225-8746-1fe70abf679b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.681459903717041
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6553022265434265
  Validation Loss: 0.6811432838439941
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6634130924940109
  Validation Loss: 0.680848240852356
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6694782078266144
  Validation Loss: 0.6805399060249329
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6625592559576035
  Validation Loss: 0.6802214980125427
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6704994738101959
  Validation Loss: 0.6799208521842957
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6665701866149902
  Validation Loss: 0.6796239018440247
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6579196453094482
  Validation Loss: 0.6793364882469177
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6553061008453369
  Validation Loss: 0.6790432333946228
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6592869907617569
  Validation Loss: 0.6787682175636292
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6730179190635681
  Validation Loss: 0.6784951090812683
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6586471945047379
  Validation Loss: 0.67823326587677
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6548565179109573
  Validation Loss: 0.6779667735099792
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6538342088460922
  Validation Loss: 0.677716851234436
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6538342088460922, 'val_roc_auc': 0.9938271604938271, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.677716851234436}
 ROC_AUC: 0.9938|| Accuracy 0.9630 || Train Loss: 0.6538
 Val Loss: 0.6777 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7197347966472755
Test ROC-AUC: 0.8744588744588745
Test Accuracy: 0.7865168539325843
test_loss: 0.7197347966472755
test_roc_auc: 0.8744588744588745
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.13291333639699587
Epoch 1/64:
  Train Loss: 0.7124695181846619
  Validation Loss: 0.6254526376724243
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.7138036638498306
  Validation Loss: 0.6246504187583923
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.7128161042928696
  Validation Loss: 0.6238030195236206
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.7020828276872635
  Validation Loss: 0.6230374574661255
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6960541605949402
  Validation Loss: 0.622300386428833
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.7106561064720154
  Validation Loss: 0.6215977072715759
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.7116845101118088
  Validation Loss: 0.6209034323692322
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.7093582898378372
  Validation Loss: 0.6202636957168579
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7075891047716141
  Validation Loss: 0.6196752786636353
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6950624585151672
  Validation Loss: 0.6190474033355713
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.7031267881393433
  Validation Loss: 0.6183879375457764
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.7064045518636703
  Validation Loss: 0.6177241206169128
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7116090506315231
  Validation Loss: 0.6170879602432251
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6937379539012909
  Validation Loss: 0.6165066957473755
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6934869140386581
  Validation Loss: 0.6159519553184509
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6925665140151978
  Validation Loss: 0.6153773665428162
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.7062366604804993
  Validation Loss: 0.614795982837677
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6992447972297668
  Validation Loss: 0.6142714023590088
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7069078087806702
  Validation Loss: 0.6137292981147766
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6959335505962372
  Validation Loss: 0.6131609678268433
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6931236833333969
  Validation Loss: 0.6126357913017273
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.697296530008316
  Validation Loss: 0.6120947599411011
  Val ROC-AUC: 0.9670329670329669
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6989402174949646
  Validation Loss: 0.6116225719451904
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6959561258554459
  Validation Loss: 0.6111045479774475
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6900565028190613
  Validation Loss: 0.6106296181678772
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6909483820199966
  Validation Loss: 0.6101649403572083
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.7001987248659134
  Validation Loss: 0.6097146272659302
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6902317255735397
  Validation Loss: 0.6092702150344849
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6916122436523438
  Validation Loss: 0.6088567972183228
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6922290772199631
  Validation Loss: 0.6084213256835938
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6809745281934738
  Validation Loss: 0.6080150008201599
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6817503422498703
  Validation Loss: 0.6076318025588989
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6904598474502563
  Validation Loss: 0.6072661876678467
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6877023130655289
  Validation Loss: 0.6069042682647705
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6977391093969345
  Validation Loss: 0.6065182089805603
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6956276446580887
  Validation Loss: 0.6061397194862366
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:04:INFO:
[92mINFO [0m:      Received: evaluate message 26eab27b-a3dc-4953-a1dc-e3bc778df140
02/07/2025 22:52:04:INFO:Received: evaluate message 26eab27b-a3dc-4953-a1dc-e3bc778df140
[92mINFO [0m:      Sent reply
02/07/2025 22:52:06:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:06:INFO:
[92mINFO [0m:      Received: train message 67cf6680-c9c7-4b49-9a5f-23f7eb694db5
02/07/2025 22:52:06:INFO:Received: train message 67cf6680-c9c7-4b49-9a5f-23f7eb694db5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6956759989261627
  Validation Loss: 0.6057780385017395
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.679842159152031
  Validation Loss: 0.6054213047027588
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6840932965278625
  Validation Loss: 0.6050417423248291
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6941644549369812
  Validation Loss: 0.6046451330184937
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6788938790559769
  Validation Loss: 0.6042690873146057
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6895239651203156
  Validation Loss: 0.6039227843284607
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6750642359256744
  Validation Loss: 0.603601336479187
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6746019273996353
  Validation Loss: 0.6032797694206238
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6763894557952881
  Validation Loss: 0.6029601693153381
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6691639870405197
  Validation Loss: 0.6026971936225891
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6788040995597839
  Validation Loss: 0.6024035811424255
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6857099235057831
  Validation Loss: 0.6021085977554321
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6828515231609344
  Validation Loss: 0.6017903685569763
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.674691691994667
  Validation Loss: 0.6015304327011108
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6690484881401062
  Validation Loss: 0.6012260317802429
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6816404312849045
  Validation Loss: 0.600958526134491
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6758672893047333
  Validation Loss: 0.600670576095581
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6715457886457443
  Validation Loss: 0.6003860831260681
  Val ROC-AUC: 0.9725274725274724
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6724789142608643
  Validation Loss: 0.6001223921775818
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6769590973854065
  Validation Loss: 0.599888265132904
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6800307035446167
  Validation Loss: 0.5996325016021729
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6790188550949097
  Validation Loss: 0.5994314551353455
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6810282617807388
  Validation Loss: 0.5992100834846497
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6781818121671677
  Validation Loss: 0.598980188369751
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6709906160831451
  Validation Loss: 0.5987346768379211
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6804863959550858
  Validation Loss: 0.598477303981781
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6756874024868011
  Validation Loss: 0.5982615947723389
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6704680919647217
  Validation Loss: 0.5980252623558044
  Val ROC-AUC: 0.978021978021978
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6704680919647217, 'val_roc_auc': 0.978021978021978, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.5980252623558044}
 ROC_AUC: 0.9780|| Accuracy 0.9259 || Train Loss: 0.6705
 Val Loss: 0.5980 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7159173769897289
Test ROC-AUC: 0.8744588744588744
Test Accuracy: 0.7865168539325843
test_loss: 0.7159173769897289
test_roc_auc: 0.8744588744588744
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.10473093901055108
Epoch 1/64:
  Train Loss: 0.6982236802577972
  Validation Loss: 0.6762568950653076
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 2/64:
  Train Loss: 0.7005218267440796
  Validation Loss: 0.6756156086921692
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 3/64:
  Train Loss: 0.6858434826135635
  Validation Loss: 0.6750187277793884
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 4/64:
  Train Loss: 0.7005154341459274
  Validation Loss: 0.6744200587272644
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.6881476640701294
  Validation Loss: 0.6738373637199402
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.6978658884763718
  Validation Loss: 0.67326420545578
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.6835823953151703
  Validation Loss: 0.67268306016922
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.6937240213155746
  Validation Loss: 0.6721186637878418
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.6860135942697525
  Validation Loss: 0.6715421080589294
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6699976474046707
  Validation Loss: 0.6709505319595337
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6887843906879425
  Validation Loss: 0.6704316139221191
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.6807376742362976
  Validation Loss: 0.6699344515800476
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.6818304359912872
  Validation Loss: 0.6694281101226807
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.668964684009552
  Validation Loss: 0.6689323782920837
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6857377290725708
  Validation Loss: 0.6684592962265015
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.6799651384353638
  Validation Loss: 0.6679829359054565
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6878440082073212
  Validation Loss: 0.667515218257904
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.6753959357738495
  Validation Loss: 0.6671076416969299
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6724061220884323
  Validation Loss: 0.6666957139968872
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6827577203512192
  Validation Loss: 0.6662524342536926
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6786612421274185
  Validation Loss: 0.6658183336257935
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:34:INFO:
[92mINFO [0m:      Received: evaluate message 82e72ed2-95e6-4f5b-b012-75f2ed4943fd
02/07/2025 22:52:34:INFO:Received: evaluate message 82e72ed2-95e6-4f5b-b012-75f2ed4943fd
[92mINFO [0m:      Sent reply
02/07/2025 22:52:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:35:INFO:
[92mINFO [0m:      Received: train message 30b8e815-fd28-44ff-9949-ba15acb504ad
02/07/2025 22:52:35:INFO:Received: train message 30b8e815-fd28-44ff-9949-ba15acb504ad
Epoch 22/64:
  Train Loss: 0.6725980788469315
  Validation Loss: 0.6654018759727478
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6785231679677963
  Validation Loss: 0.6650005578994751
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6793206483125687
  Validation Loss: 0.6645918488502502
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6904824376106262
  Validation Loss: 0.6641958951950073
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6826001405715942
  Validation Loss: 0.6638514399528503
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6741594970226288
  Validation Loss: 0.6635028719902039
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6656874865293503
  Validation Loss: 0.6631580591201782
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6638568788766861
  Validation Loss: 0.6628136038780212
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6773806065320969
  Validation Loss: 0.6624596118927002
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6785572469234467
  Validation Loss: 0.6621248722076416
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6740519851446152
  Validation Loss: 0.6618111729621887
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6767195612192154
  Validation Loss: 0.6615031361579895
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6738128811120987
  Validation Loss: 0.6611886024475098
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6718410402536392
  Validation Loss: 0.6608670353889465
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6859282106161118
  Validation Loss: 0.6605391502380371
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6741697490215302
  Validation Loss: 0.6602259278297424
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6713370084762573
  Validation Loss: 0.6599160432815552
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6683531403541565
  Validation Loss: 0.6596416234970093
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6647573411464691
  Validation Loss: 0.6593472361564636
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6491891145706177
  Validation Loss: 0.6590688824653625
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6771380305290222
  Validation Loss: 0.6588115096092224
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6598993241786957
  Validation Loss: 0.6585632562637329
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6695558130741119
  Validation Loss: 0.6583316326141357
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6587417274713516
  Validation Loss: 0.6581088900566101
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6572232395410538
  Validation Loss: 0.6578940749168396
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6596979945898056
  Validation Loss: 0.6576896905899048
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6639738529920578
  Validation Loss: 0.6575065851211548
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6733451187610626
  Validation Loss: 0.6573086380958557
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6673651933670044
  Validation Loss: 0.6571221351623535
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.656000092625618
  Validation Loss: 0.6569373607635498
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.664567232131958
  Validation Loss: 0.6567685008049011
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6735742092132568
  Validation Loss: 0.6565979719161987
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6543429791927338
  Validation Loss: 0.6564398407936096
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6695850044488907
  Validation Loss: 0.6562396287918091
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6609313935041428
  Validation Loss: 0.6560900807380676
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6592297703027725
  Validation Loss: 0.6559247374534607
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6626904159784317
  Validation Loss: 0.6557571291923523
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6580263823270798
  Validation Loss: 0.6555927395820618
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6623218655586243
  Validation Loss: 0.6554383635520935
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6587073653936386
  Validation Loss: 0.6552685499191284
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6492016762495041
  Validation Loss: 0.6551130414009094
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6611318588256836
  Validation Loss: 0.6550013422966003
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6653991341590881
  Validation Loss: 0.6548857092857361
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6653991341590881, 'val_roc_auc': 0.9588235294117647, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6548857092857361}
 ROC_AUC: 0.9588|| Accuracy 0.9630 || Train Loss: 0.6654
 Val Loss: 0.6549 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7124059893442004
Test ROC-AUC: 0.8766233766233766
Test Accuracy: 0.7865168539325843
test_loss: 0.7124059893442004
test_roc_auc: 0.8766233766233766
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.1528864488685334
Epoch 1/64:
  Train Loss: 0.6757056266069412
  Validation Loss: 0.6852774620056152
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6945623010396957
  Validation Loss: 0.684592068195343
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6818718314170837
  Validation Loss: 0.6839082837104797
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6918839514255524
  Validation Loss: 0.683255672454834
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6825212687253952
  Validation Loss: 0.6826293468475342
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6748183071613312
  Validation Loss: 0.6819888353347778
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6891943216323853
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6813598275184631
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.691271647810936
  Validation Loss: 0.6807471513748169
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.681934118270874
  Validation Loss: 0.6801639795303345
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6709613353013992
  Validation Loss: 0.6796011924743652
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6820369064807892
  Validation Loss: 0.6790305376052856
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6887782365083694
  Validation Loss: 0.6784745454788208
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.6703339666128159
  Validation Loss: 0.677924394607544
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6840878278017044
  Validation Loss: 0.677369236946106
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6675641238689423
  Validation Loss: 0.6768337488174438
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.6734918802976608
  Validation Loss: 0.6762829422950745
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6707867980003357
  Validation Loss: 0.6757698059082031
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6914316564798355
  Validation Loss: 0.675250232219696
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.679357185959816
  Validation Loss: 0.6747338175773621
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.6627053320407867
  Validation Loss: 0.6742180585861206
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6676319688558578
  Validation Loss: 0.6736857891082764
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6727518439292908
  Validation Loss: 0.673212468624115
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.6701731085777283
  Validation Loss: 0.6727383732795715
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.6685638278722763
  Validation Loss: 0.6722821593284607
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.6694609373807907
  Validation Loss: 0.6718391180038452
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6816487461328506
  Validation Loss: 0.6713786125183105
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.6759865581989288
  Validation Loss: 0.6709491610527039
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6721630692481995
  Validation Loss: 0.6705141663551331
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6628016829490662
  Validation Loss: 0.6700880527496338
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.6761369109153748
  Validation Loss: 0.6696871519088745
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.6710977107286453
  Validation Loss: 0.6693001389503479
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.6717339009046555
  Validation Loss: 0.6689262390136719
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6585101336240768
  Validation Loss: 0.6685738563537598
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6604849100112915
  Validation Loss: 0.6682102084159851
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6725559383630753
  Validation Loss: 0.667869508266449
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6675234287977219
  Validation Loss: 0.667492687702179
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6719216704368591
  Validation Loss: 0.6671393513679504
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6760551780462265
  Validation Loss: 0.6667870879173279
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.666518360376358
  Validation Loss: 0.6664358973503113
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6492851227521896
  Validation Loss: 0.6660798192024231
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.674283042550087
  Validation Loss: 0.6657612919807434
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6672752201557159
  Validation Loss: 0.665435791015625
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6716790348291397
  Validation Loss: 0.6651291251182556
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6564299464225769
  Validation Loss: 0.6648128032684326
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6663804948329926
  Validation Loss: 0.6644967198371887
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6572859585285187
  Validation Loss: 0.6641740202903748
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6546437293291092
  Validation Loss: 0.663837730884552
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6701271384954453
  Validation Loss: 0.6635355353355408
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6613103747367859
  Validation Loss: 0.6632595062255859
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6494294703006744
  Validation Loss: 0.6629835367202759
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.665255069732666
  Validation Loss: 0.6627295017242432
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6554274260997772
  Validation Loss: 0.6624710559844971
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6744735240936279
  Validation Loss: 0.6622046232223511
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6668015420436859
  Validation Loss: 0.6619438529014587
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6733537912368774
  Validation Loss: 0.6616925597190857
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6596833616495132
  Validation Loss: 0.661435604095459
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6775671988725662
  Validation Loss: 0.6611931324005127
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6690165102481842
  Validation Loss: 0.6609669327735901
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6550157219171524
  Validation Loss: 0.6607407927513123
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.660117119550705
  Validation Loss: 0.6605311632156372
  Val ROC-AUC: 0.9647058823529411
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: evaluate message 1f8a5485-b0ed-4be0-8bf8-c0ff13e62562
02/07/2025 22:53:04:INFO:Received: evaluate message 1f8a5485-b0ed-4be0-8bf8-c0ff13e62562
[92mINFO [0m:      Sent reply
02/07/2025 22:53:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: train message e897e235-313b-4f55-ac66-88972a118f29
02/07/2025 22:53:04:INFO:Received: train message e897e235-313b-4f55-ac66-88972a118f29
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6581708788871765
  Validation Loss: 0.6603296399116516
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6543392837047577
  Validation Loss: 0.6601235270500183
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6594116687774658
  Validation Loss: 0.6599157452583313
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6572240591049194
  Validation Loss: 0.6597217917442322
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6572240591049194, 'val_roc_auc': 0.9647058823529411, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6597217917442322}
 ROC_AUC: 0.9647|| Accuracy 0.9259 || Train Loss: 0.6572
 Val Loss: 0.6597 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7091671285334598
Test ROC-AUC: 0.8782467532467532
Test Accuracy: 0.797752808988764
test_loss: 0.7091671285334598
test_roc_auc: 0.8782467532467532
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.17555469355708436
Epoch 1/64:
  Train Loss: 0.6675553172826767
  Validation Loss: 0.7797828912734985
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 2/64:
  Train Loss: 0.6336281076073647
  Validation Loss: 0.7793270945549011
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 3/64:
  Train Loss: 0.6596745550632477
  Validation Loss: 0.7788909673690796
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 4/64:
  Train Loss: 0.6516718715429306
  Validation Loss: 0.7784959077835083
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 5/64:
  Train Loss: 0.6489499062299728
  Validation Loss: 0.778045117855072
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 6/64:
  Train Loss: 0.6508489698171616
  Validation Loss: 0.7775219082832336
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 7/64:
  Train Loss: 0.6392259746789932
  Validation Loss: 0.7769185304641724
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 8/64:
  Train Loss: 0.660036638379097
  Validation Loss: 0.7764080166816711
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 9/64:
  Train Loss: 0.6540417671203613
  Validation Loss: 0.7758793234825134
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 10/64:
  Train Loss: 0.6372144967317581
  Validation Loss: 0.77541184425354
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 11/64:
  Train Loss: 0.6512870490550995
  Validation Loss: 0.7749943137168884
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 12/64:
  Train Loss: 0.6599236875772476
  Validation Loss: 0.7745362520217896
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 13/64:
  Train Loss: 0.6490394920110703
  Validation Loss: 0.7741368412971497
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 14/64:
  Train Loss: 0.6379000246524811
  Validation Loss: 0.7737331986427307
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 15/64:
  Train Loss: 0.6590680181980133
  Validation Loss: 0.7732601761817932
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 16/64:
  Train Loss: 0.6536442637443542
  Validation Loss: 0.7728326916694641
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 17/64:
  Train Loss: 0.6530113965272903
  Validation Loss: 0.7724030017852783
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 18/64:
  Train Loss: 0.6442674696445465
  Validation Loss: 0.7719405293464661
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.6576522141695023
  Validation Loss: 0.7714529037475586
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.6451115757226944
  Validation Loss: 0.7709940671920776
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.6501418352127075
  Validation Loss: 0.7705622315406799
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.6449181586503983
  Validation Loss: 0.7701123356819153
  Val ROC-AUC: 0.6190476190476191
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.6462646722793579
  Validation Loss: 0.7696810960769653
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.644488513469696
  Validation Loss: 0.7692707180976868
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.6385008841753006
  Validation Loss: 0.7689169049263
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.6484528630971909
  Validation Loss: 0.768580436706543
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.651731088757515
  Validation Loss: 0.7681757807731628
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6400408148765564
  Validation Loss: 0.767738938331604
  Val ROC-AUC: 0.626984126984127
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6494321227073669
  Validation Loss: 0.7674124240875244
  Val ROC-AUC: 0.6349206349206349
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6497327983379364
  Validation Loss: 0.7670460343360901
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6375500857830048
  Validation Loss: 0.7666698098182678
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6421425044536591
  Validation Loss: 0.7662826180458069
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6437547504901886
  Validation Loss: 0.7658699750900269
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6480506956577301
  Validation Loss: 0.765498697757721
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6439013928174973
  Validation Loss: 0.765174150466919
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6419912725687027
  Validation Loss: 0.7647907137870789
  Val ROC-AUC: 0.6428571428571428
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6357365697622299
  Validation Loss: 0.7643566727638245
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6349592953920364
  Validation Loss: 0.7639386057853699
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6365074515342712
  Validation Loss: 0.7635800242424011
  Val ROC-AUC: 0.6507936507936508
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6532277762889862
  Validation Loss: 0.7633110880851746
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6394204646348953
  Validation Loss: 0.7630505561828613
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6397344172000885
  Validation Loss: 0.7627274394035339
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6391233205795288
  Validation Loss: 0.7623874545097351
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6391220986843109
  Validation Loss: 0.762040913105011
  Val ROC-AUC: 0.6587301587301587
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.6380511671304703
  Validation Loss: 0.7617514133453369
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:30:INFO:
[92mINFO [0m:      Received: evaluate message fac2413e-f23d-44a9-8afd-8913c57f77d4
02/07/2025 22:53:30:INFO:Received: evaluate message fac2413e-f23d-44a9-8afd-8913c57f77d4
[92mINFO [0m:      Sent reply
02/07/2025 22:53:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:33:INFO:
[92mINFO [0m:      Received: train message ee217392-86a7-43ea-b6ae-ae6c86c5ba31
02/07/2025 22:53:33:INFO:Received: train message ee217392-86a7-43ea-b6ae-ae6c86c5ba31
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.622021421790123
  Validation Loss: 0.7614866495132446
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.6267798691987991
  Validation Loss: 0.7612295150756836
  Val ROC-AUC: 0.6746031746031746
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.6421444565057755
  Validation Loss: 0.7609682679176331
  Val ROC-AUC: 0.6746031746031746
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6302139610052109
  Validation Loss: 0.7606647610664368
  Val ROC-AUC: 0.6746031746031746
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.6445085257291794
  Validation Loss: 0.7603786587715149
  Val ROC-AUC: 0.6746031746031746
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.6396362036466599
  Validation Loss: 0.7601086497306824
  Val ROC-AUC: 0.6746031746031746
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6236277371644974
  Validation Loss: 0.7598461508750916
  Val ROC-AUC: 0.6746031746031746
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.6401396989822388
  Validation Loss: 0.7595893144607544
  Val ROC-AUC: 0.6825396825396826
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.635637104511261
  Validation Loss: 0.7593324780464172
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6366995722055435
  Validation Loss: 0.7590223550796509
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6218673288822174
  Validation Loss: 0.7587378025054932
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.6394434720277786
  Validation Loss: 0.7584925293922424
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.63417187333107
  Validation Loss: 0.7582693099975586
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6320059299468994
  Validation Loss: 0.7580234408378601
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6445601433515549
  Validation Loss: 0.7577788829803467
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6290531754493713
  Validation Loss: 0.7575240731239319
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.627463698387146
  Validation Loss: 0.7572332620620728
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.6193024069070816
  Validation Loss: 0.7569122910499573
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.6370912492275238
  Validation Loss: 0.7566624283790588
  Val ROC-AUC: 0.6904761904761905
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.6370912492275238, 'val_roc_auc': 0.6904761904761905, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.7566624283790588}
 ROC_AUC: 0.6905|| Accuracy 0.8148 || Train Loss: 0.6371
 Val Loss: 0.7567 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7061679246050588
Test ROC-AUC: 0.8771645021645023
Test Accuracy: 0.8089887640449438
test_loss: 0.7061679246050588
test_roc_auc: 0.8771645021645023
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.08939585906773573
Epoch 1/64:
  Train Loss: 0.6774566024541855
  Validation Loss: 0.6894783973693848
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6784996688365936
  Validation Loss: 0.6888304948806763
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6747393012046814
  Validation Loss: 0.6881675124168396
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6786821037530899
  Validation Loss: 0.6875322461128235
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.675843358039856
  Validation Loss: 0.6869533658027649
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6756670325994492
  Validation Loss: 0.6863613128662109
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6722831726074219
  Validation Loss: 0.6857607960700989
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6649727672338486
  Validation Loss: 0.6851580739021301
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6794156283140182
  Validation Loss: 0.6845669150352478
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.658300369977951
  Validation Loss: 0.6839974522590637
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6588068008422852
  Validation Loss: 0.6834617257118225
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6683492362499237
  Validation Loss: 0.6829524040222168
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6696475148200989
  Validation Loss: 0.6824442744255066
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6718727350234985
  Validation Loss: 0.6819515228271484
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.666106104850769
  Validation Loss: 0.6814371347427368
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6597970724105835
  Validation Loss: 0.6809678077697754
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6722168177366257
  Validation Loss: 0.68049156665802
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6625889241695404
  Validation Loss: 0.6799931526184082
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6669541448354721
  Validation Loss: 0.6795105338096619
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.660580188035965
  Validation Loss: 0.6790075898170471
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6641837060451508
  Validation Loss: 0.6785436868667603
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6746482849121094
  Validation Loss: 0.67806077003479
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.65762959420681
  Validation Loss: 0.6776022911071777
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6652873903512955
  Validation Loss: 0.6771610379219055
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6718464195728302
  Validation Loss: 0.6767686009407043
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6602894812822342
  Validation Loss: 0.6763659119606018
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6684079468250275
  Validation Loss: 0.6759883761405945
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6555868089199066
  Validation Loss: 0.6756207346916199
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6627430319786072
  Validation Loss: 0.675237238407135
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6528378874063492
  Validation Loss: 0.6748756170272827
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6533463448286057
  Validation Loss: 0.6745465397834778/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:54:00:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:00:INFO:
[92mINFO [0m:      Received: evaluate message c19ba033-c5f8-4534-9523-0d3e22b5982b
02/07/2025 22:54:00:INFO:Received: evaluate message c19ba033-c5f8-4534-9523-0d3e22b5982b
[92mINFO [0m:      Sent reply
02/07/2025 22:54:02:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:02:INFO:
[92mINFO [0m:      Received: train message ba948176-d736-434d-81d5-e58f25d751b8
02/07/2025 22:54:02:INFO:Received: train message ba948176-d736-434d-81d5-e58f25d751b8

  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6712418049573898
  Validation Loss: 0.6742229461669922
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6617887318134308
  Validation Loss: 0.6738757491111755
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6570687144994736
  Validation Loss: 0.6735393404960632
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6621643304824829
  Validation Loss: 0.6732178926467896
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6627857238054276
  Validation Loss: 0.6728819608688354
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6581553220748901
  Validation Loss: 0.6725814938545227
  Val ROC-AUC: 0.8764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6647006422281265
  Validation Loss: 0.6722925305366516
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6530429273843765
  Validation Loss: 0.6719916462898254
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6628453880548477
  Validation Loss: 0.6716742515563965
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6583481729030609
  Validation Loss: 0.6713863015174866
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6655032634735107
  Validation Loss: 0.6710877418518066
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6563889235258102
  Validation Loss: 0.6708372831344604
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6609235554933548
  Validation Loss: 0.6705816984176636
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6530000865459442
  Validation Loss: 0.6703407764434814
  Val ROC-AUC: 0.888235294117647
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6510080099105835
  Validation Loss: 0.6700955033302307
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6645567268133163
  Validation Loss: 0.6698428988456726
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6626899838447571
  Validation Loss: 0.6695918440818787
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6609452962875366
  Validation Loss: 0.6693386435508728
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6579141169786453
  Validation Loss: 0.6690555810928345
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6558296531438828
  Validation Loss: 0.6687783002853394
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6647004634141922
  Validation Loss: 0.668533444404602
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.642393484711647
  Validation Loss: 0.6682875156402588
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6467805951833725
  Validation Loss: 0.6680460572242737
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6554691642522812
  Validation Loss: 0.6678233742713928
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6545899957418442
  Validation Loss: 0.667606770992279
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6461645662784576
  Validation Loss: 0.6673808097839355
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6681594848632812
  Validation Loss: 0.6671625375747681
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6456539332866669
  Validation Loss: 0.6669307351112366
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6537285149097443
  Validation Loss: 0.6667363047599792
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6473276317119598
  Validation Loss: 0.6665552258491516
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6524189561605453
  Validation Loss: 0.6663647294044495
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6452537477016449
  Validation Loss: 0.6661945581436157
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6516682058572769
  Validation Loss: 0.6660023331642151
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6516682058572769, 'val_roc_auc': 0.8941176470588235, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6660023331642151}
 ROC_AUC: 0.8941|| Accuracy 0.8889 || Train Loss: 0.6517
 Val Loss: 0.6660 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.703497052862403
Test ROC-AUC: 0.8777056277056278
Test Accuracy: 0.8089887640449438
test_loss: 0.703497052862403
test_roc_auc: 0.8777056277056278
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.16277322324094712
Epoch 1/64:
  Train Loss: 0.6586689800024033
  Validation Loss: 0.6917067766189575
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6847183853387833
  Validation Loss: 0.6911652088165283
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6824856847524643
  Validation Loss: 0.6906177401542664
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6687026619911194
  Validation Loss: 0.6900315284729004
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6648143380880356
  Validation Loss: 0.68947434425354
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6780937761068344
  Validation Loss: 0.6889477372169495
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6720386445522308
  Validation Loss: 0.6884044408798218
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6663890928030014
  Validation Loss: 0.687861979007721
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6695437580347061
  Validation Loss: 0.6873180270195007
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6665443480014801
  Validation Loss: 0.686764657497406
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6627152562141418
  Validation Loss: 0.6862649321556091
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6618111580610275
  Validation Loss: 0.6857946515083313
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.672851487994194
  Validation Loss: 0.6853306889533997
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6736977994441986
  Validation Loss: 0.6848673820495605
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6739997416734695
  Validation Loss: 0.6844379901885986
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6639166623353958
  Validation Loss: 0.6839866042137146
  Val ROC-AUC: 0.9629629629629629
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:54:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:29:INFO:
[92mINFO [0m:      Received: evaluate message 684353f8-79fd-412c-8c50-d8a37778b6dc
02/07/2025 22:54:29:INFO:Received: evaluate message 684353f8-79fd-412c-8c50-d8a37778b6dc
[92mINFO [0m:      Sent reply
02/07/2025 22:54:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:30:INFO:
[92mINFO [0m:      Received: train message 3243517f-85c9-4a96-92ea-b8148fd24b97
02/07/2025 22:54:30:INFO:Received: train message 3243517f-85c9-4a96-92ea-b8148fd24b97
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6655188649892807
  Validation Loss: 0.6835495233535767
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6641852408647537
  Validation Loss: 0.6831222772598267
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6685248911380768
  Validation Loss: 0.682674765586853
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6602167338132858
  Validation Loss: 0.6822018027305603
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.663290485739708
  Validation Loss: 0.6817262768745422
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6602842807769775
  Validation Loss: 0.6812291145324707
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.661253958940506
  Validation Loss: 0.680767834186554
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6763104051351547
  Validation Loss: 0.6803317070007324
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6562446057796478
  Validation Loss: 0.6799387335777283
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6609279662370682
  Validation Loss: 0.6795711517333984
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6649681925773621
  Validation Loss: 0.6792040467262268
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6586317718029022
  Validation Loss: 0.6788685321807861
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6578289717435837
  Validation Loss: 0.6785535216331482
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6690667569637299
  Validation Loss: 0.6782190799713135
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6615123152732849
  Validation Loss: 0.6778947114944458
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6615380346775055
  Validation Loss: 0.6776056885719299
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6584945470094681
  Validation Loss: 0.6773315072059631
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6565247029066086
  Validation Loss: 0.6770178079605103
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6647896617650986
  Validation Loss: 0.6766903400421143
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6592867374420166
  Validation Loss: 0.676376223564148
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6595826297998428
  Validation Loss: 0.6760746836662292
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6651950627565384
  Validation Loss: 0.6757557392120361
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6612297296524048
  Validation Loss: 0.675460934638977
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6608805060386658
  Validation Loss: 0.6752167344093323
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6582956612110138
  Validation Loss: 0.675001859664917
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6673197597265244
  Validation Loss: 0.6747716069221497
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6453838050365448
  Validation Loss: 0.6745474338531494
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6536585688591003
  Validation Loss: 0.6742628812789917
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6668528318405151
  Validation Loss: 0.6740310192108154
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6610549986362457
  Validation Loss: 0.6738295555114746
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6664241254329681
  Validation Loss: 0.6736440062522888
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6487580388784409
  Validation Loss: 0.6734674572944641
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6574262380599976
  Validation Loss: 0.6732879877090454
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6540220230817795
  Validation Loss: 0.6730765104293823
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6530631184577942
  Validation Loss: 0.6728489995002747
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6515012979507446
  Validation Loss: 0.6726400852203369
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6621913015842438
  Validation Loss: 0.6724418997764587
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6459546387195587
  Validation Loss: 0.672236979007721
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6566910296678543
  Validation Loss: 0.672069251537323
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6548298895359039
  Validation Loss: 0.6718676686286926
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6457276791334152
  Validation Loss: 0.671625018119812
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6654936373233795
  Validation Loss: 0.6713822484016418
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6586542576551437
  Validation Loss: 0.6711769104003906
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6471918821334839
  Validation Loss: 0.6709562540054321
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6466862708330154
  Validation Loss: 0.6707488894462585
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6571777760982513
  Validation Loss: 0.670559287071228
  Val ROC-AUC: 0.95679012345679
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6499925851821899
  Validation Loss: 0.670395016670227
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6534034311771393
  Validation Loss: 0.6701995134353638
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6534034311771393, 'val_roc_auc': 0.9506172839506173, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6701995134353638}
 ROC_AUC: 0.9506|| Accuracy 0.9259 || Train Loss: 0.6534
 Val Loss: 0.6702 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7011856342969316
Test ROC-AUC: 0.8777056277056278
Test Accuracy: 0.8089887640449438
test_loss: 0.7011856342969316
test_roc_auc: 0.8777056277056278
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.13512107649755006
Epoch 1/64:
  Train Loss: 0.6544994115829468
  Validation Loss: 0.7086780071258545
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6665390282869339
  Validation Loss: 0.708034873008728
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6616159677505493
  Validation Loss: 0.7074782848358154
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6684240698814392
  Validation Loss: 0.7069280743598938
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6655324995517731
  Validation Loss: 0.7063732743263245
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6607426702976227
  Validation Loss: 0.7058287858963013
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6699798405170441
  Validation Loss: 0.7053095102310181
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6559769809246063
  Validation Loss: 0.7047931551933289
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6544937193393707
  Validation Loss: 0.7042853832244873
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6494723260402679
  Validation Loss: 0.7037608027458191
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6506384611129761
  Validation Loss: 0.7032840847969055
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6519849896430969
  Validation Loss: 0.7028411030769348
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6621759980916977
  Validation Loss: 0.7023880481719971
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6602294594049454
  Validation Loss: 0.7019632458686829
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6611458659172058
  Validation Loss: 0.7015380263328552
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6599792987108231
  Validation Loss: 0.7010855674743652
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6518652439117432
  Validation Loss: 0.7006859183311462
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6579298228025436
  Validation Loss: 0.7003139853477478
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6565956175327301
  Validation Loss: 0.6999416947364807
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6538507640361786
  Validation Loss: 0.6995620727539062
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6565841883420944
  Validation Loss: 0.6991591453552246
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6409111022949219
  Validation Loss: 0.6987872123718262
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.650397002696991
  Validation Loss: 0.6984381675720215
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6598803550004959
  Validation Loss: 0.698082685470581
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6552177965641022
  Validation Loss: 0.6977161765098572
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6502968072891235
  Validation Loss: 0.6973875761032104
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6561003029346466
  Validation Loss: 0.6970686912536621
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6507415026426315
  Validation Loss: 0.6967697143554688
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6510501354932785
  Validation Loss: 0.6964827179908752
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6456114053726196
  Validation Loss: 0.6961901783943176
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6409386992454529
  Validation Loss: 0.6959336400032043
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.656663566827774
  Validation Loss: 0.6956775784492493
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6528284102678299
  Validation Loss: 0.6954467296600342
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6432198882102966
  Validation Loss: 0.6951988935470581
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6458475589752197
  Validation Loss: 0.6949347257614136
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6469014286994934
  Validation Loss: 0.6946728825569153
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6563190966844559
  Validation Loss: 0.6944271326065063
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6494646668434143
  Validation Loss: 0.6941940784454346
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6428615599870682
  Validation Loss: 0.6939384937286377
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6540378332138062
  Validation Loss: 0.6937041878700256
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6444495916366577
  Validation Loss: 0.6934692859649658
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6474284380674362
  Validation Loss: 0.6932188868522644
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6361892521381378
  Validation Loss: 0.692986249923706
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6575240939855576
  Validation Loss: 0.6927935481071472
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6493805348873138
  Validation Loss: 0.6926142573356628
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6644734591245651
  Validation Loss: 0.6923969388008118
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6516187936067581
  Validation Loss: 0.6921864151954651
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6439637243747711
  Validation Loss: 0.6919577121734619
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6339247822761536
  Validation Loss: 0.6917526125907898
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6568256765604019
  Validation Loss: 0.6915572285652161
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6501852422952652
  Validation Loss: 0.6913661360740662
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6466958075761795
  Validation Loss: 0.6911757588386536
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6519624143838882
  Validation Loss: 0.6910046935081482
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6506195068359375
  Validation Loss: 0.6908296942710876
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6513494849205017
  Validation Loss: 0.6906786561012268
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:54:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:57:INFO:
[92mINFO [0m:      Received: evaluate message 69da2e67-c2df-4276-9f3f-ae4b15b671fb
02/07/2025 22:54:57:INFO:Received: evaluate message 69da2e67-c2df-4276-9f3f-ae4b15b671fb
[92mINFO [0m:      Sent reply
02/07/2025 22:54:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:57:INFO:
[92mINFO [0m:      Received: train message 22f90c07-dc9b-4b75-805e-ad29194f0ae1
02/07/2025 22:54:57:INFO:Received: train message 22f90c07-dc9b-4b75-805e-ad29194f0ae1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6484649479389191
  Validation Loss: 0.6905219554901123
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6434284597635269
  Validation Loss: 0.6903323531150818
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6455249786376953
  Validation Loss: 0.6901692748069763
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6404285132884979
  Validation Loss: 0.6900032162666321
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6421898603439331
  Validation Loss: 0.6898208856582642
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6497145295143127
  Validation Loss: 0.6896438598632812
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6430792659521103
  Validation Loss: 0.6894789338111877
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6383417099714279
  Validation Loss: 0.689315676689148
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6416039019823074
  Validation Loss: 0.6891649961471558
  Val ROC-AUC: 0.9802631578947368
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6416039019823074, 'val_roc_auc': 0.9802631578947368, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6891649961471558}
 ROC_AUC: 0.9803|| Accuracy 0.9259 || Train Loss: 0.6416
 Val Loss: 0.6892 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6992135623867592
Test ROC-AUC: 0.8777056277056277
Test Accuracy: 0.8202247191011236
test_loss: 0.6992135623867592
test_roc_auc: 0.8777056277056277
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.06944762944522154
Epoch 1/64:
  Train Loss: 0.6736550033092499
  Validation Loss: 0.6833824515342712
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6709631234407425
  Validation Loss: 0.6829074621200562
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6718280464410782
  Validation Loss: 0.6824995875358582
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.661307618021965
  Validation Loss: 0.6820892095565796
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6670911610126495
  Validation Loss: 0.6816662549972534
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6726232916116714
  Validation Loss: 0.6812378168106079
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.6663616597652435
  Validation Loss: 0.6808243989944458
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.6811307519674301
  Validation Loss: 0.6804066896438599
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.671897754073143
  Validation Loss: 0.6800237894058228
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6588715016841888
  Validation Loss: 0.6796642541885376
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6525853872299194
  Validation Loss: 0.6793020963668823
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.6543017625808716
  Validation Loss: 0.678966224193573
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.6649758070707321
  Validation Loss: 0.6786268353462219
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.6620165258646011
  Validation Loss: 0.6783064603805542
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6647436618804932
  Validation Loss: 0.677986204624176
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.6632252186536789
  Validation Loss: 0.6776577234268188
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6542581468820572
  Validation Loss: 0.6773383617401123
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.6553129702806473
  Validation Loss: 0.6770375370979309
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6586894243955612
  Validation Loss: 0.6767463684082031
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6623287945985794
  Validation Loss: 0.6764740347862244
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6597496122121811
  Validation Loss: 0.6761905550956726
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.6497569978237152
  Validation Loss: 0.675905168056488
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6585719734430313
  Validation Loss: 0.6756476163864136
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6531975418329239
  Validation Loss: 0.6754084825515747
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6459069848060608
  Validation Loss: 0.6751161813735962
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6529770344495773
  Validation Loss: 0.674879789352417
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6570097506046295
  Validation Loss: 0.6746308207511902
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6656012535095215
  Validation Loss: 0.67441326379776
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6606563329696655
  Validation Loss: 0.6741893887519836
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6502756923437119
  Validation Loss: 0.6739911437034607
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.665383979678154
  Validation Loss: 0.6737956404685974
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6589368283748627
  Validation Loss: 0.673603892326355
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6443596631288528
  Validation Loss: 0.6734216809272766
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6560370475053787
  Validation Loss: 0.673224687576294
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6639612466096878
  Validation Loss: 0.6730411052703857
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 36/64:
  Train Loss: 0.6597984880208969
  Validation Loss: 0.6728335618972778
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 37/64:
  Train Loss: 0.6422682106494904
  Validation Loss: 0.6726375222206116
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 38/64:
  Train Loss: 0.6389807909727097
  Validation Loss: 0.6724647283554077
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 39/64:
  Train Loss: 0.6647699028253555
  Validation Loss: 0.6722836494445801
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 40/64:
  Train Loss: 0.66182442009449
  Validation Loss: 0.6721016764640808
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 41/64:
  Train Loss: 0.6424667537212372
  Validation Loss: 0.6719066500663757
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 42/64:
  Train Loss: 0.642360657453537
  Validation Loss: 0.6717345714569092
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 43/64:
  Train Loss: 0.6587507426738739
  Validation Loss: 0.6715648770332336
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 44/64:
  Train Loss: 0.6587442308664322
  Validation Loss: 0.6714302897453308
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 45/64:
  Train Loss: 0.6509252190589905
  Validation Loss: 0.6713122725486755
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 46/64:
  Train Loss: 0.6468187719583511
  Validation Loss: 0.6711860299110413
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 47/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:55:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:23:INFO:
[92mINFO [0m:      Received: evaluate message 4b512c7d-717b-4471-be20-a7ffd3e86f75
02/07/2025 22:55:23:INFO:Received: evaluate message 4b512c7d-717b-4471-be20-a7ffd3e86f75
[92mINFO [0m:      Sent reply
02/07/2025 22:55:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:23:INFO:
[92mINFO [0m:      Received: train message d3840064-dda6-4c0a-80ce-bae62c507ddc
02/07/2025 22:55:23:INFO:Received: train message d3840064-dda6-4c0a-80ce-bae62c507ddc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6467995345592499
  Validation Loss: 0.6710636019706726
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 48/64:
  Train Loss: 0.6450130045413971
  Validation Loss: 0.6709463596343994
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 49/64:
  Train Loss: 0.6594968289136887
  Validation Loss: 0.670821487903595
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 50/64:
  Train Loss: 0.6594222784042358
  Validation Loss: 0.6707127690315247
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 51/64:
  Train Loss: 0.6405877619981766
  Validation Loss: 0.6705875396728516
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 52/64:
  Train Loss: 0.6476222276687622
  Validation Loss: 0.6704747080802917
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 53/64:
  Train Loss: 0.6586440354585648
  Validation Loss: 0.6703495979309082
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 54/64:
  Train Loss: 0.6299433782696724
  Validation Loss: 0.6702068448066711
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 55/64:
  Train Loss: 0.6563042551279068
  Validation Loss: 0.6701096296310425
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 56/64:
  Train Loss: 0.6503371894359589
  Validation Loss: 0.6699768304824829
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 57/64:
  Train Loss: 0.6505008935928345
  Validation Loss: 0.6698605418205261
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 58/64:
  Train Loss: 0.6609514504671097
  Validation Loss: 0.6697601079940796
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 59/64:
  Train Loss: 0.6564700305461884
  Validation Loss: 0.6696781516075134
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 60/64:
  Train Loss: 0.6446151286363602
  Validation Loss: 0.6695990562438965
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 61/64:
  Train Loss: 0.6599201709032059
  Validation Loss: 0.6695094108581543
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 62/64:
  Train Loss: 0.6531944572925568
  Validation Loss: 0.669426679611206
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 63/64:
  Train Loss: 0.6528317928314209
  Validation Loss: 0.6693447232246399
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 64/64:
  Train Loss: 0.6470022797584534
  Validation Loss: 0.6692672371864319
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
{'train_loss': 0.6470022797584534, 'val_roc_auc': 1.0, 'val_accuracy': 1.0, 'val_loss': 0.6692672371864319}
 ROC_AUC: 1.0000|| Accuracy 1.0000 || Train Loss: 0.6470
 Val Loss: 0.6693 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6975414521908492
Test ROC-AUC: 0.8787878787878788
Test Accuracy: 0.8089887640449438
test_loss: 0.6975414521908492
test_roc_auc: 0.8787878787878788
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.06618332039458134
Epoch 1/64:
  Train Loss: 0.6695154905319214
  Validation Loss: 0.7020754218101501
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.651574894785881
  Validation Loss: 0.7015717625617981
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.6754120588302612
  Validation Loss: 0.7010568976402283
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.6610004305839539
  Validation Loss: 0.7005218267440796
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.6607412099838257
  Validation Loss: 0.7000280618667603
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.6560351848602295
  Validation Loss: 0.6995591521263123
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.665252611041069
  Validation Loss: 0.6990799903869629
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.6570611745119095
  Validation Loss: 0.6986241340637207
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.6654322892427444
  Validation Loss: 0.6981865167617798
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6634209454059601
  Validation Loss: 0.6977332234382629
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.6522833108901978
  Validation Loss: 0.6972973942756653
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.6539442539215088
  Validation Loss: 0.6968737840652466
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.6631593555212021
  Validation Loss: 0.6964706182479858
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.6507768034934998
  Validation Loss: 0.696062445640564
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.6670098453760147
  Validation Loss: 0.6956562399864197
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.6505250483751297
  Validation Loss: 0.695273220539093
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.6528206169605255
  Validation Loss: 0.694889485836029
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.6539138853549957
  Validation Loss: 0.6945303678512573
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.6633501052856445
  Validation Loss: 0.6941859126091003
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.6474159806966782
  Validation Loss: 0.693842351436615
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.6486168503761292
  Validation Loss: 0.6935065984725952
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.658867746591568
  Validation Loss: 0.693205714225769
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.6436005085706711
  Validation Loss: 0.692884087562561
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6470745801925659
  Validation Loss: 0.6925716996192932
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.6411509364843369
  Validation Loss: 0.6922649145126343
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6573634147644043
  Validation Loss: 0.6919627785682678
  Val ROC-AUC: 0.9197530864197532
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6462877988815308
  Validation Loss: 0.6916729211807251
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6517600566148758
  Validation Loss: 0.6914047002792358
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6488016247749329
  Validation Loss: 0.6911429166793823
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6497216820716858
  Validation Loss: 0.6908833384513855
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6569729447364807
  Validation Loss: 0.6906176209449768
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6582842022180557
  Validation Loss: 0.6903621554374695
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6484983861446381
  Validation Loss: 0.6901283264160156
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6409918069839478
  Validation Loss: 0.6898879408836365
  Val ROC-AUC: 0.9135802469135802
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6549699455499649
  Validation Loss: 0.6896620988845825
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:55:50:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:50:INFO:
[92mINFO [0m:      Received: evaluate message bd8cc0e1-44ff-48f3-9ed9-e0c851ccddef
02/07/2025 22:55:50:INFO:Received: evaluate message bd8cc0e1-44ff-48f3-9ed9-e0c851ccddef
[92mINFO [0m:      Sent reply
02/07/2025 22:55:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:51:INFO:
[92mINFO [0m:      Received: train message e6cc3c72-c8eb-4270-beb0-3678d1498c7d
02/07/2025 22:55:51:INFO:Received: train message e6cc3c72-c8eb-4270-beb0-3678d1498c7d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6471077501773834
  Validation Loss: 0.6894499659538269
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6442324072122574
  Validation Loss: 0.6892493963241577
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.649720162153244
  Validation Loss: 0.6890326738357544
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.639839380979538
  Validation Loss: 0.6888265013694763
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6504170298576355
  Validation Loss: 0.6886281371116638
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.653211697936058
  Validation Loss: 0.688430666923523
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.643394872546196
  Validation Loss: 0.688235342502594
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6605196893215179
  Validation Loss: 0.6880653500556946
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6550178527832031
  Validation Loss: 0.6878880858421326
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.6355966329574585
  Validation Loss: 0.6877108812332153
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6546325981616974
  Validation Loss: 0.687516450881958
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.6353472322225571
  Validation Loss: 0.6873453259468079
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.6408113092184067
  Validation Loss: 0.6872040033340454
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6413090974092484
  Validation Loss: 0.6870490312576294
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.6483947485685349
  Validation Loss: 0.6868962645530701
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.6497843563556671
  Validation Loss: 0.6867431402206421
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6298147141933441
  Validation Loss: 0.6866079568862915
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.6457505375146866
  Validation Loss: 0.6864795684814453
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.6393732279539108
  Validation Loss: 0.6863411068916321
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6416668444871902
  Validation Loss: 0.6862262487411499
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6459104120731354
  Validation Loss: 0.6861003041267395
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.6289674341678619
  Validation Loss: 0.6859818696975708
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.6498700082302094
  Validation Loss: 0.6858581900596619
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6529134958982468
  Validation Loss: 0.6857265830039978
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6413786262273788
  Validation Loss: 0.6856139302253723
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6523157507181168
  Validation Loss: 0.6855026483535767
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.647766038775444
  Validation Loss: 0.6853955388069153
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.6551081389188766
  Validation Loss: 0.6852843165397644
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.6378601044416428
  Validation Loss: 0.6851624846458435
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.6378601044416428, 'val_roc_auc': 0.9074074074074074, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.6851624846458435}
 ROC_AUC: 0.9074|| Accuracy 0.8148 || Train Loss: 0.6379
 Val Loss: 0.6852 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6960605188701929
Test ROC-AUC: 0.8793290043290044
Test Accuracy: 0.8202247191011236
test_loss: 0.6960605188701929
test_roc_auc: 0.8793290043290044
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.08498131776104856
Epoch 1/64:
  Train Loss: 0.6842306107282639
  Validation Loss: 0.6263293623924255
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6887766718864441
  Validation Loss: 0.6259270310401917
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6735839992761612
  Validation Loss: 0.625548779964447
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6753450930118561
  Validation Loss: 0.6251638531684875
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6726008504629135
  Validation Loss: 0.6247913241386414
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.66426020860672
  Validation Loss: 0.6244320273399353
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6768342107534409
  Validation Loss: 0.624079167842865
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6673888117074966
  Validation Loss: 0.6237252354621887
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6678533405065536
  Validation Loss: 0.6233653426170349
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6743042767047882
  Validation Loss: 0.6230204701423645
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6845069080591202
  Validation Loss: 0.622682511806488
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6767817437648773
  Validation Loss: 0.6223465800285339
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.666120246052742
  Validation Loss: 0.6220188736915588
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.671427920460701
  Validation Loss: 0.6217020153999329
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6756777465343475
  Validation Loss: 0.621415913105011
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6778436601161957
  Validation Loss: 0.6211279630661011
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6657151579856873
  Validation Loss: 0.6208502054214478
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6592338532209396
  Validation Loss: 0.6205839514732361
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6806538999080658
  Validation Loss: 0.6203138828277588
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6684127151966095
  Validation Loss: 0.6200409531593323
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.668007493019104
  Validation Loss: 0.6198081374168396
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:56:17:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:17:INFO:
[92mINFO [0m:      Received: evaluate message 78208fe8-ae90-48b6-b6d1-707c2e342976
02/07/2025 22:56:17:INFO:Received: evaluate message 78208fe8-ae90-48b6-b6d1-707c2e342976
[92mINFO [0m:      Sent reply
02/07/2025 22:56:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:19:INFO:
[92mINFO [0m:      Received: train message 3e636a36-9162-49e8-b52b-3d5b9c2ef210
02/07/2025 22:56:19:INFO:Received: train message 3e636a36-9162-49e8-b52b-3d5b9c2ef210
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6733971536159515
  Validation Loss: 0.6195540428161621
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6606720089912415
  Validation Loss: 0.6192927956581116
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.668260470032692
  Validation Loss: 0.6190479397773743
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6614283323287964
  Validation Loss: 0.6188157200813293
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6595046371221542
  Validation Loss: 0.6185804605484009
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6769650131464005
  Validation Loss: 0.6183707118034363
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6663141697645187
  Validation Loss: 0.6181721687316895
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6662113964557648
  Validation Loss: 0.617957353591919
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6684947311878204
  Validation Loss: 0.6177492737770081
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6811942160129547
  Validation Loss: 0.617555558681488
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6591419130563736
  Validation Loss: 0.6173848509788513
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6559525579214096
  Validation Loss: 0.6171815991401672
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6836860328912735
  Validation Loss: 0.6169930696487427
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6702158004045486
  Validation Loss: 0.6168334484100342
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6728865504264832
  Validation Loss: 0.6166704297065735
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6617259383201599
  Validation Loss: 0.6165099143981934
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6685183644294739
  Validation Loss: 0.6163330078125
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6586950570344925
  Validation Loss: 0.6161673069000244
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6673543453216553
  Validation Loss: 0.6159831881523132
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6708938479423523
  Validation Loss: 0.6157990097999573
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6602835208177567
  Validation Loss: 0.6156505942344666
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6604817658662796
  Validation Loss: 0.6154887080192566
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6751894652843475
  Validation Loss: 0.6153406500816345
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6640353798866272
  Validation Loss: 0.6152147650718689
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6697622984647751
  Validation Loss: 0.6150878667831421
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6669797003269196
  Validation Loss: 0.614947497844696
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.662729799747467
  Validation Loss: 0.6148239374160767
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6630987524986267
  Validation Loss: 0.6147043704986572
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.665127232670784
  Validation Loss: 0.6145867705345154
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6589500606060028
  Validation Loss: 0.6144772171974182
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6766470968723297
  Validation Loss: 0.6143191456794739
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6690791696310043
  Validation Loss: 0.6142126321792603
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6485676169395447
  Validation Loss: 0.6140762567520142
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6582359373569489
  Validation Loss: 0.6139630675315857
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6604296714067459
  Validation Loss: 0.6138442158699036
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6728247553110123
  Validation Loss: 0.6137199997901917
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6603928208351135
  Validation Loss: 0.6136208176612854
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6580856293439865
  Validation Loss: 0.6135128140449524
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6652981042861938
  Validation Loss: 0.6134287118911743
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6617297381162643
  Validation Loss: 0.6133198142051697
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6574159562587738
  Validation Loss: 0.6132417917251587
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6693895757198334
  Validation Loss: 0.6131396889686584
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6707120835781097
  Validation Loss: 0.6130397915840149
  Val ROC-AUC: 0.9611111111111112
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6707120835781097, 'val_roc_auc': 0.9611111111111112, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6130397915840149}
 ROC_AUC: 0.9611|| Accuracy 0.9259 || Train Loss: 0.6707
 Val Loss: 0.6130 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6948149719934785
Test ROC-AUC: 0.8798701298701298
Test Accuracy: 0.8202247191011236
test_loss: 0.6948149719934785
test_roc_auc: 0.8798701298701298
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.07008265626882348
Epoch 1/64:
  Train Loss: 0.678161695599556
  Validation Loss: 0.6290862560272217
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6768173426389694
  Validation Loss: 0.6286166906356812
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6785313934087753
  Validation Loss: 0.6281458139419556
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6740038394927979
  Validation Loss: 0.6276818513870239
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6764261573553085
  Validation Loss: 0.6272347569465637
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6749975383281708
  Validation Loss: 0.6268233060836792
  Val ROC-AUC: 0.9722222222222223
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6636815518140793
  Validation Loss: 0.6263898015022278
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6752068549394608
  Validation Loss: 0.6259860992431641
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6773956716060638
  Validation Loss: 0.6255699396133423
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6676321476697922
  Validation Loss: 0.625174343585968
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6675948649644852
  Validation Loss: 0.6248070597648621
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6636975705623627
  Validation Loss: 0.624428927898407
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6754860281944275
  Validation Loss: 0.6240455508232117
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6647392362356186
  Validation Loss: 0.6236624121665955
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6634551137685776
  Validation Loss: 0.623299241065979
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6685774475336075
  Validation Loss: 0.6229469776153564
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6729754060506821
  Validation Loss: 0.6226006746292114
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6785616278648376
  Validation Loss: 0.6222591996192932
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6667139381170273
  Validation Loss: 0.6219279170036316
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6737664192914963
  Validation Loss: 0.6216062903404236
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6626139730215073
  Validation Loss: 0.621289074420929
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6618020385503769
  Validation Loss: 0.6209770441055298
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6682885885238647
  Validation Loss: 0.6206488609313965
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6768778562545776
  Validation Loss: 0.6203457117080688
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6599074155092239
  Validation Loss: 0.6200781464576721
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6644950360059738
  Validation Loss: 0.6198172569274902
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6766689419746399
  Validation Loss: 0.6195549368858337
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6730349510908127
  Validation Loss: 0.6193071603775024
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6500049531459808
  Validation Loss: 0.6190371513366699
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6728395223617554
  Validation Loss: 0.6187761425971985
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6660913079977036
  Validation Loss: 0.6185327768325806
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6624152362346649
  Validation Loss: 0.6183003187179565
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6587273925542831
  Validation Loss: 0.6180821061134338
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6779218018054962
  Validation Loss: 0.6178667545318604
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6577360183000565
  Validation Loss: 0.6176593899726868
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6672046333551407
  Validation Loss: 0.617447018623352
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6658980697393417
  Validation Loss: 0.6172389388084412
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6706514954566956
  Validation Loss: 0.6170281767845154
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6700272262096405
  Validation Loss: 0.6168414950370789
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6615362018346786
  Validation Loss: 0.6166439056396484
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6696079671382904
  Validation Loss: 0.6164676547050476
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6642383337020874
  Validation Loss: 0.6162812113761902
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6667767912149429
  Validation Loss: 0.6161074638366699
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6572433710098267
  Validation Loss: 0.615949273109436
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6704950034618378
  Validation Loss: 0.6157854795455933
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6657812297344208
  Validation Loss: 0.6156479716300964
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6590077131986618
  Validation Loss: 0.6154983043670654
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6625667810440063
  Validation Loss: 0.615354597568512
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6716737300157547
  Validation Loss: 0.6152184009552002
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6737047433853149
  Validation Loss: 0.6150619983673096
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.671887531876564
  Validation Loss: 0.6149060130119324
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6523932367563248
  Validation Loss: 0.6147518754005432
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6533724367618561
  Validation Loss: 0.6146049499511719
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6597216129302979
  Validation Loss: 0.6144731640815735
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6702883988618851
  Validation Loss: 0.6143297553062439
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6712270379066467
  Validation Loss: 0.6141649484634399
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6572254747152328
  Validation Loss: 0.6140199899673462
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6695421487092972
  Validation Loss: 0.6139041781425476
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6616214066743851
  Validation Loss: 0.6137884855270386
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6605758368968964
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:56:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:47:INFO:
[92mINFO [0m:      Received: evaluate message 265af1d8-003d-4b6a-8df5-3d3cc25a3c7f
02/07/2025 22:56:47:INFO:Received: evaluate message 265af1d8-003d-4b6a-8df5-3d3cc25a3c7f
[92mINFO [0m:      Sent reply
02/07/2025 22:56:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:47:INFO:
[92mINFO [0m:      Received: train message 7df8cc74-898c-411d-bb60-f4a28226db77
02/07/2025 22:56:47:INFO:Received: train message 7df8cc74-898c-411d-bb60-f4a28226db77
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.613649308681488
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6590756475925446
  Validation Loss: 0.613538384437561
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6607472002506256
  Validation Loss: 0.6134098768234253
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6614223420619965
  Validation Loss: 0.6132968068122864
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6651151925325394
  Validation Loss: 0.6131723523139954
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6651151925325394, 'val_roc_auc': 0.9722222222222223, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6131723523139954}
 ROC_AUC: 0.9722|| Accuracy 0.9259 || Train Loss: 0.6651
 Val Loss: 0.6132 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6937197641040502
Test ROC-AUC: 0.8793290043290044
Test Accuracy: 0.8314606741573034
test_loss: 0.6937197641040502
test_roc_auc: 0.8793290043290044
test_accuracy: 0.8314606741573034
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.06128314882971609
Epoch 1/64:
  Train Loss: 0.6715423315763474
  Validation Loss: 0.65590900182724
  Val ROC-AUC: 0.8693181818181818
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.668584331870079
  Validation Loss: 0.6553159952163696
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6611329317092896
  Validation Loss: 0.6547368168830872
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6683816909790039
  Validation Loss: 0.6542144417762756
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6657890975475311
  Validation Loss: 0.6537123322486877
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6600464433431625
  Validation Loss: 0.6532049775123596
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6723227351903915
  Validation Loss: 0.6526985764503479
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6615386009216309
  Validation Loss: 0.6521862745285034
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6627210974693298
  Validation Loss: 0.6517170071601868
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6651664972305298
  Validation Loss: 0.6512261629104614
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.669328972697258
  Validation Loss: 0.6507981419563293
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6579858511686325
  Validation Loss: 0.6503811478614807
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6637991666793823
  Validation Loss: 0.6499664783477783
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6680789738893509
  Validation Loss: 0.6495384573936462
  Val ROC-AUC: 0.875
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6636280566453934
  Validation Loss: 0.6491566300392151
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.649069219827652
  Validation Loss: 0.648780345916748
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.657926082611084
  Validation Loss: 0.6484315991401672
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6591057479381561
  Validation Loss: 0.6480839252471924
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6580673158168793
  Validation Loss: 0.6477482318878174
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6705421209335327
  Validation Loss: 0.6474353671073914
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6602209359407425
  Validation Loss: 0.6471034288406372
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6536986231803894
  Validation Loss: 0.6467491984367371
  Val ROC-AUC: 0.8806818181818181
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6506853699684143
  Validation Loss: 0.6463829278945923
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.659529060125351
  Validation Loss: 0.6460580229759216
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6620103269815445
  Validation Loss: 0.6457349061965942
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6741033494472504
  Validation Loss: 0.6454224586486816
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6502052992582321
  Validation Loss: 0.6451072692871094
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6650479733943939
  Validation Loss: 0.6448032259941101
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.652295857667923
  Validation Loss: 0.6445246338844299
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6581530869007111
  Validation Loss: 0.6442537903785706
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6604748070240021
  Validation Loss: 0.6439789533615112
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6518050730228424
  Validation Loss: 0.6437004804611206
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6551038324832916
  Validation Loss: 0.6434314250946045
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6572467237710953
  Validation Loss: 0.6431934237480164
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6650346368551254
  Validation Loss: 0.6429606080055237
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6589424312114716
  Validation Loss: 0.6427107453346252
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6545687466859818
  Validation Loss: 0.6424738764762878
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.655325710773468
  Validation Loss: 0.6422441601753235
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6546241492033005
  Validation Loss: 0.6420378684997559
  Val ROC-AUC: 0.8920454545454546
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6511259227991104
  Validation Loss: 0.6418381333351135
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6602334976196289
  Validation Loss: 0.6416415572166443
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6625375747680664
  Validation Loss: 0.6414352655410767
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6570270657539368
  Validation Loss: 0.6412478089332581
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6586864441633224
  Validation Loss: 0.6410273909568787
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6619192808866501
  Validation Loss: 0.6408366560935974
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6660205721855164
  Validation Loss: 0.6406267881393433
  Val ROC-AUC: 0.8977272727272727
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:57:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:08:INFO:
[92mINFO [0m:      Received: evaluate message 7040295b-7569-465a-b236-401251131bb2
02/07/2025 22:57:08:INFO:Received: evaluate message 7040295b-7569-465a-b236-401251131bb2
[92mINFO [0m:      Sent reply
02/07/2025 22:57:10:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:10:INFO:
[92mINFO [0m:      Received: train message ebcc6f40-13b8-4f53-bd82-e6700628283e
02/07/2025 22:57:10:INFO:Received: train message ebcc6f40-13b8-4f53-bd82-e6700628283e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6545692682266235
  Validation Loss: 0.6404598355293274
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6588400453329086
  Validation Loss: 0.640301525592804
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6497073471546173
  Validation Loss: 0.6401216983795166
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6564980894327164
  Validation Loss: 0.639951229095459
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6526541113853455
  Validation Loss: 0.6397623419761658
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6533192247152328
  Validation Loss: 0.6395671963691711
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6492193341255188
  Validation Loss: 0.6394238471984863
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6543484777212143
  Validation Loss: 0.6392605304718018
  Val ROC-AUC: 0.8977272727272727
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6631433218717575
  Validation Loss: 0.6391264200210571
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6470583081245422
  Validation Loss: 0.639005720615387
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6528763771057129
  Validation Loss: 0.638899564743042
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6558851897716522
  Validation Loss: 0.6387646198272705
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6634756326675415
  Validation Loss: 0.6386744976043701
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6483820974826813
  Validation Loss: 0.6385713815689087
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6490743309259415
  Validation Loss: 0.638447105884552
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6508981436491013
  Validation Loss: 0.638347327709198
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6574442833662033
  Validation Loss: 0.6382468938827515
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6512971520423889
  Validation Loss: 0.6381376385688782
  Val ROC-AUC: 0.9034090909090909
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6512971520423889, 'val_roc_auc': 0.9034090909090909, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6381376385688782}
 ROC_AUC: 0.9034|| Accuracy 0.9259 || Train Loss: 0.6513
 Val Loss: 0.6381 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6927721249253562
Test ROC-AUC: 0.8793290043290044
Test Accuracy: 0.8314606741573034
test_loss: 0.6927721249253562
test_roc_auc: 0.8793290043290044
test_accuracy: 0.8314606741573034
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.05631655907200185
Epoch 1/64:
  Train Loss: 0.6713368445634842
  Validation Loss: 0.6408900618553162
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6698573380708694
  Validation Loss: 0.640440821647644
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6685026735067368
  Validation Loss: 0.6400246620178223
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6633076965808868
  Validation Loss: 0.6396104097366333
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6750709861516953
  Validation Loss: 0.6392176747322083
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6554137468338013
  Validation Loss: 0.6388247609138489
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6700013428926468
  Validation Loss: 0.638434112071991
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6734442561864853
  Validation Loss: 0.638032853603363
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.6657189279794693
  Validation Loss: 0.637651801109314
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6597166657447815
  Validation Loss: 0.6373022794723511
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6644160598516464
  Validation Loss: 0.6369253396987915
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.669635072350502
  Validation Loss: 0.6365734338760376
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.6672604233026505
  Validation Loss: 0.6362186670303345
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6766629815101624
  Validation Loss: 0.6358932256698608
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6647275537252426
  Validation Loss: 0.6355479955673218
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.6561341136693954
  Validation Loss: 0.635201096534729
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.65549336373806
  Validation Loss: 0.634865403175354
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6620413661003113
  Validation Loss: 0.6345459818840027
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6587247401475906
  Validation Loss: 0.6342674493789673
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.6688717752695084
  Validation Loss: 0.633965790271759
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6769984513521194
  Validation Loss: 0.633664071559906
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6547826826572418
  Validation Loss: 0.6333746910095215
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.661632239818573
  Validation Loss: 0.6330947875976562
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.667477622628212
  Validation Loss: 0.6328158974647522
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.658245712518692
  Validation Loss: 0.6325425505638123
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6715725809335709
  Validation Loss: 0.6322731375694275
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.6649215221405029
  Validation Loss: 0.6320216655731201
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6563999354839325
  Validation Loss: 0.6317833662033081
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6578298658132553
  Validation Loss: 0.631537139415741
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.661415234208107
  Validation Loss: 0.631284236907959
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6549922525882721
  Validation Loss: 0.6310275197029114
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:57:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:34:INFO:
[92mINFO [0m:      Received: evaluate message f971b573-7cf5-4751-a1e3-cac99197998a
02/07/2025 22:57:34:INFO:Received: evaluate message f971b573-7cf5-4751-a1e3-cac99197998a
[92mINFO [0m:      Sent reply
02/07/2025 22:57:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:34:INFO:
[92mINFO [0m:      Received: train message 6da91be1-45fa-47c8-b1e2-ca35a64332b2
02/07/2025 22:57:34:INFO:Received: train message 6da91be1-45fa-47c8-b1e2-ca35a64332b2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6563063263893127
  Validation Loss: 0.6307911276817322
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6660509407520294
  Validation Loss: 0.6305686235427856
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6574071943759918
  Validation Loss: 0.6303744912147522
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6677200347185135
  Validation Loss: 0.6301693320274353
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6602181792259216
  Validation Loss: 0.6299682259559631
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6619608253240585
  Validation Loss: 0.6297835111618042
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.663389727473259
  Validation Loss: 0.6295812726020813
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6644211858510971
  Validation Loss: 0.6293924450874329
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6669411957263947
  Validation Loss: 0.62922203540802
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6618685722351074
  Validation Loss: 0.6290450692176819
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.667053759098053
  Validation Loss: 0.6288653016090393
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6538467705249786
  Validation Loss: 0.6286999583244324
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6604181081056595
  Validation Loss: 0.6285426020622253
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6645926982164383
  Validation Loss: 0.6283887028694153
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6537710577249527
  Validation Loss: 0.628239095211029
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6524994820356369
  Validation Loss: 0.6280816197395325
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6569365113973618
  Validation Loss: 0.6279414296150208
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6531159728765488
  Validation Loss: 0.6277868747711182
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6645349711179733
  Validation Loss: 0.6276307106018066
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6674366891384125
  Validation Loss: 0.6274701356887817
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6584522128105164
  Validation Loss: 0.6273282170295715
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6550078392028809
  Validation Loss: 0.627206027507782
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6711433529853821
  Validation Loss: 0.6270741820335388
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6683564782142639
  Validation Loss: 0.6269654035568237
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6594387888908386
  Validation Loss: 0.6268443465232849
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6518366485834122
  Validation Loss: 0.6267375349998474
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6537961512804031
  Validation Loss: 0.6266120076179504
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6581858545541763
  Validation Loss: 0.626516580581665
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6570288985967636
  Validation Loss: 0.6264079809188843
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6532602459192276
  Validation Loss: 0.6263003945350647
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6559473127126694
  Validation Loss: 0.626190185546875
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6522784680128098
  Validation Loss: 0.6261017322540283
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6446400284767151
  Validation Loss: 0.6260025501251221
  Val ROC-AUC: 0.9772727272727273
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6446400284767151, 'val_roc_auc': 0.9772727272727273, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6260025501251221}
 ROC_AUC: 0.9773|| Accuracy 0.8889 || Train Loss: 0.6446
 Val Loss: 0.6260 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6919771037744672
Test ROC-AUC: 0.8793290043290043
Test Accuracy: 0.8314606741573034
test_loss: 0.6919771037744672
test_roc_auc: 0.8793290043290043
test_accuracy: 0.8314606741573034
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.02233668042117642
Epoch 1/64:
  Train Loss: 0.6609011292457581
  Validation Loss: 0.7073773145675659
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6625968217849731
  Validation Loss: 0.7069545388221741
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6658109128475189
  Validation Loss: 0.7065367698669434
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6738815605640411
  Validation Loss: 0.7061309814453125
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6545033901929855
  Validation Loss: 0.7057673931121826
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6602404713630676
  Validation Loss: 0.7054337859153748
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.650206595659256
  Validation Loss: 0.7050625681877136
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6480032056570053
  Validation Loss: 0.7047534584999084
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6441577225923538
  Validation Loss: 0.7044587135314941
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6511739939451218
  Validation Loss: 0.7041666507720947
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6449516862630844
  Validation Loss: 0.7038902640342712
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6534663438796997
  Validation Loss: 0.7035972476005554
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6510953307151794
  Validation Loss: 0.7033396363258362
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6523965895175934
  Validation Loss: 0.7030760049819946
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.639627531170845
  Validation Loss: 0.7027835249900818
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6518166810274124
  Validation Loss: 0.7025123834609985
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6560756266117096
  Validation Loss: 0.7022761106491089
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6293802559375763
  Validation Loss: 0.7020092010498047
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:57:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:55:INFO:
[92mINFO [0m:      Received: evaluate message 6025589e-29e8-4588-bd75-e189089bfdfe
02/07/2025 22:57:55:INFO:Received: evaluate message 6025589e-29e8-4588-bd75-e189089bfdfe
[92mINFO [0m:      Sent reply
02/07/2025 22:57:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:56:INFO:
[92mINFO [0m:      Received: train message 9de7751c-569a-4610-b119-cd2415b130da
02/07/2025 22:57:56:INFO:Received: train message 9de7751c-569a-4610-b119-cd2415b130da
  Train Loss: 0.6527314186096191
  Validation Loss: 0.7017782926559448
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6450449079275131
  Validation Loss: 0.7015495896339417
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6397960782051086
  Validation Loss: 0.7013162970542908
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.661473959684372
  Validation Loss: 0.7010790705680847
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6361084133386612
  Validation Loss: 0.7008446455001831
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6452504396438599
  Validation Loss: 0.7006187438964844
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6415957808494568
  Validation Loss: 0.7004439234733582
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6515087932348251
  Validation Loss: 0.7002703547477722
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.650318518280983
  Validation Loss: 0.7000852823257446
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6515880525112152
  Validation Loss: 0.6999073624610901
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6540183573961258
  Validation Loss: 0.6997218728065491
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6453098207712173
  Validation Loss: 0.699532151222229
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6416978985071182
  Validation Loss: 0.6993573307991028
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6416601091623306
  Validation Loss: 0.6991739869117737
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6410710513591766
  Validation Loss: 0.6989812254905701
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6406086087226868
  Validation Loss: 0.698826253414154
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6388448178768158
  Validation Loss: 0.698668360710144
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6484697163105011
  Validation Loss: 0.6985242962837219
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6353276968002319
  Validation Loss: 0.6983842253684998
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6593693792819977
  Validation Loss: 0.6982659101486206
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6422521770000458
  Validation Loss: 0.6981242895126343
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6458171010017395
  Validation Loss: 0.6979861855506897
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.65121790766716
  Validation Loss: 0.697857677936554
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6399992853403091
  Validation Loss: 0.6977207660675049
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6419862657785416
  Validation Loss: 0.6976021528244019
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6440263390541077
  Validation Loss: 0.6975011229515076
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6457156240940094
  Validation Loss: 0.697385311126709
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6415015161037445
  Validation Loss: 0.6972764134407043
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6428635716438293
  Validation Loss: 0.697156548500061
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6357636153697968
  Validation Loss: 0.6970505714416504
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6445060223340988
  Validation Loss: 0.696941077709198
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6467344462871552
  Validation Loss: 0.6968379020690918
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6297992318868637
  Validation Loss: 0.69673091173172
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6331271082162857
  Validation Loss: 0.6966645121574402
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6445428133010864
  Validation Loss: 0.6965906620025635
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6453833132982254
  Validation Loss: 0.6965004801750183
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6413741409778595
  Validation Loss: 0.6964239478111267
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.63483627140522
  Validation Loss: 0.6963390111923218
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6531902849674225
  Validation Loss: 0.6962759494781494
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6317766755819321
  Validation Loss: 0.6962058544158936
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6505010575056076
  Validation Loss: 0.6961415410041809
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6342096328735352
  Validation Loss: 0.6961014270782471
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.630910187959671
  Validation Loss: 0.6960155963897705
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6397620141506195
  Validation Loss: 0.6959341764450073
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6463362276554108
  Validation Loss: 0.6958749890327454
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.643068939447403
  Validation Loss: 0.6958318948745728
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.643068939447403, 'val_roc_auc': 0.9928571428571428, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6958318948745728}
 ROC_AUC: 0.9929|| Accuracy 0.9259 || Train Loss: 0.6431
 Val Loss: 0.6958 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6913535233294026
Test ROC-AUC: 0.8787878787878788
Test Accuracy: 0.8202247191011236
test_loss: 0.6913535233294026
test_roc_auc: 0.8787878787878788
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.018121209062883278
Epoch 1/64:
  Train Loss: 0.6828339099884033
  Validation Loss: 0.6018692255020142
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.677768811583519
  Validation Loss: 0.6015646457672119
  Val ROC-AUC: 0.989010989010989
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6894034147262573
  Validation Loss: 0.6012731790542603
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.674345001578331
  Validation Loss: 0.6009892821311951
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.687011107802391
  Validation Loss: 0.6007259488105774
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6670418530702591
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6004710793495178
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6640420705080032
  Validation Loss: 0.600212037563324
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6818432509899139
  Validation Loss: 0.5999724864959717
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.667776495218277
  Validation Loss: 0.599729061126709
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6688092947006226
  Validation Loss: 0.5995033383369446
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.684046596288681
  Validation Loss: 0.599245011806488
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6679746210575104
  Validation Loss: 0.5990092754364014
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6806726008653641
  Validation Loss: 0.598781406879425
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6685126721858978
  Validation Loss: 0.5985644459724426
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6807388365268707
  Validation Loss: 0.5983518958091736
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6545737981796265
  Validation Loss: 0.5981508493423462
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6783597469329834
  Validation Loss: 0.5979514122009277
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.6694699078798294
  Validation Loss: 0.5977683663368225
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6771451234817505
  Validation Loss: 0.597609281539917
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6677127033472061
  Validation Loss: 0.5974398255348206
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6746860444545746
  Validation Loss: 0.5972841382026672
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.6728343069553375
  Validation Loss: 0.5971340537071228
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6708781868219376
  Validation Loss: 0.5969581604003906
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6832484751939774
  Validation Loss: 0.5967959761619568
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6693364828824997
  Validation Loss: 0.5966479182243347
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6668259501457214
  Validation Loss: 0.5965209007263184
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6816695332527161
  Validation Loss: 0.5963988304138184
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6612154990434647
  Validation Loss: 0.5962886214256287
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6807303875684738
  Validation Loss: 0.5961796641349792
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6680878400802612
  Validation Loss: 0.5960612297058105
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6681611239910126
  Validation Loss: 0.5959450602531433
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6658130884170532
  Validation Loss: 0.5958262085914612
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6639980524778366
  Validation Loss: 0.5957168340682983
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6824943572282791
  Validation Loss: 0.5955849885940552
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6641725897789001
  Validation Loss: 0.5954849123954773
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6764761656522751
  Validation Loss: 0.5953881144523621
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.667968362569809
  Validation Loss: 0.5952773094177246
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6675191819667816
  Validation Loss: 0.5952003002166748
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6704778373241425
  Validation Loss: 0.5951125621795654
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6706874668598175
  Validation Loss: 0.595043420791626
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6667797714471817
  Validation Loss: 0.5949530005455017
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6586343944072723
  Validation Loss: 0.5948875546455383
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6629329323768616
  Validation Loss: 0.5948131680488586
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6693642139434814
  Validation Loss: 0.5947250127792358
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6566565334796906
  Validation Loss: 0.5946570634841919
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6686746180057526
  Validation Loss: 0.594595730304718
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.664181262254715
  Validation Loss: 0.5945223569869995
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.656094878911972
  Validation Loss: 0.5944753885269165
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6439700275659561
  Validation Loss: 0.5944250226020813
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6671417057514191
  Validation Loss: 0.5943671464920044
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6753935068845749
  Validation Loss: 0.5943160653114319
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6711407154798508
  Validation Loss: 0.5942723155021667
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6765236109495163
  Validation Loss: 0.5942230224609375
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6613730788230896
  Validation Loss: 0.5941798090934753
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6624763607978821
  Validation Loss: 0.59412682056427
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6739731281995773
  Validation Loss: 0.5940937399864197
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6611488163471222
  Validation Loss: 0.5940419435501099
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6479512155056
  Validation Loss: 0.5939925909042358
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6550926119089127
  Validation Loss: 0.593961775302887
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6687878370285034
  Validation Loss: 0.5939345955848694
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6607365012168884
  Validation Loss: 0.5938969254493713
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.660497784614563
  Validation Loss: 0.593855619430542
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 63/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:58:17:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:58:17:INFO:
[92mINFO [0m:      Received: evaluate message ea3a30c4-0c7f-49b8-9878-7ef79ed70762
02/07/2025 22:58:17:INFO:Received: evaluate message ea3a30c4-0c7f-49b8-9878-7ef79ed70762
[92mINFO [0m:      Sent reply
02/07/2025 22:58:18:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:58:18:INFO:
[92mINFO [0m:      Received: train message 0cd2cde7-03b0-43e5-bf51-bca5705d41fb
02/07/2025 22:58:18:INFO:Received: train message 0cd2cde7-03b0-43e5-bf51-bca5705d41fb
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.665524810552597
  Validation Loss: 0.5938339829444885
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 64/64:
  Train Loss: 0.6624185293912888
  Validation Loss: 0.5937934517860413
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
{'train_loss': 0.6624185293912888, 'val_roc_auc': 1.0, 'val_accuracy': 1.0, 'val_loss': 0.5937934517860413}
 ROC_AUC: 1.0000|| Accuracy 1.0000 || Train Loss: 0.6624
 Val Loss: 0.5938 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.690899563974209
Test ROC-AUC: 0.8777056277056278
Test Accuracy: 0.8089887640449438
test_loss: 0.690899563974209
test_roc_auc: 0.8777056277056278
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.01318628981698566
Epoch 1/64:
  Train Loss: 0.6546702980995178
  Validation Loss: 0.6865814328193665
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6635149121284485
  Validation Loss: 0.6862921118736267
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6472561359405518
  Validation Loss: 0.6860224604606628
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6561886817216873
  Validation Loss: 0.6858067512512207
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6573418527841568
  Validation Loss: 0.6855830550193787
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6546309739351273
  Validation Loss: 0.6853667497634888
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6468365788459778
  Validation Loss: 0.685164749622345
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6539501696825027
  Validation Loss: 0.6849742531776428
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6503867506980896
  Validation Loss: 0.6847843527793884
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.650193378329277
  Validation Loss: 0.6845976114273071
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6527911573648453
  Validation Loss: 0.6844316720962524
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6519309133291245
  Validation Loss: 0.6842715740203857
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6565307229757309
  Validation Loss: 0.684130847454071
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.661488801240921
  Validation Loss: 0.6839824318885803
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6562007665634155
  Validation Loss: 0.6838431358337402
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6433867961168289
  Validation Loss: 0.683691143989563
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6466986835002899
  Validation Loss: 0.6835718750953674
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6462772041559219
  Validation Loss: 0.6834617853164673
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6516111791133881
  Validation Loss: 0.6833614706993103
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6545058786869049
  Validation Loss: 0.6832813620567322
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6601254791021347
  Validation Loss: 0.6831876039505005
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6318744271993637
  Validation Loss: 0.6830761432647705
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6515389978885651
  Validation Loss: 0.6830108165740967
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.638027086853981
  Validation Loss: 0.6829326748847961
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.65762759745121
  Validation Loss: 0.6828543543815613
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6502573490142822
  Validation Loss: 0.6827768683433533
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6543228179216385
  Validation Loss: 0.6827204823493958
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6444872468709946
  Validation Loss: 0.6826610565185547
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6556020528078079
  Validation Loss: 0.6826178431510925
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6428592652082443
  Validation Loss: 0.6825718879699707
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6507233083248138
  Validation Loss: 0.6825287342071533
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6461558938026428
  Validation Loss: 0.6824925541877747
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6478101909160614
  Validation Loss: 0.6824390888214111
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6483081728219986
  Validation Loss: 0.6824135780334473
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6464692801237106
  Validation Loss: 0.6823864579200745
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.642503023147583
  Validation Loss: 0.6823667883872986
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6404612213373184
  Validation Loss: 0.6823285222053528
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6489812731742859
  Validation Loss: 0.6823170781135559
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6478579193353653
  Validation Loss: 0.6823222041130066
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6466752290725708
  Validation Loss: 0.6823013424873352
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6543008387088776
  Validation Loss: 0.6822940111160278
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6361891031265259
  Validation Loss: 0.6822810769081116
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6420852243900299
  Validation Loss: 0.6822837591171265
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6294225305318832
  Validation Loss: 0.6822620034217834
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.634786382317543
  Validation Loss: 0.6822689771652222
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6385397464036942
  Validation Loss: 0.6822785139083862
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6457142680883408
  Validation Loss: 0.682294487953186
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6525047868490219
  Validation Loss: 0.6823040843009949
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:58:39:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:58:39:INFO:
[92mINFO [0m:      Received: evaluate message 0fa91e29-c0e3-4efc-98e2-99435711d6eb
02/07/2025 22:58:39:INFO:Received: evaluate message 0fa91e29-c0e3-4efc-98e2-99435711d6eb
[92mINFO [0m:      Sent reply
02/07/2025 22:58:40:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:58:40:INFO:
[92mINFO [0m:      Received: train message 628d3cdd-71ab-4d53-978c-b1601f27436c
02/07/2025 22:58:40:INFO:Received: train message 628d3cdd-71ab-4d53-978c-b1601f27436c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.643232062458992
  Validation Loss: 0.6823005676269531
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.6363331824541092
  Validation Loss: 0.6823042035102844
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6429084241390228
  Validation Loss: 0.6823047995567322
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.644637256860733
  Validation Loss: 0.6823229193687439
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.6448349803686142
  Validation Loss: 0.6823245882987976
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6429049223661423
  Validation Loss: 0.6823473572731018
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.6455337107181549
  Validation Loss: 0.6823650002479553
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.652057096362114
  Validation Loss: 0.6823843121528625
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6411685347557068
  Validation Loss: 0.6824069619178772
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6495007276535034
  Validation Loss: 0.6824299693107605
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6374108791351318
  Validation Loss: 0.6824672818183899
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6492279767990112
  Validation Loss: 0.6824860572814941
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.647218331694603
  Validation Loss: 0.6825194358825684
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6439226567745209
  Validation Loss: 0.6825385093688965
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6459818929433823
  Validation Loss: 0.6825681924819946
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6450477838516235
  Validation Loss: 0.6825961470603943
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6450477838516235, 'val_roc_auc': 0.9802631578947367, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6825961470603943}
 ROC_AUC: 0.9803|| Accuracy 0.8889 || Train Loss: 0.6450
 Val Loss: 0.6826 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6905469137631105
Test ROC-AUC: 0.8755411255411255
Test Accuracy: 0.8089887640449438
test_loss: 0.6905469137631105
test_roc_auc: 0.8755411255411255
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3601837158203125
Dynamic noise multiplier: 0.0
Epoch 1/64:
  Train Loss: 0.6664397120475769
  Validation Loss: 0.6921840310096741
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.6536292433738708
  Validation Loss: 0.6918897032737732
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.6615356206893921
  Validation Loss: 0.6916117072105408
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.6616533994674683
  Validation Loss: 0.6913121342658997
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.6685498803853989
  Validation Loss: 0.691016435623169
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.6388170272111893
  Validation Loss: 0.6907264590263367
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.6461720168590546
  Validation Loss: 0.6904429197311401
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.6564743667840958
  Validation Loss: 0.6902046799659729
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.6559889167547226
  Validation Loss: 0.6899425983428955
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6568013578653336
  Validation Loss: 0.6897082924842834
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.6545060873031616
  Validation Loss: 0.6894541382789612
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.6458502858877182
  Validation Loss: 0.6892121434211731
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.6548488438129425
  Validation Loss: 0.688995361328125
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.6424151360988617
  Validation Loss: 0.6887791156768799
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.6563832610845566
  Validation Loss: 0.6885707974433899
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.6526792794466019
  Validation Loss: 0.688336968421936
  Val ROC-AUC: 0.8456790123456791
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.6470395475625992
  Validation Loss: 0.6881264448165894
  Val ROC-AUC: 0.8456790123456791
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.644017294049263
  Validation Loss: 0.6879168152809143
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.6504229456186295
  Validation Loss: 0.6877243518829346
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.6477381736040115
  Validation Loss: 0.6875259280204773
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.64826999604702
  Validation Loss: 0.6873301863670349
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.6335169225931168
  Validation Loss: 0.6871500611305237
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.6431958377361298
  Validation Loss: 0.6869791150093079
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6470655351877213
  Validation Loss: 0.6868107318878174
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.6462080776691437
  Validation Loss: 0.6866376996040344
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6443249136209488
  Validation Loss: 0.6864814162254333
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6491388529539108
  Validation Loss: 0.686336874961853
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.641157791018486
  Validation Loss: 0.6861904263496399
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6528247743844986
  Validation Loss: 0.6860564947128296
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6508644968271255
  Validation Loss: 0.6859260201454163
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6399441808462143
  Validation Loss: 0.6857843995094299
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6534135788679123
  Validation Loss: 0.6856487393379211
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6484070420265198
  Validation Loss: 0.6855098009109497
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6359747648239136
  Validation Loss: 0.6853762269020081
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:59:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:59:01:INFO:
[92mINFO [0m:      Received: evaluate message 0dee4513-50b8-4815-9d38-24c1250e4904
02/07/2025 22:59:01:INFO:Received: evaluate message 0dee4513-50b8-4815-9d38-24c1250e4904
[92mINFO [0m:      Sent reply
02/07/2025 22:59:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:59:01:INFO:
[92mINFO [0m:      Received: reconnect message e0ae52d0-8e0f-4b2a-aa75-687db100949f
02/07/2025 22:59:01:INFO:Received: reconnect message e0ae52d0-8e0f-4b2a-aa75-687db100949f
02/07/2025 22:59:01:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/07/2025 22:59:01:INFO:Disconnect and shut down
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6430909335613251
  Validation Loss: 0.6852613687515259
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6446189135313034
  Validation Loss: 0.6851497888565063
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6347557604312897
  Validation Loss: 0.6850171089172363
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6437812298536301
  Validation Loss: 0.6849172711372375
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6391872763633728
  Validation Loss: 0.684813916683197
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6418079286813736
  Validation Loss: 0.684716522693634
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6466087400913239
  Validation Loss: 0.6846193671226501
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6413358598947525
  Validation Loss: 0.6845179796218872
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6421058923006058
  Validation Loss: 0.6844372153282166
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.654871940612793
  Validation Loss: 0.6843574643135071
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.651573047041893
  Validation Loss: 0.6842616200447083
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6380804926156998
  Validation Loss: 0.6841706037521362
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.632794663310051
  Validation Loss: 0.6840885281562805
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.6500460058450699
  Validation Loss: 0.6840142011642456
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6410472542047501
  Validation Loss: 0.6839454174041748
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.6409821808338165
  Validation Loss: 0.6838862299919128
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.6285112649202347
  Validation Loss: 0.6838224530220032
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6388014256954193
  Validation Loss: 0.6837561130523682
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.645930141210556
  Validation Loss: 0.6836816072463989
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.6500981748104095
  Validation Loss: 0.683626115322113
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6328393965959549
  Validation Loss: 0.683550238609314
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6435461640357971
  Validation Loss: 0.6834850907325745
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.637054368853569
  Validation Loss: 0.6834236979484558
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.6332110017538071
  Validation Loss: 0.6833773255348206
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6346519738435745
  Validation Loss: 0.6833046674728394
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6416449248790741
  Validation Loss: 0.6832570433616638
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6380249410867691
  Validation Loss: 0.6832149624824524
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.6323201358318329
  Validation Loss: 0.6831740140914917
  Val ROC-AUC: 0.8641975308641975
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.6398563086986542
  Validation Loss: 0.6831309795379639
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.6467956453561783
  Validation Loss: 0.6830984354019165
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.6467956453561783, 'val_roc_auc': 0.8703703703703703, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.6830984354019165}
 ROC_AUC: 0.8704|| Accuracy 0.8148 || Train Loss: 0.6468
 Val Loss: 0.6831 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6902791660153464
Test ROC-AUC: 0.8750000000000001
Test Accuracy: 0.8089887640449438
test_loss: 0.6902791660153464
test_roc_auc: 0.8750000000000001
test_accuracy: 0.8089887640449438
eval_cid: 1
CPU Time: 1065.254655 seconds
Elapsed Time: 849.4418530464172 seconds
RAM Usage: 0.41263580322265625 megabytes
Logs saved in current directory
