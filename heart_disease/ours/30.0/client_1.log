nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:44:59:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:44:59:DEBUG:Opened insecure gRPC connection (no certificates were passed)
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738997099.158879 1773243 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
02/07/2025 22:44:59:DEBUG:ChannelConnectivity.IDLE
02/07/2025 22:44:59:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
02/07/2025 22:44:59:INFO:
[92mINFO [0m:      Received: train message a51c9a59-f0fe-405a-b523-b64d494904be
02/07/2025 22:44:59:INFO:Received: train message a51c9a59-f0fe-405a-b523-b64d494904be
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours/30.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours']
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.2303639870024199
Epoch 1/64:
  Train Loss: 0.7125523090362549
  Validation Loss: 0.763279139995575
  Val ROC-AUC: 0.7374999999999999
  Val Accuracy: 0.65625
Epoch 2/64:
  Train Loss: 0.7112912833690643
  Validation Loss: 0.7619554400444031
  Val ROC-AUC: 0.7458333333333333
  Val Accuracy: 0.65625
Epoch 3/64:
  Train Loss: 0.7100987434387207
  Validation Loss: 0.760640025138855
  Val ROC-AUC: 0.7541666666666667
  Val Accuracy: 0.65625
Epoch 4/64:
  Train Loss: 0.7089532911777496
  Validation Loss: 0.7592950463294983
  Val ROC-AUC: 0.7666666666666666
  Val Accuracy: 0.65625
Epoch 5/64:
  Train Loss: 0.7077462524175644
  Validation Loss: 0.7579758167266846
  Val ROC-AUC: 0.7666666666666666
  Val Accuracy: 0.65625
Epoch 6/64:
  Train Loss: 0.7065936923027039
  Validation Loss: 0.7567586302757263
  Val ROC-AUC: 0.775
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.7054546624422073
  Validation Loss: 0.7555333375930786
  Val ROC-AUC: 0.7791666666666667
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.7044161558151245
  Validation Loss: 0.75434410572052
  Val ROC-AUC: 0.7791666666666667
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.7033557295799255
  Validation Loss: 0.7530965805053711
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.75
Epoch 10/64:
  Train Loss: 0.7023054659366608
  Validation Loss: 0.7518808841705322
  Val ROC-AUC: 0.7958333333333334
  Val Accuracy: 0.75
Epoch 11/64:
  Train Loss: 0.7013324797153473
  Validation Loss: 0.7506392598152161
  Val ROC-AUC: 0.7916666666666666
  Val Accuracy: 0.75
Epoch 12/64:
  Train Loss: 0.7002839744091034
  Validation Loss: 0.749468207359314
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.75
Epoch 13/64:
  Train Loss: 0.6993490010499954
  Validation Loss: 0.7482624053955078
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 14/64:
  Train Loss: 0.6984046548604965
  Validation Loss: 0.7470643520355225
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 15/64:
  Train Loss: 0.6974048763513565
  Validation Loss: 0.745945155620575
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 16/64:
  Train Loss: 0.6965131312608719
  Validation Loss: 0.7448574304580688
  Val ROC-AUC: 0.8083333333333333
  Val Accuracy: 0.78125
Epoch 17/64:
  Train Loss: 0.6956034600734711
  Validation Loss: 0.7437937259674072
  Val ROC-AUC: 0.8125
  Val Accuracy: 0.78125
Epoch 18/64:
  Train Loss: 0.6947318017482758
  Validation Loss: 0.7427494525909424
  Val ROC-AUC: 0.8166666666666667
  Val Accuracy: 0.78125
Epoch 19/64:
  Train Loss: 0.6939220428466797
  Validation Loss: 0.7416983842849731
  Val ROC-AUC: 0.8208333333333333
  Val Accuracy: 0.78125
Epoch 20/64:
  Train Loss: 0.6930183619260788
  Validation Loss: 0.7407216429710388
  Val ROC-AUC: 0.8208333333333333
  Val Accuracy: 0.78125
Epoch 21/64:
  Train Loss: 0.6921896040439606
  Validation Loss: 0.739728569984436
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.78125
Epoch 22/64:
  Train Loss: 0.6913391798734665
  Validation Loss: 0.7387561202049255
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.78125
Epoch 23/64:
  Train Loss: 0.6905405074357986
  Validation Loss: 0.7377830147743225
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.78125
Epoch 24/64:
  Train Loss: 0.6897641718387604
  Validation Loss: 0.7368807792663574
  Val ROC-AUC: 0.8375
  Val Accuracy: 0.78125
Epoch 25/64:
  Train Loss: 0.6890716403722763
  Validation Loss: 0.7359771132469177
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.78125
Epoch 26/64:
  Train Loss: 0.6883315593004227
  Validation Loss: 0.7350651025772095
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.75
Epoch 27/64:
  Train Loss: 0.6875682473182678
  Validation Loss: 0.7341728210449219
  Val ROC-AUC: 0.8541666666666667
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6868390887975693
  Validation Loss: 0.7332861423492432
  Val ROC-AUC: 0.8583333333333333
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6861501485109329
  Validation Loss: 0.7323765754699707
  Val ROC-AUC: 0.8583333333333333
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6854414939880371
  Validation Loss: 0.7315290570259094
  Val ROC-AUC: 0.8541666666666667
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6847442388534546
  Validation Loss: 0.7307352423667908
  Val ROC-AUC: 0.8541666666666667
  Val Accuracy: 0.78125
Epoch 32/64:
  Train Loss: 0.68410424888134
  Validation Loss: 0.7299574613571167
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.78125
Epoch 33/64:
  Train Loss: 0.683478981256485
  Validation Loss: 0.7291730642318726
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.78125
Epoch 34/64:
  Train Loss: 0.6828405559062958
  Validation Loss: 0.7284102439880371
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.6821947991847992
  Validation Loss: 0.7276934385299683
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.6815872490406036
  Validation Loss: 0.7269550561904907
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.6809995025396347
  Validation Loss: 0.726207971572876
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6804052293300629
  Validation Loss: 0.7254674434661865
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6797835826873779
  Validation Loss: 0.7247942686080933
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6792509257793427
  Validation Loss: 0.7241144776344299
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 41/64:
  Train Loss: 0.6786961406469345
  Validation Loss: 0.7234550714492798
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 42/64:
  Train Loss: 0.6782142966985703
  Validation Loss: 0.7227864265441895
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.78125
Epoch 43/64:
  Train Loss: 0.6776374727487564
  Validation Loss: 0.7221782207489014
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.78125
Epoch 44/64:
  Train Loss: 0.6771697103977203
  Validation Loss: 0.7215917110443115
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 45/64:
  Train Loss: 0.6766513735055923
  Validation Loss: 0.7210186719894409
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.6761882603168488
  Validation Loss: 0.7204434871673584
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.6756781190633774
  Validation Loss: 0.719861626625061
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6752066910266876
  Validation Loss: 0.7192835807800293
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.6747454851865768
  Validation Loss: 0.7187003493309021
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6742938458919525
  Validation Loss: 0.7181141376495361
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6738666892051697
  Validation Loss: 0.717549204826355
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6734225004911423
  Validation Loss: 0.7170236110687256
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6730487942695618
  Validation Loss: 0.7164605259895325
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.672646164894104
  Validation Loss: 0.7158955335617065
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6722313314676285
  Validation Loss: 0.7153748273849487
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.78125
Epoch 56/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:26:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:27:INFO:
[92mINFO [0m:      Received: evaluate message 990518e5-7740-48c1-a7ac-9039f4f7cecc
02/07/2025 22:45:27:INFO:Received: evaluate message 990518e5-7740-48c1-a7ac-9039f4f7cecc
[92mINFO [0m:      Sent reply
02/07/2025 22:45:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:33:INFO:
[92mINFO [0m:      Received: train message d3ac0515-c47b-4edf-8026-bae411abc1aa
02/07/2025 22:45:33:INFO:Received: train message d3ac0515-c47b-4edf-8026-bae411abc1aa
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6718312650918961
  Validation Loss: 0.7149184942245483
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6714364588260651
  Validation Loss: 0.7144280672073364
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6710675209760666
  Validation Loss: 0.7139222025871277
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6706420928239822
  Validation Loss: 0.7133857011795044
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6702593117952347
  Validation Loss: 0.7128440141677856
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6698790937662125
  Validation Loss: 0.7123278379440308
  Val ROC-AUC: 0.8875
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6695253998041153
  Validation Loss: 0.7118242979049683
  Val ROC-AUC: 0.8875
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6691136956214905
  Validation Loss: 0.7113306522369385
  Val ROC-AUC: 0.8875
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6687875688076019
  Validation Loss: 0.7108761072158813
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.78125
{'train_loss': 0.6687875688076019, 'val_roc_auc': 0.8833333333333333, 'val_accuracy': 0.78125, 'val_loss': 0.7108761072158813}
 ROC_AUC: 0.8833|| Accuracy 0.7812 || Train Loss: 0.6688
 Val Loss: 0.7109 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7233750668282692
Test ROC-AUC: 0.6666666666666666
Test Accuracy: 0.625
test_loss: 0.7233750668282692
test_roc_auc: 0.6666666666666666
test_accuracy: 0.625
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.1824794967615162
Epoch 1/64:
  Train Loss: 0.7112689316272736
  Validation Loss: 0.755623459815979
  Val ROC-AUC: 0.7124999999999999
  Val Accuracy: 0.59375
Epoch 2/64:
  Train Loss: 0.7101105451583862
  Validation Loss: 0.7544459104537964
  Val ROC-AUC: 0.7166666666666666
  Val Accuracy: 0.59375
Epoch 3/64:
  Train Loss: 0.7089361101388931
  Validation Loss: 0.7533111572265625
  Val ROC-AUC: 0.725
  Val Accuracy: 0.625
Epoch 4/64:
  Train Loss: 0.7077551186084747
  Validation Loss: 0.7521951794624329
  Val ROC-AUC: 0.7291666666666667
  Val Accuracy: 0.625
Epoch 5/64:
  Train Loss: 0.7065930217504501
  Validation Loss: 0.7510756254196167
  Val ROC-AUC: 0.7333333333333333
  Val Accuracy: 0.625
Epoch 6/64:
  Train Loss: 0.7054326832294464
  Validation Loss: 0.7500504851341248
  Val ROC-AUC: 0.7416666666666667
  Val Accuracy: 0.625
Epoch 7/64:
  Train Loss: 0.7043924033641815
  Validation Loss: 0.7489645481109619
  Val ROC-AUC: 0.7541666666666667
  Val Accuracy: 0.625
Epoch 8/64:
  Train Loss: 0.7033173590898514
  Validation Loss: 0.7479245662689209
  Val ROC-AUC: 0.7666666666666666
  Val Accuracy: 0.625
Epoch 9/64:
  Train Loss: 0.7022545486688614
  Validation Loss: 0.7468947172164917
  Val ROC-AUC: 0.7749999999999999
  Val Accuracy: 0.625
Epoch 10/64:
  Train Loss: 0.7011874169111252
  Validation Loss: 0.745876669883728
  Val ROC-AUC: 0.7833333333333333
  Val Accuracy: 0.625
Epoch 11/64:
  Train Loss: 0.700106218457222
  Validation Loss: 0.7448654174804688
  Val ROC-AUC: 0.7875
  Val Accuracy: 0.625
Epoch 12/64:
  Train Loss: 0.6990977078676224
  Validation Loss: 0.7438789010047913
  Val ROC-AUC: 0.7875
  Val Accuracy: 0.625
Epoch 13/64:
  Train Loss: 0.6980690062046051
  Validation Loss: 0.7428916692733765
  Val ROC-AUC: 0.8
  Val Accuracy: 0.625
Epoch 14/64:
  Train Loss: 0.697045311331749
  Validation Loss: 0.7419384717941284
  Val ROC-AUC: 0.8
  Val Accuracy: 0.625
Epoch 15/64:
  Train Loss: 0.6960660666227341
  Validation Loss: 0.7410218715667725
  Val ROC-AUC: 0.8083333333333333
  Val Accuracy: 0.625
Epoch 16/64:
  Train Loss: 0.695187970995903
  Validation Loss: 0.740106463432312
  Val ROC-AUC: 0.8166666666666667
  Val Accuracy: 0.65625
Epoch 17/64:
  Train Loss: 0.694244310259819
  Validation Loss: 0.7392309904098511
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.65625
Epoch 18/64:
  Train Loss: 0.6933479309082031
  Validation Loss: 0.7383545637130737
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.65625
Epoch 19/64:
  Train Loss: 0.6924984455108643
  Validation Loss: 0.7374445796012878
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.65625
Epoch 20/64:
  Train Loss: 0.6915588229894638
  Validation Loss: 0.7366019487380981
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.65625
Epoch 21/64:
  Train Loss: 0.6907235532999039
  Validation Loss: 0.7357603907585144
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 22/64:
  Train Loss: 0.6898559629917145
  Validation Loss: 0.734917938709259
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 23/64:
  Train Loss: 0.6890078336000443
  Validation Loss: 0.7341328859329224
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 24/64:
  Train Loss: 0.6882211565971375
  Validation Loss: 0.7333495616912842
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 25/64:
  Train Loss: 0.6874017417430878
  Validation Loss: 0.732572615146637
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 26/64:
  Train Loss: 0.6866448670625687
  Validation Loss: 0.7318045496940613
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 27/64:
  Train Loss: 0.6858830153942108
  Validation Loss: 0.7310518026351929
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 28/64:
  Train Loss: 0.6850974857807159
  Validation Loss: 0.7303274869918823
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 29/64:
  Train Loss: 0.6844111084938049
  Validation Loss: 0.7295745611190796
  Val ROC-AUC: 0.8374999999999999
  Val Accuracy: 0.65625
Epoch 30/64:
  Train Loss: 0.6836419850587845
  Validation Loss: 0.7288174629211426
  Val ROC-AUC: 0.8374999999999999
  Val Accuracy: 0.65625
Epoch 31/64:
  Train Loss: 0.6829033643007278
  Validation Loss: 0.7280995845794678
  Val ROC-AUC: 0.8374999999999999
  Val Accuracy: 0.65625
Epoch 32/64:
  Train Loss: 0.682206928730011
  Validation Loss: 0.7273967266082764
  Val ROC-AUC: 0.8374999999999999
  Val Accuracy: 0.65625
Epoch 33/64:
  Train Loss: 0.6815385967493057
  Validation Loss: 0.7267128229141235
  Val ROC-AUC: 0.8374999999999999
  Val Accuracy: 0.6875
Epoch 34/64:
  Train Loss: 0.6808832436800003
  Validation Loss: 0.726019561290741
  Val ROC-AUC: 0.8416666666666667
  Val Accuracy: 0.6875
Epoch 35/64:
  Train Loss: 0.6802107095718384
  Validation Loss: 0.7253480553627014
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.6875
Epoch 36/64:
  Train Loss: 0.6795965284109116
  Validation Loss: 0.7247228622436523
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.6875
Epoch 37/64:
  Train Loss: 0.6790187656879425
  Validation Loss: 0.7241396903991699
  Val ROC-AUC: 0.8416666666666667
  Val Accuracy: 0.6875
Epoch 38/64:
  Train Loss: 0.6784896403551102
  Validation Loss: 0.723536491394043
  Val ROC-AUC: 0.8416666666666667
  Val Accuracy: 0.6875
Epoch 39/64:
  Train Loss: 0.6778863668441772
  Validation Loss: 0.7229448556900024
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.6875
Epoch 40/64:
  Train Loss: 0.6773264706134796
  Validation Loss: 0.722352147102356
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.6875
Epoch 41/64:
  Train Loss: 0.6767368763685226
  Validation Loss: 0.7218061089515686
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.6875
Epoch 42/64:
  Train Loss: 0.6762074530124664
  Validation Loss: 0.7212027311325073
  Val ROC-AUC: 0.8458333333333333
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6756658554077148
  Validation Loss: 0.720601499080658
  Val ROC-AUC: 0.85
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6751422733068466
  Validation Loss: 0.720026433467865
  Val ROC-AUC: 0.85
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.674567848443985
  Validation Loss: 0.7195065021514893
  Val ROC-AUC: 0.85
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6740862280130386
  Validation Loss: 0.7189633846282959
  Val ROC-AUC: 0.8541666666666666
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:01:INFO:
[92mINFO [0m:      Received: evaluate message 57330040-775b-463d-949d-26080fa54680
02/07/2025 22:46:01:INFO:Received: evaluate message 57330040-775b-463d-949d-26080fa54680
[92mINFO [0m:      Sent reply
02/07/2025 22:46:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:01:INFO:
[92mINFO [0m:      Received: train message 6eaba309-0f08-4328-b909-8451056a16d3
02/07/2025 22:46:01:INFO:Received: train message 6eaba309-0f08-4328-b909-8451056a16d3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6735618263483047
  Validation Loss: 0.7184395790100098
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6730929613113403
  Validation Loss: 0.7179006338119507
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6726335883140564
  Validation Loss: 0.7173828482627869
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6721402257680893
  Validation Loss: 0.7168705463409424
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.671656921505928
  Validation Loss: 0.7163581252098083
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6712189018726349
  Validation Loss: 0.7158417701721191
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6707398295402527
  Validation Loss: 0.7153497934341431
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6702983975410461
  Validation Loss: 0.7148865461349487
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.6698741018772125
  Validation Loss: 0.7144254446029663
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.6694703847169876
  Validation Loss: 0.71397465467453
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6690527051687241
  Validation Loss: 0.7135422229766846
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.6686718314886093
  Validation Loss: 0.7131021022796631
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.6682529151439667
  Validation Loss: 0.712694525718689
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.667851135134697
  Validation Loss: 0.7122969627380371
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6674970388412476
  Validation Loss: 0.7118867635726929
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6671578884124756
  Validation Loss: 0.7114815711975098
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6667756587266922
  Validation Loss: 0.7111395597457886
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6664383262395859
  Validation Loss: 0.7107582688331604
  Val ROC-AUC: 0.8833333333333333
  Val Accuracy: 0.71875
{'train_loss': 0.6664383262395859, 'val_roc_auc': 0.8833333333333333, 'val_accuracy': 0.71875, 'val_loss': 0.7107582688331604}
 ROC_AUC: 0.8833|| Accuracy 0.7188 || Train Loss: 0.6664
 Val Loss: 0.7108 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7191770563905056
Test ROC-AUC: 0.6975446428571429
Test Accuracy: 0.6346153846153846
test_loss: 0.7191770563905056
test_roc_auc: 0.6975446428571429
test_accuracy: 0.6346153846153846
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.16934550892074185
Epoch 1/64:
  Train Loss: 0.7179065495729446
  Validation Loss: 0.7098334431648254
  Val ROC-AUC: 0.6328125
  Val Accuracy: 0.5625
Epoch 2/64:
  Train Loss: 0.7164808809757233
  Validation Loss: 0.7089757323265076
  Val ROC-AUC: 0.64453125
  Val Accuracy: 0.5625
Epoch 3/64:
  Train Loss: 0.7151127457618713
  Validation Loss: 0.7080624103546143
  Val ROC-AUC: 0.6484375
  Val Accuracy: 0.5625
Epoch 4/64:
  Train Loss: 0.7138153314590454
  Validation Loss: 0.7071378231048584
  Val ROC-AUC: 0.66015625
  Val Accuracy: 0.5625
Epoch 5/64:
  Train Loss: 0.7125444114208221
  Validation Loss: 0.7062474489212036
  Val ROC-AUC: 0.66796875
  Val Accuracy: 0.5625
Epoch 6/64:
  Train Loss: 0.7112809866666794
  Validation Loss: 0.7053741812705994
  Val ROC-AUC: 0.671875
  Val Accuracy: 0.5625
Epoch 7/64:
  Train Loss: 0.710075780749321
  Validation Loss: 0.7045284509658813
  Val ROC-AUC: 0.67578125
  Val Accuracy: 0.5625
Epoch 8/64:
  Train Loss: 0.7089423537254333
  Validation Loss: 0.7036895751953125
  Val ROC-AUC: 0.6796875
  Val Accuracy: 0.59375
Epoch 9/64:
  Train Loss: 0.7077226489782333
  Validation Loss: 0.7028735876083374
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.59375
Epoch 10/64:
  Train Loss: 0.7066211253404617
  Validation Loss: 0.7020424604415894
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.59375
Epoch 11/64:
  Train Loss: 0.7055826336145401
  Validation Loss: 0.7012179493904114
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.59375
Epoch 12/64:
  Train Loss: 0.7044974714517593
  Validation Loss: 0.700430154800415
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.59375
Epoch 13/64:
  Train Loss: 0.7033984959125519
  Validation Loss: 0.6996698975563049
  Val ROC-AUC: 0.703125
  Val Accuracy: 0.625
Epoch 14/64:
  Train Loss: 0.7023369818925858
  Validation Loss: 0.6989232301712036
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 15/64:
  Train Loss: 0.7013297528028488
  Validation Loss: 0.6981586217880249
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 16/64:
  Train Loss: 0.7002695500850677
  Validation Loss: 0.6974325180053711
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.65625
Epoch 17/64:
  Train Loss: 0.6993462145328522
  Validation Loss: 0.6967204213142395
  Val ROC-AUC: 0.70703125
  Val Accuracy: 0.65625
Epoch 18/64:
  Train Loss: 0.6984416246414185
  Validation Loss: 0.6959875822067261
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.65625
Epoch 19/64:
  Train Loss: 0.6974591165781021
  Validation Loss: 0.6953152418136597
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.65625
Epoch 20/64:
  Train Loss: 0.6965795606374741
  Validation Loss: 0.6946355104446411
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.65625
Epoch 21/64:
  Train Loss: 0.6957257241010666
  Validation Loss: 0.6939524412155151
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.65625
Epoch 22/64:
  Train Loss: 0.6948585510253906
  Validation Loss: 0.6932979226112366
  Val ROC-AUC: 0.71875
  Val Accuracy: 0.65625
Epoch 23/64:
  Train Loss: 0.694034218788147
  Validation Loss: 0.6926661133766174
  Val ROC-AUC: 0.71875
  Val Accuracy: 0.65625
Epoch 24/64:
  Train Loss: 0.6932527422904968
  Validation Loss: 0.6920287609100342
  Val ROC-AUC: 0.72265625
  Val Accuracy: 0.625
Epoch 25/64:
  Train Loss: 0.6924273073673248
  Validation Loss: 0.6914052367210388
  Val ROC-AUC: 0.7265625
  Val Accuracy: 0.65625
Epoch 26/64:
  Train Loss: 0.6916989684104919
  Validation Loss: 0.690813422203064
  Val ROC-AUC: 0.7265625
  Val Accuracy: 0.625
Epoch 27/64:
  Train Loss: 0.6909713745117188
  Validation Loss: 0.6902087330818176
  Val ROC-AUC: 0.73046875
  Val Accuracy: 0.625
Epoch 28/64:
  Train Loss: 0.6902237087488174
  Validation Loss: 0.6896165609359741
  Val ROC-AUC: 0.734375
  Val Accuracy: 0.625
Epoch 29/64:
  Train Loss: 0.6894772946834564
  Validation Loss: 0.6890634894371033
  Val ROC-AUC: 0.734375
  Val Accuracy: 0.625
Epoch 30/64:
  Train Loss: 0.6887755542993546
  Validation Loss: 0.6885052919387817
  Val ROC-AUC: 0.734375
  Val Accuracy: 0.625
Epoch 31/64:
  Train Loss: 0.6881249845027924
  Validation Loss: 0.6879316568374634
  Val ROC-AUC: 0.7421875
  Val Accuracy: 0.625
Epoch 32/64:
  Train Loss: 0.6875000298023224
  Validation Loss: 0.687347412109375
  Val ROC-AUC: 0.7421875
  Val Accuracy: 0.625
Epoch 33/64:
  Train Loss: 0.6867747008800507
  Validation Loss: 0.6868013143539429
  Val ROC-AUC: 0.73828125
  Val Accuracy: 0.625
Epoch 34/64:
  Train Loss: 0.6861462444067001
  Validation Loss: 0.6862653493881226
  Val ROC-AUC: 0.73828125
  Val Accuracy: 0.625
Epoch 35/64:
  Train Loss: 0.6855213791131973
  Validation Loss: 0.685745894908905
  Val ROC-AUC: 0.734375
  Val Accuracy: 0.625
Epoch 36/64:
  Train Loss: 0.684921458363533
  Validation Loss: 0.6852326393127441
  Val ROC-AUC: 0.734375
  Val Accuracy: 0.625
Epoch 37/64:
  Train Loss: 0.6843030452728271
  Validation Loss: 0.6847195029258728
  Val ROC-AUC: 0.7421875
  Val Accuracy: 0.65625
Epoch 38/64:
  Train Loss: 0.6836939752101898
  Validation Loss: 0.6842225790023804
  Val ROC-AUC: 0.74609375
  Val Accuracy: 0.65625
Epoch 39/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:29:INFO:
[92mINFO [0m:      Received: evaluate message 4c7c0a47-c97d-41ed-b8dd-c331db2200a3
02/07/2025 22:46:29:INFO:Received: evaluate message 4c7c0a47-c97d-41ed-b8dd-c331db2200a3
[92mINFO [0m:      Sent reply
02/07/2025 22:46:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:30:INFO:
[92mINFO [0m:      Received: train message 1e2f7486-be15-4cc2-92c7-80935d176e15
02/07/2025 22:46:30:INFO:Received: train message 1e2f7486-be15-4cc2-92c7-80935d176e15
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6830761730670929
  Validation Loss: 0.6837366819381714
  Val ROC-AUC: 0.75
  Val Accuracy: 0.65625
Epoch 40/64:
  Train Loss: 0.6825290769338608
  Validation Loss: 0.6832699179649353
  Val ROC-AUC: 0.75
  Val Accuracy: 0.65625
Epoch 41/64:
  Train Loss: 0.6820064932107925
  Validation Loss: 0.682816743850708
  Val ROC-AUC: 0.7578125
  Val Accuracy: 0.65625
Epoch 42/64:
  Train Loss: 0.6814868599176407
  Validation Loss: 0.6823698878288269
  Val ROC-AUC: 0.75390625
  Val Accuracy: 0.65625
Epoch 43/64:
  Train Loss: 0.6809694916009903
  Validation Loss: 0.6819064021110535
  Val ROC-AUC: 0.75390625
  Val Accuracy: 0.65625
Epoch 44/64:
  Train Loss: 0.6804751455783844
  Validation Loss: 0.6814404726028442
  Val ROC-AUC: 0.75390625
  Val Accuracy: 0.65625
Epoch 45/64:
  Train Loss: 0.6799659430980682
  Validation Loss: 0.6809794902801514
  Val ROC-AUC: 0.75390625
  Val Accuracy: 0.6875
Epoch 46/64:
  Train Loss: 0.6794165670871735
  Validation Loss: 0.6805391907691956
  Val ROC-AUC: 0.7578125
  Val Accuracy: 0.6875
Epoch 47/64:
  Train Loss: 0.6789416521787643
  Validation Loss: 0.6800864934921265
  Val ROC-AUC: 0.7578125
  Val Accuracy: 0.6875
Epoch 48/64:
  Train Loss: 0.6784028708934784
  Validation Loss: 0.6796602606773376
  Val ROC-AUC: 0.7578125
  Val Accuracy: 0.6875
Epoch 49/64:
  Train Loss: 0.6779158115386963
  Validation Loss: 0.6792545318603516
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 50/64:
  Train Loss: 0.6774931699037552
  Validation Loss: 0.6788374781608582
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 51/64:
  Train Loss: 0.6770389080047607
  Validation Loss: 0.6784448623657227
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 52/64:
  Train Loss: 0.6766183376312256
  Validation Loss: 0.6780662536621094
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 53/64:
  Train Loss: 0.676210343837738
  Validation Loss: 0.6776703000068665
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 54/64:
  Train Loss: 0.6757958978414536
  Validation Loss: 0.6772943139076233
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 55/64:
  Train Loss: 0.6754074245691299
  Validation Loss: 0.6769145727157593
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 56/64:
  Train Loss: 0.675018236041069
  Validation Loss: 0.6765440702438354
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 57/64:
  Train Loss: 0.6746362149715424
  Validation Loss: 0.676166832447052
  Val ROC-AUC: 0.76171875
  Val Accuracy: 0.6875
Epoch 58/64:
  Train Loss: 0.6742541491985321
  Validation Loss: 0.6758344173431396
  Val ROC-AUC: 0.765625
  Val Accuracy: 0.6875
Epoch 59/64:
  Train Loss: 0.6739288419485092
  Validation Loss: 0.675494909286499
  Val ROC-AUC: 0.76953125
  Val Accuracy: 0.6875
Epoch 60/64:
  Train Loss: 0.6735735088586807
  Validation Loss: 0.6751535534858704
  Val ROC-AUC: 0.76953125
  Val Accuracy: 0.6875
Epoch 61/64:
  Train Loss: 0.6732271164655685
  Validation Loss: 0.6748045682907104
  Val ROC-AUC: 0.78125
  Val Accuracy: 0.6875
Epoch 62/64:
  Train Loss: 0.6728626787662506
  Validation Loss: 0.6744862198829651
  Val ROC-AUC: 0.78125
  Val Accuracy: 0.6875
Epoch 63/64:
  Train Loss: 0.672601580619812
  Validation Loss: 0.6741423606872559
  Val ROC-AUC: 0.78125
  Val Accuracy: 0.6875
Epoch 64/64:
  Train Loss: 0.6722605228424072
  Validation Loss: 0.6738110780715942
  Val ROC-AUC: 0.78125
  Val Accuracy: 0.71875
{'train_loss': 0.6722605228424072, 'val_roc_auc': 0.78125, 'val_accuracy': 0.71875, 'val_loss': 0.6738110780715942}
 ROC_AUC: 0.7812|| Accuracy 0.7188 || Train Loss: 0.6723
 Val Loss: 0.6738 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.714442333063254
Test ROC-AUC: 0.7213541666666666
Test Accuracy: 0.6346153846153846
test_loss: 0.714442333063254
test_roc_auc: 0.7213541666666666
test_accuracy: 0.6346153846153846
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.20716029738650832
Epoch 1/64:
  Train Loss: 0.7163603901863098
  Validation Loss: 0.6938175559043884
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.7150910496711731
  Validation Loss: 0.6932110786437988
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 3/64:
  Train Loss: 0.7137745022773743
  Validation Loss: 0.6925621032714844
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 4/64:
  Train Loss: 0.7126012593507767
  Validation Loss: 0.691947340965271
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 5/64:
  Train Loss: 0.7114315032958984
  Validation Loss: 0.6913653612136841
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 6/64:
  Train Loss: 0.7103171646595001
  Validation Loss: 0.690762996673584
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 7/64:
  Train Loss: 0.7091964483261108
  Validation Loss: 0.6902048587799072
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.7080499976873398
  Validation Loss: 0.6896792650222778
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.7069806307554245
  Validation Loss: 0.689142644405365
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.7059071660041809
  Validation Loss: 0.688575267791748
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.7048055976629257
  Validation Loss: 0.6880747079849243
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.7037936300039291
  Validation Loss: 0.6876023411750793
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.7027952373027802
  Validation Loss: 0.6871275901794434
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.701764389872551
  Validation Loss: 0.6866600513458252
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.7008128613233566
  Validation Loss: 0.6861792802810669
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6998182535171509
  Validation Loss: 0.6857396364212036
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.698868915438652
  Validation Loss: 0.6853396892547607
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6979300230741501
  Validation Loss: 0.6849290132522583
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6970388144254684
  Validation Loss: 0.6845276355743408
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6960886716842651
  Validation Loss: 0.6841809749603271
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6953186839818954
  Validation Loss: 0.6838386058807373
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6944629400968552
  Validation Loss: 0.6834423542022705
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 23/64:
  Train Loss: 0.6936500370502472
  Validation Loss: 0.6830447912216187
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 24/64:
  Train Loss: 0.6927938312292099
  Validation Loss: 0.6826795339584351
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 25/64:
  Train Loss: 0.6920677721500397
  Validation Loss: 0.68235182762146
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 26/64:
  Train Loss: 0.6912704855203629
  Validation Loss: 0.6820112466812134
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 27/64:
  Train Loss: 0.6905187517404556
  Validation Loss: 0.6816670894622803
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6897475868463516
  Validation Loss: 0.6813454627990723
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.689050167798996
  Validation Loss: 0.6810178756713867
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6882475763559341
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:58:INFO:
[92mINFO [0m:      Received: evaluate message 533d43a0-4d66-4b50-ae90-00ebeb56ab3f
02/07/2025 22:46:58:INFO:Received: evaluate message 533d43a0-4d66-4b50-ae90-00ebeb56ab3f
[92mINFO [0m:      Sent reply
02/07/2025 22:46:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:59:INFO:
[92mINFO [0m:      Received: train message 2d7f8265-e23d-4231-9273-72a8dc521518
02/07/2025 22:46:59:INFO:Received: train message 2d7f8265-e23d-4231-9273-72a8dc521518
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6807032227516174
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6875732690095901
  Validation Loss: 0.680411159992218
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6869035363197327
  Validation Loss: 0.6801254153251648
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6861821860074997
  Validation Loss: 0.6798431873321533
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6855082660913467
  Validation Loss: 0.6795260906219482
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.684873417019844
  Validation Loss: 0.6792429685592651
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.6842705756425858
  Validation Loss: 0.6789802312850952
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.6836243271827698
  Validation Loss: 0.678658127784729
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.78125
Epoch 38/64:
  Train Loss: 0.6829818338155746
  Validation Loss: 0.6783697605133057
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6824113130569458
  Validation Loss: 0.6781121492385864
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6818072199821472
  Validation Loss: 0.677865743637085
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6812402456998825
  Validation Loss: 0.677631139755249
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6806677579879761
  Validation Loss: 0.677415132522583
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6801114529371262
  Validation Loss: 0.6772089004516602
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6796246469020844
  Validation Loss: 0.6770182251930237
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6791415512561798
  Validation Loss: 0.6768265962600708
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6786552220582962
  Validation Loss: 0.6766461133956909
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6781275421380997
  Validation Loss: 0.6764814257621765
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6776675581932068
  Validation Loss: 0.6763241291046143
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6772060096263885
  Validation Loss: 0.6761593818664551
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6766909062862396
  Validation Loss: 0.675957441329956
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6762060075998306
  Validation Loss: 0.675754725933075
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6758098900318146
  Validation Loss: 0.6755822896957397
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6753746420145035
  Validation Loss: 0.6754316687583923
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6749494671821594
  Validation Loss: 0.6752444505691528
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6745278090238571
  Validation Loss: 0.6750715970993042
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6741363257169724
  Validation Loss: 0.6749299764633179
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6737378984689713
  Validation Loss: 0.6747558116912842
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6733563542366028
  Validation Loss: 0.6745563745498657
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6729874163866043
  Validation Loss: 0.6744095087051392
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6726178377866745
  Validation Loss: 0.6742467880249023
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.672219768166542
  Validation Loss: 0.674083948135376
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6718924194574356
  Validation Loss: 0.6739322543144226
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6715524345636368
  Validation Loss: 0.6738157272338867
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6712144762277603
  Validation Loss: 0.6736866235733032
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.78125
{'train_loss': 0.6712144762277603, 'val_roc_auc': 0.8431372549019608, 'val_accuracy': 0.78125, 'val_loss': 0.6736866235733032}
 ROC_AUC: 0.8431|| Accuracy 0.7812 || Train Loss: 0.6712
 Val Loss: 0.6737 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7094508538452479
Test ROC-AUC: 0.7533482142857143
Test Accuracy: 0.6538461538461539
test_loss: 0.7094508538452479
test_roc_auc: 0.7533482142857143
test_accuracy: 0.6538461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.26060913669425645
Epoch 1/64:
  Train Loss: 0.711139127612114
  Validation Loss: 0.6922920942306519
  Val ROC-AUC: 0.8196078431372549
  Val Accuracy: 0.6875
Epoch 2/64:
  Train Loss: 0.709937795996666
  Validation Loss: 0.6915313005447388
  Val ROC-AUC: 0.8235294117647058
  Val Accuracy: 0.6875
Epoch 3/64:
  Train Loss: 0.7088226974010468
  Validation Loss: 0.6907404661178589
  Val ROC-AUC: 0.8235294117647058
  Val Accuracy: 0.6875
Epoch 4/64:
  Train Loss: 0.7076633870601654
  Validation Loss: 0.6899528503417969
  Val ROC-AUC: 0.8274509803921568
  Val Accuracy: 0.6875
Epoch 5/64:
  Train Loss: 0.7066153883934021
  Validation Loss: 0.689194917678833
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.6875
Epoch 6/64:
  Train Loss: 0.7055527418851852
  Validation Loss: 0.6885287761688232
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.7045014947652817
  Validation Loss: 0.6878405809402466
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.6875
Epoch 8/64:
  Train Loss: 0.7035164535045624
  Validation Loss: 0.6871488690376282
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.6875
Epoch 9/64:
  Train Loss: 0.7025204300880432
  Validation Loss: 0.6864656209945679
  Val ROC-AUC: 0.8392156862745099
  Val Accuracy: 0.6875
Epoch 10/64:
  Train Loss: 0.701586902141571
  Validation Loss: 0.6857994198799133
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.6875
Epoch 11/64:
  Train Loss: 0.700652226805687
  Validation Loss: 0.6851452589035034
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.6875
Epoch 12/64:
  Train Loss: 0.6997344344854355
  Validation Loss: 0.6845147013664246
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.6875
Epoch 13/64:
  Train Loss: 0.6988407075405121
  Validation Loss: 0.6839041709899902
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 14/64:
  Train Loss: 0.6979679763317108
  Validation Loss: 0.683289647102356
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 15/64:
  Train Loss: 0.6970728039741516
  Validation Loss: 0.6826678514480591
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 16/64:
  Train Loss: 0.6962277144193649
  Validation Loss: 0.6820740699768066
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 17/64:
  Train Loss: 0.6954555660486221
  Validation Loss: 0.6814695596694946
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 18/64:
  Train Loss: 0.6945995837450027
  Validation Loss: 0.6808863878250122
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 19/64:
  Train Loss: 0.6938235759735107
  Validation Loss: 0.6803238987922668
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 20/64:
  Train Loss: 0.6930034905672073
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:27:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:28:INFO:
[92mINFO [0m:      Received: evaluate message 170f769c-f3b8-4667-a786-e790a6f7f6d9
02/07/2025 22:47:28:INFO:Received: evaluate message 170f769c-f3b8-4667-a786-e790a6f7f6d9
[92mINFO [0m:      Sent reply
02/07/2025 22:47:31:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:31:INFO:
[92mINFO [0m:      Received: train message 805c9c8c-1d3b-4266-ae08-2b45d6db183f
02/07/2025 22:47:31:INFO:Received: train message 805c9c8c-1d3b-4266-ae08-2b45d6db183f
  Validation Loss: 0.6797885298728943
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.6875
Epoch 21/64:
  Train Loss: 0.6922488063573837
  Validation Loss: 0.6792389154434204
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.6875
Epoch 22/64:
  Train Loss: 0.6915071755647659
  Validation Loss: 0.678683340549469
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6907310634851456
  Validation Loss: 0.6781145930290222
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6899619549512863
  Validation Loss: 0.6775798797607422
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6892698854207993
  Validation Loss: 0.6770634651184082
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6885785311460495
  Validation Loss: 0.6765471696853638
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6879063546657562
  Validation Loss: 0.6760799884796143
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.687253475189209
  Validation Loss: 0.6756072640419006
  Val ROC-AUC: 0.8431372549019609
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6865689754486084
  Validation Loss: 0.6751564741134644
  Val ROC-AUC: 0.8431372549019609
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.6859245747327805
  Validation Loss: 0.6747415661811829
  Val ROC-AUC: 0.8431372549019609
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6853777766227722
  Validation Loss: 0.6743154525756836
  Val ROC-AUC: 0.8431372549019609
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.684751495718956
  Validation Loss: 0.673920750617981
  Val ROC-AUC: 0.8431372549019609
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6841995120048523
  Validation Loss: 0.6735482811927795
  Val ROC-AUC: 0.8431372549019609
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6836163252592087
  Validation Loss: 0.6731753349304199
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6830711960792542
  Validation Loss: 0.6727690696716309
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6825352758169174
  Validation Loss: 0.6723994016647339
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6820001304149628
  Validation Loss: 0.6720410585403442
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6814836263656616
  Validation Loss: 0.6717021465301514
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6809926480054855
  Validation Loss: 0.6713576316833496
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6804950684309006
  Validation Loss: 0.6710274815559387
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6800608038902283
  Validation Loss: 0.6707018613815308
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6795862317085266
  Validation Loss: 0.6703467965126038
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6790816336870193
  Validation Loss: 0.6699929237365723
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6786661297082901
  Validation Loss: 0.6696513891220093
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6782181710004807
  Validation Loss: 0.6693178415298462
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6777474731206894
  Validation Loss: 0.6689765453338623
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6773377507925034
  Validation Loss: 0.6686597466468811
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6769109666347504
  Validation Loss: 0.6683443784713745
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6765148341655731
  Validation Loss: 0.6680378913879395
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6761055439710617
  Validation Loss: 0.6677348613739014
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.675708457827568
  Validation Loss: 0.6674189567565918
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6753132492303848
  Validation Loss: 0.6671271324157715
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6749306619167328
  Validation Loss: 0.6668283939361572
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6745450347661972
  Validation Loss: 0.6665507555007935
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6741530150175095
  Validation Loss: 0.6662561297416687
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6737391799688339
  Validation Loss: 0.6659824848175049
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6733770966529846
  Validation Loss: 0.6657203435897827
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6730267554521561
  Validation Loss: 0.6654566526412964
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6726635545492172
  Validation Loss: 0.6652066707611084
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6723288297653198
  Validation Loss: 0.664965808391571
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6719983220100403
  Validation Loss: 0.6647597551345825
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.671707883477211
  Validation Loss: 0.664557695388794
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6714055389165878
  Validation Loss: 0.6643877625465393
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6711312979459763
  Validation Loss: 0.6642273664474487
  Val ROC-AUC: 0.8509803921568627
  Val Accuracy: 0.75
{'train_loss': 0.6711312979459763, 'val_roc_auc': 0.8509803921568627, 'val_accuracy': 0.75, 'val_loss': 0.6642273664474487}
 ROC_AUC: 0.8510|| Accuracy 0.7500 || Train Loss: 0.6711
 Val Loss: 0.6642 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7042653036232178
Test ROC-AUC: 0.7730654761904762
Test Accuracy: 0.6730769230769231
test_loss: 0.7042653036232178
test_roc_auc: 0.7730654761904762
test_accuracy: 0.6730769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.25230393538549833
Epoch 1/64:
  Train Loss: 0.6917086541652679
  Validation Loss: 0.7488049268722534
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.625
Epoch 2/64:
  Train Loss: 0.6905458271503448
  Validation Loss: 0.7482254505157471
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.625
Epoch 3/64:
  Train Loss: 0.6894506067037582
  Validation Loss: 0.7477034330368042
  Val ROC-AUC: 0.7530364372469637
  Val Accuracy: 0.625
Epoch 4/64:
  Train Loss: 0.688315212726593
  Validation Loss: 0.7471944689750671
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.625
Epoch 5/64:
  Train Loss: 0.6872754842042923
  Validation Loss: 0.7467039823532104
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.625
Epoch 6/64:
  Train Loss: 0.6861086189746857
  Validation Loss: 0.7462525963783264
  Val ROC-AUC: 0.7611336032388664
  Val Accuracy: 0.625
Epoch 7/64:
  Train Loss: 0.6851183325052261
  Validation Loss: 0.7457720041275024
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.625
Epoch 8/64:
  Train Loss: 0.6840772032737732
  Validation Loss: 0.7453237771987915
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.625
Epoch 9/64:
  Train Loss: 0.6830580830574036
  Validation Loss: 0.7448765635490417
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.625
Epoch 10/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:59:INFO:
[92mINFO [0m:      Received: evaluate message 1cd4832e-2e60-4851-b889-6705452ddfe5
02/07/2025 22:47:59:INFO:Received: evaluate message 1cd4832e-2e60-4851-b889-6705452ddfe5
[92mINFO [0m:      Sent reply
02/07/2025 22:48:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:01:INFO:
[92mINFO [0m:      Received: train message 9720f2d1-2ebe-4261-abb5-3480ddab9004
02/07/2025 22:48:01:INFO:Received: train message 9720f2d1-2ebe-4261-abb5-3480ddab9004
  Train Loss: 0.682060182094574
  Validation Loss: 0.7444055676460266
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.625
Epoch 11/64:
  Train Loss: 0.6811215281486511
  Validation Loss: 0.743973970413208
  Val ROC-AUC: 0.7489878542510121
  Val Accuracy: 0.625
Epoch 12/64:
  Train Loss: 0.680096909403801
  Validation Loss: 0.7435773611068726
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.625
Epoch 13/64:
  Train Loss: 0.6792024374008179
  Validation Loss: 0.7431659698486328
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.625
Epoch 14/64:
  Train Loss: 0.678229883313179
  Validation Loss: 0.7427419424057007
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.625
Epoch 15/64:
  Train Loss: 0.6773830503225327
  Validation Loss: 0.7423139810562134
  Val ROC-AUC: 0.7489878542510121
  Val Accuracy: 0.625
Epoch 16/64:
  Train Loss: 0.6765183359384537
  Validation Loss: 0.7418949604034424
  Val ROC-AUC: 0.7489878542510121
  Val Accuracy: 0.625
Epoch 17/64:
  Train Loss: 0.6756471991539001
  Validation Loss: 0.7415118217468262
  Val ROC-AUC: 0.7489878542510121
  Val Accuracy: 0.625
Epoch 18/64:
  Train Loss: 0.6747100353240967
  Validation Loss: 0.7411555051803589
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.625
Epoch 19/64:
  Train Loss: 0.6739661544561386
  Validation Loss: 0.7407525777816772
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.625
Epoch 20/64:
  Train Loss: 0.6730939298868179
  Validation Loss: 0.7403668165206909
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.625
Epoch 21/64:
  Train Loss: 0.6723079681396484
  Validation Loss: 0.7400014400482178
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.625
Epoch 22/64:
  Train Loss: 0.6715200245380402
  Validation Loss: 0.7396165132522583
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.625
Epoch 23/64:
  Train Loss: 0.6707809120416641
  Validation Loss: 0.7392228841781616
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.625
Epoch 24/64:
  Train Loss: 0.6700771003961563
  Validation Loss: 0.7388731241226196
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.65625
Epoch 25/64:
  Train Loss: 0.6693766266107559
  Validation Loss: 0.7385262250900269
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 26/64:
  Train Loss: 0.6686499267816544
  Validation Loss: 0.7382098436355591
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 27/64:
  Train Loss: 0.6679615527391434
  Validation Loss: 0.7379146814346313
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 28/64:
  Train Loss: 0.667334109544754
  Validation Loss: 0.7376061677932739
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 29/64:
  Train Loss: 0.6666333377361298
  Validation Loss: 0.7372931241989136
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.65625
Epoch 30/64:
  Train Loss: 0.6660285741090775
  Validation Loss: 0.73697829246521
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.6875
Epoch 31/64:
  Train Loss: 0.6653886139392853
  Validation Loss: 0.7366572618484497
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.6875
Epoch 32/64:
  Train Loss: 0.6648592203855515
  Validation Loss: 0.7363153696060181
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.6875
Epoch 33/64:
  Train Loss: 0.6642562747001648
  Validation Loss: 0.7360056638717651
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.6875
Epoch 34/64:
  Train Loss: 0.6636761873960495
  Validation Loss: 0.7357391715049744
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.6875
Epoch 35/64:
  Train Loss: 0.6631765365600586
  Validation Loss: 0.7354943752288818
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6626872718334198
  Validation Loss: 0.7352068424224854
  Val ROC-AUC: 0.7611336032388665
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6621520668268204
  Validation Loss: 0.7349405288696289
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6616504788398743
  Validation Loss: 0.7346577644348145
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.661200150847435
  Validation Loss: 0.7344025373458862
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6607042700052261
  Validation Loss: 0.7341653108596802
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6602811515331268
  Validation Loss: 0.7339555025100708
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6598605662584305
  Validation Loss: 0.7337318658828735
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6594743728637695
  Validation Loss: 0.7335186004638672
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6590659022331238
  Validation Loss: 0.7332976460456848
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.65865758061409
  Validation Loss: 0.7330838441848755
  Val ROC-AUC: 0.7651821862348178
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6582829654216766
  Validation Loss: 0.7328764200210571
  Val ROC-AUC: 0.7611336032388664
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6578399688005447
  Validation Loss: 0.7327191829681396
  Val ROC-AUC: 0.757085020242915
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6574457585811615
  Validation Loss: 0.7325441241264343
  Val ROC-AUC: 0.7611336032388664
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6570640802383423
  Validation Loss: 0.7323317527770996
  Val ROC-AUC: 0.7611336032388664
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6566640436649323
  Validation Loss: 0.7321304082870483
  Val ROC-AUC: 0.7611336032388664
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6562997996807098
  Validation Loss: 0.7319503426551819
  Val ROC-AUC: 0.7570850202429149
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6559448391199112
  Validation Loss: 0.7318034172058105
  Val ROC-AUC: 0.7570850202429149
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6555716097354889
  Validation Loss: 0.7316638231277466
  Val ROC-AUC: 0.7570850202429149
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6551920920610428
  Validation Loss: 0.731490969657898
  Val ROC-AUC: 0.7570850202429149
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6548854112625122
  Validation Loss: 0.7313373684883118
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6545721590518951
  Validation Loss: 0.7311569452285767
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6542568504810333
  Validation Loss: 0.7309659123420715
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6539478749036789
  Validation Loss: 0.730783998966217
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6536456644535065
  Validation Loss: 0.7305982112884521
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6533671021461487
  Validation Loss: 0.7304110527038574
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6530935764312744
  Validation Loss: 0.7302360534667969
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6528338640928268
  Validation Loss: 0.7300270795822144
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.65257228910923
  Validation Loss: 0.7298483848571777
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6522861570119858
  Validation Loss: 0.7296783924102783
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.75
{'train_loss': 0.6522861570119858, 'val_roc_auc': 0.7449392712550608, 'val_accuracy': 0.75, 'val_loss': 0.7296783924102783}
 ROC_AUC: 0.7449|| Accuracy 0.7500 || Train Loss: 0.6523
 Val Loss: 0.7297 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6989978273900656
Test ROC-AUC: 0.7994791666666666
Test Accuracy: 0.7115384615384616
test_loss: 0.6989978273900656
test_roc_auc: 0.7994791666666666
test_accuracy: 0.7115384615384616
eval_cid: 0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.23874874337707297
Epoch 1/64:
  Train Loss: 0.6997580826282501
  Validation Loss: 0.6946836113929749
  Val ROC-AUC: 0.8431372549019607
  Val Accuracy: 0.65625
Epoch 2/64:
  Train Loss: 0.6986535489559174
  Validation Loss: 0.6940024495124817
  Val ROC-AUC: 0.8431372549019607
  Val Accuracy: 0.6875
Epoch 3/64:
  Train Loss: 0.6977041512727737
  Validation Loss: 0.693339467048645
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.6875
Epoch 4/64:
  Train Loss: 0.6967467665672302
  Validation Loss: 0.6926880478858948
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.6875
Epoch 5/64:
  Train Loss: 0.6958167403936386
  Validation Loss: 0.6920007467269897
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.6875
Epoch 6/64:
  Train Loss: 0.6948768049478531
  Validation Loss: 0.6913626194000244
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.6940159946680069
  Validation Loss: 0.6907601356506348
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.6875
Epoch 8/64:
  Train Loss: 0.6931232362985611
  Validation Loss: 0.6901518106460571
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.6875
Epoch 9/64:
  Train Loss: 0.6922261118888855
  Validation Loss: 0.689563512802124
  Val ROC-AUC: 0.8431372549019607
  Val Accuracy: 0.6875
Epoch 10/64:
  Train Loss: 0.691367968916893
  Validation Loss: 0.6889917254447937
  Val ROC-AUC: 0.8431372549019607
  Val Accuracy: 0.6875
Epoch 11/64:
  Train Loss: 0.6905210167169571
  Validation Loss: 0.6884289383888245
  Val ROC-AUC: 0.8431372549019607
  Val Accuracy: 0.6875
Epoch 12/64:
  Train Loss: 0.6896545141935349
  Validation Loss: 0.6878459453582764
  Val ROC-AUC: 0.8431372549019607
  Val Accuracy: 0.6875
Epoch 13/64:
  Train Loss: 0.688860222697258
  Validation Loss: 0.6872556209564209
  Val ROC-AUC: 0.8392156862745097
  Val Accuracy: 0.6875
Epoch 14/64:
  Train Loss: 0.6880389302968979
  Validation Loss: 0.6867096424102783
  Val ROC-AUC: 0.8392156862745097
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.687332034111023
  Validation Loss: 0.6861565113067627
  Val ROC-AUC: 0.8392156862745097
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6866192817687988
  Validation Loss: 0.685633659362793
  Val ROC-AUC: 0.8431372549019607
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6858775913715363
  Validation Loss: 0.6851005554199219
  Val ROC-AUC: 0.8431372549019607
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6851518601179123
  Validation Loss: 0.6845914721488953
  Val ROC-AUC: 0.8470588235294116
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6844418048858643
  Validation Loss: 0.6841214895248413
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6837696880102158
  Validation Loss: 0.6836810111999512
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6831636130809784
  Validation Loss: 0.6832350492477417
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.75
Epoch 22/64:
  Train Loss: 0.6825429052114487
  Validation Loss: 0.6828222274780273
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.75
Epoch 23/64:
  Train Loss: 0.6819300353527069
  Validation Loss: 0.6824171543121338
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.75
Epoch 24/64:
  Train Loss: 0.6813640594482422
  Validation Loss: 0.6820085644721985
  Val ROC-AUC: 0.8509803921568626
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6807528734207153
  Validation Loss: 0.6815898418426514
  Val ROC-AUC: 0.8549019607843137
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6801937073469162
  Validation Loss: 0.6811760663986206
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.679626926779747
  Validation Loss: 0.6807470917701721
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6790835410356522
  Validation Loss: 0.6803140640258789
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6785306334495544
  Validation Loss: 0.6798996925354004
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.677986666560173
  Validation Loss: 0.6795176267623901
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6774640083312988
  Validation Loss: 0.6791369915008545
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6769852340221405
  Validation Loss: 0.6788017153739929
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6765042841434479
  Validation Loss: 0.678442120552063
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6760083138942719
  Validation Loss: 0.6780914068222046
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6755719035863876
  Validation Loss: 0.6777306199073792
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6751468479633331
  Validation Loss: 0.6773807406425476
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6746957153081894
  Validation Loss: 0.677067756652832
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6742598861455917
  Validation Loss: 0.6767065525054932
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6738408356904984
  Validation Loss: 0.6763558387756348
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6733857840299606
  Validation Loss: 0.6760495901107788
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6730041056871414
  Validation Loss: 0.675757884979248
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.672605961561203
  Validation Loss: 0.6754977107048035
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6722070574760437
  Validation Loss: 0.6752262115478516
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6718458086252213
  Validation Loss: 0.6749369502067566
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6714808940887451
  Validation Loss: 0.6746573448181152
  Val ROC-AUC: 0.8705882352941176
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.6711031496524811
  Validation Loss: 0.6743952035903931
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.6706745624542236
  Validation Loss: 0.6740829944610596
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6703068315982819
  Validation Loss: 0.6738032102584839
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.669948399066925
  Validation Loss: 0.6735540628433228
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6695659905672073
  Validation Loss: 0.6733261346817017
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6692837923765182
  Validation Loss: 0.6730982065200806
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6689687371253967
  Validation Loss: 0.6728552579879761
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6686470955610275
  Validation Loss: 0.6726736426353455
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6683682948350906
  Validation Loss: 0.6724327802658081
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6680544167757034
  Validation Loss: 0.6722196340560913
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6677368581295013
  Validation Loss: 0.6720181703567505
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.667477160692215
  Validation Loss: 0.6717896461486816
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:29:INFO:
[92mINFO [0m:      Received: evaluate message 643e86aa-b40b-4722-af5f-3a0f85a82a5a
02/07/2025 22:48:29:INFO:Received: evaluate message 643e86aa-b40b-4722-af5f-3a0f85a82a5a
[92mINFO [0m:      Sent reply
02/07/2025 22:48:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:29:INFO:
[92mINFO [0m:      Received: train message 4df1f28d-bbb5-4a68-bd64-07222bf51885
02/07/2025 22:48:29:INFO:Received: train message 4df1f28d-bbb5-4a68-bd64-07222bf51885
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 58/64:
  Train Loss: 0.6671902388334274
  Validation Loss: 0.6715861558914185
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6669376194477081
  Validation Loss: 0.67139732837677
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6666840612888336
  Validation Loss: 0.6712514162063599
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6664585918188095
  Validation Loss: 0.6710927486419678
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6662424504756927
  Validation Loss: 0.6709465384483337
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6659833788871765
  Validation Loss: 0.6708000898361206
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6657204180955887
  Validation Loss: 0.6706576347351074
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.75
{'train_loss': 0.6657204180955887, 'val_roc_auc': 0.8823529411764706, 'val_accuracy': 0.75, 'val_loss': 0.6706576347351074}
 ROC_AUC: 0.8824|| Accuracy 0.7500 || Train Loss: 0.6657
 Val Loss: 0.6707 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6938072511783013
Test ROC-AUC: 0.8195684523809523
Test Accuracy: 0.75
test_loss: 0.6938072511783013
test_roc_auc: 0.8195684523809523
test_accuracy: 0.75
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.2610460244522983
Epoch 1/64:
  Train Loss: 0.7008361518383026
  Validation Loss: 0.6694713830947876
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 2/64:
  Train Loss: 0.6998345404863358
  Validation Loss: 0.6687788963317871
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.75
Epoch 3/64:
  Train Loss: 0.6988837122917175
  Validation Loss: 0.6681143045425415
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 4/64:
  Train Loss: 0.6980141997337341
  Validation Loss: 0.6674875020980835
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 5/64:
  Train Loss: 0.6970871835947037
  Validation Loss: 0.6669139862060547
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 6/64:
  Train Loss: 0.6962596029043198
  Validation Loss: 0.6663262844085693
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 7/64:
  Train Loss: 0.6954160630702972
  Validation Loss: 0.6657305955886841
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.75
Epoch 8/64:
  Train Loss: 0.6945383995771408
  Validation Loss: 0.6651852130889893
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.75
Epoch 9/64:
  Train Loss: 0.6938208788633347
  Validation Loss: 0.6646060943603516
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.6929952800273895
  Validation Loss: 0.6640788316726685
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6922943443059921
  Validation Loss: 0.6635817885398865
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.6915412992238998
  Validation Loss: 0.6631154417991638
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6908489614725113
  Validation Loss: 0.6626551747322083
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6901766061782837
  Validation Loss: 0.6622082591056824
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6895281225442886
  Validation Loss: 0.661771833896637
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6888570785522461
  Validation Loss: 0.661343514919281
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6881922483444214
  Validation Loss: 0.6608796715736389
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6876107007265091
  Validation Loss: 0.6604219675064087
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6869770884513855
  Validation Loss: 0.6599980592727661
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6863787323236465
  Validation Loss: 0.6596157550811768
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6858476400375366
  Validation Loss: 0.659266471862793
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6852681487798691
  Validation Loss: 0.6589113473892212
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 23/64:
  Train Loss: 0.6846867799758911
  Validation Loss: 0.6585345268249512
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 24/64:
  Train Loss: 0.6841142326593399
  Validation Loss: 0.6581313610076904
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 25/64:
  Train Loss: 0.683557391166687
  Validation Loss: 0.6577547788619995
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.75
Epoch 26/64:
  Train Loss: 0.683036282658577
  Validation Loss: 0.6573490500450134
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.75
Epoch 27/64:
  Train Loss: 0.6824459880590439
  Validation Loss: 0.6570049524307251
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.681928351521492
  Validation Loss: 0.6566683650016785
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6814464032649994
  Validation Loss: 0.6563782691955566
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6809867769479752
  Validation Loss: 0.6560596227645874
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6804801970720291
  Validation Loss: 0.6557472348213196
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6800221800804138
  Validation Loss: 0.6554664373397827
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6795351058244705
  Validation Loss: 0.6551464200019836
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6790441423654556
  Validation Loss: 0.6548343896865845
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.6785968691110611
  Validation Loss: 0.6544919013977051
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.6781208217144012
  Validation Loss: 0.6541608572006226
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.6777433007955551
  Validation Loss: 0.6538627743721008
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6773241758346558
  Validation Loss: 0.6536239981651306
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6769468635320663
  Validation Loss: 0.6533945798873901
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.676590159535408
  Validation Loss: 0.6531266570091248
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6762089133262634
  Validation Loss: 0.6528803110122681
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6758700609207153
  Validation Loss: 0.6526364088058472
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6755138784646988
  Validation Loss: 0.6524463891983032
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6752242594957352
  Validation Loss: 0.6522064208984375
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6748784482479095
  Validation Loss: 0.6519304513931274
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.674484446644783
  Validation Loss: 0.6516410112380981
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6741110682487488
  Validation Loss: 0.6513463854789734
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6737432479858398
  Validation Loss: 0.6511326432228088
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6734089255332947
  Validation Loss: 0.650922954082489
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6730672866106033
  Validation Loss: 0.6507012844085693
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6727701425552368
  Validation Loss: 0.6504560708999634
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:57:INFO:
[92mINFO [0m:      Received: evaluate message 4df9a4d5-3526-4623-ab2a-de089b016481
02/07/2025 22:48:57:INFO:Received: evaluate message 4df9a4d5-3526-4623-ab2a-de089b016481
[92mINFO [0m:      Sent reply
02/07/2025 22:48:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:58:INFO:
[92mINFO [0m:      Received: train message c8fb4f6d-4ca4-4add-94dc-c12bee4488bf
02/07/2025 22:48:58:INFO:Received: train message c8fb4f6d-4ca4-4add-94dc-c12bee4488bf
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6725137233734131
  Validation Loss: 0.6502195596694946
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6722552478313446
  Validation Loss: 0.6500285267829895
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6719758212566376
  Validation Loss: 0.6498590111732483
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6717436164617538
  Validation Loss: 0.6496504545211792
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6714357137680054
  Validation Loss: 0.6494863033294678
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6712004095315933
  Validation Loss: 0.6492990851402283
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.670942947268486
  Validation Loss: 0.6491315364837646
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6707176566123962
  Validation Loss: 0.6489614248275757
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.670479953289032
  Validation Loss: 0.648801326751709
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6702259927988052
  Validation Loss: 0.6486791372299194
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6699735224246979
  Validation Loss: 0.6485944986343384
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6697494089603424
  Validation Loss: 0.6485377550125122
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6695313155651093
  Validation Loss: 0.6484843492507935
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.71875
{'train_loss': 0.6695313155651093, 'val_roc_auc': 0.84765625, 'val_accuracy': 0.71875, 'val_loss': 0.6484843492507935}
 ROC_AUC: 0.8477|| Accuracy 0.7188 || Train Loss: 0.6695
 Val Loss: 0.6485 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6887764283097707
Test ROC-AUC: 0.8355654761904762
Test Accuracy: 0.7788461538461539
test_loss: 0.6887764283097707
test_roc_auc: 0.8355654761904762
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.22638466749413055
Epoch 1/64:
  Train Loss: 0.6925621181726456
  Validation Loss: 0.683574914932251
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.6918005347251892
  Validation Loss: 0.6827861666679382
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6910280585289001
  Validation Loss: 0.6820986270904541
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.6903009861707687
  Validation Loss: 0.681389331817627
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6895174384117126
  Validation Loss: 0.6806915998458862
  Val ROC-AUC: 0.9325396825396826
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.688826784491539
  Validation Loss: 0.680045485496521
  Val ROC-AUC: 0.9325396825396826
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6881352961063385
  Validation Loss: 0.6793992519378662
  Val ROC-AUC: 0.9325396825396826
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6874491572380066
  Validation Loss: 0.678780198097229
  Val ROC-AUC: 0.9325396825396826
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6868297904729843
  Validation Loss: 0.6781905889511108
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6861717849969864
  Validation Loss: 0.6775562763214111
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6855938732624054
  Validation Loss: 0.6769494414329529
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6849975287914276
  Validation Loss: 0.6763286590576172
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6843326985836029
  Validation Loss: 0.6757290959358215
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6838103234767914
  Validation Loss: 0.6751720905303955
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6832356154918671
  Validation Loss: 0.6746510863304138
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6826858818531036
  Validation Loss: 0.6741747260093689
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.682183101773262
  Validation Loss: 0.6736669540405273
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 18/64:
  Train Loss: 0.6816491633653641
  Validation Loss: 0.6731951236724854
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 19/64:
  Train Loss: 0.6810950040817261
  Validation Loss: 0.6727414727210999
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 20/64:
  Train Loss: 0.6805945336818695
  Validation Loss: 0.6723308563232422
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 21/64:
  Train Loss: 0.6800762712955475
  Validation Loss: 0.6718739867210388
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 22/64:
  Train Loss: 0.6796198636293411
  Validation Loss: 0.6714333295822144
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 23/64:
  Train Loss: 0.6791670173406601
  Validation Loss: 0.6709983348846436
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 24/64:
  Train Loss: 0.6787396669387817
  Validation Loss: 0.6706503629684448
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 25/64:
  Train Loss: 0.678318202495575
  Validation Loss: 0.6702824234962463
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 26/64:
  Train Loss: 0.6779181212186813
  Validation Loss: 0.6699644327163696
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 27/64:
  Train Loss: 0.6775827556848526
  Validation Loss: 0.6696717739105225
  Val ROC-AUC: 0.9325396825396826
  Val Accuracy: 0.875
Epoch 28/64:
  Train Loss: 0.6771977096796036
  Validation Loss: 0.6693829894065857
  Val ROC-AUC: 0.9325396825396826
  Val Accuracy: 0.875
Epoch 29/64:
  Train Loss: 0.6768265813589096
  Validation Loss: 0.6691253185272217
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.875
Epoch 30/64:
  Train Loss: 0.6764528453350067
  Validation Loss: 0.6687267422676086
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.875
Epoch 31/64:
  Train Loss: 0.6760642230510712
  Validation Loss: 0.6683396100997925
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.875
Epoch 32/64:
  Train Loss: 0.6756395846605301
  Validation Loss: 0.6679303050041199
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.675252839922905
  Validation Loss: 0.667563259601593
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6748697906732559
  Validation Loss: 0.6672297716140747
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6745157092809677
  Validation Loss: 0.6668905019760132
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6742210537195206
  Validation Loss: 0.6666046380996704
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6738778650760651
  Validation Loss: 0.6663323044776917
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6735442280769348
  Validation Loss: 0.6660069227218628
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6732145696878433
  Validation Loss: 0.6657019853591919
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6729101538658142
  Validation Loss: 0.6653550863265991
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.672594428062439
  Validation Loss: 0.6650272607803345
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6722891926765442
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:24:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:26:INFO:
[92mINFO [0m:      Received: evaluate message d9d2948e-7520-4154-8852-b971d06f5ffb
02/07/2025 22:49:26:INFO:Received: evaluate message d9d2948e-7520-4154-8852-b971d06f5ffb
[92mINFO [0m:      Sent reply
02/07/2025 22:49:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:28:INFO:
[92mINFO [0m:      Received: train message 8fbfb23a-4601-4675-adaf-2fd18de795cd
02/07/2025 22:49:28:INFO:Received: train message 8fbfb23a-4601-4675-adaf-2fd18de795cd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6647413969039917
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6719866245985031
  Validation Loss: 0.6644871830940247
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6716756522655487
  Validation Loss: 0.664168655872345
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.6713332235813141
  Validation Loss: 0.663864254951477
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.671031042933464
  Validation Loss: 0.6636120080947876
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6707639396190643
  Validation Loss: 0.6633380651473999
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6705094128847122
  Validation Loss: 0.6631181240081787
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6702474653720856
  Validation Loss: 0.6628658771514893
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6699934303760529
  Validation Loss: 0.6625231504440308
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6697127968072891
  Validation Loss: 0.6622649431228638
  Val ROC-AUC: 0.9404761904761905
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6694908440113068
  Validation Loss: 0.6620049476623535
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6692332476377487
  Validation Loss: 0.6617547273635864
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6689800024032593
  Validation Loss: 0.6614915132522583
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6687390804290771
  Validation Loss: 0.6612635850906372
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6684799641370773
  Validation Loss: 0.6610479354858398
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6682792901992798
  Validation Loss: 0.6608271598815918
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.6680234968662262
  Validation Loss: 0.6605755686759949
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6677887439727783
  Validation Loss: 0.6603482961654663
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6675715446472168
  Validation Loss: 0.6601150035858154
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6673513203859329
  Validation Loss: 0.6598818302154541
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.667135626077652
  Validation Loss: 0.659710168838501
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6669206023216248
  Validation Loss: 0.6594235897064209
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6667087227106094
  Validation Loss: 0.6591708660125732
  Val ROC-AUC: 0.9365079365079365
  Val Accuracy: 0.84375
{'train_loss': 0.6667087227106094, 'val_roc_auc': 0.9365079365079365, 'val_accuracy': 0.84375, 'val_loss': 0.6591708660125732}
 ROC_AUC: 0.9365|| Accuracy 0.8438 || Train Loss: 0.6667
 Val Loss: 0.6592 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6839525834299051
Test ROC-AUC: 0.8456101190476191
Test Accuracy: 0.7788461538461539
test_loss: 0.6839525834299051
test_roc_auc: 0.8456101190476191
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.22934064882065286
Epoch 1/64:
  Train Loss: 0.6949564516544342
  Validation Loss: 0.6553484201431274
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6940924376249313
  Validation Loss: 0.6546818017959595
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.693313404917717
  Validation Loss: 0.6540573835372925
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6925947070121765
  Validation Loss: 0.6534630656242371
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.6918435841798782
  Validation Loss: 0.6528651714324951
  Val ROC-AUC: 0.9568627450980391
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6911536008119583
  Validation Loss: 0.6523306369781494
  Val ROC-AUC: 0.9568627450980391
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.6904834359884262
  Validation Loss: 0.651832640171051
  Val ROC-AUC: 0.9568627450980391
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.6898213475942612
  Validation Loss: 0.651360273361206
  Val ROC-AUC: 0.9568627450980391
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6892308294773102
  Validation Loss: 0.6509476900100708
  Val ROC-AUC: 0.9568627450980391
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6886547654867172
  Validation Loss: 0.650498628616333
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 11/64:
  Train Loss: 0.6880814731121063
  Validation Loss: 0.6501157879829407
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.6875478476285934
  Validation Loss: 0.6497447490692139
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6869757622480392
  Validation Loss: 0.6493757963180542
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.6864723563194275
  Validation Loss: 0.6489882469177246
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 15/64:
  Train Loss: 0.6859280318021774
  Validation Loss: 0.6485666632652283
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 16/64:
  Train Loss: 0.6853701770305634
  Validation Loss: 0.6481786370277405
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 17/64:
  Train Loss: 0.6848116964101791
  Validation Loss: 0.6477925181388855
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 18/64:
  Train Loss: 0.6842551827430725
  Validation Loss: 0.6474317312240601
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 19/64:
  Train Loss: 0.6838002949953079
  Validation Loss: 0.6470910906791687
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 20/64:
  Train Loss: 0.6832445710897446
  Validation Loss: 0.6467760801315308
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 21/64:
  Train Loss: 0.6827317774295807
  Validation Loss: 0.6464505791664124
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 22/64:
  Train Loss: 0.6822200864553452
  Validation Loss: 0.6461526155471802
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 23/64:
  Train Loss: 0.6817963868379593
  Validation Loss: 0.645916223526001
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.78125
Epoch 24/64:
  Train Loss: 0.6813269853591919
  Validation Loss: 0.6456561088562012
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 25/64:
  Train Loss: 0.6809059977531433
  Validation Loss: 0.6454388499259949
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 26/64:
  Train Loss: 0.6805161684751511
  Validation Loss: 0.6452318429946899
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 27/64:
  Train Loss: 0.6801345348358154
  Validation Loss: 0.6450492143630981
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 28/64:
  Train Loss: 0.6797671169042587
  Validation Loss: 0.6448023319244385
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 29/64:
  Train Loss: 0.6793154031038284
  Validation Loss: 0.6445338726043701
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 30/64:
  Train Loss: 0.6789156645536423
  Validation Loss: 0.6442921757698059
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 31/64:
  Train Loss: 0.6785156577825546
  Validation Loss: 0.6440389752388
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:57:INFO:
[92mINFO [0m:      Received: evaluate message dd7abf66-06fa-46c2-b0f5-e751cf95550e
02/07/2025 22:49:57:INFO:Received: evaluate message dd7abf66-06fa-46c2-b0f5-e751cf95550e
[92mINFO [0m:      Sent reply
02/07/2025 22:49:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:58:INFO:
[92mINFO [0m:      Received: train message 9f786d7e-30a6-4422-88b8-6693402ed4e1
02/07/2025 22:49:58:INFO:Received: train message 9f786d7e-30a6-4422-88b8-6693402ed4e1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 32/64:
  Train Loss: 0.6781113296747208
  Validation Loss: 0.6437900066375732
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 33/64:
  Train Loss: 0.6777445077896118
  Validation Loss: 0.6435678005218506
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.78125
Epoch 34/64:
  Train Loss: 0.6773438155651093
  Validation Loss: 0.6433274149894714
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6769820600748062
  Validation Loss: 0.6430809497833252
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6766148507595062
  Validation Loss: 0.6429041624069214
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6762930899858475
  Validation Loss: 0.6427730321884155
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6759698987007141
  Validation Loss: 0.6426741480827332
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6756328791379929
  Validation Loss: 0.6425672173500061
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.675325557589531
  Validation Loss: 0.6423971652984619
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6750189065933228
  Validation Loss: 0.6423014402389526
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6747074574232101
  Validation Loss: 0.642158031463623
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6744311451911926
  Validation Loss: 0.642063319683075
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.6741486489772797
  Validation Loss: 0.641957700252533
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6738655716180801
  Validation Loss: 0.6418634653091431
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.6736025214195251
  Validation Loss: 0.6417702436447144
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.6733339726924896
  Validation Loss: 0.6416714787483215
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6730689704418182
  Validation Loss: 0.6415770649909973
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.6727830171585083
  Validation Loss: 0.6414591073989868
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6725284308195114
  Validation Loss: 0.6413547992706299
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6722646951675415
  Validation Loss: 0.6412411332130432
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6720083653926849
  Validation Loss: 0.6411258578300476
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6717732101678848
  Validation Loss: 0.641003429889679
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.671528697013855
  Validation Loss: 0.6408905982971191
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6712704300880432
  Validation Loss: 0.6407665610313416
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.6710435450077057
  Validation Loss: 0.6407264471054077
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6708316057920456
  Validation Loss: 0.6406635046005249
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6706281304359436
  Validation Loss: 0.6405719518661499
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6704162955284119
  Validation Loss: 0.6405131816864014
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6702144294977188
  Validation Loss: 0.6404649019241333
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.670034721493721
  Validation Loss: 0.6403783559799194
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.669795960187912
  Validation Loss: 0.6402866840362549
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6695675849914551
  Validation Loss: 0.640250027179718
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6693908125162125
  Validation Loss: 0.6401563882827759
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
{'train_loss': 0.6693908125162125, 'val_roc_auc': 0.9372549019607843, 'val_accuracy': 0.78125, 'val_loss': 0.6401563882827759}
 ROC_AUC: 0.9373|| Accuracy 0.7812 || Train Loss: 0.6694
 Val Loss: 0.6402 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6794367719155091
Test ROC-AUC: 0.8571428571428571
Test Accuracy: 0.7788461538461539
test_loss: 0.6794367719155091
test_roc_auc: 0.8571428571428571
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.2529964592304168
Epoch 1/64:
  Train Loss: 0.695917472243309
  Validation Loss: 0.6355613470077515
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6951882243156433
  Validation Loss: 0.6351207494735718
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6945412904024124
  Validation Loss: 0.6346182227134705
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.693887248635292
  Validation Loss: 0.6341071128845215
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6932041347026825
  Validation Loss: 0.6336368322372437
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.6925444900989532
  Validation Loss: 0.6331698894500732
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 7/64:
  Train Loss: 0.6919489055871964
  Validation Loss: 0.6327465772628784
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 8/64:
  Train Loss: 0.6913501471281052
  Validation Loss: 0.6323277950286865
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 9/64:
  Train Loss: 0.6907630562782288
  Validation Loss: 0.6319503784179688
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 10/64:
  Train Loss: 0.6901811510324478
  Validation Loss: 0.6315838694572449
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 11/64:
  Train Loss: 0.6896277815103531
  Validation Loss: 0.631212055683136
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 12/64:
  Train Loss: 0.6890392452478409
  Validation Loss: 0.630858302116394
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 13/64:
  Train Loss: 0.6884887963533401
  Validation Loss: 0.6304770112037659
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 14/64:
  Train Loss: 0.6879378706216812
  Validation Loss: 0.6301535367965698
  Val ROC-AUC: 0.9254901960784314
  Val Accuracy: 0.78125
Epoch 15/64:
  Train Loss: 0.687429741024971
  Validation Loss: 0.6298582553863525
  Val ROC-AUC: 0.9254901960784314
  Val Accuracy: 0.78125
Epoch 16/64:
  Train Loss: 0.6869827061891556
  Validation Loss: 0.629557728767395
  Val ROC-AUC: 0.9254901960784314
  Val Accuracy: 0.78125
Epoch 17/64:
  Train Loss: 0.6865387707948685
  Validation Loss: 0.6292630434036255
  Val ROC-AUC: 0.9254901960784314
  Val Accuracy: 0.78125
Epoch 18/64:
  Train Loss: 0.6860388517379761
  Validation Loss: 0.6289800405502319
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.78125
Epoch 19/64:
  Train Loss: 0.6856048703193665
  Validation Loss: 0.6287111639976501
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.78125
Epoch 20/64:
  Train Loss: 0.6852097362279892
  Validation Loss: 0.6284710168838501
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.78125
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:24:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:25:INFO:
[92mINFO [0m:      Received: evaluate message 192fabb8-cac3-4110-a1c5-8b44d321fcfd
02/07/2025 22:50:25:INFO:Received: evaluate message 192fabb8-cac3-4110-a1c5-8b44d321fcfd
[92mINFO [0m:      Sent reply
02/07/2025 22:50:27:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:27:INFO:
[92mINFO [0m:      Received: train message 80734324-a533-4765-ba26-ffd01589e0ab
02/07/2025 22:50:27:INFO:Received: train message 80734324-a533-4765-ba26-ffd01589e0ab
Epoch 21/64:
  Train Loss: 0.6848102062940598
  Validation Loss: 0.6282212734222412
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.78125
Epoch 22/64:
  Train Loss: 0.6844133734703064
  Validation Loss: 0.6279676556587219
  Val ROC-AUC: 0.9254901960784314
  Val Accuracy: 0.78125
Epoch 23/64:
  Train Loss: 0.6840366572141647
  Validation Loss: 0.6277599334716797
  Val ROC-AUC: 0.9254901960784314
  Val Accuracy: 0.78125
Epoch 24/64:
  Train Loss: 0.6836623251438141
  Validation Loss: 0.6275736093521118
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 25/64:
  Train Loss: 0.6833053678274155
  Validation Loss: 0.627403736114502
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 26/64:
  Train Loss: 0.6829844117164612
  Validation Loss: 0.627194881439209
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 27/64:
  Train Loss: 0.6826406568288803
  Validation Loss: 0.6269849538803101
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 28/64:
  Train Loss: 0.6822509318590164
  Validation Loss: 0.626800537109375
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 29/64:
  Train Loss: 0.6819524019956589
  Validation Loss: 0.6265795230865479
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 30/64:
  Train Loss: 0.6815274953842163
  Validation Loss: 0.6263613104820251
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 31/64:
  Train Loss: 0.681167483329773
  Validation Loss: 0.6261433959007263
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 32/64:
  Train Loss: 0.6807845234870911
  Validation Loss: 0.625935435295105
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 33/64:
  Train Loss: 0.6804978549480438
  Validation Loss: 0.6257597804069519
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 34/64:
  Train Loss: 0.6801460981369019
  Validation Loss: 0.6256015300750732
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 35/64:
  Train Loss: 0.6797759085893631
  Validation Loss: 0.6254394054412842
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 36/64:
  Train Loss: 0.6794852912425995
  Validation Loss: 0.6252788305282593
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 37/64:
  Train Loss: 0.6791344732046127
  Validation Loss: 0.6251070499420166
  Val ROC-AUC: 0.9215686274509804
  Val Accuracy: 0.78125
Epoch 38/64:
  Train Loss: 0.6788107752799988
  Validation Loss: 0.6249693036079407
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 39/64:
  Train Loss: 0.678519606590271
  Validation Loss: 0.6248244643211365
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 40/64:
  Train Loss: 0.6782539337873459
  Validation Loss: 0.6246926784515381
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 41/64:
  Train Loss: 0.6779402941465378
  Validation Loss: 0.6245707869529724
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 42/64:
  Train Loss: 0.6777031272649765
  Validation Loss: 0.62447190284729
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 43/64:
  Train Loss: 0.67744579911232
  Validation Loss: 0.6243095397949219
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 44/64:
  Train Loss: 0.67721226811409
  Validation Loss: 0.6241441965103149
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 45/64:
  Train Loss: 0.6769347339868546
  Validation Loss: 0.6239937543869019
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.6767007559537888
  Validation Loss: 0.6238961219787598
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.6764572560787201
  Validation Loss: 0.6237993240356445
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6762192249298096
  Validation Loss: 0.623664379119873
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.6760006844997406
  Validation Loss: 0.6235648393630981
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6757472008466721
  Validation Loss: 0.6234874725341797
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6755217909812927
  Validation Loss: 0.6233939528465271
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6752820611000061
  Validation Loss: 0.6233173608779907
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6750655025243759
  Validation Loss: 0.6232022047042847
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.6748025715351105
  Validation Loss: 0.6231309175491333
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6746153980493546
  Validation Loss: 0.6230896711349487
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.6744019985198975
  Validation Loss: 0.6230487823486328
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6741720885038376
  Validation Loss: 0.6229951977729797
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6739652007818222
  Validation Loss: 0.6229104399681091
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6737638413906097
  Validation Loss: 0.6228618621826172
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6735405474901199
  Validation Loss: 0.6227989196777344
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6733394414186478
  Validation Loss: 0.6226866245269775
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.673124760389328
  Validation Loss: 0.622573971748352
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6729320138692856
  Validation Loss: 0.6224371790885925
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6727519482374191
  Validation Loss: 0.6223291754722595
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.78125
{'train_loss': 0.6727519482374191, 'val_roc_auc': 0.9019607843137255, 'val_accuracy': 0.78125, 'val_loss': 0.6223291754722595}
 ROC_AUC: 0.9020|| Accuracy 0.7812 || Train Loss: 0.6728
 Val Loss: 0.6223 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.675239527454743
Test ROC-AUC: 0.8634672619047619
Test Accuracy: 0.7884615384615384
test_loss: 0.675239527454743
test_roc_auc: 0.8634672619047619
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.1781373735411762
Epoch 1/64:
  Train Loss: 0.6877719163894653
  Validation Loss: 0.6527389287948608
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6870024502277374
  Validation Loss: 0.6522567868232727
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.6864088028669357
  Validation Loss: 0.6517727375030518
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6857158988714218
  Validation Loss: 0.6513149738311768
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.685054138302803
  Validation Loss: 0.6508764028549194
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6844421178102493
  Validation Loss: 0.6504589915275574
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.683868482708931
  Validation Loss: 0.6500227451324463
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.683231309056282
  Validation Loss: 0.6496121883392334
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6826949119567871
  Validation Loss: 0.6492241621017456
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6821883618831635
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:56:INFO:
[92mINFO [0m:      Received: evaluate message 10eef2fb-25f1-45e5-b77f-d12541cfa7f2
02/07/2025 22:50:56:INFO:Received: evaluate message 10eef2fb-25f1-45e5-b77f-d12541cfa7f2
[92mINFO [0m:      Sent reply
02/07/2025 22:50:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:59:INFO:
[92mINFO [0m:      Received: train message 9e9a761a-0243-4a39-b59f-2fb5c07d317e
02/07/2025 22:50:59:INFO:Received: train message 9e9a761a-0243-4a39-b59f-2fb5c07d317e
  Validation Loss: 0.6488445997238159
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 11/64:
  Train Loss: 0.6815885007381439
  Validation Loss: 0.6484830975532532
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.6810420602560043
  Validation Loss: 0.6481696367263794
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6806028485298157
  Validation Loss: 0.6478198766708374
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.6801102459430695
  Validation Loss: 0.647484540939331
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.6796044111251831
  Validation Loss: 0.6471431255340576
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6791221648454666
  Validation Loss: 0.6468496918678284
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.6787000000476837
  Validation Loss: 0.6465598344802856
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.6782852411270142
  Validation Loss: 0.6462883353233337
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6778527349233627
  Validation Loss: 0.64601731300354
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6774203330278397
  Validation Loss: 0.6457802057266235
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6770189255475998
  Validation Loss: 0.6455461382865906
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.676656037569046
  Validation Loss: 0.6452978849411011
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.676308885216713
  Validation Loss: 0.6450445652008057
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.8125
Epoch 24/64:
  Train Loss: 0.6759421080350876
  Validation Loss: 0.6448067426681519
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.8125
Epoch 25/64:
  Train Loss: 0.67559514939785
  Validation Loss: 0.6445720195770264
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.8125
Epoch 26/64:
  Train Loss: 0.6752359420061111
  Validation Loss: 0.6443465352058411
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.8125
Epoch 27/64:
  Train Loss: 0.674903392791748
  Validation Loss: 0.6441395878791809
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 28/64:
  Train Loss: 0.6746012419462204
  Validation Loss: 0.6439419984817505
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 29/64:
  Train Loss: 0.6742954105138779
  Validation Loss: 0.6437370181083679
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 30/64:
  Train Loss: 0.6740213632583618
  Validation Loss: 0.643520712852478
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 31/64:
  Train Loss: 0.673695832490921
  Validation Loss: 0.643323540687561
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 32/64:
  Train Loss: 0.6733825653791428
  Validation Loss: 0.6431123614311218
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 33/64:
  Train Loss: 0.6730721890926361
  Validation Loss: 0.6429039239883423
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6727701723575592
  Validation Loss: 0.6426792144775391
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6724788099527359
  Validation Loss: 0.6424752473831177
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.67219477891922
  Validation Loss: 0.6422979831695557
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6719364672899246
  Validation Loss: 0.6421220302581787
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6716408133506775
  Validation Loss: 0.641984224319458
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6714334785938263
  Validation Loss: 0.6418120861053467
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.671133503317833
  Validation Loss: 0.6416537165641785
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6708823293447495
  Validation Loss: 0.6414849162101746
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6706307977437973
  Validation Loss: 0.6413270831108093
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6703657656908035
  Validation Loss: 0.6411339044570923
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.6701416224241257
  Validation Loss: 0.6409638524055481
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6698798686265945
  Validation Loss: 0.6408318281173706
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6696572750806808
  Validation Loss: 0.6406815052032471
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6694192439317703
  Validation Loss: 0.6405225992202759
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6691881716251373
  Validation Loss: 0.6403944492340088
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6689905077219009
  Validation Loss: 0.6402745842933655
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.6687976121902466
  Validation Loss: 0.640134334564209
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.6685509234666824
  Validation Loss: 0.6400270462036133
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6683753430843353
  Validation Loss: 0.6399087905883789
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6681687831878662
  Validation Loss: 0.6398029327392578
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6679733842611313
  Validation Loss: 0.6396734118461609
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.667768806219101
  Validation Loss: 0.6395477056503296
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6675859242677689
  Validation Loss: 0.639427900314331
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6674117296934128
  Validation Loss: 0.6393185257911682
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.6672380566596985
  Validation Loss: 0.639202356338501
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6670596599578857
  Validation Loss: 0.6391127109527588
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6669480055570602
  Validation Loss: 0.6390005350112915
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 61/64:
  Train Loss: 0.666806548833847
  Validation Loss: 0.6388814449310303
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6666578203439713
  Validation Loss: 0.6387660503387451
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6664964258670807
  Validation Loss: 0.6386584639549255
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6663639545440674
  Validation Loss: 0.6385565996170044
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.84375
{'train_loss': 0.6663639545440674, 'val_roc_auc': 0.9019607843137255, 'val_accuracy': 0.84375, 'val_loss': 0.6385565996170044}
 ROC_AUC: 0.9020|| Accuracy 0.8438 || Train Loss: 0.6664
 Val Loss: 0.6386 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6712853779586462
Test ROC-AUC: 0.8701636904761905
Test Accuracy: 0.7884615384615384
test_loss: 0.6712853779586462
test_roc_auc: 0.8701636904761905
test_accuracy: 0.7884615384615384
eval_cid: 0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.2782800375189254
Epoch 1/64:
  Train Loss: 0.6638688445091248
  Validation Loss: 0.7352583408355713
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6631222069263458
  Validation Loss: 0.7348407506942749
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6624625474214554
  Validation Loss: 0.7344620227813721
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6618169695138931
  Validation Loss: 0.7340697050094604
  Val ROC-AUC: 0.8874458874458875
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6612781584262848
  Validation Loss: 0.733779788017273
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.6606887131929398
  Validation Loss: 0.7335134744644165
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 7/64:
  Train Loss: 0.6602239459753036
  Validation Loss: 0.7332462072372437
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 8/64:
  Train Loss: 0.6597143411636353
  Validation Loss: 0.7329509258270264
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 9/64:
  Train Loss: 0.6592748761177063
  Validation Loss: 0.7326740622520447
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 10/64:
  Train Loss: 0.6587341278791428
  Validation Loss: 0.7323883771896362
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 11/64:
  Train Loss: 0.6582691520452499
  Validation Loss: 0.732140302658081
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 12/64:
  Train Loss: 0.6578575968742371
  Validation Loss: 0.7319070100784302
  Val ROC-AUC: 0.8831168831168832
  Val Accuracy: 0.75
Epoch 13/64:
  Train Loss: 0.6574170738458633
  Validation Loss: 0.7317053079605103
  Val ROC-AUC: 0.8787878787878789
  Val Accuracy: 0.75
Epoch 14/64:
  Train Loss: 0.6569929420948029
  Validation Loss: 0.7314344644546509
  Val ROC-AUC: 0.8787878787878789
  Val Accuracy: 0.75
Epoch 15/64:
  Train Loss: 0.656576469540596
  Validation Loss: 0.731165885925293
  Val ROC-AUC: 0.8787878787878789
  Val Accuracy: 0.75
Epoch 16/64:
  Train Loss: 0.6561794579029083
  Validation Loss: 0.7308874130249023
  Val ROC-AUC: 0.8787878787878789
  Val Accuracy: 0.75
Epoch 17/64:
  Train Loss: 0.6557967215776443
  Validation Loss: 0.7305984497070312
  Val ROC-AUC: 0.8701298701298701
  Val Accuracy: 0.75
Epoch 18/64:
  Train Loss: 0.6553956419229507
  Validation Loss: 0.7303525805473328
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 19/64:
  Train Loss: 0.6550282090902328
  Validation Loss: 0.7300513982772827
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 20/64:
  Train Loss: 0.6546446084976196
  Validation Loss: 0.7298778891563416
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 21/64:
  Train Loss: 0.6542685180902481
  Validation Loss: 0.7297073602676392
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.75
Epoch 22/64:
  Train Loss: 0.6539322733879089
  Validation Loss: 0.72955322265625
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.75
Epoch 23/64:
  Train Loss: 0.6536196172237396
  Validation Loss: 0.7294319868087769
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.75
Epoch 24/64:
  Train Loss: 0.653283417224884
  Validation Loss: 0.729317307472229
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.75
Epoch 25/64:
  Train Loss: 0.652971550822258
  Validation Loss: 0.7291406393051147
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.75
Epoch 26/64:
  Train Loss: 0.6526419073343277
  Validation Loss: 0.7289746403694153
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.75
Epoch 27/64:
  Train Loss: 0.6522942334413528
  Validation Loss: 0.7288382053375244
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6520128697156906
  Validation Loss: 0.7286542654037476
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6517075896263123
  Validation Loss: 0.7284208536148071
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6513879746198654
  Validation Loss: 0.7281912565231323
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.651074230670929
  Validation Loss: 0.7279906272888184
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6508059352636337
  Validation Loss: 0.7278189659118652
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6505322754383087
  Validation Loss: 0.7276602983474731
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6502822786569595
  Validation Loss: 0.7274686098098755
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.6500199884176254
  Validation Loss: 0.7272918224334717
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.6497834920883179
  Validation Loss: 0.7271356582641602
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.6495130360126495
  Validation Loss: 0.7269959449768066
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.649262323975563
  Validation Loss: 0.7268612384796143
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6490599811077118
  Validation Loss: 0.7267813682556152
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6488403975963593
  Validation Loss: 0.7267288565635681
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6486348807811737
  Validation Loss: 0.7266895174980164
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.648405909538269
  Validation Loss: 0.7265764474868774
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6481817662715912
  Validation Loss: 0.7264748215675354
  Val ROC-AUC: 0.8484848484848485
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6479989588260651
  Validation Loss: 0.7263660430908203
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.647813692688942
  Validation Loss: 0.7262227535247803
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6476110517978668
  Validation Loss: 0.7261213064193726
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6474487036466599
  Validation Loss: 0.7260407209396362
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6472900062799454
  Validation Loss: 0.7259861826896667
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.6471594125032425
  Validation Loss: 0.7259106636047363
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6469457447528839
  Validation Loss: 0.7258223295211792
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6468014121055603
  Validation Loss: 0.7257297039031982
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6466400474309921
  Validation Loss: 0.7256580591201782
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6465202271938324
  Validation Loss: 0.725558876991272
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6464373916387558
  Validation Loss: 0.7254693508148193
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6463204920291901
  Validation Loss: 0.7254073023796082
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.6461982578039169
  Validation Loss: 0.7253093719482422
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6460526585578918
  Validation Loss: 0.7252435088157654
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6458988338708878
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:51:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:31:INFO:
[92mINFO [0m:      Received: evaluate message 411ddfd8-8fbc-440f-a8dc-406d29044643
02/07/2025 22:51:31:INFO:Received: evaluate message 411ddfd8-8fbc-440f-a8dc-406d29044643
[92mINFO [0m:      Sent reply
02/07/2025 22:51:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:34:INFO:
[92mINFO [0m:      Received: train message 508771c7-0caa-471b-9b6b-9dd021fe298a
02/07/2025 22:51:34:INFO:Received: train message 508771c7-0caa-471b-9b6b-9dd021fe298a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.7251747846603394
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6457354873418808
  Validation Loss: 0.72510826587677
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6455829441547394
  Validation Loss: 0.7250592112541199
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6454131603240967
  Validation Loss: 0.7249377369880676
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6452514678239822
  Validation Loss: 0.7248406410217285
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6451074481010437
  Validation Loss: 0.7247157096862793
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6449574679136276
  Validation Loss: 0.7245903015136719
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.78125
{'train_loss': 0.6449574679136276, 'val_roc_auc': 0.8571428571428571, 'val_accuracy': 0.78125, 'val_loss': 0.7245903015136719}
 ROC_AUC: 0.8571|| Accuracy 0.7812 || Train Loss: 0.6450
 Val Loss: 0.7246 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6677604750371896
Test ROC-AUC: 0.8735119047619048
Test Accuracy: 0.7980769230769231
test_loss: 0.6677604750371896
test_roc_auc: 0.8735119047619048
test_accuracy: 0.7980769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.26870214825066796
Epoch 1/64:
  Train Loss: 0.6782186627388
  Validation Loss: 0.6655799150466919
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.677722617983818
  Validation Loss: 0.6651862859725952
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 3/64:
  Train Loss: 0.6772385686635971
  Validation Loss: 0.6648030281066895
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 4/64:
  Train Loss: 0.6767300069332123
  Validation Loss: 0.6644768118858337
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 5/64:
  Train Loss: 0.6762503385543823
  Validation Loss: 0.6641436815261841
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 6/64:
  Train Loss: 0.6757596135139465
  Validation Loss: 0.6637935638427734
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 7/64:
  Train Loss: 0.6752563267946243
  Validation Loss: 0.663489043712616
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.6748836487531662
  Validation Loss: 0.6632097363471985
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.674443319439888
  Validation Loss: 0.6629548668861389
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.6740214675664902
  Validation Loss: 0.6626769304275513
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6735740900039673
  Validation Loss: 0.6624240279197693
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.6731943041086197
  Validation Loss: 0.6621484160423279
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6727327257394791
  Validation Loss: 0.6619240045547485
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6723745465278625
  Validation Loss: 0.6616348028182983
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6719750016927719
  Validation Loss: 0.6613893508911133
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6715910881757736
  Validation Loss: 0.661171555519104
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6712562441825867
  Validation Loss: 0.6609561443328857
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.670892059803009
  Validation Loss: 0.6607669591903687
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6705076694488525
  Validation Loss: 0.6605797410011292
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6701323240995407
  Validation Loss: 0.6604130268096924
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6697995662689209
  Validation Loss: 0.6602208614349365
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6694705039262772
  Validation Loss: 0.6600399017333984
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6691475808620453
  Validation Loss: 0.6598176956176758
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6688295602798462
  Validation Loss: 0.6595649719238281
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.668444812297821
  Validation Loss: 0.6593531370162964
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6681211590766907
  Validation Loss: 0.6591838002204895
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6677814275026321
  Validation Loss: 0.6590220332145691
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.667483389377594
  Validation Loss: 0.6588451862335205
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6671433299779892
  Validation Loss: 0.6586846113204956
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.6668495237827301
  Validation Loss: 0.6585348844528198
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6665438860654831
  Validation Loss: 0.6584106087684631
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6662973165512085
  Validation Loss: 0.6582881808280945
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6660424768924713
  Validation Loss: 0.6581616997718811
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6657818406820297
  Validation Loss: 0.658004879951477
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6655402928590775
  Validation Loss: 0.6578190326690674
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6652742177248001
  Validation Loss: 0.6576353907585144
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6650271564722061
  Validation Loss: 0.6574636101722717
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6647578328847885
  Validation Loss: 0.6573047637939453
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6645110994577408
  Validation Loss: 0.657137393951416
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.664278507232666
  Validation Loss: 0.6569730043411255
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6640113741159439
  Validation Loss: 0.6568663120269775
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6638003289699554
  Validation Loss: 0.6567662954330444
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6636037230491638
  Validation Loss: 0.6566318273544312
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6633949130773544
  Validation Loss: 0.6564833521842957
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6631847620010376
  Validation Loss: 0.6563485264778137
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.662956714630127
  Validation Loss: 0.6562047004699707
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6627201437950134
  Validation Loss: 0.6561211347579956
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:04:INFO:
[92mINFO [0m:      Received: evaluate message 22cf98db-d3c3-49fd-bddd-e998a9fde067
02/07/2025 22:52:04:INFO:Received: evaluate message 22cf98db-d3c3-49fd-bddd-e998a9fde067
[92mINFO [0m:      Sent reply
02/07/2025 22:52:06:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:06:INFO:
[92mINFO [0m:      Received: train message 8cb7df66-4fe5-4b44-9032-6858c2bab48f
02/07/2025 22:52:06:INFO:Received: train message 8cb7df66-4fe5-4b44-9032-6858c2bab48f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6625191569328308
  Validation Loss: 0.6560155153274536
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6623227298259735
  Validation Loss: 0.6558510065078735
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6621324717998505
  Validation Loss: 0.655722975730896
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6619482338428497
  Validation Loss: 0.655579149723053
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6617302447557449
  Validation Loss: 0.6554601192474365
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6615638732910156
  Validation Loss: 0.6553664207458496
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6613747477531433
  Validation Loss: 0.6552616357803345
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6611917465925217
  Validation Loss: 0.6551093459129333
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6610200703144073
  Validation Loss: 0.6550204753875732
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6608546525239944
  Validation Loss: 0.6548970341682434
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6607187986373901
  Validation Loss: 0.6548599004745483
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6606105417013168
  Validation Loss: 0.6548141837120056
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6604993045330048
  Validation Loss: 0.6547354459762573
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6603595465421677
  Validation Loss: 0.6546367406845093
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6602242439985275
  Validation Loss: 0.6545574069023132
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6600995361804962
  Validation Loss: 0.6544933915138245
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6599902808666229
  Validation Loss: 0.654401421546936
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.75
{'train_loss': 0.6599902808666229, 'val_roc_auc': 0.8666666666666666, 'val_accuracy': 0.75, 'val_loss': 0.654401421546936}
 ROC_AUC: 0.8667|| Accuracy 0.7500 || Train Loss: 0.6600
 Val Loss: 0.6544 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6644829686444539
Test ROC-AUC: 0.8779761904761904
Test Accuracy: 0.7980769230769231
test_loss: 0.6644829686444539
test_roc_auc: 0.8779761904761904
test_accuracy: 0.7980769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.2377036283905909
Epoch 1/64:
  Train Loss: 0.6775517761707306
  Validation Loss: 0.6571880578994751
  Val ROC-AUC: 0.7764705882352941
  Val Accuracy: 0.65625
Epoch 2/64:
  Train Loss: 0.6769466698169708
  Validation Loss: 0.6568349599838257
  Val ROC-AUC: 0.7764705882352941
  Val Accuracy: 0.65625
Epoch 3/64:
  Train Loss: 0.6764280796051025
  Validation Loss: 0.6564876437187195
  Val ROC-AUC: 0.7764705882352941
  Val Accuracy: 0.65625
Epoch 4/64:
  Train Loss: 0.6759006083011627
  Validation Loss: 0.6561340093612671
  Val ROC-AUC: 0.7803921568627451
  Val Accuracy: 0.65625
Epoch 5/64:
  Train Loss: 0.675425797700882
  Validation Loss: 0.6557398438453674
  Val ROC-AUC: 0.7843137254901961
  Val Accuracy: 0.65625
Epoch 6/64:
  Train Loss: 0.6749574393033981
  Validation Loss: 0.6553623676300049
  Val ROC-AUC: 0.788235294117647
  Val Accuracy: 0.65625
Epoch 7/64:
  Train Loss: 0.6744799464941025
  Validation Loss: 0.6549814343452454
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 8/64:
  Train Loss: 0.6739854514598846
  Validation Loss: 0.6546515822410583
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 9/64:
  Train Loss: 0.6735476553440094
  Validation Loss: 0.6542859077453613
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 10/64:
  Train Loss: 0.6730300188064575
  Validation Loss: 0.6539034843444824
  Val ROC-AUC: 0.7882352941176471
  Val Accuracy: 0.65625
Epoch 11/64:
  Train Loss: 0.6725709587335587
  Validation Loss: 0.6535502076148987
  Val ROC-AUC: 0.7882352941176471
  Val Accuracy: 0.65625
Epoch 12/64:
  Train Loss: 0.6721330285072327
  Validation Loss: 0.6532571911811829
  Val ROC-AUC: 0.7882352941176471
  Val Accuracy: 0.65625
Epoch 13/64:
  Train Loss: 0.6717540323734283
  Validation Loss: 0.6529640555381775
  Val ROC-AUC: 0.7882352941176471
  Val Accuracy: 0.65625
Epoch 14/64:
  Train Loss: 0.6713311225175858
  Validation Loss: 0.6526839137077332
  Val ROC-AUC: 0.7882352941176471
  Val Accuracy: 0.65625
Epoch 15/64:
  Train Loss: 0.6709935069084167
  Validation Loss: 0.6524385213851929
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 16/64:
  Train Loss: 0.6706405580043793
  Validation Loss: 0.6521391272544861
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 17/64:
  Train Loss: 0.6702625602483749
  Validation Loss: 0.6518226265907288
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 18/64:
  Train Loss: 0.6699022352695465
  Validation Loss: 0.6515148878097534
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 19/64:
  Train Loss: 0.6695773303508759
  Validation Loss: 0.651216447353363
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 20/64:
  Train Loss: 0.6692727208137512
  Validation Loss: 0.6509307622909546
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.65625
Epoch 21/64:
  Train Loss: 0.668924942612648
  Validation Loss: 0.6506263017654419
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.6875
Epoch 22/64:
  Train Loss: 0.6686133146286011
  Validation Loss: 0.6503495573997498
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.6875
Epoch 23/64:
  Train Loss: 0.6683149188756943
  Validation Loss: 0.6501032710075378
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.6875
Epoch 24/64:
  Train Loss: 0.6680185198783875
  Validation Loss: 0.6498669385910034
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 25/64:
  Train Loss: 0.6677399724721909
  Validation Loss: 0.6496090292930603
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 26/64:
  Train Loss: 0.6674276739358902
  Validation Loss: 0.6493545174598694
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 27/64:
  Train Loss: 0.667171835899353
  Validation Loss: 0.6491107940673828
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 28/64:
  Train Loss: 0.6669416278600693
  Validation Loss: 0.6488687992095947
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 29/64:
  Train Loss: 0.6666775643825531
  Validation Loss: 0.6486307382583618
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.6875
Epoch 30/64:
  Train Loss: 0.6663983911275864
  Validation Loss: 0.6484243869781494
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.6875
Epoch 31/64:
  Train Loss: 0.6661219596862793
  Validation Loss: 0.6482698917388916
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.6875
Epoch 32/64:
  Train Loss: 0.6658614575862885
  Validation Loss: 0.6481026411056519
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.6875
Epoch 33/64:
  Train Loss: 0.6656246483325958
  Validation Loss: 0.6479432582855225
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6654176861047745
  Validation Loss: 0.6477470397949219
  Val ROC-AUC: 0.7921568627450981
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6651593148708344
  Validation Loss: 0.64752197265625
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6648939698934555
  Validation Loss: 0.6473410129547119
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6646507382392883
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:32:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:34:INFO:
[92mINFO [0m:      Received: evaluate message 5bb460bb-9520-4d56-8813-73d7f888d1b9
02/07/2025 22:52:34:INFO:Received: evaluate message 5bb460bb-9520-4d56-8813-73d7f888d1b9
[92mINFO [0m:      Sent reply
02/07/2025 22:52:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:35:INFO:
[92mINFO [0m:      Received: train message 91c775a0-c64f-4831-9d73-fb8de93a590a
02/07/2025 22:52:35:INFO:Received: train message 91c775a0-c64f-4831-9d73-fb8de93a590a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6471216678619385
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6644120216369629
  Validation Loss: 0.6469082236289978
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6642241925001144
  Validation Loss: 0.6466861367225647
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6639938950538635
  Validation Loss: 0.6465144157409668
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6638156026601791
  Validation Loss: 0.6463598012924194
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6636124849319458
  Validation Loss: 0.6461984515190125
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6634684056043625
  Validation Loss: 0.6460010409355164
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6632727533578873
  Validation Loss: 0.6458550095558167
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6631106585264206
  Validation Loss: 0.6456905007362366
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6629365086555481
  Validation Loss: 0.6455552577972412
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6628221273422241
  Validation Loss: 0.6454064846038818
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.662669762969017
  Validation Loss: 0.6453195810317993
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6625804603099823
  Validation Loss: 0.6452569961547852
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6624418646097183
  Validation Loss: 0.6452024579048157
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6623399555683136
  Validation Loss: 0.6451488733291626
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6622422188520432
  Validation Loss: 0.6450894474983215
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6621245592832565
  Validation Loss: 0.6450138092041016
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6620126068592072
  Validation Loss: 0.6449394226074219
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6619030237197876
  Validation Loss: 0.6448782682418823
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6617897152900696
  Validation Loss: 0.6447814702987671
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6616349220275879
  Validation Loss: 0.6446605324745178
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6615358293056488
  Validation Loss: 0.6445240378379822
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6614164412021637
  Validation Loss: 0.6444398164749146
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6612953394651413
  Validation Loss: 0.6442880630493164
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6611758321523666
  Validation Loss: 0.644188642501831
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6610120534896851
  Validation Loss: 0.6441311240196228
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6608796268701553
  Validation Loss: 0.6440885066986084
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6607805788516998
  Validation Loss: 0.6440342664718628
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
{'train_loss': 0.6607805788516998, 'val_roc_auc': 0.8, 'val_accuracy': 0.75, 'val_loss': 0.6440342664718628}
 ROC_AUC: 0.8000|| Accuracy 0.7500 || Train Loss: 0.6608
 Val Loss: 0.6440 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6615426996006415
Test ROC-AUC: 0.8813244047619048
Test Accuracy: 0.7980769230769231
test_loss: 0.6615426996006415
test_roc_auc: 0.8813244047619048
test_accuracy: 0.7980769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.23383948922734513
Epoch 1/64:
  Train Loss: 0.6841119825839996
  Validation Loss: 0.6202319860458374
  Val ROC-AUC: 0.8980392156862745
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.683563694357872
  Validation Loss: 0.6201381683349609
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6831405907869339
  Validation Loss: 0.6200662851333618
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.6827000975608826
  Validation Loss: 0.6199705600738525
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6822288632392883
  Validation Loss: 0.6198529005050659
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.681847408413887
  Validation Loss: 0.6197710633277893
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6814120709896088
  Validation Loss: 0.6196449995040894
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6809718459844589
  Validation Loss: 0.619563639163971
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6805905252695084
  Validation Loss: 0.6194591522216797
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6802268326282501
  Validation Loss: 0.6193450093269348
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6798380464315414
  Validation Loss: 0.6192317008972168
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6794831156730652
  Validation Loss: 0.6191246509552002
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6790896654129028
  Validation Loss: 0.6190037131309509
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6787353605031967
  Validation Loss: 0.6188737154006958
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6783894747495651
  Validation Loss: 0.6187558174133301
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6780426949262619
  Validation Loss: 0.6186487078666687
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6777279227972031
  Validation Loss: 0.6185669302940369
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6774351894855499
  Validation Loss: 0.6184350252151489
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6771070063114166
  Validation Loss: 0.618341326713562
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6767725348472595
  Validation Loss: 0.6182126402854919
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6764326840639114
  Validation Loss: 0.6180809736251831
  Val ROC-AUC: 0.8941176470588235
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6760793328285217
  Validation Loss: 0.6179727911949158
  Val ROC-AUC: 0.8980392156862746
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6757580190896988
  Validation Loss: 0.617874264717102
  Val ROC-AUC: 0.8980392156862746
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6754637360572815
  Validation Loss: 0.6177937388420105
  Val ROC-AUC: 0.8980392156862746
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6751553267240524
  Validation Loss: 0.6177048683166504
  Val ROC-AUC: 0.8980392156862746
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.674812376499176
  Validation Loss: 0.6175739765167236
  Val ROC-AUC: 0.8980392156862746
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6745311617851257
  Validation Loss: 0.6174424886703491
  Val ROC-AUC: 0.8980392156862746
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6742504239082336
  Validation Loss: 0.6173459887504578
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6739848405122757
  Validation Loss: 0.6172658205032349
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: evaluate message 96f13e45-867b-4bf2-a7c9-d08fba4fa0c5
02/07/2025 22:53:04:INFO:Received: evaluate message 96f13e45-867b-4bf2-a7c9-d08fba4fa0c5
[92mINFO [0m:      Sent reply
02/07/2025 22:53:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: train message b94caac5-410c-4864-b9aa-647150d0b702
02/07/2025 22:53:04:INFO:Received: train message b94caac5-410c-4864-b9aa-647150d0b702
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 30/64:
  Train Loss: 0.673721432685852
  Validation Loss: 0.6172018051147461
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6734634637832642
  Validation Loss: 0.6171593070030212
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6731947511434555
  Validation Loss: 0.617098331451416
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.672932893037796
  Validation Loss: 0.6170375943183899
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6726745963096619
  Validation Loss: 0.6169880032539368
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6724696755409241
  Validation Loss: 0.6169106960296631
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6722453236579895
  Validation Loss: 0.6168297529220581
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6720417141914368
  Validation Loss: 0.6167445182800293
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6718106120824814
  Validation Loss: 0.6166404485702515
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.671577975153923
  Validation Loss: 0.6165262460708618
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6713684499263763
  Validation Loss: 0.6164366006851196
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6711754202842712
  Validation Loss: 0.6163852214813232
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6710313260555267
  Validation Loss: 0.6163329482078552
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6708423495292664
  Validation Loss: 0.6162910461425781
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6706899851560593
  Validation Loss: 0.6162500381469727
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.6705231666564941
  Validation Loss: 0.6162275671958923
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6703210473060608
  Validation Loss: 0.6161763668060303
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6701601147651672
  Validation Loss: 0.6161178350448608
  Val ROC-AUC: 0.8862745098039216
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6699766367673874
  Validation Loss: 0.6160680055618286
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6698315292596817
  Validation Loss: 0.6160311698913574
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6696875691413879
  Validation Loss: 0.6159887909889221
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.669561967253685
  Validation Loss: 0.6159375905990601
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6694384813308716
  Validation Loss: 0.6158655285835266
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6692751944065094
  Validation Loss: 0.6158283948898315
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6691690534353256
  Validation Loss: 0.6158018112182617
  Val ROC-AUC: 0.8901960784313726
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6690616458654404
  Validation Loss: 0.6157805919647217
  Val ROC-AUC: 0.8823529411764707
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.6689107120037079
  Validation Loss: 0.6157314777374268
  Val ROC-AUC: 0.8823529411764707
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.6687421202659607
  Validation Loss: 0.6157011389732361
  Val ROC-AUC: 0.8823529411764707
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6686291396617889
  Validation Loss: 0.6157082319259644
  Val ROC-AUC: 0.8823529411764707
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6685497015714645
  Validation Loss: 0.6157411932945251
  Val ROC-AUC: 0.8823529411764707
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.6685042977333069
  Validation Loss: 0.6157904863357544
  Val ROC-AUC: 0.8823529411764707
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6684317737817764
  Validation Loss: 0.6158145070075989
  Val ROC-AUC: 0.8823529411764707
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6683523058891296
  Validation Loss: 0.6158066391944885
  Val ROC-AUC: 0.8823529411764707
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6682845801115036
  Validation Loss: 0.6158164739608765
  Val ROC-AUC: 0.8823529411764707
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6681948602199554
  Validation Loss: 0.615855872631073
  Val ROC-AUC: 0.8823529411764707
  Val Accuracy: 0.84375
{'train_loss': 0.6681948602199554, 'val_roc_auc': 0.8823529411764707, 'val_accuracy': 0.84375, 'val_loss': 0.615855872631073}
 ROC_AUC: 0.8824|| Accuracy 0.8438 || Train Loss: 0.6682
 Val Loss: 0.6159 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6588964872062206
Test ROC-AUC: 0.8816964285714286
Test Accuracy: 0.8076923076923077
test_loss: 0.6588964872062206
test_roc_auc: 0.8816964285714286
test_accuracy: 0.8076923076923077
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.18900053053888163
Epoch 1/64:
  Train Loss: 0.6855961233377457
  Validation Loss: 0.6054733395576477
  Val ROC-AUC: 0.9764705882352942
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6852130591869354
  Validation Loss: 0.605380654335022
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.6847850233316422
  Validation Loss: 0.605302095413208
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6843768060207367
  Validation Loss: 0.6052371263504028
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.6839783489704132
  Validation Loss: 0.6051878929138184
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6836214959621429
  Validation Loss: 0.605104923248291
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6832666993141174
  Validation Loss: 0.6050713658332825
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.682870477437973
  Validation Loss: 0.6049953699111938
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6824838072061539
  Validation Loss: 0.604936957359314
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6821110844612122
  Validation Loss: 0.6048874855041504
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.681757777929306
  Validation Loss: 0.604831337928772
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6814107447862625
  Validation Loss: 0.6047908067703247
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6810809075832367
  Validation Loss: 0.6047420501708984
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6807521283626556
  Validation Loss: 0.6046985387802124
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6804047226905823
  Validation Loss: 0.6046806573867798
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6800863146781921
  Validation Loss: 0.6046504974365234
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.679775059223175
  Validation Loss: 0.6046290397644043
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6794526278972626
  Validation Loss: 0.6046098470687866
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6791364401578903
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:30:INFO:
[92mINFO [0m:      Received: evaluate message f8e09492-b9cd-41a8-a08f-57c3071149ba
02/07/2025 22:53:30:INFO:Received: evaluate message f8e09492-b9cd-41a8-a08f-57c3071149ba
[92mINFO [0m:      Sent reply
02/07/2025 22:53:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:33:INFO:
[92mINFO [0m:      Received: train message a9dae3f1-e120-48ce-9ae0-94b27642ab1e
02/07/2025 22:53:33:INFO:Received: train message a9dae3f1-e120-48ce-9ae0-94b27642ab1e
  Validation Loss: 0.6045832633972168
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6788762360811234
  Validation Loss: 0.6045902967453003
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6786029785871506
  Validation Loss: 0.6045700311660767
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6783368140459061
  Validation Loss: 0.6045529842376709
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6780807822942734
  Validation Loss: 0.6044891476631165
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6777685731649399
  Validation Loss: 0.6044480800628662
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6775046586990356
  Validation Loss: 0.6044226884841919
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6772682964801788
  Validation Loss: 0.604423999786377
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6770064234733582
  Validation Loss: 0.6044285297393799
  Val ROC-AUC: 0.9568627450980393
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6767429560422897
  Validation Loss: 0.6044192314147949
  Val ROC-AUC: 0.9529411764705883
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6764883100986481
  Validation Loss: 0.6044607758522034
  Val ROC-AUC: 0.9529411764705883
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6762843877077103
  Validation Loss: 0.6044903993606567
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6760337650775909
  Validation Loss: 0.6045187711715698
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6758093535900116
  Validation Loss: 0.6045228242874146
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6755910217761993
  Validation Loss: 0.6045048832893372
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6753120124340057
  Validation Loss: 0.6045292615890503
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6751002371311188
  Validation Loss: 0.6045424938201904
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6748296171426773
  Validation Loss: 0.6045455932617188
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6746218055486679
  Validation Loss: 0.6045424342155457
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6744193732738495
  Validation Loss: 0.6044998168945312
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.674187645316124
  Validation Loss: 0.6044690608978271
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6740028411149979
  Validation Loss: 0.604488730430603
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6738298088312149
  Validation Loss: 0.6044825911521912
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6736417263746262
  Validation Loss: 0.6045188903808594
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6734666675329208
  Validation Loss: 0.6045165657997131
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6732770204544067
  Validation Loss: 0.6044846773147583
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.673102855682373
  Validation Loss: 0.6044869422912598
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6729254573583603
  Validation Loss: 0.6044599413871765
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6727315485477448
  Validation Loss: 0.604455292224884
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6725836396217346
  Validation Loss: 0.604486346244812
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6723950803279877
  Validation Loss: 0.6045000553131104
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6722613722085953
  Validation Loss: 0.604548454284668
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6721094697713852
  Validation Loss: 0.6045361757278442
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6719754040241241
  Validation Loss: 0.604579746723175
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6718354821205139
  Validation Loss: 0.6045998334884644
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6716765761375427
  Validation Loss: 0.6046205759048462
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6715332716703415
  Validation Loss: 0.6046383380889893
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.6713440716266632
  Validation Loss: 0.6046338081359863
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.6712004989385605
  Validation Loss: 0.6046223640441895
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.671030730009079
  Validation Loss: 0.6046063899993896
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6708639562129974
  Validation Loss: 0.6046029329299927
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.67073854804039
  Validation Loss: 0.6045894622802734
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8125
Epoch 61/64:
  Train Loss: 0.6705865114927292
  Validation Loss: 0.6046042442321777
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6704588234424591
  Validation Loss: 0.6046249866485596
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8125
Epoch 63/64:
  Train Loss: 0.6703354716300964
  Validation Loss: 0.6046531200408936
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6702055931091309
  Validation Loss: 0.6047205328941345
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8125
{'train_loss': 0.6702055931091309, 'val_roc_auc': 0.9294117647058824, 'val_accuracy': 0.8125, 'val_loss': 0.6047205328941345}
 ROC_AUC: 0.9294|| Accuracy 0.8125 || Train Loss: 0.6702
 Val Loss: 0.6047 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6564840324796163
Test ROC-AUC: 0.8813244047619048
Test Accuracy: 0.8173076923076923
test_loss: 0.6564840324796163
test_roc_auc: 0.8813244047619048
test_accuracy: 0.8173076923076923
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.21701214529457502
Epoch 1/64:
  Train Loss: 0.672977864742279
  Validation Loss: 0.6466009616851807
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6725792586803436
  Validation Loss: 0.6461136937141418
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.6722473502159119
  Validation Loss: 0.6457238793373108
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6719411462545395
  Validation Loss: 0.6453427076339722
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.671678751707077
  Validation Loss: 0.6449541449546814
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6713563650846481
  Validation Loss: 0.64458829164505
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.6710622012615204
  Validation Loss: 0.6442257165908813
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.6707937717437744
  Validation Loss: 0.643882155418396
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:00:INFO:
[92mINFO [0m:      Received: evaluate message 08d64600-3a0f-4a35-87aa-dca5188091f5
02/07/2025 22:54:00:INFO:Received: evaluate message 08d64600-3a0f-4a35-87aa-dca5188091f5
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6705185770988464
  Validation Loss: 0.6435260772705078
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6702715754508972
  Validation Loss: 0.6431300640106201
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 11/64:
  Train Loss: 0.6699836850166321
  Validation Loss: 0.6427745819091797
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.6697355806827545
  Validation Loss: 0.6424717903137207
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.669499009847641
  Validation Loss: 0.6421695947647095
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.6692797690629959
  Validation Loss: 0.6419007182121277
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.6690418422222137
  Validation Loss: 0.6415975689888
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6688393950462341
  Validation Loss: 0.6413683891296387
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.6686211079359055
  Validation Loss: 0.641142725944519
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.66844542324543
  Validation Loss: 0.6409434080123901
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6682679206132889
  Validation Loss: 0.6407310366630554
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6680649071931839
  Validation Loss: 0.6404743194580078
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6678600013256073
  Validation Loss: 0.6402408480644226
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.6676391065120697
  Validation Loss: 0.6399662494659424
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.6674322187900543
  Validation Loss: 0.6397290229797363
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.667236715555191
  Validation Loss: 0.6394708752632141
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6670412868261337
  Validation Loss: 0.6392475366592407
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6668752580881119
  Validation Loss: 0.6390587687492371
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6666955351829529
  Validation Loss: 0.6388572454452515
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6665332764387131
  Validation Loss: 0.6386770009994507
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6663887649774551
  Validation Loss: 0.6385304927825928
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6662207245826721
  Validation Loss: 0.6383757591247559
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6661051958799362
  Validation Loss: 0.6381837129592896
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6659869104623795
  Validation Loss: 0.6379985809326172
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 33/64:
  Train Loss: 0.6658538430929184
  Validation Loss: 0.6378014087677002
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 34/64:
  Train Loss: 0.665732279419899
  Validation Loss: 0.637607216835022
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 35/64:
  Train Loss: 0.6655629426240921
  Validation Loss: 0.6374263763427734
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 36/64:
  Train Loss: 0.6654439121484756
  Validation Loss: 0.6372405290603638
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 37/64:
  Train Loss: 0.6652964204549789
  Validation Loss: 0.6370762586593628
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 38/64:
  Train Loss: 0.6651864796876907
  Validation Loss: 0.6368991732597351
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 39/64:
  Train Loss: 0.6650436520576477
  Validation Loss: 0.6367089748382568
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 40/64:
  Train Loss: 0.6649023294448853
  Validation Loss: 0.6364972591400146
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 41/64:
  Train Loss: 0.6647519022226334
  Validation Loss: 0.6363495588302612
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 42/64:
  Train Loss: 0.6646397709846497
  Validation Loss: 0.6361917853355408
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 43/64:
  Train Loss: 0.664504736661911
  Validation Loss: 0.636027455329895
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 44/64:
  Train Loss: 0.6643905192613602
  Validation Loss: 0.6359024047851562
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 45/64:
  Train Loss: 0.6643246561288834
  Validation Loss: 0.6357472538948059
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 46/64:
  Train Loss: 0.6642194092273712
  Validation Loss: 0.635595440864563
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 47/64:
  Train Loss: 0.6641113460063934
  Validation Loss: 0.6354585886001587
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 48/64:
  Train Loss: 0.6640140414237976
  Validation Loss: 0.6353689432144165
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 49/64:
  Train Loss: 0.663916140794754
  Validation Loss: 0.6352480053901672
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 50/64:
  Train Loss: 0.6638126075267792
  Validation Loss: 0.635108470916748
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 51/64:
  Train Loss: 0.663662314414978
  Validation Loss: 0.634945809841156
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 52/64:
  Train Loss: 0.6635393798351288
  Validation Loss: 0.6348105669021606
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 53/64:
  Train Loss: 0.6634194850921631
  Validation Loss: 0.634710431098938
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 54/64:
  Train Loss: 0.6633512824773788
  Validation Loss: 0.6346054077148438
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 55/64:
  Train Loss: 0.6632485091686249
  Validation Loss: 0.6345329880714417
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 56/64:
  Train Loss: 0.6631578952074051
  Validation Loss: 0.6344200968742371
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 57/64:
  Train Loss: 0.6630444973707199
  Validation Loss: 0.634265124797821
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 58/64:
  Train Loss: 0.6629278063774109
  Validation Loss: 0.6341171264648438
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 59/64:
  Train Loss: 0.662842333316803
  Validation Loss: 0.6339698433876038
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 60/64:
  Train Loss: 0.6627288162708282
  Validation Loss: 0.6338492631912231
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 61/64:
  Train Loss: 0.6626379936933517
  Validation Loss: 0.6337451934814453
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 62/64:
  Train Loss: 0.6625718772411346
  Validation Loss: 0.6336594820022583
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 63/64:
  Train Loss: 0.6625038683414459
  Validation Loss: 0.6336003541946411
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 64/64:
  Train Loss: 0.6624162793159485
  Validation Loss: 0.6334950923919678
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
{'train_loss': 0.6624162793159485, 'val_roc_auc': 0.9285714285714286, 'val_accuracy': 0.875, 'val_loss': 0.6334950923919678}
 ROC_AUC: 0.9286|| Accuracy 0.8750 || Train Loss: 0.6624
 Val Loss: 0.6335 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6543741303567703
[92mINFO [0m:      Sent reply
02/07/2025 22:54:02:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:02:INFO:
[92mINFO [0m:      Received: train message 6243eb2a-b364-467b-847a-2c246b0ffedc
02/07/2025 22:54:02:INFO:Received: train message 6243eb2a-b364-467b-847a-2c246b0ffedc
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Test ROC-AUC: 0.8813244047619048
Test Accuracy: 0.7980769230769231
test_loss: 0.6543741303567703
test_roc_auc: 0.8813244047619048
test_accuracy: 0.7980769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.2057357353448121
Epoch 1/64:
  Train Loss: 0.6798458248376846
  Validation Loss: 0.6111848950386047
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6794398427009583
  Validation Loss: 0.610785961151123
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.679103434085846
  Validation Loss: 0.6104865074157715
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.6787130683660507
  Validation Loss: 0.6101643443107605
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6783882826566696
  Validation Loss: 0.6098449230194092
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.6781057268381119
  Validation Loss: 0.609615683555603
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6777979284524918
  Validation Loss: 0.6094015836715698
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6775936782360077
  Validation Loss: 0.6091514825820923
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6773310452699661
  Validation Loss: 0.6088101863861084
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6770655959844589
  Validation Loss: 0.60855633020401
  Val ROC-AUC: 0.9087301587301586
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6768493354320526
  Validation Loss: 0.6082621812820435
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6766084730625153
  Validation Loss: 0.6079912185668945
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6763347834348679
  Validation Loss: 0.6077278256416321
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.676089271903038
  Validation Loss: 0.6075369715690613
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6758546680212021
  Validation Loss: 0.607345461845398
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6756369173526764
  Validation Loss: 0.6071523427963257
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6754265129566193
  Validation Loss: 0.607028603553772
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6752320230007172
  Validation Loss: 0.6068825721740723
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6750339716672897
  Validation Loss: 0.6066563129425049
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6748222857713699
  Validation Loss: 0.6064786314964294
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6745809763669968
  Validation Loss: 0.6063027381896973
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6743825376033783
  Validation Loss: 0.6061476469039917
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.674173578619957
  Validation Loss: 0.6059894561767578
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6739644855260849
  Validation Loss: 0.6058699488639832
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.673777624964714
  Validation Loss: 0.6057904362678528
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6736078411340714
  Validation Loss: 0.6057159900665283
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6734579503536224
  Validation Loss: 0.6055667996406555
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6732757836580276
  Validation Loss: 0.6054674386978149
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6731691062450409
  Validation Loss: 0.6053822636604309
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6730371862649918
  Validation Loss: 0.6052429676055908
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6728850901126862
  Validation Loss: 0.6050888299942017
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6727586090564728
  Validation Loss: 0.6049078106880188
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6725930571556091
  Validation Loss: 0.6047772169113159
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6724593043327332
  Validation Loss: 0.6046056151390076
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6722953617572784
  Validation Loss: 0.6044409275054932
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6721568405628204
  Validation Loss: 0.6043218374252319
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6720139384269714
  Validation Loss: 0.6042188405990601
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6719064116477966
  Validation Loss: 0.604131817817688
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6718152463436127
  Validation Loss: 0.6040246486663818
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6717424839735031
  Validation Loss: 0.6039645671844482
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.671619638800621
  Validation Loss: 0.6039495468139648
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6715335696935654
  Validation Loss: 0.6038853526115417
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6714278161525726
  Validation Loss: 0.6037955284118652
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6712993383407593
  Validation Loss: 0.6037046909332275
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.6711883991956711
  Validation Loss: 0.6035974025726318
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6710911691188812
  Validation Loss: 0.6035299897193909
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6709997057914734
  Validation Loss: 0.6035283803939819
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6709203273057938
  Validation Loss: 0.6035349369049072
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6708539873361588
  Validation Loss: 0.6035284996032715
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6707727313041687
  Validation Loss: 0.6034454107284546
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6706905961036682
  Validation Loss: 0.6033761501312256
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6706394553184509
  Validation Loss: 0.6033577919006348
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6705850511789322
  Validation Loss: 0.603257417678833
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6705019176006317
  Validation Loss: 0.6031479835510254
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.670452207326889
  Validation Loss: 0.6030161380767822
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.6703842431306839
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:54:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:29:INFO:
[92mINFO [0m:      Received: evaluate message 70cbb98d-a0c3-4aa9-bba8-ab5c488f35c7
02/07/2025 22:54:29:INFO:Received: evaluate message 70cbb98d-a0c3-4aa9-bba8-ab5c488f35c7
[92mINFO [0m:      Sent reply
02/07/2025 22:54:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:30:INFO:
[92mINFO [0m:      Received: train message 44214762-bf66-468b-8206-a0f7c9bcea50
02/07/2025 22:54:30:INFO:Received: train message 44214762-bf66-468b-8206-a0f7c9bcea50
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6028962135314941
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.670325830578804
  Validation Loss: 0.6028057336807251
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.670276328921318
  Validation Loss: 0.6027112007141113
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6702514737844467
  Validation Loss: 0.6026762127876282
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.6701797097921371
  Validation Loss: 0.6026109457015991
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6701465249061584
  Validation Loss: 0.602568507194519
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6701200902462006
  Validation Loss: 0.6025009751319885
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6700546890497208
  Validation Loss: 0.6024487018585205
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6699764430522919
  Validation Loss: 0.6023920178413391
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
{'train_loss': 0.6699764430522919, 'val_roc_auc': 0.9206349206349207, 'val_accuracy': 0.84375, 'val_loss': 0.6023920178413391}
 ROC_AUC: 0.9206|| Accuracy 0.8438 || Train Loss: 0.6700
 Val Loss: 0.6024 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6527473634252181
Test ROC-AUC: 0.879092261904762
Test Accuracy: 0.7884615384615384
test_loss: 0.6527473634252181
test_roc_auc: 0.879092261904762
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.15979364454324244
Epoch 1/64:
  Train Loss: 0.6647283136844635
  Validation Loss: 0.6643251180648804
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 2/64:
  Train Loss: 0.6643880158662796
  Validation Loss: 0.6639887094497681
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 3/64:
  Train Loss: 0.6641046106815338
  Validation Loss: 0.6637395620346069
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 4/64:
  Train Loss: 0.6638002842664719
  Validation Loss: 0.6635096073150635
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 5/64:
  Train Loss: 0.6635332852602005
  Validation Loss: 0.6632768511772156
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 6/64:
  Train Loss: 0.6632581502199173
  Validation Loss: 0.6630327701568604
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 7/64:
  Train Loss: 0.6630549132823944
  Validation Loss: 0.6628062129020691
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 8/64:
  Train Loss: 0.6627880781888962
  Validation Loss: 0.6625988483428955
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 9/64:
  Train Loss: 0.6625270247459412
  Validation Loss: 0.6624037027359009
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 10/64:
  Train Loss: 0.6623002290725708
  Validation Loss: 0.6621816754341125
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 11/64:
  Train Loss: 0.6620540469884872
  Validation Loss: 0.6620149612426758
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 12/64:
  Train Loss: 0.6618633717298508
  Validation Loss: 0.6618446111679077
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 13/64:
  Train Loss: 0.6616335660219193
  Validation Loss: 0.6616668701171875
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 14/64:
  Train Loss: 0.6614519357681274
  Validation Loss: 0.6614726781845093
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 15/64:
  Train Loss: 0.661244124174118
  Validation Loss: 0.6612659692764282
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.90625
Epoch 16/64:
  Train Loss: 0.6610291004180908
  Validation Loss: 0.6610772013664246
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 17/64:
  Train Loss: 0.6608084142208099
  Validation Loss: 0.6609168648719788
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 18/64:
  Train Loss: 0.6606473028659821
  Validation Loss: 0.6607881784439087
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 19/64:
  Train Loss: 0.6604626029729843
  Validation Loss: 0.6606435775756836
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 20/64:
  Train Loss: 0.6602857112884521
  Validation Loss: 0.6605079174041748
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 21/64:
  Train Loss: 0.6601354628801346
  Validation Loss: 0.6603425741195679
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 22/64:
  Train Loss: 0.6599546074867249
  Validation Loss: 0.6601651906967163
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 23/64:
  Train Loss: 0.6597817838191986
  Validation Loss: 0.6600412130355835
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 24/64:
  Train Loss: 0.6596657931804657
  Validation Loss: 0.6599217653274536
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 25/64:
  Train Loss: 0.6595194041728973
  Validation Loss: 0.6598148941993713
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.875
Epoch 26/64:
  Train Loss: 0.6593989878892899
  Validation Loss: 0.6597152948379517
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 27/64:
  Train Loss: 0.6592694669961929
  Validation Loss: 0.6596492528915405
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 28/64:
  Train Loss: 0.6591383665800095
  Validation Loss: 0.6595632433891296
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 29/64:
  Train Loss: 0.6590189635753632
  Validation Loss: 0.6594818234443665
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 30/64:
  Train Loss: 0.6589210331439972
  Validation Loss: 0.6593949794769287
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 31/64:
  Train Loss: 0.6587717533111572
  Validation Loss: 0.6593047976493835
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 32/64:
  Train Loss: 0.6586657017469406
  Validation Loss: 0.6592731475830078
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 33/64:
  Train Loss: 0.6585542559623718
  Validation Loss: 0.6592162847518921
  Val ROC-AUC: 0.9554655870445343
  Val Accuracy: 0.875
Epoch 34/64:
  Train Loss: 0.6584672331809998
  Validation Loss: 0.6591660380363464
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 35/64:
  Train Loss: 0.6583642959594727
  Validation Loss: 0.6591031551361084
  Val ROC-AUC: 0.9635627530364372
  Val Accuracy: 0.875
Epoch 36/64:
  Train Loss: 0.6582531034946442
  Validation Loss: 0.6590200662612915
  Val ROC-AUC: 0.9635627530364372
  Val Accuracy: 0.875
Epoch 37/64:
  Train Loss: 0.6581351608037949
  Validation Loss: 0.6589412689208984
  Val ROC-AUC: 0.9635627530364372
  Val Accuracy: 0.875
Epoch 38/64:
  Train Loss: 0.658017709851265
  Validation Loss: 0.6588292121887207
  Val ROC-AUC: 0.9635627530364372
  Val Accuracy: 0.875
Epoch 39/64:
  Train Loss: 0.657902717590332
  Validation Loss: 0.6587424874305725
  Val ROC-AUC: 0.9635627530364372
  Val Accuracy: 0.875
Epoch 40/64:
  Train Loss: 0.657840296626091
  Validation Loss: 0.6586532592773438
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 41/64:
  Train Loss: 0.6577273458242416
  Validation Loss: 0.6586036682128906
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 42/64:
  Train Loss: 0.6576170921325684
  Validation Loss: 0.6585408449172974
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 43/64:
  Train Loss: 0.6575049757957458
  Validation Loss: 0.6584737300872803
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 44/64:
  Train Loss: 0.6574444323778152
  Validation Loss: 0.6584244966506958
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 45/64:
  Train Loss: 0.6573423445224762
  Validation Loss: 0.6583691835403442
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 46/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:54:54:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:57:INFO:
[92mINFO [0m:      Received: evaluate message 9bd6f028-21f8-4eea-9679-11800389c2ee
02/07/2025 22:54:57:INFO:Received: evaluate message 9bd6f028-21f8-4eea-9679-11800389c2ee
[92mINFO [0m:      Sent reply
02/07/2025 22:54:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:54:57:INFO:
[92mINFO [0m:      Received: train message 2cde0c22-4082-4bff-9ace-f46c1f95b1ae
02/07/2025 22:54:57:INFO:Received: train message 2cde0c22-4082-4bff-9ace-f46c1f95b1ae
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6572666317224503
  Validation Loss: 0.6583133935928345
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 47/64:
  Train Loss: 0.6571623235940933
  Validation Loss: 0.658271312713623
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 48/64:
  Train Loss: 0.6570724695920944
  Validation Loss: 0.6582289934158325
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 49/64:
  Train Loss: 0.6570007354021072
  Validation Loss: 0.6581684350967407
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 50/64:
  Train Loss: 0.656912699341774
  Validation Loss: 0.6580891013145447
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 51/64:
  Train Loss: 0.6568354368209839
  Validation Loss: 0.6580578088760376
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 52/64:
  Train Loss: 0.6567542105913162
  Validation Loss: 0.6580501198768616
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 53/64:
  Train Loss: 0.6566925048828125
  Validation Loss: 0.6580636501312256
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 54/64:
  Train Loss: 0.6566309630870819
  Validation Loss: 0.6580274701118469
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 55/64:
  Train Loss: 0.6565601527690887
  Validation Loss: 0.658005952835083
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 56/64:
  Train Loss: 0.6564939916133881
  Validation Loss: 0.6579844951629639
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 57/64:
  Train Loss: 0.6564604490995407
  Validation Loss: 0.6579703688621521
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 58/64:
  Train Loss: 0.6564046293497086
  Validation Loss: 0.6579570174217224
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 59/64:
  Train Loss: 0.6563509851694107
  Validation Loss: 0.6579221487045288
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 60/64:
  Train Loss: 0.656290665268898
  Validation Loss: 0.6578606367111206
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 61/64:
  Train Loss: 0.6562265306711197
  Validation Loss: 0.6578153371810913
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 62/64:
  Train Loss: 0.656163215637207
  Validation Loss: 0.6578112840652466
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 63/64:
  Train Loss: 0.6561447381973267
  Validation Loss: 0.6578047275543213
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 64/64:
  Train Loss: 0.6560928523540497
  Validation Loss: 0.6577644944190979
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.90625
{'train_loss': 0.6560928523540497, 'val_roc_auc': 0.9595141700404859, 'val_accuracy': 0.90625, 'val_loss': 0.6577644944190979}
 ROC_AUC: 0.9595|| Accuracy 0.9062 || Train Loss: 0.6561
 Val Loss: 0.6578 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6514472373976157
Test ROC-AUC: 0.8783482142857143
Test Accuracy: 0.7884615384615384
test_loss: 0.6514472373976157
test_roc_auc: 0.8783482142857143
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.1364473522571643
Epoch 1/64:
  Train Loss: 0.6640547066926956
  Validation Loss: 0.6602615118026733
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 2/64:
  Train Loss: 0.663693979382515
  Validation Loss: 0.6602413654327393
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 3/64:
  Train Loss: 0.6634147614240646
  Validation Loss: 0.6601972579956055
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 4/64:
  Train Loss: 0.6630826592445374
  Validation Loss: 0.6601355671882629
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 5/64:
  Train Loss: 0.6628221273422241
  Validation Loss: 0.6600939631462097
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 6/64:
  Train Loss: 0.6625581234693527
  Validation Loss: 0.6600246429443359
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 7/64:
  Train Loss: 0.6622699052095413
  Validation Loss: 0.6600008010864258
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 8/64:
  Train Loss: 0.6620171815156937
  Validation Loss: 0.6599730849266052
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.875
Epoch 9/64:
  Train Loss: 0.661750003695488
  Validation Loss: 0.6599280834197998
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6614836901426315
  Validation Loss: 0.6598806381225586
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6612374186515808
  Validation Loss: 0.6598682999610901
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6609834879636765
  Validation Loss: 0.6598575711250305
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6607574224472046
  Validation Loss: 0.65985506772995
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6605696529150009
  Validation Loss: 0.6598852872848511
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6603487282991409
  Validation Loss: 0.6598587036132812
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.660117968916893
  Validation Loss: 0.6598432660102844
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6599555164575577
  Validation Loss: 0.6598273515701294
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.659735381603241
  Validation Loss: 0.6598114967346191
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6594962179660797
  Validation Loss: 0.6597946286201477
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.659328043460846
  Validation Loss: 0.6597775816917419
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6591269075870514
  Validation Loss: 0.6597763895988464
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6589263677597046
  Validation Loss: 0.6598201990127563
  Val ROC-AUC: 0.9554655870445344
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.658758819103241
  Validation Loss: 0.6598533391952515
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6585949063301086
  Validation Loss: 0.6598869562149048
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6584094315767288
  Validation Loss: 0.6599122285842896
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6582376062870026
  Validation Loss: 0.6599013805389404
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.658064991235733
  Validation Loss: 0.6599283814430237
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6579256653785706
  Validation Loss: 0.6599576473236084
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6577647775411606
  Validation Loss: 0.6600120067596436
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6576268672943115
  Validation Loss: 0.6600804924964905
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6574992537498474
  Validation Loss: 0.6601114273071289
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6573526561260223
  Validation Loss: 0.6601443290710449
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6572407782077789
  Validation Loss: 0.6601861715316772
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6570920646190643
  Validation Loss: 0.6602298021316528
  Val ROC-AUC: 0.951417004048583
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6569491326808929
  Validation Loss: 0.6602327823638916
  Val ROC-AUC: 0.9473684210526315
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:55:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:23:INFO:
[92mINFO [0m:      Received: evaluate message b0151c7a-d5b1-4682-8485-cefeb215d5fd
02/07/2025 22:55:23:INFO:Received: evaluate message b0151c7a-d5b1-4682-8485-cefeb215d5fd
[92mINFO [0m:      Sent reply
02/07/2025 22:55:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:23:INFO:
[92mINFO [0m:      Received: train message d9a6791f-b020-4cdb-a7fa-592b5c3471a8
02/07/2025 22:55:23:INFO:Received: train message d9a6791f-b020-4cdb-a7fa-592b5c3471a8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6567894965410233
  Validation Loss: 0.6602591276168823
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6566903442144394
  Validation Loss: 0.6602815389633179
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6565313041210175
  Validation Loss: 0.6603165864944458
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6564119905233383
  Validation Loss: 0.6603460907936096
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.6562611311674118
  Validation Loss: 0.6603790521621704
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6561212837696075
  Validation Loss: 0.6604230403900146
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.65601547062397
  Validation Loss: 0.6604349613189697
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6558509469032288
  Validation Loss: 0.6604831218719482
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.655737891793251
  Validation Loss: 0.6605513095855713
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6556415408849716
  Validation Loss: 0.6606141328811646
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6555339992046356
  Validation Loss: 0.6606861352920532
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6554391831159592
  Validation Loss: 0.6607695817947388
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6553821265697479
  Validation Loss: 0.660895586013794
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6553031653165817
  Validation Loss: 0.6609870791435242
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.6552223116159439
  Validation Loss: 0.6610636711120605
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.6551289856433868
  Validation Loss: 0.6611183881759644
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6550409942865372
  Validation Loss: 0.6611859202384949
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6549696028232574
  Validation Loss: 0.6612581014633179
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6548814624547958
  Validation Loss: 0.661310076713562
  Val ROC-AUC: 0.9473684210526315
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6547842621803284
  Validation Loss: 0.6613515615463257
  Val ROC-AUC: 0.9392712550607288
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6546903103590012
  Validation Loss: 0.6613857746124268
  Val ROC-AUC: 0.9392712550607288
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6546055376529694
  Validation Loss: 0.6613900661468506
  Val ROC-AUC: 0.9392712550607288
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.6545140445232391
  Validation Loss: 0.6614291667938232
  Val ROC-AUC: 0.9352226720647774
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6544379144906998
  Validation Loss: 0.6614716053009033
  Val ROC-AUC: 0.9352226720647774
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6543642282485962
  Validation Loss: 0.6615117192268372
  Val ROC-AUC: 0.9352226720647774
  Val Accuracy: 0.8125
Epoch 61/64:
  Train Loss: 0.6543021500110626
  Validation Loss: 0.6615782976150513
  Val ROC-AUC: 0.9352226720647774
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6542284041643143
  Validation Loss: 0.6616557836532593
  Val ROC-AUC: 0.9352226720647774
  Val Accuracy: 0.8125
Epoch 63/64:
  Train Loss: 0.6541774421930313
  Validation Loss: 0.6617141366004944
  Val ROC-AUC: 0.9352226720647774
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6541117429733276
  Validation Loss: 0.6617425680160522
  Val ROC-AUC: 0.9352226720647774
  Val Accuracy: 0.8125
{'train_loss': 0.6541117429733276, 'val_roc_auc': 0.9352226720647774, 'val_accuracy': 0.8125, 'val_loss': 0.6617425680160522}
 ROC_AUC: 0.9352|| Accuracy 0.8125 || Train Loss: 0.6541
 Val Loss: 0.6617 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6504192730555167
Test ROC-AUC: 0.8761160714285714
Test Accuracy: 0.7692307692307693
test_loss: 0.6504192730555167
test_roc_auc: 0.8761160714285714
test_accuracy: 0.7692307692307693
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.13926707872694047
Epoch 1/64:
  Train Loss: 0.6657916158437729
  Validation Loss: 0.6475040316581726
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 2/64:
  Train Loss: 0.6654418706893921
  Validation Loss: 0.6472752094268799
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 3/64:
  Train Loss: 0.6651850938796997
  Validation Loss: 0.6470156908035278
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 4/64:
  Train Loss: 0.664864256978035
  Validation Loss: 0.6467640995979309
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 5/64:
  Train Loss: 0.6646046936511993
  Validation Loss: 0.6465473175048828
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 6/64:
  Train Loss: 0.6643698513507843
  Validation Loss: 0.6463128924369812
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.6641215682029724
  Validation Loss: 0.6460764408111572
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.6875
Epoch 8/64:
  Train Loss: 0.6638602167367935
  Validation Loss: 0.6458631753921509
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.6875
Epoch 9/64:
  Train Loss: 0.6636110544204712
  Validation Loss: 0.6456785202026367
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.6875
Epoch 10/64:
  Train Loss: 0.6633801460266113
  Validation Loss: 0.6454960107803345
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.6875
Epoch 11/64:
  Train Loss: 0.6631594598293304
  Validation Loss: 0.6453099846839905
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.6875
Epoch 12/64:
  Train Loss: 0.6629210114479065
  Validation Loss: 0.6451423764228821
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6627086699008942
  Validation Loss: 0.6449615955352783
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6624798774719238
  Validation Loss: 0.6447970867156982
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6622932255268097
  Validation Loss: 0.6446149349212646
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6621249914169312
  Validation Loss: 0.6444408893585205
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6619383096694946
  Validation Loss: 0.6442681550979614
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6617227494716644
  Validation Loss: 0.6441004276275635
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6615689694881439
  Validation Loss: 0.6439619064331055
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6613568067550659
  Validation Loss: 0.6437978744506836
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6611731201410294
  Validation Loss: 0.6436299681663513
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6609834879636765
  Validation Loss: 0.6434610486030579
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6607856601476669
  Validation Loss: 0.6433029174804688
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6606198698282242
  Validation Loss: 0.6431219577789307
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6604347974061966
  Validation Loss: 0.6429805755615234
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.660300076007843
  Validation Loss: 0.6428279876708984
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.71875
Epoch 27/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:55:49:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:50:INFO:
[92mINFO [0m:      Received: evaluate message 8c7f1348-63a5-4a14-9743-caa8905e191e
02/07/2025 22:55:50:INFO:Received: evaluate message 8c7f1348-63a5-4a14-9743-caa8905e191e
[92mINFO [0m:      Sent reply
02/07/2025 22:55:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:55:51:INFO:
[92mINFO [0m:      Received: train message 3d79c822-7747-43a6-ac02-9fa544d2aa77
02/07/2025 22:55:51:INFO:Received: train message 3d79c822-7747-43a6-ac02-9fa544d2aa77
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6601140052080154
  Validation Loss: 0.6426887512207031
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.659956619143486
  Validation Loss: 0.64256352186203
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6598454862833023
  Validation Loss: 0.6424282789230347
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.659739077091217
  Validation Loss: 0.6423263549804688
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6596143841743469
  Validation Loss: 0.642192006111145
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6594775319099426
  Validation Loss: 0.6420835852622986
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6593622118234634
  Validation Loss: 0.641960620880127
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6592428088188171
  Validation Loss: 0.6418600082397461
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6591338217258453
  Validation Loss: 0.6417430639266968
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6590281873941422
  Validation Loss: 0.6416492462158203
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6589257121086121
  Validation Loss: 0.641584038734436
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6588404476642609
  Validation Loss: 0.6415069103240967
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6587361395359039
  Validation Loss: 0.6414263248443604
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.65864397585392
  Validation Loss: 0.6413589715957642
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6585743129253387
  Validation Loss: 0.6412642002105713
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6584827601909637
  Validation Loss: 0.6411939859390259
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6584077775478363
  Validation Loss: 0.6411057710647583
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.658320739865303
  Validation Loss: 0.6410204172134399
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.658237099647522
  Validation Loss: 0.6409428715705872
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6581410765647888
  Validation Loss: 0.6408852338790894
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6580539643764496
  Validation Loss: 0.6408060193061829
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6579833626747131
  Validation Loss: 0.6407321691513062
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6579277813434601
  Validation Loss: 0.64063960313797
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6578522026538849
  Validation Loss: 0.6405575275421143
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6577911972999573
  Validation Loss: 0.6404551267623901
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6577118933200836
  Validation Loss: 0.6403775811195374
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6576444506645203
  Validation Loss: 0.6402995586395264
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6575891822576523
  Validation Loss: 0.640209436416626
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.6575095653533936
  Validation Loss: 0.6401124596595764
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.6574424356222153
  Validation Loss: 0.6400377750396729
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6574049443006516
  Validation Loss: 0.6399956345558167
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.657377302646637
  Validation Loss: 0.6399427652359009
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.6573511213064194
  Validation Loss: 0.6398653984069824
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.6573011130094528
  Validation Loss: 0.639826238155365
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6572507470846176
  Validation Loss: 0.6397851705551147
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6571977883577347
  Validation Loss: 0.6397199630737305
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6571506559848785
  Validation Loss: 0.6396794319152832
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6571052372455597
  Validation Loss: 0.6396278738975525
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.71875
{'train_loss': 0.6571052372455597, 'val_roc_auc': 0.859375, 'val_accuracy': 0.71875, 'val_loss': 0.6396278738975525}
 ROC_AUC: 0.8594|| Accuracy 0.7188 || Train Loss: 0.6571
 Val Loss: 0.6396 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6495760791003704
Test ROC-AUC: 0.8746279761904763
Test Accuracy: 0.7788461538461539
test_loss: 0.6495760791003704
test_roc_auc: 0.8746279761904763
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.09644435178536999
Epoch 1/64:
  Train Loss: 0.6635748594999313
  Validation Loss: 0.6514049768447876
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6632312089204788
  Validation Loss: 0.6512749195098877
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6629287749528885
  Validation Loss: 0.6511211395263672
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6626413911581039
  Validation Loss: 0.6510367393493652
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6623199135065079
  Validation Loss: 0.6509641408920288
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.6620464473962784
  Validation Loss: 0.6508961915969849
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.71875
Epoch 7/64:
  Train Loss: 0.6617832779884338
  Validation Loss: 0.6507879495620728
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.6615039855241776
  Validation Loss: 0.650696337223053
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.6612508893013
  Validation Loss: 0.6506686806678772
  Val ROC-AUC: 0.9007936507936509
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.6610260158777237
  Validation Loss: 0.6505917906761169
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6607671529054642
  Validation Loss: 0.6505410671234131
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.6605455577373505
  Validation Loss: 0.6504970192909241
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6602981984615326
  Validation Loss: 0.6504873633384705
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6601061969995499
  Validation Loss: 0.6504833698272705
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6599000096321106
  Validation Loss: 0.6504665613174438
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6597072035074234
  Validation Loss: 0.6504585146903992
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6595097482204437
  Validation Loss: 0.6504606008529663
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6593350172042847
  Validation Loss: 0.6504645347595215
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.71875
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:56:16:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:17:INFO:
[92mINFO [0m:      Received: evaluate message 701fbc52-7e78-4fc2-a7fb-b754263c7462
02/07/2025 22:56:17:INFO:Received: evaluate message 701fbc52-7e78-4fc2-a7fb-b754263c7462
[92mINFO [0m:      Sent reply
02/07/2025 22:56:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:19:INFO:
[92mINFO [0m:      Received: train message 43586ad1-962a-4340-aeb1-5ee51e301119
02/07/2025 22:56:19:INFO:Received: train message 43586ad1-962a-4340-aeb1-5ee51e301119
Epoch 19/64:
  Train Loss: 0.6591587215662003
  Validation Loss: 0.6504785418510437
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6589933931827545
  Validation Loss: 0.6504977941513062
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.658831462264061
  Validation Loss: 0.6505175828933716
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6586944162845612
  Validation Loss: 0.6505405902862549
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.658522218465805
  Validation Loss: 0.6505177021026611
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6583627164363861
  Validation Loss: 0.6505128741264343
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6582038700580597
  Validation Loss: 0.6505404710769653
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6580612808465958
  Validation Loss: 0.6505402326583862
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.657927542924881
  Validation Loss: 0.6505444049835205
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6577649116516113
  Validation Loss: 0.6505649089813232
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6576303243637085
  Validation Loss: 0.6505619287490845
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.6574879288673401
  Validation Loss: 0.6505721807479858
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6573481410741806
  Validation Loss: 0.6506005525588989
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6572355926036835
  Validation Loss: 0.6506055593490601
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.65708988904953
  Validation Loss: 0.6506013870239258
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6569629013538361
  Validation Loss: 0.6506194472312927
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6568537205457687
  Validation Loss: 0.6506301164627075
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6567404419183731
  Validation Loss: 0.6506754755973816
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.65663743019104
  Validation Loss: 0.6506909132003784
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6565281897783279
  Validation Loss: 0.6507203578948975
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6564286798238754
  Validation Loss: 0.6507464647293091
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6563337743282318
  Validation Loss: 0.6507925987243652
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.65621517598629
  Validation Loss: 0.6508224010467529
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6561226397752762
  Validation Loss: 0.6508357524871826
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6560362577438354
  Validation Loss: 0.6509005427360535
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6559421867132187
  Validation Loss: 0.6509438753128052
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6558642238378525
  Validation Loss: 0.6509935855865479
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6558082699775696
  Validation Loss: 0.6510379314422607
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6557430177927017
  Validation Loss: 0.6510562896728516
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6556654423475266
  Validation Loss: 0.6510690450668335
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6555690616369247
  Validation Loss: 0.6511075496673584
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6554960012435913
  Validation Loss: 0.6511527299880981
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6554268896579742
  Validation Loss: 0.6511976718902588
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6553460508584976
  Validation Loss: 0.6512237191200256
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6552638113498688
  Validation Loss: 0.6512616872787476
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6551857590675354
  Validation Loss: 0.6513046026229858
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6551216095685959
  Validation Loss: 0.6513466835021973
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6550572365522385
  Validation Loss: 0.6513667702674866
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6550066769123077
  Validation Loss: 0.6514277458190918
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6549427062273026
  Validation Loss: 0.6514475345611572
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6548904776573181
  Validation Loss: 0.6514519453048706
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6548059731721878
  Validation Loss: 0.6514806747436523
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6547626703977585
  Validation Loss: 0.6515313982963562
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6547349989414215
  Validation Loss: 0.651587188243866
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6547031104564667
  Validation Loss: 0.6516361236572266
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6546599268913269
  Validation Loss: 0.6516333222389221
  Val ROC-AUC: 0.884920634920635
  Val Accuracy: 0.75
{'train_loss': 0.6546599268913269, 'val_roc_auc': 0.884920634920635, 'val_accuracy': 0.75, 'val_loss': 0.6516333222389221}
 ROC_AUC: 0.8849|| Accuracy 0.7500 || Train Loss: 0.6547
 Val Loss: 0.6516 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6489391114849311
Test ROC-AUC: 0.8731398809523809
Test Accuracy: 0.7788461538461539
test_loss: 0.6489391114849311
test_roc_auc: 0.8731398809523809
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.0939262122483342
Epoch 1/64:
  Train Loss: 0.6622895896434784
  Validation Loss: 0.6526271104812622
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6620164066553116
  Validation Loss: 0.6525251269340515
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6617703139781952
  Validation Loss: 0.6524064540863037
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6615750640630722
  Validation Loss: 0.6522924900054932
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6613862663507462
  Validation Loss: 0.6521438360214233
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.6611518412828445
  Validation Loss: 0.6520378589630127
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 7/64:
  Train Loss: 0.6609190553426743
  Validation Loss: 0.6519275903701782
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 8/64:
  Train Loss: 0.6607228070497513
  Validation Loss: 0.6518257856369019
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 9/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:56:46:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:47:INFO:
[92mINFO [0m:      Received: evaluate message 98d6cf32-6e67-43d7-93d6-04875b0ed83e
02/07/2025 22:56:47:INFO:Received: evaluate message 98d6cf32-6e67-43d7-93d6-04875b0ed83e
  Train Loss: 0.6605232208967209
  Validation Loss: 0.6517399549484253
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 10/64:
  Train Loss: 0.6603376716375351
  Validation Loss: 0.6516449451446533
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 11/64:
  Train Loss: 0.6601830273866653
  Validation Loss: 0.6515446901321411
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 12/64:
  Train Loss: 0.6599730849266052
  Validation Loss: 0.6514556407928467
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 13/64:
  Train Loss: 0.6597778350114822
  Validation Loss: 0.6513752937316895
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 14/64:
  Train Loss: 0.6596189141273499
  Validation Loss: 0.6513084769248962
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 15/64:
  Train Loss: 0.6594594717025757
  Validation Loss: 0.6512478590011597
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 16/64:
  Train Loss: 0.6592842787504196
  Validation Loss: 0.6511766314506531
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 17/64:
  Train Loss: 0.6591423600912094
  Validation Loss: 0.6510984301567078
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 18/64:
  Train Loss: 0.6590057760477066
  Validation Loss: 0.6510210037231445
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 19/64:
  Train Loss: 0.6588767170906067
  Validation Loss: 0.6509487628936768
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 20/64:
  Train Loss: 0.6587297022342682
  Validation Loss: 0.6508892774581909
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 21/64:
  Train Loss: 0.6585849970579147
  Validation Loss: 0.6508693099021912
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 22/64:
  Train Loss: 0.65846948325634
  Validation Loss: 0.6508063673973083
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 23/64:
  Train Loss: 0.6583492904901505
  Validation Loss: 0.6507430672645569
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 24/64:
  Train Loss: 0.6582255065441132
  Validation Loss: 0.650641679763794
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 25/64:
  Train Loss: 0.6580915749073029
  Validation Loss: 0.6505851745605469
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 26/64:
  Train Loss: 0.6579875648021698
  Validation Loss: 0.6505369544029236
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 27/64:
  Train Loss: 0.6578888446092606
  Validation Loss: 0.6505091190338135
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 28/64:
  Train Loss: 0.657808393239975
  Validation Loss: 0.6504743695259094
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 29/64:
  Train Loss: 0.6577241271734238
  Validation Loss: 0.650429368019104
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 30/64:
  Train Loss: 0.6576420366764069
  Validation Loss: 0.6503815650939941
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 31/64:
  Train Loss: 0.6575450152158737
  Validation Loss: 0.6503601670265198
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 32/64:
  Train Loss: 0.6574660539627075
  Validation Loss: 0.6503498554229736
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 33/64:
  Train Loss: 0.657405212521553
  Validation Loss: 0.6503203511238098
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 34/64:
  Train Loss: 0.6573067307472229
  Validation Loss: 0.6503012180328369
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6572563350200653
  Validation Loss: 0.650254487991333
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6571759730577469
  Validation Loss: 0.6502500176429749
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6571217477321625
  Validation Loss: 0.6502252817153931
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6570454686880112
  Validation Loss: 0.6501846313476562
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6569880694150925
  Validation Loss: 0.6501456499099731
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.6569211781024933
  Validation Loss: 0.6501071453094482
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6568511873483658
  Validation Loss: 0.6500593423843384
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6567977964878082
  Validation Loss: 0.6500366926193237
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6567431092262268
  Validation Loss: 0.6500234603881836
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.6567080020904541
  Validation Loss: 0.650046706199646
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6566753834486008
  Validation Loss: 0.6500465869903564
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6566342413425446
  Validation Loss: 0.6500592231750488
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6565721333026886
  Validation Loss: 0.6500364542007446
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6565374284982681
  Validation Loss: 0.650024950504303
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6564811766147614
  Validation Loss: 0.6499983668327332
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.6564453393220901
  Validation Loss: 0.6499801278114319
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.6564062386751175
  Validation Loss: 0.6499705910682678
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6563648283481598
  Validation Loss: 0.649957001209259
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6563124358654022
  Validation Loss: 0.6499238610267639
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6562585085630417
  Validation Loss: 0.6498966813087463
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6562378406524658
  Validation Loss: 0.6499062776565552
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6562113761901855
  Validation Loss: 0.6498846411705017
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6561845242977142
  Validation Loss: 0.6498602628707886
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.6561393439769745
  Validation Loss: 0.6498394012451172
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6560943573713303
  Validation Loss: 0.6498395204544067
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6560725420713425
  Validation Loss: 0.6498423218727112
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 61/64:
  Train Loss: 0.656032532453537
  Validation Loss: 0.6498473286628723
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6559853255748749
  Validation Loss: 0.6497828960418701
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 63/64:
  Train Loss: 0.6559370905160904
  Validation Loss: 0.649763286113739
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6558965146541595
  Validation Loss: 0.6496965289115906
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
{'train_loss': 0.6558965146541595, 'val_roc_auc': 0.9047619047619048, 'val_accuracy': 0.8125, 'val_loss': 0.6496965289115906}
 ROC_AUC: 0.9048|| Accuracy 0.8125 || Train Loss: 0.6559
 Val Loss: 0.6497 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6484244548930571
Test ROC-AUC: [92mINFO [0m:      Sent reply
02/07/2025 22:56:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:56:47:INFO:
[92mINFO [0m:      Received: train message 01369e49-591a-4064-8e69-ce5cb9896949
02/07/2025 22:56:47:INFO:Received: train message 01369e49-591a-4064-8e69-ce5cb9896949
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
0.8705357142857142
Test Accuracy: 0.7788461538461539
test_loss: 0.6484244548930571
test_roc_auc: 0.8705357142857142
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.07066709011572433
Epoch 1/64:
  Train Loss: 0.6579702496528625
  Validation Loss: 0.6653144359588623
  Val ROC-AUC: 0.78515625
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.6577594876289368
  Validation Loss: 0.665115475654602
  Val ROC-AUC: 0.78515625
  Val Accuracy: 0.71875
Epoch 3/64:
  Train Loss: 0.6575053334236145
  Validation Loss: 0.6649278402328491
  Val ROC-AUC: 0.7890625
  Val Accuracy: 0.71875
Epoch 4/64:
  Train Loss: 0.6572784334421158
  Validation Loss: 0.6646996736526489
  Val ROC-AUC: 0.7890625
  Val Accuracy: 0.71875
Epoch 5/64:
  Train Loss: 0.6570320874452591
  Validation Loss: 0.6644776463508606
  Val ROC-AUC: 0.7890625
  Val Accuracy: 0.71875
Epoch 6/64:
  Train Loss: 0.6567862778902054
  Validation Loss: 0.6643043756484985
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 7/64:
  Train Loss: 0.6565479040145874
  Validation Loss: 0.6641197800636292
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.6562978327274323
  Validation Loss: 0.6638984084129333
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.656089648604393
  Validation Loss: 0.6636955738067627
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.6558787673711777
  Validation Loss: 0.6635101437568665
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6556774973869324
  Validation Loss: 0.6633449196815491
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.6554888933897018
  Validation Loss: 0.6632075905799866
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6553014069795609
  Validation Loss: 0.6630419492721558
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.655120000243187
  Validation Loss: 0.6628952026367188
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6549766957759857
  Validation Loss: 0.6627607345581055
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6548056751489639
  Validation Loss: 0.6626650094985962
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6546580344438553
  Validation Loss: 0.6625317335128784
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6545134335756302
  Validation Loss: 0.6624285578727722
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6543803811073303
  Validation Loss: 0.6623244285583496
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.654249295592308
  Validation Loss: 0.66219562292099
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.654101088643074
  Validation Loss: 0.6621149182319641
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.653998389840126
  Validation Loss: 0.6619518995285034
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6538523137569427
  Validation Loss: 0.6618448495864868
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6537223756313324
  Validation Loss: 0.6617273092269897
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6535994708538055
  Validation Loss: 0.6616482734680176
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.653496190905571
  Validation Loss: 0.6615433692932129
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6533819884061813
  Validation Loss: 0.6614569425582886
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6532776802778244
  Validation Loss: 0.6613689064979553
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6532035917043686
  Validation Loss: 0.6612821817398071
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6530928313732147
  Validation Loss: 0.6611950397491455
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6530248522758484
  Validation Loss: 0.6611067056655884
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6529400646686554
  Validation Loss: 0.6610749959945679
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6528656780719757
  Validation Loss: 0.6610114574432373
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6527827978134155
  Validation Loss: 0.6609776020050049
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.6527198404073715
  Validation Loss: 0.6609312295913696
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.6526612937450409
  Validation Loss: 0.6608791947364807
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.652635008096695
  Validation Loss: 0.6608186960220337
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6525472700595856
  Validation Loss: 0.6607943773269653
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6524975150823593
  Validation Loss: 0.6607397794723511
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6524286270141602
  Validation Loss: 0.6607158184051514
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6523793488740921
  Validation Loss: 0.6606519222259521
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6523050367832184
  Validation Loss: 0.6606042385101318
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6522493958473206
  Validation Loss: 0.6605280637741089
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6521744430065155
  Validation Loss: 0.6604650020599365
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6520964652299881
  Validation Loss: 0.6603914499282837
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6520671397447586
  Validation Loss: 0.6603858470916748
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.652031660079956
  Validation Loss: 0.660362958908081
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6519751995801926
  Validation Loss: 0.6603217720985413
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6519245952367783
  Validation Loss: 0.6602824926376343
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6518845558166504
  Validation Loss: 0.6602171063423157
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6518418490886688
  Validation Loss: 0.6602057218551636
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6518082320690155
  Validation Loss: 0.6601986289024353
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6517898589372635
  Validation Loss: 0.660172164440155
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.6517461240291595
  Validation Loss: 0.6601084470748901
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6517155021429062
  Validation Loss: 0.6600560545921326
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.6516775190830231
  Validation Loss: 0.6600309610366821
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6516523063182831
  Validation Loss: 0.6600319147109985
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6516372263431549
  Validation Loss: 0.6599878668785095
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6516162306070328
  Validation Loss: 0.6599686145782471
  Val ROC-AUC: 0.8046875
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6515848636627197
  Validation Loss: 0.6599545478820801
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:57:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:08:INFO:
[92mINFO [0m:      Received: evaluate message 7572c7a1-8327-4de5-8771-2d07c5eff0fa
02/07/2025 22:57:08:INFO:Received: evaluate message 7572c7a1-8327-4de5-8771-2d07c5eff0fa
[92mINFO [0m:      Sent reply
02/07/2025 22:57:10:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:10:INFO:
[92mINFO [0m:      Received: train message 1ba03018-f13e-48a6-8157-c401a67327b0
02/07/2025 22:57:10:INFO:Received: train message 1ba03018-f13e-48a6-8157-c401a67327b0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6515527665615082
  Validation Loss: 0.6599099636077881
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6515373289585114
  Validation Loss: 0.659915566444397
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6515167653560638
  Validation Loss: 0.6599056720733643
  Val ROC-AUC: 0.80859375
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6515002101659775
  Validation Loss: 0.6599000692367554
  Val ROC-AUC: 0.8125
  Val Accuracy: 0.78125
{'train_loss': 0.6515002101659775, 'val_roc_auc': 0.8125, 'val_accuracy': 0.78125, 'val_loss': 0.6599000692367554}
 ROC_AUC: 0.8125|| Accuracy 0.7812 || Train Loss: 0.6515
 Val Loss: 0.6599 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6479897911732013
Test ROC-AUC: 0.8683035714285714
Test Accuracy: 0.7788461538461539
test_loss: 0.6479897911732013
test_roc_auc: 0.8683035714285714
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.05731481072628716
Epoch 1/64:
  Train Loss: 0.6635734140872955
  Validation Loss: 0.6398148536682129
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6633332818746567
  Validation Loss: 0.640041708946228
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6631055176258087
  Validation Loss: 0.6402799487113953
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6628032773733139
  Validation Loss: 0.6404590606689453
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6625416129827499
  Validation Loss: 0.6406996846199036
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.662295788526535
  Validation Loss: 0.6409425139427185
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.78125
Epoch 7/64:
  Train Loss: 0.6620375514030457
  Validation Loss: 0.6411734819412231
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.78125
Epoch 8/64:
  Train Loss: 0.6618035435676575
  Validation Loss: 0.6414014101028442
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 9/64:
  Train Loss: 0.6615575850009918
  Validation Loss: 0.6416351199150085
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 10/64:
  Train Loss: 0.6613215804100037
  Validation Loss: 0.6418603658676147
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 11/64:
  Train Loss: 0.6611123979091644
  Validation Loss: 0.6420900821685791
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 12/64:
  Train Loss: 0.6608849614858627
  Validation Loss: 0.6422958374023438
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 13/64:
  Train Loss: 0.6606376469135284
  Validation Loss: 0.6424996852874756
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 14/64:
  Train Loss: 0.660416379570961
  Validation Loss: 0.6427451372146606
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 15/64:
  Train Loss: 0.6602222174406052
  Validation Loss: 0.6429658532142639
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 16/64:
  Train Loss: 0.6599986702203751
  Validation Loss: 0.6431661248207092
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.78125
Epoch 17/64:
  Train Loss: 0.6597793698310852
  Validation Loss: 0.6433692574501038
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.78125
Epoch 18/64:
  Train Loss: 0.659617155790329
  Validation Loss: 0.6436203718185425
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.78125
Epoch 19/64:
  Train Loss: 0.6594370156526566
  Validation Loss: 0.643791675567627
  Val ROC-AUC: 0.9137254901960784
  Val Accuracy: 0.78125
Epoch 20/64:
  Train Loss: 0.6592521518468857
  Validation Loss: 0.6439989805221558
  Val ROC-AUC: 0.9137254901960784
  Val Accuracy: 0.78125
Epoch 21/64:
  Train Loss: 0.659049466252327
  Validation Loss: 0.644203782081604
  Val ROC-AUC: 0.9137254901960784
  Val Accuracy: 0.78125
Epoch 22/64:
  Train Loss: 0.6588896661996841
  Validation Loss: 0.6444275379180908
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 23/64:
  Train Loss: 0.6586985737085342
  Validation Loss: 0.6446155309677124
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 24/64:
  Train Loss: 0.6585388332605362
  Validation Loss: 0.6448169350624084
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 25/64:
  Train Loss: 0.6583725959062576
  Validation Loss: 0.6450216770172119
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.78125
Epoch 26/64:
  Train Loss: 0.6582181751728058
  Validation Loss: 0.6452146768569946
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.78125
Epoch 27/64:
  Train Loss: 0.6580429673194885
  Validation Loss: 0.6453802585601807
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.78125
Epoch 28/64:
  Train Loss: 0.6579080820083618
  Validation Loss: 0.6455490589141846
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.78125
Epoch 29/64:
  Train Loss: 0.6577782928943634
  Validation Loss: 0.6457576751708984
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.78125
Epoch 30/64:
  Train Loss: 0.6576397567987442
  Validation Loss: 0.6459789872169495
  Val ROC-AUC: 0.8980392156862745
  Val Accuracy: 0.78125
Epoch 31/64:
  Train Loss: 0.6574659049510956
  Validation Loss: 0.6461328864097595
  Val ROC-AUC: 0.8980392156862745
  Val Accuracy: 0.78125
Epoch 32/64:
  Train Loss: 0.657333254814148
  Validation Loss: 0.6462924480438232
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.78125
Epoch 33/64:
  Train Loss: 0.6572030186653137
  Validation Loss: 0.6464585065841675
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.78125
Epoch 34/64:
  Train Loss: 0.6570756584405899
  Validation Loss: 0.6466253399848938
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 35/64:
  Train Loss: 0.6569422632455826
  Validation Loss: 0.6467868089675903
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.78125
Epoch 36/64:
  Train Loss: 0.6568119823932648
  Validation Loss: 0.6469882130622864
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.78125
Epoch 37/64:
  Train Loss: 0.6567239463329315
  Validation Loss: 0.6471999883651733
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.78125
Epoch 38/64:
  Train Loss: 0.6565915644168854
  Validation Loss: 0.6473534107208252
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.78125
Epoch 39/64:
  Train Loss: 0.6564927697181702
  Validation Loss: 0.6475303769111633
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.78125
Epoch 40/64:
  Train Loss: 0.6564031094312668
  Validation Loss: 0.6477208733558655
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 41/64:
  Train Loss: 0.656265377998352
  Validation Loss: 0.647851824760437
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 42/64:
  Train Loss: 0.6561883240938187
  Validation Loss: 0.6480381488800049
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 43/64:
  Train Loss: 0.6560750305652618
  Validation Loss: 0.6481849551200867
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 44/64:
  Train Loss: 0.6560056507587433
  Validation Loss: 0.6483465433120728
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 45/64:
  Train Loss: 0.6559154391288757
  Validation Loss: 0.6485142707824707
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.6558386087417603
  Validation Loss: 0.6486960649490356
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.6557509750127792
  Validation Loss: 0.6488537192344666
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.655633345246315
  Validation Loss: 0.6490081548690796
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.655537948012352
  Validation Loss: 0.6491307616233826
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6554672420024872
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:57:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:34:INFO:
[92mINFO [0m:      Received: evaluate message 7e7fcd3b-bd95-48fa-8be1-beb770891292
02/07/2025 22:57:34:INFO:Received: evaluate message 7e7fcd3b-bd95-48fa-8be1-beb770891292
[92mINFO [0m:      Sent reply
02/07/2025 22:57:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:34:INFO:
[92mINFO [0m:      Received: train message 8d96b01b-2d10-4600-a35d-7b78c0f06636
02/07/2025 22:57:34:INFO:Received: train message 8d96b01b-2d10-4600-a35d-7b78c0f06636
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6492894887924194
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6553976535797119
  Validation Loss: 0.6494195461273193
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6553196161985397
  Validation Loss: 0.649581253528595
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6552437990903854
  Validation Loss: 0.6496848464012146
  Val ROC-AUC: 0.8784313725490196
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.6551452428102493
  Validation Loss: 0.6498521566390991
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6550666391849518
  Validation Loss: 0.6499910354614258
  Val ROC-AUC: 0.8745098039215686
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.655028685927391
  Validation Loss: 0.6501235961914062
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6549710333347321
  Validation Loss: 0.6502652764320374
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6549468338489532
  Validation Loss: 0.6504164934158325
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.65486079454422
  Validation Loss: 0.6505484580993652
  Val ROC-AUC: 0.8627450980392157
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6548009067773819
  Validation Loss: 0.6506762504577637
  Val ROC-AUC: 0.8627450980392157
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6547638326883316
  Validation Loss: 0.6508359313011169
  Val ROC-AUC: 0.8627450980392157
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6546810865402222
  Validation Loss: 0.6509244441986084
  Val ROC-AUC: 0.8588235294117648
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6546232551336288
  Validation Loss: 0.6510329246520996
  Val ROC-AUC: 0.8588235294117648
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.654575526714325
  Validation Loss: 0.6511711478233337
  Val ROC-AUC: 0.8588235294117648
  Val Accuracy: 0.78125
{'train_loss': 0.654575526714325, 'val_roc_auc': 0.8588235294117648, 'val_accuracy': 0.78125, 'val_loss': 0.6511711478233337}
 ROC_AUC: 0.8588|| Accuracy 0.7812 || Train Loss: 0.6546
 Val Loss: 0.6512 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.647739514708519
Test ROC-AUC: 0.8679315476190477
Test Accuracy: 0.7788461538461539
test_loss: 0.647739514708519
test_roc_auc: 0.8679315476190477
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.052211461954357205
Epoch 1/64:
  Train Loss: 0.6702163815498352
  Validation Loss: 0.608945906162262
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.669940635561943
  Validation Loss: 0.6087620258331299
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6697111129760742
  Validation Loss: 0.6086385250091553
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.6695339232683182
  Validation Loss: 0.6085655689239502
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6693636924028397
  Validation Loss: 0.6084414720535278
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.6691745668649673
  Validation Loss: 0.6083482503890991
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6690423488616943
  Validation Loss: 0.6082652807235718
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6689019948244095
  Validation Loss: 0.6082279682159424
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6687624007463455
  Validation Loss: 0.6081624031066895
  Val ROC-AUC: 0.8730158730158731
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6686417609453201
  Validation Loss: 0.6080924272537231
  Val ROC-AUC: 0.8730158730158731
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.668555349111557
  Validation Loss: 0.6080925464630127
  Val ROC-AUC: 0.8730158730158731
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6684186607599258
  Validation Loss: 0.608039379119873
  Val ROC-AUC: 0.8730158730158731
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6683017611503601
  Validation Loss: 0.607995867729187
  Val ROC-AUC: 0.8730158730158731
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6681860536336899
  Validation Loss: 0.6079800724983215
  Val ROC-AUC: 0.8730158730158731
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6680829972028732
  Validation Loss: 0.6079230308532715
  Val ROC-AUC: 0.8730158730158731
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6679886877536774
  Validation Loss: 0.6079057455062866
  Val ROC-AUC: 0.8730158730158731
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.667906790971756
  Validation Loss: 0.6078810095787048
  Val ROC-AUC: 0.8730158730158731
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6677926480770111
  Validation Loss: 0.6078894734382629
  Val ROC-AUC: 0.8769841269841271
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6677021235227585
  Validation Loss: 0.6078751087188721
  Val ROC-AUC: 0.8769841269841271
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6676382571458817
  Validation Loss: 0.6078528165817261
  Val ROC-AUC: 0.8769841269841271
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6675341427326202
  Validation Loss: 0.6078640222549438
  Val ROC-AUC: 0.8769841269841271
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.667465403676033
  Validation Loss: 0.6078916192054749
  Val ROC-AUC: 0.8769841269841271
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.667371928691864
  Validation Loss: 0.607865571975708
  Val ROC-AUC: 0.8769841269841271
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6672845631837845
  Validation Loss: 0.6078364253044128
  Val ROC-AUC: 0.8769841269841271
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6671979576349258
  Validation Loss: 0.607813835144043
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 26/64:
  Train Loss: 0.6671135574579239
  Validation Loss: 0.6077945232391357
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 27/64:
  Train Loss: 0.6670431196689606
  Validation Loss: 0.6077703833580017
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 28/64:
  Train Loss: 0.6669754385948181
  Validation Loss: 0.6077356338500977
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 29/64:
  Train Loss: 0.6669073849916458
  Validation Loss: 0.6077142953872681
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.8125
Epoch 30/64:
  Train Loss: 0.6668359786272049
  Validation Loss: 0.6076843738555908
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 31/64:
  Train Loss: 0.6667755395174026
  Validation Loss: 0.6076561212539673
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 32/64:
  Train Loss: 0.6667289733886719
  Validation Loss: 0.6076653003692627
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 33/64:
  Train Loss: 0.6666682809591293
  Validation Loss: 0.6076558828353882
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6666182279586792
  Validation Loss: 0.6076139211654663
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6665453910827637
  Validation Loss: 0.6076520085334778
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6664988398551941
  Validation Loss: 0.6076564788818359
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6664464920759201
  Validation Loss: 0.6076617240905762
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6663989722728729
  Validation Loss: 0.6076526641845703
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.666382372379303
  Validation Loss: 0.6076688170433044
  Val ROC-AUC: 0.8690476190476191
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:57:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:55:INFO:
[92mINFO [0m:      Received: evaluate message 612c819c-75e9-4653-9c12-e412717f3209
02/07/2025 22:57:55:INFO:Received: evaluate message 612c819c-75e9-4653-9c12-e412717f3209
[92mINFO [0m:      Sent reply
02/07/2025 22:57:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:57:56:INFO:
[92mINFO [0m:      Received: train message 3321ae10-c4dd-4f67-992f-3a950f41f39e
02/07/2025 22:57:56:INFO:Received: train message 3321ae10-c4dd-4f67-992f-3a950f41f39e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.6663541942834854
  Validation Loss: 0.6076744794845581
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6662939488887787
  Validation Loss: 0.6076785326004028
  Val ROC-AUC: 0.8650793650793651
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6662493795156479
  Validation Loss: 0.6076956987380981
  Val ROC-AUC: 0.8650793650793651
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6662120372056961
  Validation Loss: 0.6077038049697876
  Val ROC-AUC: 0.8650793650793651
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.6661625057458878
  Validation Loss: 0.6077162623405457
  Val ROC-AUC: 0.8650793650793651
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6661169975996017
  Validation Loss: 0.6077286005020142
  Val ROC-AUC: 0.8650793650793651
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6660735756158829
  Validation Loss: 0.6077182292938232
  Val ROC-AUC: 0.8650793650793651
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6660348176956177
  Validation Loss: 0.607744574546814
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6660005897283554
  Validation Loss: 0.6077613234519958
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6659686267375946
  Validation Loss: 0.6077889204025269
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.6659353226423264
  Validation Loss: 0.607772946357727
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.665898323059082
  Validation Loss: 0.6077989935874939
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6658809781074524
  Validation Loss: 0.6077907085418701
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.665855810046196
  Validation Loss: 0.6078029274940491
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6658107340335846
  Validation Loss: 0.6077724695205688
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6657662242650986
  Validation Loss: 0.6077828407287598
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6657498627901077
  Validation Loss: 0.6077347993850708
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6656967401504517
  Validation Loss: 0.6077510118484497
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6656916588544846
  Validation Loss: 0.6077852249145508
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6656953692436218
  Validation Loss: 0.6078342199325562
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6656685322523117
  Validation Loss: 0.6078627109527588
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.665640726685524
  Validation Loss: 0.6078492403030396
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6656114310026169
  Validation Loss: 0.6078552603721619
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6655779927968979
  Validation Loss: 0.6078549027442932
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.665580227971077
  Validation Loss: 0.6079212427139282
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.78125
{'train_loss': 0.665580227971077, 'val_roc_auc': 0.865079365079365, 'val_accuracy': 0.78125, 'val_loss': 0.6079212427139282}
 ROC_AUC: 0.8651|| Accuracy 0.7812 || Train Loss: 0.6656
 Val Loss: 0.6079 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6476702039631513
Test ROC-AUC: 0.8675595238095237
Test Accuracy: 0.7788461538461539
test_loss: 0.6476702039631513
test_roc_auc: 0.8675595238095237
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.03621112311157048
Epoch 1/64:
  Train Loss: 0.6503737717866898
  Validation Loss: 0.6857725381851196
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 2/64:
  Train Loss: 0.6501419246196747
  Validation Loss: 0.6856998205184937
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 3/64:
  Train Loss: 0.6498980075120926
  Validation Loss: 0.6856017112731934
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 4/64:
  Train Loss: 0.6497233211994171
  Validation Loss: 0.6855300068855286
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 5/64:
  Train Loss: 0.6495770215988159
  Validation Loss: 0.6855062246322632
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 6/64:
  Train Loss: 0.6494283527135849
  Validation Loss: 0.6854552030563354
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 7/64:
  Train Loss: 0.6492956876754761
  Validation Loss: 0.6854037046432495
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 8/64:
  Train Loss: 0.6491617262363434
  Validation Loss: 0.6853802800178528
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 9/64:
  Train Loss: 0.6490413248538971
  Validation Loss: 0.6853435039520264
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 10/64:
  Train Loss: 0.6489416658878326
  Validation Loss: 0.6853255033493042
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 11/64:
  Train Loss: 0.6488032937049866
  Validation Loss: 0.6853216886520386
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 12/64:
  Train Loss: 0.6486867666244507
  Validation Loss: 0.6853111982345581
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 13/64:
  Train Loss: 0.6486035287380219
  Validation Loss: 0.6853131055831909
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 14/64:
  Train Loss: 0.6485191136598587
  Validation Loss: 0.685346782207489
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 15/64:
  Train Loss: 0.6484401971101761
  Validation Loss: 0.6853612065315247
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6483417600393295
  Validation Loss: 0.6853532791137695
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6482509225606918
  Validation Loss: 0.6853475570678711
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6481686234474182
  Validation Loss: 0.6853303909301758
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6480991840362549
  Validation Loss: 0.6853076815605164
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.648030236363411
  Validation Loss: 0.6853350400924683
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6479440629482269
  Validation Loss: 0.6853224039077759
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6478703618049622
  Validation Loss: 0.6853261590003967
  Val ROC-AUC: 0.8791666666666667
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6477867960929871
  Validation Loss: 0.6852959394454956
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6477207392454147
  Validation Loss: 0.6853057146072388
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6476621031761169
  Validation Loss: 0.6853252649307251
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.647595077753067
  Validation Loss: 0.6853697299957275
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.647537887096405
  Validation Loss: 0.6853585243225098
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6474768221378326
  Validation Loss: 0.685331404209137
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6474275290966034
  Validation Loss: 0.6853182315826416
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 30/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:58:17:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:58:17:INFO:
[92mINFO [0m:      Received: evaluate message 60503b13-0456-4b54-8dfe-1b3b2a007fe5
02/07/2025 22:58:17:INFO:Received: evaluate message 60503b13-0456-4b54-8dfe-1b3b2a007fe5
[92mINFO [0m:      Sent reply
02/07/2025 22:58:18:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:58:18:INFO:
[92mINFO [0m:      Received: train message abae9167-2712-477c-8754-7193d00d4116
02/07/2025 22:58:18:INFO:Received: train message abae9167-2712-477c-8754-7193d00d4116
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6473627090454102
  Validation Loss: 0.6853196620941162
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6473198235034943
  Validation Loss: 0.6853090524673462
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6472924649715424
  Validation Loss: 0.6853532791137695
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6472451537847519
  Validation Loss: 0.6853368282318115
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6472099274396896
  Validation Loss: 0.6853498816490173
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6471765488386154
  Validation Loss: 0.6853689551353455
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6471295803785324
  Validation Loss: 0.68538498878479
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6470880806446075
  Validation Loss: 0.685418963432312
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6470465213060379
  Validation Loss: 0.685404896736145
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6470033079385757
  Validation Loss: 0.6854091882705688
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6469679772853851
  Validation Loss: 0.6854230165481567
  Val ROC-AUC: 0.8625
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6469301730394363
  Validation Loss: 0.6854218244552612
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6468966752290726
  Validation Loss: 0.6854254603385925
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6468385308980942
  Validation Loss: 0.685437798500061
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6468188613653183
  Validation Loss: 0.6854579448699951
  Val ROC-AUC: 0.8583333333333334
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6467999517917633
  Validation Loss: 0.685472846031189
  Val ROC-AUC: 0.8541666666666667
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6467683464288712
  Validation Loss: 0.6854977607727051
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6467442661523819
  Validation Loss: 0.6855134963989258
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6467195451259613
  Validation Loss: 0.6855503916740417
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6466805189847946
  Validation Loss: 0.6855870485305786
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6466542482376099
  Validation Loss: 0.6855802536010742
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6466566324234009
  Validation Loss: 0.6856201887130737
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6466394513845444
  Validation Loss: 0.6856085658073425
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6466228812932968
  Validation Loss: 0.68562912940979
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6466262489557266
  Validation Loss: 0.6856568455696106
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.6465997844934464
  Validation Loss: 0.685627281665802
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.6465668380260468
  Validation Loss: 0.6856314539909363
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6465499848127365
  Validation Loss: 0.6856563091278076
  Val ROC-AUC: 0.8500000000000001
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.6465358436107635
  Validation Loss: 0.6856595873832703
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.6465272158384323
  Validation Loss: 0.6856954097747803
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.64652881026268
  Validation Loss: 0.6857366561889648
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6465189605951309
  Validation Loss: 0.6857165098190308
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6464882493019104
  Validation Loss: 0.6857014894485474
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6464616060256958
  Validation Loss: 0.685711145401001
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6464629769325256
  Validation Loss: 0.68568354845047
  Val ROC-AUC: 0.8458333333333334
  Val Accuracy: 0.71875
{'train_loss': 0.6464629769325256, 'val_roc_auc': 0.8458333333333334, 'val_accuracy': 0.71875, 'val_loss': 0.68568354845047}
 ROC_AUC: 0.8458|| Accuracy 0.7188 || Train Loss: 0.6465
 Val Loss: 0.6857 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6477059317895999
Test ROC-AUC: 0.8671874999999999
Test Accuracy: 0.7788461538461539
test_loss: 0.6477059317895999
test_roc_auc: 0.8671874999999999
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.015104506176915793
Epoch 1/64:
  Train Loss: 0.6394976377487183
  Validation Loss: 0.7273625135421753
  Val ROC-AUC: 0.774891774891775
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.6393140703439713
  Validation Loss: 0.7273262739181519
  Val ROC-AUC: 0.7792207792207793
  Val Accuracy: 0.71875
Epoch 3/64:
  Train Loss: 0.6391335874795914
  Validation Loss: 0.7272864580154419
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 4/64:
  Train Loss: 0.6389850080013275
  Validation Loss: 0.7272950410842896
  Val ROC-AUC: 0.7662337662337663
  Val Accuracy: 0.71875
Epoch 5/64:
  Train Loss: 0.6388243436813354
  Validation Loss: 0.7272857427597046
  Val ROC-AUC: 0.7662337662337663
  Val Accuracy: 0.71875
Epoch 6/64:
  Train Loss: 0.6386555135250092
  Validation Loss: 0.7272196412086487
  Val ROC-AUC: 0.7662337662337663
  Val Accuracy: 0.71875
Epoch 7/64:
  Train Loss: 0.6384536772966385
  Validation Loss: 0.727190375328064
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.6383148282766342
  Validation Loss: 0.7271983623504639
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.6381455957889557
  Validation Loss: 0.7272017598152161
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.6379995048046112
  Validation Loss: 0.7271784543991089
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6378174424171448
  Validation Loss: 0.7271614074707031
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.6376854926347733
  Validation Loss: 0.7271451950073242
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6375308781862259
  Validation Loss: 0.7271395921707153
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6373954564332962
  Validation Loss: 0.7271147966384888
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6372892111539841
  Validation Loss: 0.7271010875701904
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6371476352214813
  Validation Loss: 0.7270834445953369
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6370210498571396
  Validation Loss: 0.7270515561103821
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6369139105081558
  Validation Loss: 0.7270787954330444
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6368033438920975
  Validation Loss: 0.7270926833152771
  Val ROC-AUC: 0.7662337662337662
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:58:39:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:58:39:INFO:
[92mINFO [0m:      Received: evaluate message 268b0217-cdd0-425e-a9bc-428058d6f746
02/07/2025 22:58:39:INFO:Received: evaluate message 268b0217-cdd0-425e-a9bc-428058d6f746
[92mINFO [0m:      Sent reply
02/07/2025 22:58:40:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:58:40:INFO:
[92mINFO [0m:      Received: train message 6f0d17f5-acd5-45b1-a35b-f5b75c02b6e6
02/07/2025 22:58:40:INFO:Received: train message 6f0d17f5-acd5-45b1-a35b-f5b75c02b6e6
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.636695459485054
  Validation Loss: 0.7270883321762085
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6365757137537003
  Validation Loss: 0.7270826101303101
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.636479839682579
  Validation Loss: 0.7270683646202087
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.636361762881279
  Validation Loss: 0.7270694375038147
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6362632364034653
  Validation Loss: 0.7270715236663818
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6361895352602005
  Validation Loss: 0.7270894050598145
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.636114701628685
  Validation Loss: 0.7271217703819275
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6360240876674652
  Validation Loss: 0.7271286249160767
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6359291225671768
  Validation Loss: 0.7271325588226318
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6358731538057327
  Validation Loss: 0.7271698117256165
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.6357970386743546
  Validation Loss: 0.7271666526794434
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.63571797311306
  Validation Loss: 0.7271952033042908
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6356699466705322
  Validation Loss: 0.7272480130195618
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6355948895215988
  Validation Loss: 0.7272528409957886
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6355230957269669
  Validation Loss: 0.7272982597351074
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6354667395353317
  Validation Loss: 0.7273012399673462
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6353992521762848
  Validation Loss: 0.727295994758606
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6353475004434586
  Validation Loss: 0.7273297309875488
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6352987140417099
  Validation Loss: 0.7273069620132446
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6352437436580658
  Validation Loss: 0.7273287773132324
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6352230906486511
  Validation Loss: 0.7273551225662231
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6351838409900665
  Validation Loss: 0.7273809909820557
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6351340860128403
  Validation Loss: 0.7273977994918823
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6350812613964081
  Validation Loss: 0.727425217628479
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6350285559892654
  Validation Loss: 0.7274600863456726
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6350029855966568
  Validation Loss: 0.727482259273529
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.634978249669075
  Validation Loss: 0.7275124788284302
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.634947195649147
  Validation Loss: 0.7275177240371704
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6349075734615326
  Validation Loss: 0.7275148034095764
  Val ROC-AUC: 0.7575757575757576
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6348634660243988
  Validation Loss: 0.7275310754776001
  Val ROC-AUC: 0.7575757575757576
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6348422020673752
  Validation Loss: 0.7275649309158325
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6348123699426651
  Validation Loss: 0.7275744676589966
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6347856819629669
  Validation Loss: 0.7275892496109009
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6347565203905106
  Validation Loss: 0.7276074290275574
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6347488611936569
  Validation Loss: 0.7276499271392822
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.6347324699163437
  Validation Loss: 0.7276748418807983
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.63470359146595
  Validation Loss: 0.7277073860168457
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6346969753503799
  Validation Loss: 0.7277528643608093
  Val ROC-AUC: 0.748917748917749
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.6346696466207504
  Validation Loss: 0.7277563214302063
  Val ROC-AUC: 0.748917748917749
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.634643942117691
  Validation Loss: 0.7277748584747314
  Val ROC-AUC: 0.748917748917749
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.6346154510974884
  Validation Loss: 0.7277793288230896
  Val ROC-AUC: 0.748917748917749
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6345847994089127
  Validation Loss: 0.7277852296829224
  Val ROC-AUC: 0.7445887445887446
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6345651596784592
  Validation Loss: 0.7277954816818237
  Val ROC-AUC: 0.7445887445887446
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.63453409075737
  Validation Loss: 0.7278119325637817
  Val ROC-AUC: 0.7445887445887446
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6345184147357941
  Validation Loss: 0.7278169393539429
  Val ROC-AUC: 0.7445887445887446
  Val Accuracy: 0.71875
{'train_loss': 0.6345184147357941, 'val_roc_auc': 0.7445887445887446, 'val_accuracy': 0.71875, 'val_loss': 0.7278169393539429}
 ROC_AUC: 0.7446|| Accuracy 0.7188 || Train Loss: 0.6345
 Val Loss: 0.7278 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6477218207258445
Test ROC-AUC: 0.8675595238095237
Test Accuracy: 0.7692307692307693
test_loss: 0.6477218207258445
test_roc_auc: 0.8675595238095237
test_accuracy: 0.7692307692307693
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.359954833984375
Dynamic noise multiplier: 0.0
Epoch 1/64:
  Train Loss: 0.661395400762558
  Validation Loss: 0.6377661228179932
  Val ROC-AUC: 0.8671875
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.6611249893903732
  Validation Loss: 0.637787401676178
  Val ROC-AUC: 0.8671875
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6609136164188385
  Validation Loss: 0.637778103351593
  Val ROC-AUC: 0.8671875
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.6606690138578415
  Validation Loss: 0.6378012299537659
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6604757010936737
  Validation Loss: 0.6377963423728943
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.6602436900138855
  Validation Loss: 0.6378070712089539
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.660053163766861
  Validation Loss: 0.6378413438796997
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.6598298251628876
  Validation Loss: 0.6378973126411438
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6596557945013046
  Validation Loss: 0.6379204988479614
  Val ROC-AUC: 0.859375
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:59:00:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:59:01:INFO:
[92mINFO [0m:      Received: evaluate message ba327a74-69d2-43ac-93e5-a6b708c6ab8a
02/07/2025 22:59:01:INFO:Received: evaluate message ba327a74-69d2-43ac-93e5-a6b708c6ab8a
[92mINFO [0m:      Sent reply
02/07/2025 22:59:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:59:01:INFO:
[92mINFO [0m:      Received: reconnect message c1c55db2-e105-457b-adf0-608bae69d686
02/07/2025 22:59:01:INFO:Received: reconnect message c1c55db2-e105-457b-adf0-608bae69d686
02/07/2025 22:59:01:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/07/2025 22:59:01:INFO:Disconnect and shut down
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6594861298799515
  Validation Loss: 0.6379621028900146
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 11/64:
  Train Loss: 0.6593064069747925
  Validation Loss: 0.6380029916763306
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.6591428816318512
  Validation Loss: 0.6380226016044617
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6589717864990234
  Validation Loss: 0.6380677223205566
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.6588185131549835
  Validation Loss: 0.6381117701530457
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.6586849987506866
  Validation Loss: 0.6381866931915283
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6585308164358139
  Validation Loss: 0.6382531523704529
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.6583930402994156
  Validation Loss: 0.6382843255996704
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.6582645326852798
  Validation Loss: 0.6383577585220337
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6581455767154694
  Validation Loss: 0.6384276747703552
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6580384373664856
  Validation Loss: 0.6384902000427246
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6579088270664215
  Validation Loss: 0.638568103313446
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.6578100174665451
  Validation Loss: 0.6386324167251587
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.6577188074588776
  Validation Loss: 0.6386854648590088
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 24/64:
  Train Loss: 0.6576244235038757
  Validation Loss: 0.6387601494789124
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 25/64:
  Train Loss: 0.6575088948011398
  Validation Loss: 0.6388068795204163
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 26/64:
  Train Loss: 0.6574435383081436
  Validation Loss: 0.6388872265815735
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 27/64:
  Train Loss: 0.657328262925148
  Validation Loss: 0.6389399766921997
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 28/64:
  Train Loss: 0.6572393625974655
  Validation Loss: 0.6390073299407959
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 29/64:
  Train Loss: 0.6571447253227234
  Validation Loss: 0.6390790939331055
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 30/64:
  Train Loss: 0.6570774912834167
  Validation Loss: 0.6391525268554688
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 31/64:
  Train Loss: 0.6570004224777222
  Validation Loss: 0.639241099357605
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 32/64:
  Train Loss: 0.65696781873703
  Validation Loss: 0.6393305659294128
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 33/64:
  Train Loss: 0.6568847894668579
  Validation Loss: 0.6394070982933044
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6568070650100708
  Validation Loss: 0.6394776105880737
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6567489355802536
  Validation Loss: 0.6395536661148071
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6567045152187347
  Validation Loss: 0.6396117806434631
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6566518545150757
  Validation Loss: 0.6396920680999756
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6565699577331543
  Validation Loss: 0.6397638320922852
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6565246134996414
  Validation Loss: 0.6398276090621948
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.6564745903015137
  Validation Loss: 0.6398822665214539
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6564351469278336
  Validation Loss: 0.6399720311164856
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6563850492238998
  Validation Loss: 0.640032172203064
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6563280671834946
  Validation Loss: 0.6400840282440186
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.656300812959671
  Validation Loss: 0.6401569843292236
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6562459915876389
  Validation Loss: 0.6402166485786438
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6562202423810959
  Validation Loss: 0.6403067111968994
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6561852991580963
  Validation Loss: 0.6403582692146301
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6561441421508789
  Validation Loss: 0.6404440402984619
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6561210751533508
  Validation Loss: 0.6404993534088135
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.6560951918363571
  Validation Loss: 0.6405808329582214
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.6560801416635513
  Validation Loss: 0.6406619548797607
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6560590416193008
  Validation Loss: 0.6407163143157959
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.65601646900177
  Validation Loss: 0.6407774090766907
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6559733748435974
  Validation Loss: 0.6408159732818604
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6559527665376663
  Validation Loss: 0.6408719420433044
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6559331566095352
  Validation Loss: 0.6409490704536438
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.655898705124855
  Validation Loss: 0.6409990787506104
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.6558852195739746
  Validation Loss: 0.6410824060440063
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6558665335178375
  Validation Loss: 0.6411502361297607
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6558514386415482
  Validation Loss: 0.6412090063095093
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.8125
Epoch 61/64:
  Train Loss: 0.6558388024568558
  Validation Loss: 0.6412670612335205
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6558240652084351
  Validation Loss: 0.6413177251815796
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.8125
Epoch 63/64:
  Train Loss: 0.6558099687099457
  Validation Loss: 0.6413748264312744
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6557935178279877
  Validation Loss: 0.6414306163787842
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.8125
{'train_loss': 0.6557935178279877, 'val_roc_auc': 0.84765625, 'val_accuracy': 0.8125, 'val_loss': 0.6414306163787842}
 ROC_AUC: 0.8477|| Accuracy 0.8125 || Train Loss: 0.6558
 Val Loss: 0.6414 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6477278803403561
Test ROC-AUC: 0.8660714285714285
Test Accuracy: 0.7596153846153846
test_loss: 0.6477278803403561
test_roc_auc: 0.8660714285714285
test_accuracy: 0.7596153846153846
eval_cid: 0
CPU Time: 1030.236565 seconds
Elapsed Time: 846.1123721599579 seconds
RAM Usage: 0.4053840637207031 megabytes
Logs saved in current directory
